authFullName_s,authIdHal_i,authIdHal_s,title_s,halId_s,producedDateY_i,doiId_s,keyword_s,abstract_s,uri_s,domain_s
"['Iolanda Decorato', 'Zaher Kharboutly', 'Tommaso Vassallo', 'Justin Penrose', 'Cécile Legallais', 'Anne-Virginie Salsac']","[170850, 172643]","['cecile-legallais', 'anne-virginie-salsac']",Numerical simulation of the fluid structure interactions in a compliant patient-specific arteriovenous fistula,hal-02019727,2014,10.1002/cnm.2595,"['Arteriovenous fistula', 'Fluid-structure interactions', 'Hemodynamics vessel wall internal stresses']","['The objective of the study is to investigate numerically the fluid‐structure interactions (FSI) in a patient‐specific arteriovenous fistula (AVF) and analyze the degree of complexity that such a numerical simulation requires to provide clinically relevant information. The reference FSI simulation takes into account the non‐Newtonian behavior of blood, as well as the variation in mechanical properties of the vascular walls along the AVF. We have explored whether less comprehensive versions of the simulation could still provide relevant results. The non‐Newtonian blood model is necessary to predict the hemodynamics in the AVF because of the predominance of low shear rates in the vein. An uncoupled fluid simulation provides informative qualitative maps of the hemodynamic conditions in the AVF; quantitatively, the hemodynamic parameters are accurate within 20% maximum. Conversely, an uncoupled structural simulation with non‐uniform wall properties along the vasculature provides the accurate distribution of internal wall stresses, but only at one instant of time within the cardiac cycle. The FSI simulation advantageously provides the time‐evolution of both the hemodynamic and structural stresses. However, the higher computational cost renders a clinical use still difficult in routine. Copyright © 2013 John Wiley & Sons, Ltd.']",https://hal.utc.fr/hal-02019727,"['0.phys', '1.phys.meca', '2.phys.meca.biom']"
"['Y.J. Li', 'D. Barthès-Biesel', 'Anne-Virginie Salsac']",[172643],['anne-virginie-salsac'],Polymerization kinetics of n-butyl cyanoacrylate glues used for vascular embolization,hal-02019556,2017,10.1016/j.jmbbm.2017.01.003,"['Vascular embolization', 'Interfacial polymerization', 'Volumetric polymerization', 'Glubran 2', 'Histoacryl']","['Vascular embolization is a minimally invasive treatment used for the management of vascular malformations and tumors. It is carried out under X-ray by navigating a microcatheter into the targeted blood vessel, through which embolic agents are delivered to occlude the vessels. Cyanoacrylate liquid glues have been widely used for vascular embolization owing to their low viscosity, rapid polymerization/solidification rate, good penetration ability and low tissue toxicity. The objective of this study is to quantitatively investigate the physical properties of two n-butyl cyanoacrylate (nBCA) glues (Glubran 2 and Histoacryl) mixed with an iodized oil (Lipiodol) at various concentrations. We show that an homogeneous solution results from the mixing of the glue and Lipiodol, and that the viscosity, density and interfacial tension of the mixture increase with the proportion in Lipiodol. We have designed a new experimental setup to systemically characterize the polymerization kinetics of a glue mixture upon contact with an ionic solution. We observe that the whole polymerization process includes two phases: an interfacial polymerization that takes place at the interface as soon as the two liquids are in contact with a characteristic time scale of the order of the minute; a volumetric polymerization during which a reaction front propagates within the mixture bulk with a characteristic time scale of the order of tens of minutes. The polymerization rate, front propagation speed and volume reduction increase with the glue concentrations. It is the first time that such comprehensive results are obtained on liquid embolic agents.']",https://hal.utc.fr/hal-02019556,"['0.phys', '1.phys.meca', '2.phys.meca.biom']"
"['Jonathan Gubspun', 'Pierre-Yves Gires', 'Clement de Loubens', 'Dominique Barthès-Biesel', 'Julien Deschamps', 'Marc Georgelin', 'Marc Leonetti', 'Eric Leclerc', 'Florence Edwards-Lévy', 'Anne-Virginie Salsac']","[172663, 1215270, 741748, 983509, 172643]","['clement-de-loubens', 'julien-deschamps', 'marc-leonetti', 'anne-virginie-salsac']",Characterization of the mechanical properties of cross-linked serum albumin microcapsules: effect of size and protein concentration,hal-01331128,2016,10.1007/s00396-016-3885-8,"['Microcapsule', 'Interfacial cross-linking', 'Shear elastic modulus', 'Microfluidics', 'Albumin']","['A microfluidic technique is used to characterize the mechanical behavior of capsules that are produced in a two-step process: first, an emulsification step to form droplets, followed by a cross-linking step to encapsulate the droplets within a thin membrane composed of cross-linked proteins. The objective is to study the influence of the capsule size and protein concentration on the membrane mechanical properties. The microcapsules are fabricated by cross-linking of human serum albumin (HSA) with concentrations from 15 to 35 % (w/v). A wide range of capsule radii (∼40–450 μm) is obtained by varying the stirring speed in the emulsification step. For each stirring speed, a low threshold value in protein concentration is found, below which no coherent capsules could be produced. The smaller the stirring speed, the lower the concentration can be. Increasing the concentration from the threshold value and considering capsules of a given size, we show that the surface shear modulus of the membrane increases with the concentration following a sigmoidal curve. The increase in mechanical resistance reveals a higher degree of cross-linking in the membrane. Varying the stirring speed, we find that the surface shear modulus strongly increases with the capsule radius: its increase is two orders of magnitude larger than the increase in size for the capsules under consideration. It demonstrates that the cross-linking reaction is a function of the emulsion size distribution and that capsules produced in batch through emulsification processes inherently have a distribution in mechanical resistance.']",https://hal.science/hal-01331128,"['0.spi', '1.spi.meca', '2.spi.meca.biom', '0.phys', '1.phys.cond', '2.phys.cond.cm-scm', '0.phys', '1.phys.meca', '2.phys.meca.mefl']"
"['Pierre-Yves Gires', 'Dominique Barthès-Biesel', 'Eric Leclerc', 'Anne-Virginie Salsac']","[945746, 172643]","['cnrslec', 'anne-virginie-salsac']",Transient behavior and relaxation of microcapsules with a cross-linked human serum albumin membrane,hal-02019566,2016,10.1016/j.jmbbm.2015.09.008,"['Microcapsules', 'Relaxation', 'Microfluidic experiment', 'Mechanical characterization', 'Fluid structure interactions']","['Capsules consist of droplets enclosed by a membrane with shear resistant properties especially when fabricated by interfacial cross-linking. In many applications, the protection and release of the internal medium need to be strictly controlled. It is possible to tune the membrane mechanical properties by changing the physico-chemical conditions of the fabrication process, but a good control of the production requires their characterization, which is a scientific challenge, since the objects are a few tens of microns in size at most. One advantageous approach is to resort to microfluidic techniques. We study the transient response of capsules having a cross-linked human serum albumin (HSA) membrane, as they flow through a sudden expansion. We determine the characteristic time scales of the capsule relaxation and compare them to the ones predicted by a full numerical model of the relaxation of a capsule flowing in a rectangular channel, for which the membrane is assumed to be purely elastic. We show that the membrane is viscoelastic and that the relaxation is solely a function of the ratio of the relaxation time to the convective time.']",https://hal.utc.fr/hal-02019566,"['0.phys', '1.phys.meca', '2.phys.meca.biom']"
"['Jean Matthieu Prot', 'Caroline Aninat', 'Laurent Griscom', 'Florence Razan', 'Céline Brochot', 'Christiane Guguen Guillouzo', 'Cécile Legallais', 'Anne Corlu', 'Eric Leclerc']","[4784, 753153, 170850]","['florence-razan', 'celine-brochot', 'cecile-legallais']",Improvement of HepG2/C3a cell functions in a microfluidic biochip.,hal-00740224,2011,10.1002/bit.23104,"['Transcriptomic', 'PDMS', 'Microfluidic biochip', 'Hepatocytes', 'Liver', 'Transcriptomic']","[""Current developments in tissue engineering and microtechnology fields allow the use of microfluidic biochip as microtools for in vitro investigations. In the present study, we describe the behavior of HepG2/C3a cells cultivated in a poly(dimethylsiloxane) (PDMS) microfluidic biochip coupled to a perfusion system. Cell culture in the microfluidic biochip for 96 h including 72 h of perfusion provoked a 24 h delay in cell growth compared to plate cultures. Inside the microfluidic biochip, few apoptosis, and necrosis were detected along the culture and 3D cell organization was observed. Regarding the hepatic metabolism, glucose and glutamine consumptions as well as albumin synthesis were maintained. A transcriptomic analysis performed at 96 h of culture using Affymetrix GeneChip demonstrated that 1,025 genes with a fold change above 1.8 were statistically differentially expressed in the microfluidic biochip cultures compared to plate cultures. Among those genes, phase I enzymes involved in the xenobiotic's metabolism such as the cytochromes P450 (CYP) 1A1/2, 2B6, 3A4, 3A5, and 3A7 were up-regulated. The CYP1A1/2 up-regulation was associated with the appearance of CYP1A1/2's activity evidenced by using EROD biotransformation assay. Several phase II enzymes such as sulfotransferases (SULT1A1 and SULT1A2), UDP-glucuronyltransferase (UGT1A1, UGT2B7) and phase III transporters (such as MDR1, MRP2) were also up-regulated. In conclusion, microfluidic biochip could and provide an important insight to exploring the xenobiotic's metabolism. Altogether, these results suggest that this kind of biochip could be considered as a new pertinent tool for predicting cell toxicity and clearance of xenobiotics in vitro.""]",https://hal.science/hal-00740224,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg']"
"['Leila Choucha-Snouber', 'Caroline Aninat', 'Laurent Grsicom', 'Geoffrey Madalinski', 'Céline Brochot', 'Paul Emile Poleni', 'Florence Razan', 'Christiane Guguen Guillouzo', 'Cécile Legallais', 'Anne Corlu', 'Eric Leclerc']","[753153, 4784, 170850, 945746]","['celine-brochot', 'florence-razan', 'cecile-legallais', 'cnrslec']",Investigation of ifosfamide nephrotoxicity induced in a liver-kidney co-culture biochip.,inserm-00864839,2013,10.1002/bit.24707,"['Liver', 'Kidney', 'Co-culture', 'Ifosfamide', 'Micro fluidic biochips', 'PDMS']","['In this article, we present a liver-kidney co-culture model in a micro fluidic biochip. The liver was modeled using HepG2/C3a and HepaRG cell lines and the kidney using MDCK cell lines. To demonstrate the synergic interaction between both organs, we investigated the effect of ifosfamide, an anticancerous drug. Ifosfamide is a prodrug which is metabolized by the liver to isophosforamide mustard, an active metabolite. This metabolism process also leads to the formation of chloroacetaldehyde, a nephrotoxic metabolite and acrolein a urotoxic one. In the biochips of MDCK cultures, we did not detect any nephrotoxic effects after 72\u2009h of 50\u2009µM ifosfamide exposure. However, in the liver-kidney biochips, the same 72\u2009h exposure leads to a nephrotoxicity illustrated by a reduction of the number of MDCK cells (up to 30% in the HepaRG-MDCK) when compared to untreated co-cultures or treated MDCK monocultures. The reduction of the MDCK cell number was not related to a modification of the cell cycle repartition in ifosfamide treated cases when compared to controls. The ifosfamide biotransformation into 3-dechloroethylifosfamide, an equimolar byproduct of the chloroacetaldehyde production, was detected by mass spectrometry at a rate of apparition of 0.3\u2009±\u20090.1 and 1.1\u2009±\u20090.3\u2009pg/h/biochips in HepaRG monocultures and HepaRG-MDCK co-cultures respectively. Any metabolite was detected in HepG2/C3a cultures. Furthermore, the ifosfamide treatment in HepaRG-MDCK co-culture system triggered an increase in the intracellular calcium release in MDCK cells on contrary to the treatment on MDCK monocultures. As 3-dechloroethylifosfamide is not toxic, we have tested the effect of equimolar choloroacetaldehyde concentration onto the MDCK cells. At this concentration, we found a quite similar calcium perturbation and MDCK nephrotoxicity via a reduction of 30% of final cell numbers such as in the ifosfamide HepaRG-MDCK co-culture experiments. Our results suggest that ifosfamide nephrotoxicity in a liver-kidney micro fluidic co-culture model using HepaRG-MDCK cells is induced by the metabolism of ifosfamide into chloroacetaldehyde whereas this pathway is not functional in HepG2/C3a-MDCK model. This study demonstrates the interest in the development of systemic organ-organ interactions using micro fluidic biochips. It also illustrated their potential in future predictive toxicity model using in vitro models as alternative methods.']",https://inserm.hal.science/inserm-00864839,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg']"
"['Laetitia Shintu', 'Régis Baudoin', 'Vincent Navratil', 'Jean-Matthieu Prot', 'Clément Pontoizeau', 'Marianne Defernez', 'Benjamin J. Blaise', 'Céline Domange', 'Alexandre R.R. Pery', 'Pierre Toulhoat', 'Cécile Legallais', 'Céline Brochot', 'Eric Leclerc', 'Marc-Emmanuel Dumas']","[766228, 766229, 14338, 181284, 170850, 753153, 750569]","['celine-domange', 'alexandre-pery', 'cecile-legallais', 'celine-brochot', 'marc-emmanuel-dumas']",Metabolomics-on-a-Chip and Predictive Systems Toxicology in Microfluidic Bioartificial Organs,hal-00699575,2012,10.1021/ac2011075,"['NMR-SPECTROSCOPY', 'NUCLEAR-MAGNETIC-RESONANCE', 'HEPATIC-ENCEPHALOPATHY', 'LIVER', 'DATA SETS', 'PATTERN-RECOGNITION', 'CORRELATION SPECTROSCOPY', 'CAENORHABDITIS-ELEGANS', 'OXIDATIVE STRESS', 'DRUG TOXICITY']","['The world faces complex challenges for chemical hazard assessment. Microfluidic bioartificial organs enable the spatial and temporal control of cell growth and biochemistry, critical for organ-specific metabolic functions and particularly relevant to testing the metabolic dose-response signatures associated with both pharmaceutical and environmental toxicity. Here we present an approach combining a microfluidic system with H-1 NMR-based metabolomic footprinting as a high-throughput small-molecule screening approach. We characterized the toxicity of several molecules: ammonia (NH3), an environmental pollutant leading to metabolic acidosis and liver and kidney toxicity; dimethylsulfoxide (DMSO), a free radical-scavenging solvent; and N-acetyl-para-aminophenol (APAP, or paracetamol), a hepatotoxic analgesic drug. We report organ-specific NH3 dose-dependent metabolic responses in several microfluidic bioartificial organs (liver, kidney, and cocultures), as well as predictive (99% accuracy for NH3 and 94% for APAP) compound-specific signatures. Our integration of microtechnology, cell culture in microfluidic biochips, and metabolic profiling opens the development of so-called ""metabolomics-on-a-chip"" assays in pharmaceutical and environmental toxicology.']",https://hal.science/hal-00699575,"['0.chim', '1.chim.anal']"
"['Leila Choucha-Snouber', 'Andrei Bunescu', 'Cécile Legallais', 'Céline Brochot', 'Marc-Emmanuel Dumas', 'Bénédicte Elena-Herrmann', 'Eric Leclerc']","[170850, 753153, 750569, 178268]","['cecile-legallais', 'celine-brochot', 'marc-emmanuel-dumas', 'benedicte-elena-herrmann']",Metabolomics-on-a-chip of hepatotoxicity induced by anticancer drug flutamide and its active metabolite hydroxyflutamide using HepG2/C3a microfluidic biochips,ineris-00963445,2013,10.1093/toxsci/kfs230,"['LIVER MICROFLUIDIC BIOCHIPS', 'METABOLOMICS', 'FLUTAMIDE', 'HEPATOTOXICITY']","['We used the recently introduced ""metabolomics-on-a-chip"" approach to test secondary drug toxicity in bioartificial organs. Bioartificial organs cultivated in microfluidic culture conditions provide a beneficial environment, in which the cellular cytoprotective mechanisms are enhanced, compared with Petri dish culture conditions. We investigated the metabolic response of HepG2/C3a cells exposed to flutamide, an anticancer prodrug, and hydroxyflutamide (HF), its active metabolite, in a microfluidic biochip. The cellular response was analyzed by (1)H nuclear magnetic resonance spectroscopy to identify cell-specific molecule-response markers. The metabolic response to flutamide results in a disruption of glucose homeostasis and in mitochondrial dysfunctions. This flutamide-specific metabolic response was illustrated by a reduction of the extracellular glucose and fructose consumptions and a general reduction of the tricarboxylic acid cycle activity leading to the reduction of the consumption of several amino acids. We also found a higher production of 3-hydroxybutyrate and lactate, and the reduction of the albumin production compared with controls. The toxic metabolic signature associated with the active metabolite HF was illustrated by a high-energy demand and an increase in several amino acid metabolism. Finally, for both molecules, the hepatotoxicity was correlated to the glutathione (GSH) metabolism illustrated by the levels of the 2-hydroxybutyrate and pyroglutamate productions and the increase of the glutamate and glycine productions. Thus, the entire set of results contributed to extract specific mechanistic toxic signatures and their relation to hepatotoxicity, which appeared consistent with literature reports. As new finding of HepG2/C3a cells hepatotoxicity, we propose a metabolic network with a related list of metabolite variations to describe the GSH depletion when followed by a cell death for the HepG2/C3a cells cultivated in our polydimethylsiloxane microfluidic biochips. Our findings illustrate the potential of metabolomics-on-a-chip as an in vitro alternative method for predictive toxicology.']",https://ineris.hal.science/ineris-00963445,"['0.sdv', '1.sdv.tox', '0.sde']"
"['Jean-Matthieu Prot', 'Luis Maciel', 'Thibault Bricks', 'Franck Merlier', 'Jérôme Cotton', 'Patrick Paullier', 'Frédéric Y. Bois', 'Eric Leclerc']","[775837, 777699]",,First pass intestinal and liver metabolism of paracetamol in a microfluidic platform coupled with a mathematical modeling as a means of evaluating ADME processes in humans,ineris-01855015,2014,10.1002/bit.25232,"['LIVER MICROFLUIDIC BIOCHIP', 'IN VITRO/IN VIVO EXTRAPOLATION', 'CACO-2 PERMEABILITY', 'PARACETAMOL', 'PHARMACOKINETIC MODEL', 'PHASE II METABOLISM', 'ALTERNATIVE METHODS', 'LIVER MICROFLUIDIC BIOCHIP']","['We developed a microfluidic platform to investigate paracetamol intestinal and liver first pass metabolism. This approach was coupled with a mathematical model to estimate intrinsic in vitro parameters and to predict in vivo processes. The kinetic modeling estimated the paracetamol and paracetamol sulfate permeabilities, the sulfate and glucuronide effluxes in the intestine compartment. Based on a gut model, we estimated intrinsic intestinal clearance of between 26 and 77 L/h for paracetamol in humans, a permeability of 10 L/h, and a gut availability between 0.17 and 0.53 (compared to 0.95-1 in vivo). The role played by the liver in paracetamol metabolism was estimated via in vitro intrinsic clearances of 7.6, 13.6, and 11.5 mu L/min/10(6) cells for HepG2/C3a, rat primary hepatocytes, and human primary hepatocytes, respectively. Based on a parallel tube model to describe the liver, the paracetamol hepatic clearance, and the paracetamol hepatic availability in humans were estimated at 6.5 mL/min/kg of bodyweight (BDW) and 0.7, respectively (when compared to 5 mL/min/kg of BDW and 0.77 to 0.88 for in vivo values, respectively). The drug availability was predicted ranging between 0.24 and 0.41 (0.88 in vivo). The overall approach provided a first step in an integrated strategy combining in silico/in vitro methods based on microfluidic for evaluating drug absorption, distribution and metabolism processes.']",https://ineris.hal.science/ineris-01855015,"['0.sdv', '1.sdv.tox']"
"['Jean-Matthieu Prot', 'Orianne Videau', 'Céline Brochot', 'Cécile Legallais', 'Henri Benech', 'Eric Leclerc']","[753153, 170850]","['celine-brochot', 'cecile-legallais']",A cocktail of metabolic probes demonstrates the relevance of primary human hepatocyte cultures in a microfluidic biochip for pharmaceutical drug screening,ineris-00963290,2011,10.1016/j.ijpharm.2011.01.054,"['METABOLISM', 'CIME COCKTAIL', 'HUMAN PRIMARY HEPATOCYTES', 'MICROFLUIDIC', 'BIOCHIP', 'DRUG SCREENING']","[""In this paper, we compare the biotransformation capacities of cryopreserved primary human hepatocytes cultivated in a liver microfluidic biochip and in plates. The hepatocytes were exposed to the CIME cocktail (Carte d'Identité MEtabolique), a mixture of seven probes (acetaminophen, amodiaquine, caffeine, dextromethorphan, midazolam, omeprazole and tolbutamide) for key enzymes involved in the xenobiotic metabolism and pharmacokinetics. The purpose of the cocktail was to give an overview of the metabolic profile of the hepatocytes due to concomitant exposure and a simultaneous mass spectrometric detection method of the metabolites. The results showed a greater activity for CYP1A2, CYP2C9, CYP2C19 CYP2D6, CYP3A and UGT1A1 after 4 h of incubation in the microfluidic biochip when compared to the plate cultures. Furthermore, the metabolic ratio time-course measured at 1 h, 3 h and 4 h indicated that the enzymatic activity increased when the hepatocytes were cultivated in the microfluidic biochip, in contrast with their response in the plate cultures. These results illustrated the functional relevance of liver culture in the PDMS microfluidic biochip. The original method based on a microfluidic culture coupled with CIME cocktail analysis allowed the maintenance and the evaluation of the metabolic performances of the primary human hepatocytes through a new rapid assay. This metabolic analysis can thus become the reference situation when parallel studies of drug metabolism and toxicities are planned with functional hepatocytes in biochips.""]",https://ineris.hal.science/ineris-00963290,"['0.sdv', '1.sdv.tox', '0.sde']"
"['Jean-Matthieu Prot', 'Andrei Bunescu', 'Bénédicte Elena-Herrmann', 'Caroline Aninat', 'Leila Choucha Snouber', 'Laurent Griscom', 'Florence Razan', 'Frédéric Y. Bois', 'Cécile Legallais', 'Céline Brochot', 'Anne Corlu', 'Marc-Emmanuel Dumas', 'Eric Leclerc']","[178268, 4784, 170850, 753153, 750569, 945746]","['benedicte-elena-herrmann', 'florence-razan', 'cecile-legallais', 'celine-brochot', 'marc-emmanuel-dumas', 'cnrslec']","Predictive toxicology using systemic biology and liver microfluidic ""on chip"" approaches: Application to acetaminophen injury",hal-00699551,2012,10.1016/j.taap.2011.12.017,"['Microfluidic biochip', 'PDMS', 'Liver tissue engineering', 'Predictive toxicology', 'Acetaminophen', 'Transcriptomic', 'Proteomic', 'Metabolomic', 'Biomarkers identification', 'SPRAGUE-DAWLEY RATS', 'DRUG-METABOLISM', 'TOXICITY', 'METABONOMICS', 'MICE', 'TOOL', 'HEPATOTOXICITY', 'NEPHROTOXICITY', 'PERSPECTIVES', 'HEPATOCYTES']","['We have analyzed transcriptomic, proteomic and metabolomic profiles of hepatoma cells cultivated inside a microfluidic biochip with or without acetaminophen (APAP). Without APAP, the results show an adaptive cellular response to the microfluidic environment, leading to the induction of anti-oxidative stress and cytoprotective pathways. In presence of APAP, calcium homeostasis perturbation, lipid peroxidation and cell death are observed. These effects can be attributed to APAP metabolism into its highly reactive metabolite. N-acetyl-p-benzoquinone imine (NAPQI). That toxicity pathway was confirmed by the detection of GSH-APAP, the large production of 2-hydroxybutyrate and 3-hydroxybutyrate, and methionine, cystine, and histidine consumption in the treated biochips. Those metabolites have been reported as specific biomarkers of hepatotoxicity and glutathione depletion in the literature. In addition, the integration of the metabolomic, transcriptomic and proteomic collected profiles allowed a more complete reconstruction of the APAP injury pathways. To our knowledge, this work is the first example of a global integration of microfluidic biochip data in toxicity assessment. Our results demonstrate the potential of that new approach to predictive toxicology.']",https://hal.science/hal-00699551,"['0.chim', '1.chim.anal']"
"['Audrey Legendre', 'Régis Baudoin', 'Giulia Alberto', 'Patrick Paullier', 'Marie Naudot', 'Thibault Bricks', 'Jessy Brocheton', 'Sébastien Jacques', 'Jérôme Cotton', 'Eric Leclerc']","[753943, 1150006, 775837]",['audrey-legendre'],Metabolic Characterization of Primary Rat Hepatocytes Cultivated in Parallel Microfluidic Biochips,hal-03820701,2013,10.1002/jps.23466,"['Hepatocytes', 'Hepatic metabolism', 'Drug delivery system', 'Cytochrome P450', 'Phase II metabolism', 'Efflux pumps', 'In vitro models']","['The functionality of primary rat hepatocytes was assessed in an Integrated Dynamic Cell Cultures in Microsystem (IDCCM) device. We characterized the hepatocytes over 96\u2005h of culture and evaluated the impact of dynamic cell culture on their viability, inducibility, and metabolic activity. Reverse Transcription quantitative Polymerase Chain Reaction (RTqPCR) was performed on selected genes: liver transcription factors (HNF4α and CEBP), nuclear receptors sensitive to xenobiotics (AhR, PXR, CAR, and FXR), cytochromes P450 (CYPs) (1A2, 3A2, 3A23/3A1, 7A1, 2B1, 2C6, 2C, 2D1, 2D2, and 2E1), phase II metabolism enzymes (GSTA2, SULT1A1, and UGT1A6), ABC transporters (ABCB1b and ABCC2), and oxidative stress related enzymes (HMOX1 and NQO1). Microperfused-cultured hepatocytes remained viable and differentiated with in vivo-like phenotype and genotype. In contrast with postadhesion gene levels, the first 48\u2005h of perfusion enhanced the expression of xenosensors and their target CYPs. Furthermore, CYP3A1, CYP2B1, GSTA2, SULT1A1, UGT1A1, ABCB1b, and ABCC2 were upregulated in IDCCM and reached above postextraction levels all along the duration of culture. Metabolic activities were also confirmed with the detection of metabolism rate and induced mRNAs after exposure to several inducers: 3-methylcholanthrene, caffeine, phenacetin, paracetamol,, and midazolam. Finally, this metabolic characterization confirms that IDCCM is able to maintain rat hepatocytes functions to investigate drug metabolism']",https://hal.science/hal-03820701,"['0.sdv', '1.sdv.bio', '0.sdv', '1.sdv.bc', '2.sdv.bc.bc', '0.sdv', '1.sdv.sp']"
"['Amal Essaouiba', 'Teru Okitsu', 'R. Kinoshita', 'Rachid Jellali', 'Yasuyuki Sakai', 'Mathieu Danoy', 'C. Legallais', 'Marie Shinohara', 'Eric Leclerc']","[170850, 945746]","['cecile-legallais', 'cnrslec']",Development of a pancreas-liver organ-on-chip coculture model for organ-to-organ interaction studies,hal-03095499,2020,10.1016/j.bej.2020.107783,"['Islets of Langerhans', 'Hepatocytes', 'Coculture', 'Microfluidic biochips', 'Glucose homeostasis']","['Advances in organ-on-chip technology allowed the recapitulation of two or more organs interaction thanks to dedicated microbioreactors interconnected by microfluidic network. Here, we developed pancreas-liver coculture model in a microfluidic biochip, using rat Langerhans islets and hepatocytes. The behavior and functionality of the model were compared to islets and hepatocytes (with/without insulin) monocultures. We confirmed the insulin, glucagon and C-peptide secretions by islets monoculture and coculture. Furthermore, C-peptide and insulin secretions were higher in coculture after 5 days of culture. The islets coculture presented downregulation of Pdx1, Glut2, Gcg, App, Ins1, Neurod, Neurog3 and Gcgr genes, compared to monocultures. In hepatic compartment, the monocultures without insulin were negative to CK18 staining and displayed a weaker production of albumin when compared to monocultures with insulin. They also presented a moderate protein expression of CYP3A2, GLUT2, INSR and modulation of several hepatic genes. In coculture model, hepatocytes displayed albumin productions similar to those in monoculture with insulin. The hepatocytes cocultures were highly positive to INSR, GLUT2, CK18 and CYP3A2 immunostaining and allowed to recover mRNA levels similar to monoculture with insulin (Gcgr, Insr, Hnf4a, Igfbp1 and Alb). The result illustrated that islets can produce insulin to supplement the culture medium and recover hepatic functionality. We believe that our model illustrated the potential of organ-on-chip technology to reproduce cross-talk between liver and pancreas.']",https://hal.science/hal-03095499,['0.sdv']
"['Kevin Lepetit', 'Khalil Ben Mansour', 'Adrien Letocart', 'Sofiane Boudaoud', 'Kiyoka Kinugawa', 'Jean-François Grosset', 'Frédéric Marin']",[857467],['sofiane-boudaoud'],Optimized scoring tool to quantify the functional performance during the sit-to-stand transition with a magneto-inertial measurement unit,hal-02406859,2019,10.1016/j.clinbiomech.2019.07.012,"['Sit-to-stand', 'Magneto-inertial measurement unit', 'Frailty', 'Age', 'Biomechanics']","[""Background Sit-to-stand is used as a qualitative test to evaluate functional performance, especially to detect fall risks and frail individuals. The use of various quantitative criteria would enable a better understanding of musculoskeletal deficits and movement strategy modifications. This quantification was proven possible with a magneto-inertial unit which provides a compatible wearable device for clinical routine motion analysis. Methods Sit-to-stand movements were recorded using a single magneto-inertial measurement unit fixed on the chest for 74 subjects in three groups healthy young, healthy senior and frail. MIMU data was used to compute 15 spatiotemporal, kinematic and energetic parameters. Nonparametric statistical test showed a significant influence of age and frailness. After reducing the number of parameters by a principal component analysis, an AgingScore and a FrailtyScore were computed. Findings The fraction of variance explained by the first principal component was 77.48\u202f±\u202f2.80% for principal component analysis with healthy young and healthy senior groups, and 74.94\u202f±\u202f2.24% with healthy and frail senior groups. By receiver operating characteristic curve analysis of this score, we were able to refine the analysis to differentiate between healthy young and healthy senior subjects as well as healthy senior and frail subjects. By radar plot of the most discriminate parameters, the motion's strategy could be characterized and be used to detect premature functional deficit or frail subjects. Interpretation Sit-to-stand measured by a single magneto-inertial unit and dedicated post processing is able to quantify subject's musculoskeletal performance and will allow longitudinal investigation of aging population.""]",https://hal.utc.fr/hal-02406859,"['0.phys', '1.phys.meca', '2.phys.meca.biom']"
"['Vincent Carriou', 'Sofiane Boudaoud', 'Jeremy Laforet', 'Adriana Mendes', 'Francis Canon', 'David Guiraud']","[21949, 735990, 8582]","['jeremy-laforet', 'francis-canon', 'david-guiraud']",Multiscale Hill-type modeling of the mechanical muscle behavior driven by the neural drive in isometric conditions,lirmm-02307823,2019,10.1016/j.compbiomed.2019.103480,"['Isometric contraction', 'Motor unit', 'Recruitment scheme', 'Muscle multiscale mechanical model']","['In this study, we present a new model describing the mechanical behavior of the skeletal muscle during isometric contraction. This model is based on a former Hill-inspired model detailing the electromechanical behavior of the muscle based on the Huxley formulation. However, in this new multiscale model the muscle is represented at the Motor Unit (MU) scale. The proposed model is driven by a physiological input describing the firing moments of the activated MUs. Definition of both voluntary and evoked MU recruitment schemes are described, enabling the study of both contractions in isometric conditions. During this type of contraction, there is no movement of the joints and the tendon-muscle complex remains at the same length. Moreover, some well-established macroscopic relationships such as force-length or force-velocity properties are considered. A comparison with a twitch model using the same input definition is provided with both recruitment schemes exhibiting limitations of twitch type models. Finally, the proposed model is validated with a comparison between simulated and recorded force profiles following eight electrical stimulation in isometric conditions. The simulated muscle force was generated to mimic the one recorded from the quadriceps of a patient implanted with a functional electrical stimulation neuroprosthesis. This validation demonstrates the ability of the proposed model to reproduce realistically the skeletal muscle contractions and to take into account subject-specific parameters.']",https://hal-lirmm.ccsd.cnrs.fr/lirmm-02307823,"['0.spi', '1.spi.auto', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.phy', '0.sdv', '1.sdv.neu', '2.sdv.neu.nb']"
"['Ahmad Diab', 'Sofiane Boudaoud', 'Brynjar Karlsson', 'Catherine Marque']","[1108808, 857467, 173423]","['sofiane-boudaoud', 'catherine-marque']",Performance Comparison of Coupling-Evaluation Methods in Discriminating Between Pregnancy and Labor EHG Signals,hal-03329927,2021,10.1016/j.compbiomed.2021.104308,"['Labor detection', 'EHG', 'Non-stationarity', 'Connectivity', 'Propagation direction', 'Classification rate']","['Background Recent years have seen an increased interest in electrohysterogram (EHG) signals as a means to evaluate the synchronization of uterine contractions. Several studies have pointed out that the quality of signal processing – and hence the interpretation of measurement results – is affected significantly by the choice of measurement technique and the presence of non-stationary frequency content in EHG signals. To our knowledge, the effect of time variance on the quality of EHG signal processing has never been fully investigated. How best to process EHG signals with the goal of distinguishing labor-induced contractions from their harmless, pre-labor cousins, remains an open question. Method Our methodology is based on three pillars. The first consists of a new method for EHG preprocessing in which we apply a second-order Butterworth filter to retain only the EHG fast-wave, low-frequency band (FWL), then use a bivariate piecewise stationary pre-segmentation (bPSP) algorithm to segment the EHG signal into stationary parts. The second pillar addresses the estimation of connectivity and directionality using three methods: nonlinear correlation coefficient (h2), general synchronization (H), and Granger causality (GC). The third pillar is related to signal classification and discrimination between pregnancy and labor using receiver operating curves (ROC) and connectivity and direction maps. For this purpose, we analyze the impact of four factors on data processing efficiency: i) method of connectivity detection, ii) effect of piecewise stationary segmentation preprocessing, iii) retained frequency content and iv) electrode configuration used for EHG recording (bipolar vs. unipolar). Results Our results show that piecewise signal segmentation and filtering considerably improves classification performance and statistical significance for some connectivity methods, in particular the h2. To this end we propose a new approach (detailed below) for h2 called Filtered-Windowed (FW) h2 that better highlights the differences between pregnancy and labor in the connectivity matrix and directionality maps. Conclusions This is the first comparative study of the effects of multiple processing factors on connectivity measurement efficiency. Our results indicate that appropriate preprocessing can improve the differentiation of pregnancy and labor-induced contraction signals and may lead to innovative applications in the prevention of preterm labor.']",https://hal.sorbonne-universite.fr/hal-03329927,"['0.info', '0.sdv']"
"['Kevin Lepetit', 'Khalil Ben Mansour', 'Sofiane Boudaoud', 'Kiyoka Kinugawa-Bourron', 'Frédéric Marin']",[735688],['frederic-marin'],Evaluation of the kinetic energy of the torso by magneto-inertial measurement unit during the sit-to-stand movement,hal-02896597,2018,10.1016/j.jbiomech.2017.11.028,"['Sit-to-stand', 'Magneto-inertial measurement unit', 'Kinetic energy', 'Motion capture', 'Motion analysis']","['Sit-to-stand tests are used in geriatrics as a qualitative issue in order to evaluate motor control and stability. In terms of measured indicators, it is traditionally the duration of the task that is reported, however it appears that the use of the kinetic energy as a new quantitative criterion allows getting a better understanding of musculoskeletal deficits of elderly subjects. The aim of this study was to determine the feasibility to obtain the measure of kinetic energy using magneto-inertial measurement units (MIMU) during sit-to-stand movements at various paces. 26 healthy subjects contributed to this investigation. Measured results were compared to a marker-based motion capture using the correlation coefficient and the normalized root mean square error (nRMSE). nRMSE were below 10% and correlation coefficients were over 0.97. In addition, errors on the mean kinetic energy were also investigated using Bland-Altman 95% limits of agreement (0.63\u202fJ–0.77\u202fJ), RMSE (0.29\u202fJ–0.38\u202fJ) and correlation coefficient (0.96–0.98). The results obtained highlighted that the method based on MIMU data could be an alternative to optoelectronic data acquisition to assess the kinetic energy of the torso during the sit-to-stand test, suggesting this method as being a promising alternative to determine kinetic energy during the sit-to-stand movement.']",https://hal.science/hal-02896597,"['0.spi', '1.spi.meca', '2.spi.meca.biom']"
"['Valentina Fedchenko', 'Dario Maria Nicolosi', 'Glenn Roe']",,,À la recherche des réseaux intertextuels : défis de la recherche littéraire à grande échelle,hal-04637976,2024,10.4000/11wmw,"['Literature', 'Intertextuality', 'Network analysis', 'Text reuse', 'Machine learning']","['Cet article expose certains des défis qui ont émergé au cours des premières phases du projet Modern, programme de recherche financé par l’ERC (European Research Council, ou Conseil européen de la recherche) pour cinq ans, qui adopte une nouvelle approche partant des données (data driven) pour étudier l’histoire littéraire du siècle des Lumières. À partir d’un grand corpus de textes français du début de la période moderne, les auteurs détaillent les diverses étapes de la construction de réseaux intertextuels en se servant des résultats d’algorithmes de réutilisation de textes. De l’harmonisation du corpus et des métadonnées à l’entraînement d’un réseau neuronal pour filtrer les passages «\xa0bruités\xa0», cet article propose une chaîne de traitement pragmatique pour les projets similaires travaillant sur d’importantes collections de textes numérisés, tout en mettant en lumière les promesses ainsi que les périls de la recherche littéraire à grande échelle.', 'This article outlines some of the challenges that have arisen during the first phases of the ERC-funded Modern project, a five-year research programme that takes a new “data driven” approach to the literary history of the French Enlightenment. Drawing on a large curated corpus of French texts of the Early Modern period, the authors describe in detail the various steps for building intertextual networks using the output of text reuse algorithms. From corpus and metadata cleaning to training a neural network for filtering ‘noisy’ passages, this article provides a pragmatic technical pipeline for similar projects working with massive collections of digitised text, highlighting both the promise and perils of conducting literary research at scale.']",https://hal.science/hal-04637976,"['0.shs', '1.shs.litt', '0.info', '1.info.info-si']"
"['David Flacher', 'Hugo Harari-Kermadec', 'Léonard Moulin']","[838289, 1321919, 9313]","['hugo-harari-kermadec', 'leonard-moulin']",Faut-il (vraiment) augmenter les frais d'inscription à l'université ?,hal-00749625,2012,10.3917/rfe.123.0145,"[""Frais d'inscription""]","[""Cet article propose une analyse des arguments couramment avancés en faveur des frais d'inscription: 1) l'iniquité du système français; 2) l'efficience du marché pour sélectionner, orienter et inciter à l'effort; 3) le financement de l'université. Nous défendons la thèse selon laquelle ces frais peuvent conduire de potentiels étudiants à renoncer à leurs études, à modifier l'orientation qui aurait été la leur en l'absence de frais ou encore à modifier leur comportement sur le marché du travail sous le poids de la dette. Nous montrons que les frais ne garantissent ni l'équité, ni un fonctionnement efficient du système d'enseignement supérieur, ni un accroissement des ressources des établissements."", 'Should we (really) raise tuition fees ? This article offers a critical analysis of the usual arguments in favour of tuition fees: 1) the iniquity of the French system, 2) market efficiency to select, guide and encourage the effort, 3) the financing of the university. We defend the thesis that, due to these costs and due to debt burden, potential students could drop out of higher education, change their vocational orientation or behaviour on the labour market. We show that tuition fees do not guarantee equity, efficiency and resources increase for universities.']",https://hal.science/hal-00749625v2,"['0.shs', '1.shs.eco']"
"['Léonard Moulin', 'David Flacher', 'Hugo Harari-Kermadec']","[9313, 838289, 1321919]","['leonard-moulin', 'hugo-harari-kermadec']",Tuition Fees and Social Segregation : Lessons from a Natural Experiment at the University of Paris 9-Dauphine,hal-01346937,2016,10.1080/00036846.2016.1148253,['Tuition Fees'],"['Using a natural experiment, a sharp rise in tuition fees in some of the programmes at the University of Paris 9-Dauphine, we study the impact of tuition fees on students’ pathways, and outcomes. We apply an optimal matching method to the national database of students’ registrations (SISE) to define a typology of pathways. We then use a nonordered multinomial logit model to evaluate the impact of the rise in tuition fees on the types of pathways selected by the university. We show that there is a significant impact on these pathways. The increase in tuition fees reduces geographic and social mobility, thereby accentuating the phenomena of social segregation. Furthermore, contrary to what some of the studies assert, the rise does not appear to encourage greater effort: we find no impact on the graduation success rate.']",https://hal.science/hal-01346937,"['0.shs', '1.shs.eco', '0.shs', '1.shs.edu', '0.shs', '1.shs.demo', '0.shs', '1.shs.socio']"
"['David Flacher', 'Hugues Jennequin']","[838289, 181309]",['hugues-jennequin'],Access regulation and geographic deployment of a new generation infrastructure,hal-02391280,2014,10.1016/j.telpol.2014.01.005,"['Access regulation', 'Geographic deployment', 'Network industries', 'Telecommunications', 'Investment']","['This paper addresses the impact of regulatory policy on levels of infrastructure deployment and derived welfare in the telecommunications sector. The model considers two potentially coexisting and partially competing technologies (the “old generation network” – OGN – and the “new” generation network – NGN). This framework allows us to show that the “regulation defining access charge in order to maximize infrastructure deployment” is strictly equivalent to the case in which “no regulation applies”. We also derive from the model that these two types of regulation induce higher social welfare, but lower numbers of NGN consumers, compared to the “ex post access prices” regulation. Finally, we show that the level of infrastructure deployment (as well as social welfare and number of NGN consumers) will be highest if both investment and access charge decisions are taken by the welfare maximizing regulator. This suggests that the social optimum will be achieved through a calls-for-tender process that includes deployment and access charge requirements.']",https://hal.science/hal-02391280,"['0.shs', '1.shs.eco']"
"['David Flacher', 'Hugo Harari-Kermadec', 'Léonard Moulin']","[838289, 1321919, 9313]","['hugo-harari-kermadec', 'leonard-moulin']",Régime par répartition dans l’enseignement supérieur : fondements théoriques et estimations empiriques,hal-03178992,2018,10.4000/ei.6233,"['Domaine 2 - Savoirs', 'Économie']","['Après avoir rappelé qu’un régime par “capitalisation” ne garantissait ni l’équité, ni l’efficience, ni même le financement de l’enseignement supérieur, nous définissons ce que pourrait être un régime d’éducation par “répartition” et discutons de ses atouts et limites, pour construire une approche théorique du concept. Une éducation par répartition conjugue la gratuité de l’accès, une allocation universelle d’autonomie et un accroissement des dépenses publiques destinées à l’université. Nous montrons qu’un tel régime peut se révéler équitable et efficace pour financer le système éducatif et discutons des conditions permettant à un tel système d’être efficient. Nous chiffrons le coût du régime par répartition (en année pleine : 5 milliards d’euros pour accroître les besoins de financement des universités et 21,6 milliards d’euros pour l’allocation d’autonomie), proposons des modalités de financement et analysons l’effet de ce régime sur les revenus de foyers types. Nous concluons en présentant les limites et perspectives de recherche.']",https://hal.science/hal-03178992,['0.shs']
"['Cédric Durand', 'David Flacher', 'Vincent Frigant']","[838717, 838289, 997377]",,Étudier les chaînes globales de valeur comme une forme d’organisation industrielle,hal-02422865,2018,10.4000/rei.7177,"['Global value chains', 'Global production networks', 'Industrial organization', 'International economics', 'Multinational firms', 'Chaînes globales de valeur', 'Réseaux de production globaux', 'Organisation industrielle', 'Économie internationale', 'Multinationales']","['Cet article revient sur l’origine et les usages des concepts de chaînes globales de valeur (global value chains) et de réseaux de production globaux (global production networks). Il trace l’intensification de la circulation de ces notions dans les années 1990 et 2000 parmi les chercheurs en sociologie, en gestion, en géographie puis en économie et discute les raisons pour lesquelles, depuis une dizaine d’années, ils ont été appropriés par les institutions internationales et les gouvernements afin de définir des politiques de développement et de croissance centrées sur la compétitivité. Il s’interroge également sur les fragilités théoriques de ces cadres d’analyse et pointe la nécessité de prendre davantage en compte la fonction d’intégration des chaînes en tant que modalité particulière d’organisation de la division du travail. La dernière section de l’article introduit brièvement les articles qui constituent ce numéro spécial de la Revue d’économie industrielle.', 'This article discusses the origin and uses of the concepts of global value chains and global production networks. It traces the intensification of the circulation of these concepts in the 1990s and 2000s among researchers in sociology, management, geography, and economics. The article then discusses the reasons why, over the past decade, they have been appropriated by international institutions and governments in order to define development and growth policies focused on competitiveness. It also questions the theoretical fragility of these analytical frameworks and points to the need to take greater account of the role of supply chain integration as a particular means of organizing the division of labor. The last section briefly introduces the articles that make up this special issue of the Revue d’économie industrielle.']",https://hal.science/hal-02422865,"['0.shs', '1.shs.eco', '0.shs', '1.shs.gestion']"
"['Serge Bouchardon', 'Isabelle Cailleau', 'Stéphane Crozat', 'Bruno Bachimont', 'Thibaud Hulin']","[171198, 2495, 1208418, 559]","['serge-bouchardon', 'stephane-crozat', 'bruno-bachimont', 'thibaud-hulin']",Explorer les possibles de l'écriture multimédia,halshs-01153863,2011,10.3917/enic.hs03.0002,"['Écriture multimédia', 'Numérique', 'Approche conceptuelle', 'Institut national de l’audiovisuel', 'INA']","['Dans cet article, nous posons la question d’une écriture multimédia et de ses spécificités. Le multimédia permet-il d’ouvrir des possibles pour l’écriture ? Pour comprendre et explorer ces possibles, nous mobilisons une théorie du numérique et proposons un modèle en trois niveaux de l’écriture multimédia. Nous utilisons cette approche conceptuelle pour analyser des pratiques éditoriales professionnelles à l’Institut national de l’audiovisuel (Ina).']",https://shs.hal.science/halshs-01153863,"['0.shs', '1.shs.info']"
"['Victor Petit', 'Serge Bouchardon']","[180715, 171198]","['victor-petit', 'serge-bouchardon']",L’écriture numérique ou l’écriture selon les machines. Enjeux philosophiques et pédagogiques.,hal-01960029,2017,10.3917/comla.191.0129,"['Teaching', 'Electronic literature', 'Digital literacy', 'Digital writing', 'Physical medium', 'Digital', 'Trace', 'Milieu', 'Numérique', 'Enseignement', 'Écriture numérique', 'Littérature numérique', 'Littératie numérique', 'Support', 'Milieu']","['Cet article est une argumentation en faveur du concept d’écriture numérique et de son enseignement. Il vise à montrer que l’écriture numérique existe, qu’elle a des propriétés et des tensions spécifiques, mais aussi qu’elle peut s’enseigner. Reprenant un certain nombre de questions héritées des études menées sur les rapports entre l’écriture et l’informatique, les auteurs s’intéressent à la dimension pédagogique de l’écriture dite « numérique » à partir de l’exemple d’un programme de recherche mené dans le cadre de la Région Picardie : PRECIP, PRatiques d’ÉCriture Interactive en Picardie.', 'This paper is an argument in favor of the concept of digital writing and its teaching. It aims to show that digital writing exists, that it has specific properties and tensions, but also that it can be taught. Taking up a number of questions inherited from studies on the relationship between writing and computer science, the authors are interested in the pedagogical dimension of digital writing based on the example of the research program PRECIP funded by the Picardy region.']",https://hal.utc.fr/hal-01960029,"['0.shs', '1.shs.info']"
['Serge Bouchardon'],[171198],['serge-bouchardon'],Figures of gestural manipulation in digital fictions,hal-01972084,2013,10.4324/9780203078112-10,"['Digital fiction', 'Interactive narrative', 'Figure']","['Digital fictions often rely on gestural manipulations from the reader. In this essay, I propose a semio-rhetorical approach to analyze the role of these gestural manipulations in the building of meaning. These manipulations contribute to the constitution of figures that I call figures of manipulation.']",https://hal.science/hal-01972084,"['0.shs', '1.shs.info']"
"['Bruno Lamas', 'Mathias L Richard', 'Valentin Leducq', 'Hang-Phuong Pham', 'Marie-Laure Michel', 'Gregory da Costa', 'Chantal Bridonneau', 'Sarah Jegou', 'Thomas W Hoffmann', 'Jane M Natividad', 'Loic Brot', 'Soraya Taleb', 'Aurélie Couturier-Maillard', 'Isabelle Nion-Larmurier', 'Fatiha Merabtene', 'Philippe Seksik', 'Anne Bourrier', 'Jacques Cosnes', 'Bernhard Ryffel', 'Laurent Beaugerie', 'Jean Marie Launay', 'Philippe Langella', 'Ramnik J Xavier', 'Harry Sokol']","[746828, 1172276, 1221765, 761210, 841831, 801170]","['blamas', 'marie-laure-michel', 'seksik-philippe', 'harry-sokol']",CARD9 impacts colitis by altering gut microbiota metabolism of tryptophan into aryl hydrocarbon receptor ligands.,hal-01314089,2016,10.1038/nm.4102,"['Inflammatory bowel disease', 'Mucosal immunology']","['Complex interactions between the host and the gut microbiota govern intestinal homeostasis but remain poorly understood. Here we reveal a relationship between gut microbiota and caspase recruitment domain family member 9 (CARD9), a susceptibility gene for inflammatory bowel disease (IBD) that functions in the immune response against microorganisms. CARD9 promotes recovery from colitis by promoting interleukin (IL)-22 production, and Card9-/- mice are more susceptible to colitis. The microbiota is altered in Card9-/- mice, and transfer of the microbiota from Card9-/- to wild-type, germ-free recipients increases their susceptibility to colitis. The microbiota from Card9-/- mice fails to metabolize tryptophan into metabolites that act as aryl hydrocarbon receptor (AHR) ligands. Intestinal inflammation is attenuated after inoculation of mice with three Lactobacillus strains capable of metabolizing tryptophan or by treatment with an AHR agonist. Reduced production of AHR ligands is also observed in the microbiota from individuals with IBD, particularly in those with CARD9 risk alleles associated with IBD. Our findings reveal that host genes affect the composition and function of the gut microbiota, altering the production of microbial metabolites and intestinal inflammation.']",https://hal.science/hal-01314089,"['0.chim', '1.chim.orga']"
"['Harry Sokol', 'Valentin Leducq', 'Hugues Aschard', 'Hang-Phuong Pham', 'Sarah Jegou', 'Cecilia Landman', 'David Cohen', 'Giuseppina Liguori', 'Anne Bourrier', 'Isabelle Nion-Larmurier', 'Jacques Cosnes', 'Philippe Seksik', 'Philippe Langella', 'David Skurnik', 'Mathias L Richard', 'Laurent Beaugerie']","[801170, 756279, 761210]","['harry-sokol', 'seksik-philippe']",Fungal microbiota dysbiosis in IBD.,hal-01270909,2016,10.1136/gutjnl-2015-310746,"['Inflammatory-Bowel-Disease', 'Chemically-Induced Colitis', 'Familial Crohns-Disease', 'Saccharomyces-Boulardii', 'Candida-Albicans', 'Colonization', 'Gut', 'Defensins', 'Mouse Model', 'Responses']","[""The bacterial intestinal microbiota plays major roles in human physiology and IBDs. Although some data suggest a role of the fungal microbiota in IBD pathogenesis, the available data are scarce. The aim of our study was to characterise the faecal fungal microbiota in patients with IBD. Bacterial and fungal composition of the faecal microbiota of 235 patients with IBD and 38 healthy subjects (HS) was determined using 16S and ITS2 sequencing, respectively. The obtained sequences were analysed using the Qiime pipeline to assess composition and diversity. Bacterial and fungal taxa associated with clinical parameters were identified using multivariate association with linear models. Correlation between bacterial and fungal microbiota was investigated using Spearman's test and distance correlation. We observed that fungal microbiota is skewed in IBD, with an increased Basidiomycota/Ascomycota ratio, a decreased proportion of Saccharomyces cerevisiae and an increased proportion of Candida albicans compared with HS. We also identified disease-specific alterations in diversity, indicating that a Crohn's disease-specific gut environment may favour fungi at the expense of bacteria. The concomitant analysis of bacterial and fungal microbiota showed a dense and homogenous correlation network in HS but a dramatically unbalanced network in IBD, suggesting the existence of disease-specific inter-kingdom alterations. Besides bacterial dysbiosis, our study identifies a distinct fungal microbiota dysbiosis in IBD characterised by alterations in biodiversity and composition. Moreover, we unravel here disease-specific inter-kingdom network alterations in IBD, suggesting that, beyond bacteria, fungi might also play a role in IBD pathogenesis.""]",https://hal.science/hal-01270909,"['0.sdv', '1.sdv.mp']"
"['Jane Natividad', 'Allison Agus', 'Julien Planchais', 'Bruno Lamas', 'Anne Charlotte Jarry', 'Rebeca Martin', 'Marie-Laure Michel', 'Caroline Chong-Nguyen', 'Ronan Roussel', 'Marjolene Straube', 'Sarah Jégou', 'Claire Mcquitty', 'Maude Le Gall', 'Grégory da Costa', 'Emmanuelle Lecornet', 'Chloé Michaudel', 'Morgane Modoux', 'Jérémy Glodt', 'Chantal Bridonneau', 'Bruno Sovran', 'Louise Dupraz', 'André Bado', 'Mathias Richard', 'Philippe Langella', 'Boris Hansel', 'Jean-Marie Launay', 'Ramnik Xavier', 'Henri Duboc', 'Harry Sokol']","[746828, 1169253, 1172276, 1258625, 1202821, 882907, 757247, 801170]","['blamas', 'rebeca-martin-rosique', 'marie-laure-michel', 'chloe-michaudel', 'harry-sokol']",Impaired Aryl Hydrocarbon Receptor Ligand Production by the Gut Microbiota Is a Key Factor in Metabolic Syndrome,hal-01895943,2018,10.1016/j.cmet.2018.07.001,"['AhR', 'Microbiota metabolites', 'High-fat diet', 'L reuteri', 'Ob/ob mice']","['The extent to which microbiota alterations define or influence the outcome of metabolic diseases is still unclear, but the byproducts of microbiota metabolism are known to have an important role in mediating the host-microbiota interaction. Here, we identify that in both pre-clinical and clinical settings, metabolic syndrome is associated with the reduced capacity of the microbiota to metabolize tryptophan into derivatives that are able to activate the aryl hydrocarbon receptor. This alteration is not merely an effect of the disease as supplementation with AhR agonist or a Lactobacillus strain, with a high AhR ligand-production capacity, leads to improvement of both dietary- and genetic-induced metabolic impairments, particularly glucose dysmetabolism and liver steatosis, through improvement of intestinal barrier function and secretion of the incretin hormone GLP-1. These results highlight the role of gut microbiota-derived metabolites as a biomarker and as a basis for novel preventative or therapeutic interventions for metabolic disorders.']",https://hal.sorbonne-universite.fr/hal-01895943,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.em', '0.sdv', '1.sdv.aen']"
"['Jane Natividad', 'Bruno Lamas', 'Hang Phuong Pham', 'Marie-Laure Michel', 'Dominique Rainteau', 'Chantal Bridonneau', 'Grégory da Costa', 'Johan van Hylckama Vlieg', 'Bruno Sovran', 'Celia Chamignon', 'Julien Planchais', 'Mathias Richard', 'Philippe Langella', 'Patrick P. Veiga', 'Harry Sokol']","[746828, 1172276, 1223457, 735757, 801170]","['blamas', 'marie-laure-michel', 'celia-chamignon', 'harry-sokol']",Bilophila wadsworthia aggravates high fat diet induced metabolic dysfunctions in mice,hal-01960210,2018,10.1038/s41467-018-05249-7,"['Akkermansia-muciniphila', 'Intestinal barrier', 'Induced obesity', 'Bile-acids', 'Bacteremia', 'Akkermansia-muciniphila', 'Gut microbiota', 'Expression data', 'Inflammation', 'Butyrate', 'Dysbiosis', 'Gut microbiota']","[""Dietary lipids favor the growth of the pathobiont Bilophila wadsworthia, but the relevance of this expansion in metabolic syndrome pathogenesis is poorly understood. Here, we showed that B. wadsworthia synergizes with high fat diet (HFD) to promote higher inflammation, intestinal barrier dysfunction and bile acid dysmetabolism, leading to higher glucose dysmetabolism and hepatic steatosis. Host-microbiota transcriptomics analysis reveal pathways, particularly butanoate metabolism, which may underlie the metabolic effects mediated by B. wadsworthia. Pharmacological suppression of B. wadsworthia-associated inflammation demonstrate the bacterium's intrinsic capacity to induce a negative impact on glycemic control and hepatic function. Administration of the probiotic Lactobacillus rhamnosus CNCM I-3690 limits B. wadsworthia-induced immune and metabolic impairment by limiting its expansion, reducing inflammation and reinforcing intestinal barrier. Our results suggest a new avenue for interventions against western diet-driven inflammatory and metabolic diseases.""]",https://hal.sorbonne-universite.fr/hal-01960210,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.em', '0.sdv', '1.sdv.aen']"
"['Giovanni Cammarota', 'Gianluca Ianiro', 'Colleen Kelly', 'Benjamin Mullish', 'Jessica Allegretti', 'Zain Kassam', 'Lorenza Putignani', 'Monika Fischer', 'Josbert Keller', 'Samuel Paul Costello', 'Harry Sokol', 'Patrizia Kump', 'Reetta Satokari', 'Stacy Kahn', 'Dina Kao', 'Perttu Arkkila', 'Ed Kuijper', 'Maria Vehreschild', 'Cristina Pintus', 'Loris Lopetuso', 'Luca Masucci', 'Franco Scaldaferri', 'E Terveer', 'Max Nieuwdorp', 'Antonio López-Sanromán', 'Juozas Kupcinskas', 'Ailsa Hart', 'Herbert Tilg', 'Antonio Gasbarrini']","[1080631, 801170, 764351]",['harry-sokol'],International consensus conference on stool banking for faecal microbiota transplantation in clinical practice,hal-02983798,2019,10.1136/gutjnl-2019-319548,"['Clostridium-difficile Infection', 'Active Ulcerative-colitis', 'Intestinal Microbiota', 'Insulin Sensitivity', 'Organ Donation', 'Donor Feces', 'Recurrent', 'Efficacy', 'Frozen', 'Metaanalysis']","['Although faecal microbiota transplantation (FMT) has a well-established role in the treatment of recurrent Clostridioides difficile infection (CDI), its widespread dissemination is limited by several obstacles, including lack of dedicated centres, difficulties with donor recruitment and complexities related to regulation and safety monitoring. Given the considerable burden of CDI on global healthcare systems, FMT should be widely available to most centres. Stool banks may guarantee reliable, timely and equitable access to FMT for patients and a traceable workflow that ensures safety and quality of procedures. In this consensus project, FMT experts from Europe, North America and Australia gathered and released statements on the following issues related to the stool banking: general principles, objectives and organisation of the stool bank; selection and screening of donors; collection, preparation and storage of faeces; services and clients; registries, monitoring of outcomes and ethical issues; and the evolving role of FMT in clinical practice, Consensus on each statement was achieved through a Delphi process and then in a plenary face-to-face meeting. For each key issue, the best available evidence was assessed, with the aim of providing guidance for the development of stool banks in order to promote accessibility to FMT in clinical practice.']",https://hal.inrae.fr/hal-02983798,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg']"
"['Maxime Breban', 'Julien Tap', 'Ariane Leboime', 'Roula Said-Nahal', 'Philippe Langella', 'Gilles Chiocchia', 'Jean-Pierre Furet', 'Harry Sokol']","[1166492, 1172956, 801170]","['julien-tap', 'harry-sokol']",Faecal microbiota study reveals specific dysbiosis in spondyloarthritis,hal-03856549,2017,10.1136/annrheumdis-2016-211064,"['Spondyloarthritis', 'Ankylosing spondylitis', 'Infection', 'Inflammation', 'Rheumatoid arthritis', 'Spondyloarthritis']","['Altered microbiota composition or dysbiosis is suspected to be implicated in the pathogenesis of chronic inflammatory diseases, such as spondyloarthritis (SpA) and rheumatoid arthritis (RA). Methods 16S ribosomal RNA gene sequencing was performed on faecal DNA isolated from stool samples in two consecutive cross-sectional cohorts, each comprising three groups of adult volunteers: SpA, RA and healthy controls (HCs). In the second study, HCs comprised a majority of aged-matched siblings of patients with known HLA-B27 status. Alpha and beta diversities were assessed using QIIME, and comparisons were performed using linear discriminant analysis effect size to examine differences between groups. Results In both cohorts, dysbiosis was evidenced in SpA and RA, as compared with HCs, and was disease specific. A restriction of microbiota biodiversity was detected in both disease groups. The most striking change was a twofold to threefold increased abundance of Ruminococcus gnavus in SpA, as compared with both RA and HCs that was significant in both studies and positively correlated with disease activity in patients having a history of inflammatory bowel disease (IBD). Among HCs, significant difference in microbiota composition were also detected between HLA-B27+ and HLA-B27 negative siblings, suggesting that genetic background may influence gut microbiota composition. Conclusion Our results suggest that distinctive dysbiosis characterise both SpA and RA and evidence a reproducible increase in R. gnavus that appears specific for SpA and a marker of disease activity. This observation is consistent with the known proinflammatory role of this bacteria and its association with IBD. It may provide an explanation for the link that exists between SpA and IBD.']",https://hal.inrae.fr/hal-03856549,"['0.sdv', '1.sdv.mp', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.rsoa']"
"['Giuseppina Liguori', 'Bruno Lamas', 'Mathias L. Richard', 'Giovanni Brandi', 'Gregory da Costa', 'Thomas W. Hoffmann', 'Massimo Pierluigi Di Simone', 'Carlo Calabrese', 'Gilberto Poggioli', 'Philippe Langella', 'Massimo Campieri', 'Harry Sokol']","[746828, 1221765, 801170]","['blamas', 'harry-sokol']",Fungal Dysbiosis in Mucosa-associated Microbiota of Crohn’s Disease Patients,hal-01300475,2015,10.1093/ecco-jcc/jjv209,"['Inflammatory bowel disease', 'Mucosa-associated microbiota', 'Fungal microbiota']","[""Background and Aims: Gut microbiota is involved in many physiological functions and its imbalance is associated with several diseases, particularly with inflammatory bowel diseases. Mucosa-associated microbiota could have a key role in induction of host immunity and in inflammatory process. Although the role of fungi has been suggested in inflammatory disease pathogenesis, the fungal microbiota has not yet been deeply explored. Here we analysed the bacterial and fungal composition of the mucosa-associated microbiota of Crohn's disease patients and healthy subjects. Methods: Our prospective, observational study evaluated bacterial and fungal composition of mucosa-associated microbiota of 23 Crohn's disease patients [16 in flare, 7 in remission] and 10 healthy subjects, using 16S [MiSeq] and ITS2 [pyrosequencing] sequencing, respectively. Global fungal load was assessed by real time quantitative polymerase chain reaction. Results: Bacterial microbiota in Crohn's disease patients was characterised by a restriction in biodiversity. with an increase of Proteobacteria and Fusobacteria. Global fungus load was significantly increased in Crohn's disease flare compared with healthy subjects [p < 0.05]. In both groups, the colonic mucosa-associated fungal microbiota was dominated by Basidiomycota and Ascomycota phyla. Cystofilobasidiaceae family and Candida glabrata species were overrepresented in Crohn's disease. Saccharomyces cerevisiae and Filobasidium uniguttulatum species were associated with non-inflamed mucosa, whereas Xylariales order was associated with inflamed mucosa. Conclusions: Our study confirms the alteration of the bacterial microbiota and is the first demonstration of the existence of an altered fungal microbiota in Crohn's disease patients, suggesting that fungi may play a role in pathogenesis.""]",https://hal.sorbonne-universite.fr/hal-01300475,"['0.sdv', '1.sdv.mhep']"
"['Harry Sokol', 'Cecilia Landman', 'Philippe Seksik', 'Laurence Berard', 'Mélissa Montil', 'Isabelle Nion-Larmurier', 'Anne Bourrier', 'Guillaume Le Gall', 'Valérie Lalande', 'Alexis de Rougemont', 'Julien Kirchgesner', 'Anne Daguenel', 'Marine Cachanado', 'Alexandra Rousseau', 'Élodie Drouet', 'Michelle Rosenzwajg', 'Hervé Hagege', 'Xavier Dray', 'David Klatzman', 'Philippe Marteau', 'Laurent Beaugerie', 'Tabassome Simon']","[801170, 761210, 748817, 767316, 801871, 741176]","['harry-sokol', 'seksik-philippe', 'julien-kirchgesner', 'tabassome-simon']",Fecal microbiota transplantation to maintain remission in Crohn’s disease: a pilot randomized controlled study,hal-03031236,2020,10.1186/s40168-020-0792-5,"['Fecal microbiota transplantation', ""Crohn's disease"", 'Randomized controlled trial']","[""Background: The role of the gut microbiota in Crohn's disease (CD) is established and fecal microbiota transplantation (FMT) is an attractive therapeutic strategy. No randomized controlled clinical trial results are available. We performed a randomized, single-blind, sham-controlled pilot trial of FMT in adults with colonic or ileocolonic CD. Method: Patients enrolled while in flare received oral corticosteroid. Once in clinical remission, patients were randomized to receive either FMT or sham transplantation during a colonoscopy. Corticosteroids were tapered and a second colonoscopy was performed at week 6. The primary endpoint was the implantation of the donor microbiota at week 6 (Sorensen index > 0.6). Results: Eight patients received FMT and nine sham transplantation. None of the patients reached the primary endpoint. The steroid-free clinical remission rate at 10 and 24 weeks was 44.4% (4/9) and 33.3% (3/9) in the sham transplantation group and 87.5% (7/8) and 50.0% (4/8; one patient loss of follow-up while in remission at week 12 and considered in flare at week 24) in the FMT group. Crohn's Disease Endoscopic Index of Severity decreased 6 weeks after FMT (p = 0.03) but not after sham transplantation (p = 0.8). Conversely, the CRP level increased 6 weeks after sham transplantation (p = 0.008) but not after FMT (p = 0.5). Absence of donor microbiota engraftment was associated with flare. No safety signal was identified. Conclusion: The primary endpoint was not reached for any patient. In this pilot study, higher colonization by donor microbiota was associated with maintenance of remission. These results must be confirmed in larger studies (NCT02097797).""]",https://hal.sorbonne-universite.fr/hal-03031236,['0.sdv']
"['Emmanuel Pardo', 'Thomas Lescot', 'Jean-Charles Preiser', 'Pablo Massanet', 'Antoine Pons', 'Samir Jaber', 'Vincent Fraipont', 'Eric Levesque', 'Carole Ichai', 'Laurent Petit', 'Fabienne Tamion', 'Garry Taverny', 'Priscilla Boizeau', 'Corinne Alberti', 'Jean-Michel Constantin', 'Marie-Pierre Bonnet']","[1215725, 1327347]",,Association between early nutrition support and 28-day mortality in critically ill patients: the FRANS prospective nutrition cohort study,hal-03929934,2023,10.1186/s13054-022-04298-1,"['Clinical nutrition Intensive care unit Enteral nutrition Parenteral nutrition Critical illness Clinical nutrition guidelines Mortality Early nutrition support', 'Clinical nutrition', 'Intensive care unit', 'Enteral nutrition', 'Parenteral nutrition', 'Critical illness', 'Clinical nutrition guidelines', 'Mortality', 'Early nutrition support']","['Abstract Background Current guidelines suggest the introduction of early nutrition support within the first 48\xa0h of admission to the intensive care unit (ICU) for patients who cannot eat. In that context, we aimed to describe nutrition practices in the ICU and study the association between the introduction of early nutrition support (<\u200948\xa0h) in the ICU and patient mortality at day 28 (D28) using data from a multicentre prospective cohort. Methods The ‘French-Speaking ICU Nutritional Survey’ (FRANS) study was conducted in 26 ICUs in France and Belgium over 3\xa0months in 2015. Adult patients with a predicted ICU length of stay\u2009>\u20093\xa0days were consecutively included and followed for 10\xa0days. Their mortality was assessed at D28. We investigated the association between early nutrition (<\u200948\xa0h) and mortality at D28 using univariate and multivariate propensity-score-weighted logistic regression analyses. Results During the study period, 1206 patients were included. Early nutrition support was administered to 718 patients (59.5%), with 504 patients receiving enteral nutrition and 214 parenteral nutrition. Early nutrition was more frequently prescribed in the presence of multiple organ failure and less frequently in overweight and obese patients. Early nutrition was significantly associated with D28 mortality in the univariate analysis (crude odds ratio (OR) 1.69, 95% confidence interval (CI) 1.23–2.34) and propensity-weighted multivariate analysis (adjusted OR (aOR) 1.05, 95% CI 1.00–1.10). In subgroup analyses, this association was stronger in patients\u2009≤\u200965\xa0years and with SOFA scores\u2009≤\u20098. Compared with no early nutrition, a significant association was found of D28 mortality with early enteral (aOR 1.06, 95% CI 1.01–1.11) but not early parenteral nutrition (aOR 1.04, 95% CI 0.98–1.11). Conclusions In this prospective cohort study, early nutrition support in the ICU was significantly associated with increased mortality at D28, particularly in younger patients with less severe disease. Compared to no early nutrition, only early enteral nutrition appeared to be associated with increased mortality. Such findings are in contrast with current guidelines on the provision of early nutrition support in the ICU and may challenge our current practices, particularly concerning patients at low nutrition risk. Trial registration ClinicalTrials.gov Identifier: NCT02599948. Retrospectively registered on November 5th 2015.']",https://hal.science/hal-03929934,['0.sdv']
"['Sebastien Rubin', 'Arthur Orieux', 'Renaud Prevel', 'Antoine Garric', 'Marie-Lise Bats', 'Sandrine Dabernat', 'Fabrice Camou', 'Olivier Guisset', 'Nahema Issa', 'Gaelle Mourissoux', 'Antoine Dewitte', 'Olivier Joannes-Boyau', 'Catherine Fleureau', 'Hadrien Rozé', 'Cédric Carrié', 'Laurent Petit', 'Benjamin Clouzeau', 'Charline Sazio', 'Hoang-Nam Bui', 'Odile Pillet', 'Claire Rigothier', 'Frederic Vargas', 'Christian Combe', 'Didier Gruson', 'Alexandre Boyer']","[935412, 786695, 756127]",,Characterization of acute kidney injury in critically ill patients with severe coronavirus disease 2019,hal-03194408,2020,10.1093/ckj/sfaa099,"['Acute interstitial nephritis', 'Acute kidney injury', 'Acute tubular injury', 'COVID-19', 'Critically ill patients', 'Renal replacement therapy']","['Abstract Background Coronavirus disease 2019 (COVID-19)-associated acute kidney injury (AKI) frequency, severity and characterization in critically ill patients has not been reported. Methods Single-centre cohort performed from 3 March 2020 to 14 April 2020 in four intensive care units in Bordeaux University Hospital, France. All patients with COVID-19 and pulmonary severity criteria were included. AKI was defined using Kidney Disease: Improving Global Outcomes (KDIGO) criteria. A systematic urinary analysis was performed. The incidence, severity, clinical presentation, biological characterization (transient versus persistent AKI; proteinuria, haematuria and glycosuria) and short-term outcomes were evaluated. Results Seventy-one patients were included, with basal serum creatinine (SCr) of 69 ± 21 µmol/L. At admission, AKI was present in 8/71 (11%) patients. Median [interquartile range (IQR)] follow-up was 17 (12–23) days. AKI developed in a total of 57/71 (80%) patients, with 35% Stage 1, 35% Stage 2 and 30% Stage 3 AKI; 10/57 (18%) required renal replacement therapy (RRT). Transient AKI was present in only 4/55 (7%) patients and persistent AKI was observed in 51/55 (93%). Patients with persistent AKI developed a median (IQR) urine protein/creatinine of 82 (54–140) (mg/mmol) with an albuminuria/proteinuria ratio of 0.23 ± 20, indicating predominant tubulointerstitial injury. Only two (4%) patients had glycosuria. At Day 7 after onset of AKI, six (11%) patients remained dependent on RRT, nine (16%) had SCr &gt;200 µmol/L and four (7%) had died. Day 7 and Day 14 renal recovery occurred in 28% and 52%, respectively. Conclusion Severe COVID-19-associated AKI is frequent, persistent, severe and characterized by an almost exclusive tubulointerstitial injury without glycosuria.']",https://hal.science/hal-03194408,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.mi', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.me', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.un', '0.sdv', '1.sdv.spee']"
"['Stéphane Multon', 'Martin Cyr', 'Alain Sellier', 'Paco Diederich', 'Laurent Petit']","[17233, 17119, 17699]","['stephanemulton', 'martin-cyr', 'alain-sellier']",Effects of aggregate size and alkali content on ASR expansion,hal-01724664,2010,10.1016/j.cemconres.2009.08.002,"['Alkali', 'Expansion', 'Particle size', 'Alkali-Silica Reaction']","['Attempts to model ASR expansion are usually limited by the difficulty of taking into account the heterogeneous nature and size range of reactive aggregates. This work is a part of an overall project aimed at developing models to predict the potential expansion of concrete containing alkali-reactive aggregates. The paper gives measurements in order to provide experimental data concerning the effect of particle size of an alkali-reactive siliceous limestone on mortar expansion. Results show that no expansion was measured on the mortars using small particles (under 80 mu m) while the coarse particles (0.63-1.25 mm) gave the largest expansions (0.33%). When two sizes of aggregate were used, ASR-expansions decreased with the proportion of small particles. Models are proposed to study correlations between the measured expansions and parameters such as the size of aggregates and the alkali and reactive silica contents. The pessimum effect of reactive aggregate size is assessed and the consequences on accelerated laboratory tests are discussed.']",https://hal.insa-toulouse.fr/hal-01724664,"['0.spi', '1.spi.mat', '0.spi', '1.spi.gciv']"
"['Stéphane Multon', 'Martin Cyr', 'Alain Sellier', 'Ali-Nordine Leklou', 'Laurent Petit']","[17233, 17119, 17699]","['stephanemulton', 'martin-cyr', 'alain-sellier']",Coupled effects of aggregate size and alkali content on ASR expansion,hal-01006003,2007,10.1016/j.cemconres.2007.09.013,"['Alkali-aggregate reaction', 'Particle size', 'Alkali content', 'Expansion', 'Model']","['This work is a part of an overall project aimed at developing models to predict the potential expansion of concrete containing alkali-reactive aggregates. First, this paper reports experimental results concerning the effect of particle size of an alkali-reactive siliceous limestone on mortar expansion. Special attention is paid to the proportions of alkali (Na2Oeq) in the mixtures and reactive silica in the aggregate. Results show that ASR expansion is seven times larger for coarse particles (1.25–3.15 mm) than for smaller ones (80–160 μm). In mortars for which the two size fractions were used, ASR expansion increased in almost linear proportion to the amount of coarse reactive particles, for two different alkali contents. Then, an empirical model is proposed to study correlations between the measured expansions and parameters such as the size of aggregates and the alkali and reactive silica contents. Starting with the procedure for calibrating the empirical model using the experimental program combined with results from the literature, it is shown that the expansion of a mortar containing different sizes of reactive aggregate can be assessed with acceptable accuracy.']",https://hal.science/hal-01006003,"['0.spi', '1.spi.meca', '0.spi', '1.spi.mat']"
"['Cédric Boudot', 'Zuzana Saidak', 'Abdel Krim Boulanouar', 'Laurent Petit', 'Fabrice Gouilleux', 'Ziad Massy', 'Michel Brazier', 'Romuald Mentaverri', 'Saïd Kamel']","[1150779, 1114819, 180708, 1003368, 956098, 956099, 1120771]","['cedric-boudot', 'fabrice-gouilleux', '80956099', 'said-kamel']",Implication of the calcium sensing receptor and the Phosphoinositide 3-kinase/Akt pathway in the extracellular calcium-mediated migration of RAW 264.7 osteoclast precursor cells,hal-03411296,2010,10.1016/j.bone.2010.01.383,"['Calcium sensing receptor', 'Osteoclast precursors', 'Migration', 'Extracellular Ca2+', 'Phosphoinositide 3-kinase', 'Akt phosphorylation']","['While the processes involved in the formation, maturation and apoptosis of osteoclasts have been investigated extensively in previous studies, little is known about the mechanisms responsible for the localization and homing of osteoclast precursor cells to the bone environment in order to initiate the bone remodeling process. Recent studies have suggested that the extracellular Ca2+ (Ca2+o) concentration gradient present near the bone environment may be one of the participating factors, producing a chemoattractant effect on osteoclast precursors. Using the murine osteoclast precursor cells of the monocyte–macrophage lineage, the RAW 264.7 cell line, we have shown that Ca2+o increases the migration of these cells in a directional manner. The participation of the calcium sensing receptor (CaR) in this effect was tested by knocking down its expression through RNA interference, which resulted in an abolition of the migratory response. By the use of specific pathway inhibitors and western blot analysis, the phosphoinositide 3-kinase (PI3K)/Akt and phospholipase Cβ pathways were shown to be implicated in the migratory effect. The implication of the Akt pathway in the Ca2+o-induced chemoattraction of RAW 264.7 cells was also confirmed by transducing the cells with the fusion protein TAT-dominant negative-Akt, which decreased the migratory effect. In contrast, the MAPK pathways (ERK1/2, p38 and JNK) were not involved in the production of the migratory effect. We conclude that through the activation of the CaR and subsequent signaling via the PI3K/Akt pathway, Ca2+o produces a chemoattractant effect on the osteoclast precursor RAW 264.7 cells. These results suggest that the Ca2+o gradient present near the bone may be one of the initiating factors for the homing of osteoclast precursors to bone, thus possibly playing a role in the initiation of bone remodeling.']",https://hal.science/hal-03411296,"['0.sdv', '1.sdv.bc']"
"['Michelle Rosenzwajg', 'Guillaume Churlaud', 'Roberto Mallone', 'Adrien Six', 'Nicolas Dérian', 'Wahiba Chaara', 'Roberta Lorenzon', 'S Alice Long', 'Jane H Buckner', 'Georgia Afonso', 'Hang-Phuong Pham', 'Agnès Hartemann', 'Aixin Yu', 'Alberto Pugliese', 'Thomas R Malek', 'David Klatzmann']","[934586, 764561, 760696, 773126, 860339]",,Low-dose interleukin-2 fosters a dose-dependent regulatory T cell tuned milieu in T1D patients,hal-01112156,2015,10.1016/j.jaut.2015.01.001,"['Immunopathology', 'Inflammation', 'Tolerance', 'Immunotherapy', 'Pharmacokinetics']","['Most autoimmune diseases (AID) are linked to an imbalance between autoreactive effector T cells (Teffs) and regulatory T cells (Tregs). While blocking Teffs with immunosuppression has long been the only therapeutic option, activating/expanding Tregs may achieve the same objective without the toxicity of immunosuppression. We showed that low-dose interleukin-2 (ld-IL-2) safely expands/activates Tregs in patients with AID, such HCV-induced vasculitis and Type 1 Diabetes (T1D). Here we analyzed the kinetics and dose-relationship of IL-2 effects on immune responses in T1D patients. Ld-IL-2 therapy induced a dose-dependent increase in CD4+Foxp3+ and CD8+Foxp3+ Treg numbers and proportions, the duration of which was markedly dose-dependent. Tregs expressed enhanced levels of activation markers, including CD25, GITR, CTLA-4 and basal pSTAT5, and retained a 20-fold higher sensitivity to IL-2 than Teff and NK cells. Plasma levels of regulatory cytokines were increased in a dose-dependent manner, while cytokines linked to Teff and Th17 inflammatory cells were mostly unchanged. Global transcriptome analyses showed a dose-dependent decrease in immune response signatures. At the highest dose, Teff responses against beta-cell antigens were suppressed in all 4 patients tested. These results inform of broader changes induced by ld-IL-2 beyond direct effects on Tregs, and relevant for further development of ld-IL-2 for therapy and prevention of T1D, and other autoimmune and inflammatory diseases.']",https://hal.sorbonne-universite.fr/hal-01112156,"['0.sdv', '1.sdv.imm', '2.sdv.imm.imm']"
"['Mohamad J. Zeidan', 'David Saadoun', 'Marlene Garrido', 'David Klatzmann', 'Adrien Six', 'Patrice Cacoub']","[759697, 757052, 760696, 923051]",,Behçet’s disease physiopathology: a contemporary review,hal-01274661,2016,10.1007/s13317-016-0074-1,"['Behçet disease', 'Physiopathology', 'Autoimmunity', 'Inflammation']","['Behçet’s disease, also known as the Silk Road Disease, is a rare systemic vasculitis disorder of unknown etiology. Recurrent attacks of acute inflammation characterize Behçet’s disease. Frequent oral aphthous ulcers, genital ulcers, skin lesions and ocular lesions are the most common manifestations. Inflammation is typically self-limiting in time and relapsing episodes of clinical manifestations represent a hallmark of Behçet’s disease. Other less frequent yet severe manifestations that have a major prognostic impact involve the eyes, the central nervous system, the main large vessels and the gastrointestinal tract. Behçet’s disease has a heterogeneous onset and is associated with significant morbidity and premature mortality. This study presents a current immunological review of the disease and provides a synopsis of clinical aspects and treatment options.']",https://hal.sorbonne-universite.fr/hal-01274661,"['0.sdv', '1.sdv.mhep']"
"['Yohan Dubois', 'Sébastien Peirani', 'Christophe Pichon', 'Julien Devriendt', 'Raphaël Gavazzi', 'Charlotte Welker', 'Marta Volonteri']","[738810, 738765, 783182, 766152]","['yohan-dubois', 'christophe-pichon']",The HORIZON-AGN simulation: morphological diversity of galaxies promoted by AGN feedback,hal-03645013,2016,10.1093/mnras/stw2265,"['Methods numerical', 'Galaxies active', 'Galaxies evolution', 'Galaxies formation', 'Galaxies kinematics and dynamics', 'Astrophysics - Astrophysics of Galaxies']","['The interplay between cosmic gas accretion on to galaxies and galaxy mergers drives the observed morphological diversity of galaxies. By comparing the state-of-the-art hydrodynamical cosmological simulations HORIZON-AGN and HORIZON-NOAGN, we unambiguously identify the critical role of active galactic nuclei (AGN) in setting up the correct galaxy morphology for the massive end of the population. With AGN feedback, typical kinematic and morpho-metric properties of galaxy populations as well as the galaxy-halo mass relation are in much better agreement with observations. Only AGN feedback allows massive galaxies at the centre of groups and clusters to become ellipticals, while without AGN feedback those galaxies reform discs. It is the merger-enhanced AGN activity that is able to freeze the morphological type of the post-merger remnant by durably quenching its quiescent star formation. Hence morphology is shown to be driven not only by mass but also by the nature of cosmic accretion: at constant galaxy mass, ellipticals are galaxies that are mainly assembled through mergers, while discs are preferentially built from the in situ star formation fed by smooth cosmic gas infall.']",https://hal.science/hal-03645013,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Yohan Dubois', 'Raphaël Gavazzi', 'Sébastien Peirani', 'Joseph Silk']",[738810],['yohan-dubois'],AGN-driven quenching of star formation: morphological and dynamical implications for early-type galaxies,hal-03645498,2013,10.1093/mnras/stt997,"['Methods numerical', 'Galaxies active', 'Galaxies elliptical and lenticular', 'CD', 'Galaxies formation', 'Galaxies jets', 'Galaxies kinematics and dynamics', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['In order to understand the physical mechanisms at work during the formation of massive early-type galaxies, we performed six zoomed hydrodynamical cosmological simulations of haloes in the mass range 4.3 × 10<SUP>12</SUP> ≤ M<SUB>vir</SUB> ≤ 8.0 × 10<SUP>13</SUP> M<SUB>⊙</SUB> at z = 0, using the Adaptive Mesh Refinement code RAMSES. These simulations explore the role of active galactic nuclei (AGN), through jets powered by the accretion on to supermassive black holes on the formation of massive elliptical galaxies. In the absence of AGN feedback, large amounts of stars accumulate in the central galaxies to form overly massive, blue, compact and rotation-dominated galaxies. Powerful AGN jets transform the central galaxies into red extended and dispersion-dominated galaxies. This morphological transformation of disc galaxies into elliptical galaxies is driven by the efficient quenching of the in situ star formation due to AGN feedback, which transform these galaxies into systems built up by accretion. For galaxies mainly formed by accretion, the proportion of stars deposited farther away from the centre increases, and galaxies have larger sizes. The accretion is also directly responsible for randomizing the stellar orbits, increasing the amount of dispersion over rotation of stars as a function of time. Finally, we find that our galaxies simulated with AGN feedback better match the observed scaling laws, such as the size-mass, velocity dispersion-mass, Fundamental Plane relations and slope of the total density profiles at z ∼ 0, from dynamical and strong lensing constraints.']",https://hal.science/hal-03645498,['0.sdu']
"['Rachel Mandelbaum', 'Barnaby Rowe', 'Robert Armstrong', 'Deborah Bard', 'Emmanuel Bertin', 'James Bosch', 'Dominique Boutigny', 'Frederic Courbin', 'William A. Dawson', 'Annamaria Donnarumma', 'Ian Fenech Conti', 'Raphaël Gavazzi', 'Marc Gentile', 'Mandeep S. S. Gill', 'David W. Hogg', 'Eric M. Huff', 'M. James Jee', 'Tomasz Kacprzak', 'Martin Kilbinger', 'Thibault Kuntzer', 'Dustin Lang', 'Wentao Luo', 'Marisa C. March', 'Philip J. Marshall', 'Joshua E. Meyers', 'Lance Miller', 'Hironao Miyatake', 'Reiko Nakajima', 'Fred Maurice Ngolé Mboula', 'Guldariya Nurbaeva', 'Yuki Okura', 'Stéphane Paulin-Henriksson', 'Jason Rhodes', 'Michael D. Schneider', 'Huanyuan Shan', 'Erin S. Sheldon', 'Melanie Simet', 'Jean-Luc Starck', 'Florent Sureau', 'Malte Tewes', 'Kristian Zarb Adami', 'Jun Zhang', 'Joe Zuntz']","[760422, 976697, 760762, 755435]",,GREAT3 results - I. Systematic errors in shear estimation and the impact of real galaxy morphology,insu-03644902,2015,10.1093/mnras/stv781,"['Gravitational lensing weak', 'Methods data analysis', 'Techniques image processing', 'Cosmology observations', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","[""We present first results from the third GRavitational lEnsing Accuracy Testing (GREAT3) challenge, the third in a sequence of challenges for testing methods of inferring weak gravitational lensing shear distortions from simulated galaxy images. GREAT3 was divided into experiments to test three specific questions, and included simulated space- and ground-based data with constant or cosmologically varying shear fields. The simplest (control) experiment included parametric galaxies with a realistic distribution of signal-to-noise, size, and ellipticity, and a complex point spread function (PSF). The other experiments tested the additional impact of realistic galaxy morphology, multiple exposure imaging, and the uncertainty about a spatially varying PSF; the last two questions will be explored in Paper II. The 24 participating teams competed to estimate lensing shears to within systematic error tolerances for upcoming Stage-IV dark energy surveys, making 1525 submissions overall. GREAT3 saw considerable variety and innovation in the types of methods applied. Several teams now meet or exceed the targets in many of the tests conducted (to within the statistical errors). We conclude that the presence of realistic galaxy morphology in simulations changes shear calibration biases by ∼1 per cent for a wide range of methods. Other effects such as truncation biases due to finite galaxy postage stamps, and the impact of galaxy type as measured by the Sérsic index, are quantified for the first time. Our results generalize previous studies regarding sensitivities to galaxy size and signal-to-noise, and to PSF properties such as seeing and defocus. Almost all methods' results support the simple model in which additive shear biases depend linearly on PSF ellipticity.""]",https://insu.hal.science/insu-03644902,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Justin Alsing', 'Tom Charnock', 'Stephen Feeney', 'Benjamin Wandelt']",,,Fast likelihood-free cosmology with neural density estimators and active learning,hal-02088678,2019,10.1093/mnras/stz1960,['Data analysis methods'],"['Likelihood-free inference provides a framework for performing rigorous Bayesian inference using only forward simulations, properly accounting for all physical and observational effects that can be successfully included in the simulations. The key challenge for likelihood-free applications in cosmology, where simulation is typically expensive, is developing methods that can achieve high-fidelity posterior inference with as few simulations as possible. Density-estimation likelihood-free inference (DELFI) methods turn inference into a density-estimation task on a set of simulated data-parameter pairs, and give orders of magnitude improvements over traditional Approximate Bayesian Computation approaches to likelihood-free inference. In this paper, we use neural density estimators (NDEs) to learn the likelihood function from a set of simulated data sets, with active learning to adaptively acquire simulations in the most relevant regions of parameter space on the fly. We demonstrate the approach on a number of cosmological case studies, showing that for typical problems high-fidelity posterior inference can be achieved with just |$\\mathcal {O}(10^3)$| simulations or fewer. In addition to enabling efficient simulation-based inference, for simple problems where the form of the likelihood is known, DELFI offers a fast alternative to Markov Chain Monte Carlo (MCMC) sampling, giving orders of magnitude speed-up in some cases. Finally, we introduce pydelfi – a flexible public implementation of DELFI with NDEs and active learning – available at https://github.com/justinalsing/pydelfi.']",https://hal.science/hal-02088678,"['0.phys', '1.phys.astr']"
"['Justin Alsing', 'Benjamin Wandelt', 'Stephen Feeney']",,,"Massive optimal data compression and density estimation for scalable, likelihood-free inference in cosmology",hal-01703719,2018,10.1093/mnras/sty819,['Methods data analysis'],"['Many statistical models in cosmology can be simulated forwards but have intractable likelihood functions. Likelihood-free inference methods allow us to perform Bayesian inference from these models using only forward simulations, free from any likelihood assumptions or approximations. Likelihood-free inference generically involves simulating mock data and comparing to the observed data; this comparison in data space suffers from the curse of dimensionality and requires compression of the data to a small number of summary statistics to be tractable. In this paper, we use massive asymptotically optimal data compression to reduce the dimensionality of the data space to just one number per parameter, providing a natural and optimal framework for summary statistic choice for likelihood-free inference. Secondly, we present the first cosmological application of Density Estimation Likelihood-Free Inference (delfi), which learns a parametrized model for joint distribution of data and parameters, yielding both the parameter posterior and the model evidence. This approach is conceptually simple, requires less tuning than traditional Approximate Bayesian Computation approaches to likelihood-free inference and can give high-fidelity posteriors from orders of magnitude fewer forward simulations. As an additional bonus, it enables parameter inference and Bayesian model comparison simultaneously. We demonstrate delfi with massive data compression on an analysis of the joint light-curve analysis supernova data, as a simple validation case study. We show that high-fidelity posterior inference is possible for full-scale cosmological data analyses with as few as ∼10^4 simulations, with substantial scope for further improvement, demonstrating the scalability of likelihood-free inference to large and complex cosmological data sets.']",https://hal.science/hal-01703719,"['0.phys', '1.phys.astr']"
"['Sandrine Codis', 'Christophe Pichon', 'Julien Devriendt', 'Adrianne Slyz', 'Dmitry Pogosyan', 'Yohan Dubois', 'Thierry Sousbie']","[738807, 738765, 783182, 738810]","['scodis', 'christophe-pichon', 'yohan-dubois']",Connecting the cosmic web to the spin of dark haloes: implications for galaxy formation,hal-03645694,2012,10.1111/j.1365-2966.2012.21636.x,"['Methods numerical', 'Galaxies formation', 'Galaxies haloes', 'Large-scale structure of Universe', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","[""We investigate the alignment of the spin of dark matter haloes relative (i) to the surrounding large-scale filamentary structure, and (ii) to the tidal tensor eigenvectors using the Horizon 4π dark matter simulation which resolves over 43 million dark matter haloes at redshift zero. We detect a clear mass transition: the spin of dark matter haloes above a critical mass M0s≈5(±1)×1012 M tends to be perpendicular to the closest large-scale filament (with an excess probability of up to 12 per cent), and aligned with the intermediate axis of the tidal tensor (with an excess probability of up to 40 per cent), whereas the spin of low-mass haloes is more likely to be aligned with the closest filament (with an excess probability of up to 15 per cent). Furthermore, this critical mass is redshift-dependent, scaling as M crit s(z)≈M0s(1+z)-γs with γ<SUB>s</SUB> = 2.5 ± 0.2. A similar fit for the redshift evolution of the tidal tensor transition mass yields M0t≈8(±2)×1012 M and γ<SUB>t</SUB> = 3 ± 0.3. This critical mass also varies weakly with the scale defining filaments. <P />We propose an interpretation of this signal in terms of large-scale cosmic flows. In this picture, most low-mass haloes are formed through the winding of flows embedded in misaligned walls; hence, they acquire a spin parallel to the axis of the resulting filaments forming at the intersection of these walls. On the other hand, more massive haloes are typically the products of later mergers along such filaments, and thus they acquire a spin perpendicular to this direction when their orbital angular momentum is converted into spin. We show that this scenario is consistent with both measured excess probabilities of alignment with respect to the eigendirections of the tidal tensor, and halo merger histories. On a more qualitative level, it also seems compatible with 3D visualization of the structure of the cosmic web as traced by 'smoothed' dark matter simulations or gas tracer particles. Finally, it provides extra support to the disc-forming paradigm presented by Pichon et al. as it extends it by characterizing the geometry of secondary infall at high redshift.""]",https://hal.science/hal-03645694,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Yohan Dubois', 'Ricarda Beckmann', 'Frédéric Bournaud', 'Hoseung Choi', 'Julien Devriendt', 'Ryan Jackson', 'Sugata Kaviraj', 'Taysun Kimm', 'Katarina Kraljic', 'Clotilde Laigle', 'Garreth Martin', 'Min-Jung Park', 'Sébastien Peirani', 'Christophe Pichon', 'Marta Volonteri', 'Sukyoung K. Yi']","[738810, 798436, 798080, 783182, 755810, 783719, 768572, 769791, 798079, 738765, 766152]","['yohan-dubois', 'christophe-pichon']",Introducing the NEWHORIZON simulation: Galaxy properties with resolved internal dynamics across cosmic time,hal-03306199,2021,10.1051/0004-6361/202039429,"['Galaxies general', 'Galaxies evolution', 'Galaxies stellar content', 'Galaxies kinematics and dynamics', 'Methods numerical']","['Hydrodynamical cosmological simulations are increasing their level of realism by considering more physical processes and having greater resolution or larger statistics. However, usually either the statistical power of such simulations or the resolution reached within galaxies are sacrificed. Here, we introduce the NEWHORIZON project in which we simulate at high resolution a zoom-in region of ∼(16\u2006Mpc)3 that is larger than a standard zoom-in region around a single halo and is embedded in a larger box. A resolution of up to 34\u2006pc, which is typical of individual zoom-in, up-to-date resimulated halos, is reached within galaxies; this allows the simulation to capture the multi-phase nature of the interstellar medium and the clumpy nature of the star formation process in galaxies. In this introductory paper, we present several key fundamental properties of galaxies and their black holes, including the galaxy mass function, cosmic star formation rate, galactic metallicities, the Kennicutt–Schmidt relation, the stellar-to-halo mass relation, galaxy sizes, stellar kinematics and morphology, gas content within galaxies and its kinematics, and the black hole mass and spin properties over time. The various scaling relations are broadly reproduced by NEWHORIZON with some differences with the standard observables. Owing to its exquisite spatial resolution, NEWHORIZON captures the inefficient process of star formation in galaxies, which evolve over time from being more turbulent, gas rich, and star bursting at high redshift. These high-redshift galaxies are also more compact, and they are more elliptical and clumpier until the level of internal gas turbulence decays enough to allow for the formation of discs. The NEWHORIZON simulation gives access to a broad range of galaxy formation and evolution physics at low-to-intermediate stellar masses, which is a regime that will become accessible in the near future through surveys such as the LSST.']",https://hal.science/hal-03306199,"['0.phys', '1.phys.astr']"
"['Nora Elisa Chisari', 'Mark L.A. Richardson', 'Julien Devriendt', 'Yohan Dubois', 'Aurel Schneider', 'Amandine Le Brun', 'Ricarda S. Beckmann', 'Sebastien Peirani', 'Adrianne Slyz', 'Christophe Pichon']","[783182, 738810, 738765]","['yohan-dubois', 'christophe-pichon']",The impact of baryons on the matter power spectrum from the Horizon-AGN cosmological hydrodynamical simulation,hal-01707538,2018,10.1093/mnras/sty2093,"['Gravitational lensing weak', 'Methods numerical', 'Large-scale structure of Universe', 'Cosmology theory']","['Accurate cosmology from upcoming weak lensing surveys relies on knowledge of the total matter power spectrum at per cent level at scales k < 10 h\u2009Mpc^−1, for which modelling the impact of baryonic physics is crucial. We compare measurements of the total matter power spectrum from the Horizon cosmological hydrodynamical simulations: a dark-matter-only run, one with full baryonic physics, and another lacking active galactic nucleus (AGN) feedback. Baryons cause a suppression of power at k ≃ 10 h\u2009Mpc^−1 of |${\\lt}15{{\\ \\rm per\\ cent}}$| at |$z$| = 0, and an enhancement of a factor of a few at smaller scales due to the more efficient cooling and star formation. The results are sensitive to the presence of the highest mass haloes in the simulation and the distribution of dark matter is also impacted up to a few per cent. The redshift evolution of the effect is non-monotonic throughout |$z$| = 0−5 due to an interplay between AGN feedback and gas pressure, and the growth of structure. We investigate the effectiveness of an analytic ‘baryonic correction model’ in describing our results. We require a different redshift evolution and propose an alternative fitting function with four free parameters that reproduces our results within |$5{{\\ \\rm per\\ cent}}$|\u2060. Compared to other simulations, we find the impact of baryonic processes on the total matter power spectrum to be smaller at |$z$| = 0. Correspondingly, our results suggest that AGN feedback is not strong enough in the simulation. Total matter power spectra from the Horizon simulations are made publicly available at https://www.horizon-simulation.org/catalogues.html.']",https://hal.science/hal-01707538,"['0.phys', '1.phys.astr']"
"['Jonathan Carrick', 'Stephen J. Turnbull', 'Guilhem Lavaux', 'Michael J. Hudson']",[738873],['g-lavaux'],Cosmological parameters from the comparison of peculiar velocities with predictions from the 2M++ density field,insu-03644924,2015,10.1093/mnras/stv547,"['Local Group', 'Cosmic background radiation', 'Cosmological parameters', 'Large-scale structure of Universe', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['Peculiar velocity measurements are the only tool available in the low-redshift Universe for mapping the large-scale distribution of matter and can thus be used to constrain cosmology. Using redshifts from the 2M++ redshift compilation, we reconstruct the density of galaxies within 200 h<SUP>-1</SUP> Mpc, allowing for the first time good sampling of important superclusters such as the Shapley Concentration. We compare the predicted peculiar velocities from 2M++ to Tully-Fisher and SNe peculiar velocities. We find a value of β* ≡ Ω <SUB>m</SUB>^{0.55}/b^* = 0.431 ± 0.021, suggesting Ω <SUB>m</SUB>^{0.55}σ _{8,lin} = 0.401 ± 0.024, in good agreement with other probes. The predicted peculiar velocity of the Local Group arising from the 2M++ volume alone is 540 ± 40 km s<SUP>-1</SUP>, towards l = 268° ± 4°, b = 38° ± 6°, only 10° out of alignment with the cosmic microwave background dipole. To account for velocity contributions arising from sources outside the 2M++ volume, we fit simultaneously for β* and an external bulk flow in our analysis. We find that an external bulk flow is preferred at the 5.1σ level, and the best fit has a velocity of 159 ± 23 km s<SUP>- 1</SUP> towards l = 304° ± 11°, b = 6° ± 13°. Finally, the predicted bulk flow of a 50 h<SUP>-1</SUP> Mpc Gaussian-weighted volume centred on the Local Group is 230 ± 30 km s<SUP>-1</SUP>, in the direction l = 293° ± 8°, b = 14° ± 10°, in agreement with predictions from Λ cold dark matter.']",https://insu.hal.science/insu-03644924,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Guilhem Lavaux', 'Michael J. Hudson']",[738873],['g-lavaux'],The 2M++ galaxy redshift catalogue,insu-03645868,2011,10.1111/j.1365-2966.2011.19233.x,['Astrophysics - Cosmology and Nongalactic Astrophysics'],"['Peculiar velocities arise from gravitational instability, and thus are linked to the surrounding distribution of matter. In order to understand the motion of the Local Group with respect to the cosmic microwave background, a deep all-sky map of the galaxy distribution is required. Here we present a new redshift compilation of 69 160 galaxies, dubbed 2M++, to map large-scale structures of the local Universe over nearly the whole sky, and reaching depths of K≤ 12.5, or 200 h<SUP>-1</SUP> Mpc. The target catalogue is based on the Two-Micron All-Sky Survey Extended Source Catalog (2MASS-XSC). The primary sources of redshifts are the 2MASS Redshift Survey, the 6dF galaxy redshift survey and the Sloan Digital Sky Survey (Data Release 7). We assess redshift completeness in each region and compute the weights required to correct for redshift incompleteness and apparent magnitude limits, and discuss corrections for incompleteness in the zone of avoidance. We present the density field for this survey, and discuss the importance of large-scale structures such as the Shapley Concentration.']",https://insu.hal.science/insu-03645868,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Jens Jasche', 'Guilhem Lavaux']",[738873],['g-lavaux'],Physical Bayesian modelling of the non-linear matter distribution: new insights into the Nearby Universe,hal-01846806,2019,10.1051/0004-6361/201833710,"['Methods data analysis', 'Large-scale structure of Universe', 'Methods statistical', 'Cosmology observations', 'Galaxies statistics']","['Accurate analyses of present and next-generation cosmological galaxy surveys require new ways to handle effects of non-linear gravitational structure formation processes in data. To address these needs we present an extension of our previously developed algorithm for Bayesian Origin Reconstruction from Galaxies (BORG) to analyse matter clustering at non-linear scales in observations. This is achieved by incorporating a numerical particle mesh model of gravitational structure formation into our Bayesian inference framework. The algorithm simultaneously infers the three-dimensional primordial matter fluctuations from which present non-linear observations formed and provides reconstructions of velocity fields and structure formation histories. The physical forward modelling approach automatically accounts for the non-Gaussian features in gravitationally evolved matter density fields and addresses the redshift space distortion problem associated with peculiar motions of observed galaxies. Our algorithm employs a hierarchical Bayes approach to jointly account for various observational effects, such as unknown galaxy biases, selection effects, and observational noise. Corresponding parameters of the data model are marginalized out via a sophisticated Markov chain Monte Carlo approach relying on a combination of a multiple block sampling framework and an efficient implementation of a Hamiltonian Monte Carlo sampler. We demonstrate the performance of the method by applying it to the 2M++ galaxy compilation, tracing the matter distribution of the nearby universe. We show accurate and detailed inferences of the three-dimensional non-linear dark matter distribution of the nearby universe. As exemplified in the case of the Coma cluster, our method provides complementary mass estimates that are compatible with those obtained from weak lensing and X-ray observations. For the first time, we also present a reconstruction of the vorticity of the non-linear velocity field from observations. In summary, our method provides plausible and very detailed inferences of the dark matter and velocity fields of our cosmic neighbourhood.Key words: methods: data analysis / large-scale structure of Universe / methods: statistical / cosmology: observations / galaxies: statistics']",https://hal.science/hal-01846806,"['0.phys', '1.phys.astr']"
"['Supranta S. Boruah', 'Michael J. Hudson', 'Guilhem Lavaux']",[738873],['g-lavaux'],Cosmic flows in the nearby Universe: new peculiar velocities from SNe and cosmological constraints,hal-02467203,2020,10.1093/mnras/staa2485,"['Galaxy kinematics and dynamics', 'Galaxies statistics', 'Large-scale structure of Universe', 'Cosmology observations']","['The peculiar velocity field offers a unique way to probe dark matter density field on large scales at low redshifts. In this work, we have compiled a new sample of 465 peculiar velocities from low redshift (\u2060|$z$| < 0.067) Type Ia supernovae. We compare the reconstructed velocity field derived from the 2M++ galaxy redshift compilation to the supernovae, the SFI++\xa0and the 2MTF Tully–Fisher distance catalogues. We used a forward method to jointly infer the distances and the velocities of distance indicators by comparing the observations to the reconstruction. Comparison of the reconstructed peculiar velocity fields to observations allows us to infer the cosmological parameter combination fσ_8, and the bulk flow velocity arising from outside the survey volume. The residual bulk flow arising from outside the 2M++\xa0volume is inferred to be |$171^{+11}_{-11}$| km s^−1 in the direction l\xa0= 301° ± 4° and b\xa0= 0° ± 3°. We obtain fσ_8\xa0= 0.400\xa0±\xa00.017, equivalent to S_8 ≈ σ_8(Ω_m/0.3)^0.55\xa0= 0.776\xa0±\xa00.033, which corresponds to an approximately |$4{{\\ \\rm per\\ cent}}\\,$| statistical uncertainty on the value of fσ_8. Our inferred value is consistent with other low redshift results in the literature.']",https://hal.science/hal-02467203,"['0.phys', '1.phys.astr']"
"['P. M. Sutter', 'Guilhem Lavaux', 'Nico Hamaus', 'Benjamin D. Wandelt', 'David H. Weinberg', 'Michael S. Warren']",[738873],['g-lavaux'],"Sparse sampling, galaxy bias, and voids",insu-03645359,2014,10.1093/mnras/stu893,"['Methods data analysis', 'Methods numerical', 'Cosmology theory', 'Large-scale structure of Universe', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['To study the impact of sparsity and galaxy bias on void statistics, we use a single large-volume, high-resolution N-body simulation to compare voids in multiple levels of subsampled dark matter, halo populations, and mock galaxies from a halo occupation distribution model tuned to different galaxy survey densities. We focus our comparison on three key observational statistics: number functions, ellipticity distributions, and radial density profiles. We use the hierarchical tree structure of voids to interpret the impacts of sampling density and galaxy bias, and theoretical and empirical functions to describe the statistics in all our sample populations. We are able to make simple adjustments to theoretical expectations to offer prescriptions for translating from analytics to the void properties measured in realistic observations. We find that sampling density has a much larger effect on void sizes than galaxy bias. At lower tracer density, small voids disappear and the remaining voids are larger, more spherical, and have slightly steeper profiles. When a proper lower mass threshold is chosen, voids in halo distributions largely mimic those found in galaxy populations, except for ellipticities, where galaxy bias leads to higher values. We use the void density profile of Hamaus et al. to show that voids follow a self-similar and universal trend, allowing simple translations between voids studied in dark matter and voids identified in galaxy surveys. We have added the mock void catalogues used in this work to the Public Cosmic Void Catalog at http://www.cosmicvoids.net.']",https://insu.hal.science/insu-03645359,['0.sdu']
"['P. M. Sutter', 'Guilhem Lavaux', 'Benjamin D. Wandelt', 'David H. Weinberg', 'Michael S. Warren', 'Alice Pisani']",[738873],['g-lavaux'],"Voids in the SDSS DR9: observations, simulations, and the impact of the survey mask",insu-03645337,2014,10.1093/mnras/stu1094,"['Methods data analysis', 'Cosmology observations', 'Large-scale structure of Universe', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['We present and study cosmic voids identified using the watershed void finder VIDE in the Sloan Digital Sky Survey Data Release 9, compare these voids to ones identified in mock catalogues, and assess the impact of the survey mask on void statistics such as number functions, ellipticity distributions, and radial density profiles. The nearly 1000 identified voids span three nearly volume-limited samples from redshift z = 0.43 to 0.7. For comparison, we use 98 of the publicly available second-order Lagrangian perturbation theory-based mock galaxy catalogues of Manera et al., and also generate our own mock catalogues by applying a Halo Occupation Distribution model to an N-body simulation. We find that the mask reduces the number density of voids at all scales by a factor of 3 and slightly skews the relative size distributions. This engenders an increase in the mean ellipticity by roughly 30 per cent. However, we find that radial density profiles are largely robust to the effects of the mask. We see excellent agreement between the data and both mock catalogues, and find no tension between the observed void properties and the properties derived from Λcolddarkmatter simulations. We have added the void catalogues from both data and mock galaxy populations discussed in this work to the Public Cosmic Void Catalog at http://www.cosmicvoids.net.']",https://insu.hal.science/insu-03645337,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Guilhem Lavaux', 'Jens Jasche']",[738873],['g-lavaux'],Unmasking the masked Universe: the 2M++ catalogue through Bayesian eyes,insu-03747403,2016,10.1093/mnras/stv2499,"['Methods data analysis', 'Methods statistical', 'Galaxies statistics', 'Large-scale structure of Universe', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['This work describes a full Bayesian analysis of the Nearby Universe as traced by galaxies of the 2M++ survey. The analysis is run in two sequential steps. The first step self-consistently derives the luminosity-dependent galaxy biases, the power spectrum of matter fluctuations and matter density fields within a Gaussian statistic approximation. The second step makes a detailed analysis of the three-dimensional large-scale structures, assuming a fixed bias model and a fixed cosmology. This second step allows for the reconstruction of both the final density field and the initial conditions at z = 1000 assuming a fixed bias model. From these, we derive fields that self-consistently extrapolate the observed large-scale structures. We give two examples of these extrapolation and their utility for the detection of structures: the visibility of the Sloan Great Wall, and the detection and characterization of the Local Void using DIVA, a Lagrangian based technique to classify structures.']",https://insu.hal.science/insu-03747403,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Suvodip Mukherjee', 'Guilhem Lavaux', 'François R. Bouchet', 'Jens Jasche', 'Benjamin D. Wandelt', 'Samaya Nissanke', 'Florent Leclercq', 'Kenta Hotokezaka']","[738873, 1181873]","['g-lavaux', 'florent-leclercq']",Velocity correction for Hubble constant measurements from standard sirens,hal-03135361,2021,10.1051/0004-6361/201936724,"['Gravitational waves', 'Cosmological parameters', 'Galaxies peculiar', 'Cosmology observations']","['Gravitational wave (GW) sources are an excellent probe of the luminosity distance and offer a novel measure of the Hubble constant, H0. This estimation of H0 from standard sirens requires an accurate estimation of the cosmological redshift of the host galaxy of the GW source after correcting for its peculiar velocity. The absence of an accurate peculiar velocity correction affects both the precision and accuracy of the measurement of H0, particularly for nearby sources. Here, we propose a framework to incorporate such a peculiar velocity correction for GW sources. A first implementation of our method to the event GW170817, combined with observations taken with Very Large Baseline Interferometry (VLBI), leads to a revised value of H0 = 68.3−4.5+4.6 km s−1 Mpc−1. While this revision is minor, it demonstrates that our method makes it possible to obtain unbiased and accurate measurements of H0 at the precision required for the standard siren cosmology.']",https://hal.science/hal-03135361,"['0.phys', '1.phys.astr']"
"['Stuart Mcalpine', 'John C. Helly', 'Matthieu Schaller', 'Till Sawala', 'Guilhem Lavaux', 'Jens Jasche', 'Carlos S. Frenk', 'Adrian Jenkins', 'John R. Lucey', 'Peter H. Johansson']","[800142, 785437, 738873, 784733]",['g-lavaux'],SIBELIUS-DARK: a galaxy catalogue of the local volume from a constrained realization simulation,hal-03597289,2022,10.1093/mnras/stac295,"['Methods numerical', 'Galaxies formation', 'Cosmology theory', 'Dark matter', 'Large-scale structure of Universe']","['We present sibelius-dark, a constrained realization simulation of the local volume to a distance of 200\xa0Mpc from the Milky Way. sibelius-dark is the first study of the ‘Simulations Beyond The Local Universe’ (sibelius) project, which has the goal of embedding a model Local Group-like system within the correct cosmic environment. The simulation is dark-matter-only, with the galaxy population calculated using the semi-analytic model of galaxy formation, galform. We demonstrate that the large-scale structure that emerges from the sibelius constrained initial conditions matches well the observational data. The inferred galaxy population of sibelius-dark also match well the observational data, both statistically for the whole volume and on an object-by-object basis for the most massive clusters. For example, the K-band number counts across the whole sky, and when divided between the northern and southern Galactic hemispheres, are well reproduced by sibelius-dark. We find that the local volume is somewhat unusual in the wider context of ΛCDM: it contains an abnormally high number of supermassive clusters, as well as an overall large-scale underdensity at the level of ≈5\xa0per\u2009cent relative to the cosmic mean. However, whilst rare, the extent of these peculiarities does not significantly challenge the ΛCDM model. sibelius-dark is the most comprehensive constrained realization simulation of the local volume to date, and with this paper we publicly release the halo and galaxy catalogues at z\xa0= 0, which we hope will be useful to the wider astronomy community.']",https://hal.science/hal-03597289,"['0.phys', '1.phys.astr']"
"['Rafael Alves Batista', 'Rogerio M. de Almeida', 'Bruno Lago', 'Kumiko Kotera']",,,Cosmogenic photon and neutrino fluxes in the Auger era,hal-01839700,2019,10.1088/1475-7516/2019/01/002,"['Cosmic radiation UHE', 'Redshift dependence', 'Gamma ray burst', 'Star formation', 'Photon flux', 'Neutrino flux', 'Power spectrum', 'Observatory', 'Auger', 'Injection', 'Spectral', 'Nitrogen', 'Silicon', 'Nucleus', 'History', 'AGN']","['The interaction of ultra-high-energy cosmic rays (UHECRs) with pervasive photon fields generates associated cosmogenic fluxes of neutrinos and photons due to photohadronic and photonuclear processes taking place in the intergalactic medium. We perform a fit of the UHECR spectrum and composition measured by the Pierre Auger Observatory for four source emissivity scenarios: power-law redshift dependence with one free parameter, active galactic nuclei, gamma-ray bursts, and star formation history. We show that negative source emissivity evolution is favoured if we treat the source evolution as a free parameter. In all cases, the best fit is obtained for relatively hard spectral indices and low maximal rigidities, for compositions at injection dominated by intermediate nuclei (nitrogen and silicon groups). In light of these results, we calculate the associated fluxes of neutrinos and photons. Finally, we discuss the prospects for the future generation of high-energy neutrino and gamma-ray observatories to constrain the sources of UHECRs.']",https://hal.science/hal-01839700,"['0.phys', '1.phys.astr']"
"['Kumiko Kotera', 'Elena Amato', 'Pasquale Blasi']",,,The fate of ultrahigh energy nuclei in the immediate environment of young fast-rotating pulsars,insu-03644884,2015,10.1088/1475-7516/2015/08/026,['Astrophysics - High Energy Astrophysical Phenomena'],"[""Young, fast-rotating neutron stars are promising candidate sources for the production of ultrahigh energy cosmic rays (UHECRs). The interest in this model has recently been boosted by the latest chemical composition measurements of cosmic rays, that seem to show the presence of a heavy nuclear component at the highest energies. Neutrons stars, with their metal-rich surfaces, are potentially interesting sources of such nuclei, but some open issues remain: 1) is it possible to extract these nuclei from the star's surface? 2) Do the nuclei survive the severe conditions present in the magnetosphere of the neutron star? 3) What happens to the surviving nuclei once they enter the wind that is launched outside the light cylinder? In this paper we address these issues in a quantitative way, proving that for the most reasonable range of neutron star surface temperatures (T<10<SUP>7</SUP> K), a large fraction of heavy nuclei survive photo-disintegration losses. These processes, together with curvature losses and acceleration in the star's electric potential, lead to injection of nuclei with a chemical composition that is mixed, even if only iron is extracted from the surface. We show that under certain conditions the chemical composition injected into the wind region is compatible with that required in previous work based on purely phenomenological arguments (typically ~50% protons, ~30% CNO and ~20% Fe), and provides a reasonable explanation of the mass abundance inferred from ultra high energy data.""]",https://insu.hal.science/insu-03644884,['0.sdu']
"['Ke Fang', 'Brian D. Metzger', 'Kohta Murase', 'Imre Bartos', 'Kumiko Kotera']",,,Multimessenger Implications of AT2018cow: High-energy Cosmic-Ray and Neutrino Emissions from Magnetar-powered Superluminous Transients,hal-01982915,2019,10.3847/1538-4357/ab1b72,"['Neutrino flux', 'IceCube sensitivity', 'Baryon background', 'Gamma ray burst', 'Gamma ray energy', 'Photon thermal', 'Magnetar', 'Observatory', 'Supernova luminosity', 'Optical', 'UHE', 'Astroparticle physics', 'Supernovae general', 'Cosmic radiation interaction', 'Cosmic radiation production', 'Messenger']","['Newly born, rapidly spinning magnetars have been invoked as the power sources of superluminous transients, including the class of “fast blue optical transients” (FBOTs). The extensive multiwavelength analysis of AT2018cow, the first FBOT discovered in real time, is consistent with the magnetar scenario and offers an unprecedented opportunity to comprehend the nature of these sources and assess their broader implications. Using AT2018cow as a prototype, we investigate high-energy neutrino and cosmic-ray production from FBOTs and the more general class of superluminous supernovae (SLSNe). By calculating the interaction of cosmic rays and the time-evolving radiation field and baryon background, we find that particles accelerated in the magnetar wind may escape the ejecta at ultrahigh energies. The predicted high-energy neutrino fluence from AT2018cow is below the sensitivity of the IceCube Observatory, and estimates of the cosmically integrated neutrino flux from FBOTs are consistent with the extreme-high-energy upper limits posed by IceCube. High-energy γ rays exceeding GeV energies are obscured for the first months to years by thermal photons in the magnetar nebula, but are potentially observable at later times. Given their potentially higher volumetric rate compared to other engine-powered transients (e.g., SLSNe and gamma-ray bursts), we conclude that FBOTs are favorable targets for current and next-generation multimessenger observatories.']",https://hal.science/hal-01982915,"['0.phys', '1.phys.astr']"
"['Claire Guépin', 'Benoît Cerutti', 'Kumiko Kotera']",,,Proton acceleration in pulsar magnetospheres,hal-02403730,2020,10.1051/0004-6361/201936816,"['Pulsars general -acceleration of particles -methods numerical', 'Pulsars general', 'Acceleration of particles', 'Methods numerical', 'P acceleration', 'Pair production yield', 'Cosmic radiation acceleration', 'P yield', 'Particle acceleration', 'Energy kinetic', 'Electric field induced', 'Neutron star surface', 'Electric field high', 'Star rotation', 'Symmetry axial', 'Pulsar', 'Electron', 'Cosmic radiation UHE', 'Electromagnetic field', 'Positron', 'Lorentz', 'Site', 'Pole', 'Spin', 'Gap']","['Pulsars have been identified as good candidates for the acceleration of cosmic rays, up to ultra-high energies. However, a precise description of the acceleration processes at play is still to be established. Using 2D particle-in-cell simulations, we study proton acceleration in axisymmetric pulsar magnetospheres. Protons and electrons are extracted from the neutron star surface by the strong electric field induced by the rotation of the star, and electrons and positrons are produced in the magnetosphere through pair production process. As pair production has a crucial impact on electromagnetic fields, on gaps and thus on particle acceleration, we study its influence on the maximum energy and luminosity of protons escaping the magnetosphere. Protons are accelerated and escape in all our simulations. However, the acceleration sites are different for the protons and the pairs. As shown in previous studies, pairs are accelerated to their highest energies at the Y-point and in the equatorial current sheet, where magnetic reconnection plays an important role. In contrast, protons gain most of their kinetic energy below the light-cylinder radius within the separatrix current layers, but they are not confined within the equatorial current sheet. Their maximum Lorentz factors can reach 15% to 75% of the maximum Lorentz factor obtained by acceleration through the full vacuum potential drop from pole to equator, and increase with decreasing pair production. Their luminosity can reach 0.2% to 4% of the theoretical spin down luminosity of an aligned pulsar, and the minimum luminosity is obtained at the transition between the force-free and electrosphere regimes. These estimates support that millisecond pulsars could accelerate cosmic rays up to PeV energies and that new born millisecond pulsars could accelerate cosmic rays up to ultra-high energies.Key words: pulsars: general / acceleration of particles / methods: numerical']",https://hal.science/hal-02403730,"['0.phys', '1.phys.astr']"
"['Clarisse Aujoux', 'Kumiko Kotera', 'Odile Blanchard']",[3557],['odile-blanchard'],"Estimating the carbon footprint of the GRAND project, a multi-decade astrophysics experiment",hal-03228304,2021,10.1016/j.astropartphys.2021.102587,"['Greenhouse gas emission', 'Carbon footprint', 'Climate change', 'Large-scale astrophysics experiment', 'Radio-detection']","['We present a pioneering estimate of the global yearly greenhouse gas emissions of a large-scale Astrophysics experiment over several decades: the Giant Array for Neutrino Detection (GRAND). The project aims at detecting ultra-high energy neutrinos with a 200,000 radio antenna array over 200,000 km as of the 2030s. With a fully transparent methodology based on open source data, we calculate the emissions related to three unavoidable sources: travel, digital technologies and hardware equipment. We find that these emission sources have a different impact depending on the stages of the experiment. Digital technologies and travel prevail for the small-scale prototyping phase (GRANDProto300), whereas hardware equipment (material production and transportation) and data transfer/storage largely outweigh the other emission sources in the large-scale phase (GRAND200k). In the mid-scale phase (GRAND10k), the three sources contribute equally. This study highlights the considerable carbon footprint of a large-scale astrophysics experiment, but also shows that there is room for improvement. We discuss various lines of actions that could be implemented. The GRAND project being still in its prototyping stage, our results provide guidance to the future collaborative practices and instrumental design in order to reduce its carbon footprint.']",https://hal.science/hal-03228304,"['0.sde', '0.sdu', '0.shs', '1.shs.eco']"
"['Claire Guépin', 'Kumiko Kotera', 'Foteini Oikonomou']",,,High-energy neutrino transients and the future of multi-messenger astronomy,hal-03752040,2022,10.1038/s42254-022-00504-9,"['Particle acceleration', 'Electromagnetic', 'Messenger', 'Particle interaction', 'Landscape']","['The recent discovery of high-energy astrophysical neutrinos and first hints of coincident electromagnetic and neutrino emission herald the beginning of the era of multi-messenger astronomy. Due to their high power, transient sources are expected to supply a significant fraction of the observed energetic astroparticles, through enhanced particle acceleration and interactions. Here, we review theoretical expectations of neutrino emission from transient astrophysical sources and the current and upcoming experimental landscape, highlighting the most promising channels for discovery and specifying their detectability.']",https://hal.science/hal-03752040,"['0.phys', '1.phys.astr']"
"['Claire Guépin', 'Kumiko Kotera', 'Enrico Barausse', 'Ke Fang', 'Kohta Murase']",,,Ultra-High Energy Cosmic Rays and Neutrinos from Tidal Disruptions by Massive Black Holes,hal-01886575,2018,10.1051/0004-6361/201732392,"['Cosmic radiation UHE', 'Cosmic radiation production', 'Neutrino production', 'Cosmic radiation spectrum', 'Neutrino flux', 'Nucleus energy', 'Energy high', 'P', 'Luminosity', 'Black hole', 'Propagation', 'Signature', 'Redshift', 'IceCube', 'Photon', 'Auger', 'Star', 'Yukawa']","['Tidal disruptions are extremely powerful phenomena that have been designated as candidate sources of ultra-high-energy cosmic rays. The disruption of a star by a black hole can naturally provide protons and heavier nuclei, which can be injected and accelerated to ultra-high energies within a jet. Inside the jet, accelerated nuclei are likely to interact with a dense photon field, leading to a significant production of neutrinos and secondary particles. We model numerically the propagation and interactions of high-energy nuclei in jetted tidal disruption events in order to evaluate consistently their signatures in cosmic rays and neutrinos. We propose a simple model of the light curve of tidal disruption events, consisting of two stages: a high state with bright luminosity and short duration and a medium state, less bright and longer lasting. These two states have different impacts on the production of cosmic rays and neutrinos. In order to calculate the diffuse fluxes of cosmic rays and neutrinos, we model the luminosity function and redshift evolution of jetted tidal disruption events. We find that we can fit the latest ultra-high-energy cosmic-ray spectrum and composition results of the Auger experiment for a range of reasonable parameters. The diffuse neutrino flux associated with this scenario is found to be subdominant, but nearby events can be detected by IceCube or next-generation detectors such as IceCube-Gen2.']",https://hal.science/hal-01886575,"['0.phys', '1.phys.astr']"
"['Leidy Vargas-Ibáñez', 'Kumiko Kotera', 'Odile Blanchard', 'Peggy Zwolinski', 'Alexis Cheffer', 'Mathieu Collilieux', 'Paul Lambert', 'Quentin Lefèbvre', 'Thomas Protois']","[1146634, 865723]",['leidy-tatiana-vargas-ibanez'],Life Cycle Analysis of the GRAND Experiment,hal-04373613,2024,10.1016/j.astropartphys.2023.102903,"['Life Cycle Analysis', 'Large-Scale Astrophysics Experiment', 'Environmental Impact', 'Radio-Detection', 'Astroparticle Detection']","['The goal of our study is to assess the environmental impact of the installation and use of the Giant Radio Array for Neutrino Detection (GRAND) prototype detection units, based on the life cycle assessment (LCA) methodology, and to propose recommendations that contribute to reduce the environmental impacts of the project at later stages. The functional unit, namely the quantified description of the studied system and of the performance requirements it fulfils, is to detect radio signals autonomously during 20 years, with 300 detection units deployed over 200 km in the Gansu province in China (corresponding to the prototype GRANDProto300). We consider four main phases: the extraction of the materials and the production of the detection units (upstream phases), the use and the end-of-life phases (downstream phases), with transportation between each step. An inventory analysis is performed for the seven components of each detection unit, based on transparent assumptions. Most of the inventory data are taken from the Idemat2021 database (Industrial Design & Engineering Materials). Our results show that the components with the highest environmental impact are the antenna structure and the battery. The most pregnant indicators are ‘resource use’, mineral and metals’; ‘resource use, fossils’; ‘ionizing radiation, human health’; ‘climate change’; and ‘acidification’. Therefore, the actions that we recommend in the first place aim at reducing the impact of these components. They include limiting the mass of the raw material used in the antenna, changing the alloy of the antenna, considering another type of battery with an extended useful life, and the use of recycled materials for construction. As a pioneering study applying the LCA methodology to a large-scale physics experiment, this work can serve as a basis for future assessments by other collaborations.']",https://ifp.hal.science/hal-04373613,"['0.sde', '0.sde', '1.sde.mcg']"
"['Kumiko Kotera', 'M. Angeles Perez-Garcia', 'Joseph Silk']",,,Strangelets and the TeV-PeV cosmic-ray anisotropies,hal-03645468,2013,10.1016/j.physletb.2013.07.010,['Astrophysics - High Energy Astrophysical Phenomena'],"['Several experiments (e.g., Milagro and IceCube) have reported the presence in the sky of regions with significant excess in the arrival direction distributions of Galactic cosmic rays in the TeV-to-PeV energy range. Here we study the possibility that these hotspots are a manifestation of the peculiar nature of these cosmic rays, and of the presence of molecular clouds near the sources. We propose that stable quark matter lumps or so-called strangelets can be emitted in the course of the transition of a neutron star to a more compact astrophysical object. A fraction of these massive particles would lose their charge by spallation or electron capture in molecular clouds located in the immediate neighborhood of their source, and propagate rectilinearly without decaying further, hence inducing anisotropies of the order of the cloud size. With reasonable astrophysical assumptions regarding the neutron star transition rate, strangelet injection and neutralization rates, we can reproduce successfully the observed hotspot characteristics and their distribution in the sky.']",https://hal.science/hal-03645468,['0.sdu']
"['Yohan Dubois', 'Marta Volonteri', 'Joseph Silk', 'Julien Devriendt', 'Adrianne Slyz', 'Romain Teyssier']","[738810, 766152, 783182, 755250]",['yohan-dubois'],Black hole evolution - I. Supernova-regulated black hole growth,insu-03644865,2015,10.1093/mnras/stv1416,"['Methods numerical', 'Galaxies active', 'Galaxies evolution', 'Galaxies formation', 'Astrophysics - Astrophysics of Galaxies']","['The growth of a supermassive black hole (BH) is determined by how much gas the host galaxy is able to feed it, which in turn is controlled by the cosmic environment, through galaxy mergers and accretion of cosmic flows that time how galaxies obtain their gas, and also by internal processes in the galaxy, such as star formation and feedback from stars and the BH itself. In this paper, we study the growth of a 10<SUP>12</SUP> M<SUB>⊙</SUB> halo at z = 2, which is the progenitor of a group of galaxies at z = 0, and of its central BH by means of a high-resolution zoomed cosmological simulation, the Seth simulation. We study the evolution of the BH driven by the accretion of cold gas in the galaxy, and explore the efficiency of the feedback from supernovae (SNe). For a relatively inefficient energy input from SNe, the BH grows at the Eddington rate from early times, and reaches self-regulation once it is massive enough. We find that at early cosmic times z > 3.5, efficient feedback from SNe forbids the formation of a settled disc as well as the accumulation of dense cold gas in the vicinity of the BH and starves the central compact object. As the galaxy and its halo accumulate mass, they become able to confine the nuclear inflows provided by major mergers and the BH grows at a sustained near-to-Eddington accretion rate. We argue that this mechanism should be ubiquitous amongst low-mass galaxies, corresponding to galaxies with a stellar mass below ≲ 10<SUP>9</SUP> M<SUB>⊙</SUB> in our simulations.']",https://insu.hal.science/insu-03644865,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Taysun Kimm', 'Renyue Cen', 'Julien Devriendt', 'Yohan Dubois', 'Adrianne Slyz']","[783719, 780576, 783182, 738810]",['yohan-dubois'],Towards simulating star formation in turbulent high-z galaxies with mechanical supernova feedback,insu-03644881,2015,10.1093/mnras/stv1211,"['Galaxies formation', 'Galaxies high-redshift', 'Galaxies ISM']","['To better understand the impact of supernova (SN) explosions on the evolution of galaxies, we perform a suite of high-resolution (12 pc), zoom-in cosmological simulations of a Milky Way-like galaxy at z = 3 with adaptive mesh refinement. We find that SN explosions can efficiently regulate star formation, leading to the stellar mass and metallicity consistent with the observed mass-metallicity relation and stellar mass-halo mass relation at z ∼ 3. This is achieved by making three important changes to the classical feedback scheme: (i) the different phases of SN blast waves are modelled directly by injecting radial momentum expected at each stage, (ii) the realistic time delay of SNe is required to disperse very dense gas before a runaway collapse sets in, and (iii) a non-uniform density distribution of the interstellar medium (ISM) is taken into account below the computational grid scale for the cell in which an SN explodes. The simulated galaxy with the SN feedback model shows strong outflows, which carry approximately 10 times larger mass than star formation rate, as well as smoothly rising circular velocity. Although the metallicity of the outflow depends sensitively on the feedback model used, we find that the accretion rate and metallicity of the cold flow around the virial radius is impervious to SN feedback. Our results suggest that understanding the structure of the turbulent ISM may be crucial to assess the role of SN and other feedback processes in galaxy formation theory.']",https://insu.hal.science/insu-03644881,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Yohan Dubois', 'Marta Volonteri', 'Joseph Silk']","[738810, 766152]",['yohan-dubois'],Black hole evolution - III. Statistical properties of mass growth and spin evolution using large-scale hydrodynamical cosmological simulations,insu-03645654,2014,10.1093/mnras/stu373,"['Methods numerical', 'Galaxies active', 'Galaxies formation', 'Cosmology theory', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['Supermassive black holes (BHs) at the centres of galaxies can rapidly change their mass and spin by gas accretion and mergers. Using hydrodynamical cosmological simulations, with prescriptions for BH growth and feedback from active galactic nuclei, we study how the evolution of BH mass growth is driven by gas accretion and mergers. Using a semi-analytical approach to evolve spins, we also highlight the mechanisms responsible for driving the magnitude and the direction of spins as a function of cosmic time. We find that in the high-redshift universe galaxies maintain large values of gas accretion on to BHs, which therefore is the main driver of their mass and spin evolution. Sustained accretion of cold gas at high redshift tends to align BH spins with the angular momentum of the surrounding gas and maximize their magnitude. Conversely, at low redshift, as BHs get more massive and galaxies more gas poor, the contribution from binary coalescences to the total BH mass growth increases, especially at the high-mass end, and tends to decrease the magnitude of spins and change their direction.']",https://insu.hal.science/insu-03645654,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Mélanie Habouzit', 'Marta Volonteri', 'Muhammad Latif', 'Yohan Dubois', 'Sébastien Peirani']","[981762, 766152, 738810]",['yohan-dubois'],On the number density of ‘direct collapse’ black hole seeds,hal-01402990,2016,10.1093/mnras/stw1924,"['Galaxies high-redshift', 'Quasars supermassive black holes', 'Early Universe', 'Dark ages', 'Reionization', 'First stars']","['Supermassive black holes (BHs) reside in the centre of most local galaxies, but they also power active galactic nuclei and quasars, detected up to z = 7. These quasars put constraints on early BH growth and the mass of BH seeds. The scenario of ‘direct collapse’ is appealing as it leads to the formation of large mass BH seeds, 104–106\u2009M⊙, which eases explaining how quasars at z = 6–7 are powered by BHs with masses >109\u2009M⊙. Direct collapse, however, appears to be rare, as the conditions required by the scenario are that gas is metal-free, the presence of a strong photodissociating Lyman–Werner flux, and large inflows of gas at the centre of the halo, sustained for 10–100 Myr. We performed several cosmological hydrodynamical simulations that cover a large range of box sizes and resolutions, thus allowing us to understand the impact of several physical processes on the distribution of direct collapse BHs. We identify haloes where direct collapse can happen, and derive the number density of BHs. We also investigate the discrepancies between hydrodynamical simulations, direct or post-processed, and semi-analytical studies. Under optimistic assumptions, we find that for direct collapse to account for BHs in normal galaxies, the critical Lyman–Werner flux required for direct collapse must be about two orders of magnitude lower than predicted by 3D simulations that include detailed chemical models. However, when supernova feedback is relatively weak, enough direct collapse BHs to explain z = 6–7 quasars can be obtained for Lyman–Werner fluxes about one order of magnitude lower than found in 3D simulations.']",https://hal.sorbonne-universite.fr/hal-01402990,"['0.phys', '1.phys.astr']"
"['Yohan Dubois', 'Christophe Pichon', 'Martin Haehnelt', 'Taysun Kimm', 'Adrianne Slyz', 'Julien Devriendt', 'Dmitry Pogosyan']","[738810, 738765, 783719, 783182]","['yohan-dubois', 'christophe-pichon']",Feeding compact bulges and supermassive black holes with low angular momentum cosmic gas at high redshift,hal-03645808,2012,10.1111/j.1365-2966.2012.21160.x,"['Cosmology theory', 'Galaxies evolution', 'Galaxies formation', 'Galaxies haloes', 'Galaxies kinematics and dynamics', 'Large-scale structure of Universe', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['We use cosmological hydrodynamical simulations to show that a significant fraction of the gas in high redshift rare massive haloes falls nearly radially to their very centre on extremely short time-scales. This process results in the formation of very compact bulges with specific angular momentum a factor of 5-30 smaller than the average angular momentum of the baryons in the whole halo. Such low angular momentum originates from both segregation and effective cancellation when the gas flows to the centre of the halo along well-defined cold filamentary streams. These filaments penetrate deep inside the halo and connect to the bulge from multiple rapidly changing directions. Structures falling in along the filaments (satellite galaxies) or formed by gravitational instabilities triggered by the inflow (star clusters) further reduce the angular momentum of the gas in the bulge. Finally, the fraction of gas radially falling to the centre appears to increase with the mass of the halo; we argue that this is most likely due to an enhanced cancellation of angular momentum in rarer haloes which are fed by more isotropically distributed cold streams. Such an increasingly efficient funnelling of low angular momentum gas to the centre of very massive haloes at high redshift may account for the rapid pace at which the most massive supermassive black holes grow to reach observed masses around 10<SUP>9</SUP> M<SUB>⊙</SUB> at an epoch when the Universe is barely 1 Gyr old.']",https://hal.science/hal-03645808,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Yohan Dubois', 'Christophe Pichon', 'Julien Devriendt', 'Joseph Silk', 'Martin Haehnelt', 'Taysun Kimm', 'Adrianne Slyz']","[738810, 738765, 783182, 783719]","['yohan-dubois', 'christophe-pichon']",Blowing cold flows away: the impact of early AGN activity on the formation of a brightest cluster galaxy progenitor,hal-03645612,2013,10.1093/mnras/sts224,"['Galaxies high-redshift', 'Cosmology theory', 'Astrophysics - Cosmology and Nongalactic Astrophysics', 'Methods numerical', 'Galaxies active', 'Galaxies formation', 'Galaxies haloes']","[""Supermassive black holes (BH) are powerful sources of energy that are already in place at very early epochs of the Universe (by z = 6). Using hydrodynamical simulations of the formation of a massive M<SUB>vir</SUB> = 5 × 10<SUP>11</SUP> M<SUB>⊙</SUB> halo by z = 6 (the most massive progenitor of a cluster of M<SUB>vir</SUB> = 2 × 10<SUP>15</SUP> M<SUB>⊙</SUB> at z = 0), we evaluate the impact of active galactic nuclei (AGN) on galaxy mass content, BH self-regulation and gas distribution inside this massive halo. We find that supernova feedback has a marginal influence on the stellar structure, and no influence on the mass distribution on large scales. In contrast, AGN feedback alone is able to significantly alter the stellar-bulge mass content by quenching star formation when the BH is self-regulating, and by depleting the cold gas reservoir in the centre of the galaxy. The growth of the BH proceeds first by a rapid Eddington-limited period fed by direct cold filamentary infall. When the energy delivered by the AGN is sufficiently large to unbind the cold gas of the bulge, the accretion of gas on to the BH is maintained by both smooth gas inflow and clump migration through the galactic disc triggered by merger-induced torques. The feedback from the AGN has also a severe consequence on the baryon mass content within the halo, producing large-scale hot superwinds, able to blow away some of the cold filamentary material from the centre and reduce the baryon fraction by more than 30 per cent within the halo's virial radius. Thus, in the very young universe, AGN feedback is likely to be a key process, shaping the properties of the most massive galaxies.""]",https://hal.science/hal-03645612,['0.sdu']
"['Romain Jonchiere', 'Ari P. Seitsonen', 'Guillaume Ferlat', 'A. Marco Saitta', 'Rodolphe Vuilleumier']","[756213, 847969]",['rodolphe-vuilleumier'],Van der Waals effects in ab initio water at ambient and supercritical conditions,insu-03606444,2011,10.1063/1.3651474,"['Ab initio calculations', 'Density functional theory', 'Diffusion', 'Liquid structure', 'Van der Waals forces', 'Water', '6120Ne', '6610C', '6120Ja', 'Structure of simple liquids', 'Diffusion and thermal diffusion', 'Computer simulation of liquid structure']","['Density functional theory (DFT) within the generalized gradient approximation (GGA) is known to poorly reproduce the experimental properties of liquid water. The poor description of the dispersion forces in the exchange correlation functionals is one of the possible causes. Recent studies have demonstrated an improvement in the simulated properties when they are taken into account. We present here a study of the effects on liquid water of the recently proposed semi-empirical correction of Grimme et al. [J. Chem. Phys. 132, 154104 (2010)]. The difference between standard and corrected DFT-GGA simulations is rationalized with a detailed analysis upon modifying an accurate parameterised potential. This allows an estimate of the typical range of dispersion forces in water. We also show that the structure and diffusivity of ambient-like liquid water are sensitive to the fifth neighbor position, thus highlighting the key role played by this neighbor. Our study is extended to water at supercritical conditions, where experimental and theoretical results are much more scarce. We show that the semi-empirical correction by Grimme et al. improves significantly, although somewhat counter-intuitively, both the structural and the dynamical description of supercritical water.']",https://insu.hal.science/insu-03606444,['0.sdu']
"['Gleb S. Pokrovski', 'Maria A. Kokh', 'Damien Guillaume', 'Anastassia Y. Borisova', 'Pascal Gisquet', 'Jean-Louis Hazemann', 'Eric Lahera', 'William del Net', 'Olivier Proux', 'Denis Testemale', 'Volker Haigis', 'Romain Jonchiere', 'Ari P. Seitsonen', 'Guillaume Ferlat', 'Rodolphe Vuilleumier', 'Antonino Marco Saitta', 'Marie-Christine Boiron', 'Jean Dubessy']","[749067, 170093, 739650, 172032, 176391, 5875, 756213, 847969, 175134, 749084]","['gleb-pokrovski', 'damien-guillaume', 'anastassia-borisova', 'jean-louis-hazemann', 'olivier-proux', 'denis-testemale', 'rodolphe-vuilleumier', 'antonino-marco-saitta', 'marie-christine-boiron']",Sulfur radical species form gold deposits on Earth,hal-01284137,2015,10.1073/pnas.1506378112,"['Gold', 'Sulfur', 'Trisulfur ion', 'Ore deposit', 'Hydrothermal fluid']","['Current models of the formation and distribution of gold deposits on Earth are based on the long-standing paradigm that hydrogen sulfide and chloride are the ligands responsible for gold mobilization and precipitation by fluids across the lithosphere. Here we challenge this view by demonstrating, using in situ X-ray absorption spectroscopy and solubility measurements, coupled with molecular dynamics and thermodynamic simulations, that sulfur radical species, such as the trisulfur ion S-3(-), form very stable and soluble complexes with Au+ in aqueous solution at elevated temperatures (>250 degrees C) and pressures (>100 bar). These species enable extraction, transport, and focused precipitation of gold by sulfur-rich fluids 10-100 times more efficiently than sulfide and chloride only. As a result, S-3(-) exerts an important control on the source, concentration, and distribution of gold in its major economic deposits from magmatic, hydrothermal, and metamorphic settings. The growth and decay of S-3(-) during the fluid generation and evolution is one of the key factors that determine the fate of gold in the lithosphere.']",https://hal.univ-lorraine.fr/hal-01284137,"['0.sdu', '1.sdu.stu']"
"['Georges Calas', 'Laurence Galoisy', 'Laurent Cormier', 'Guillaume Ferlat', 'Gerald Lelong']","[1216180, 1216182, 177070, 756213]",['laurent-cormier'],The Structural Properties of Cations in Nuclear Glasses,hal-01104152,2014,10.1016/j.mspro.2014.10.005,"['Nuclear glasses', 'Neutron diffraction', 'EXAFS', 'XANES', 'Glass structure']","['The structure of nuclear glasses and of simplified surrogates has been investigated using complementary diffraction and spectroscopic methods, together with numerical modeling. The diversity of structural surroundings of cations in glasses is reviewed at various scales. Cations usually occur in smaller sites in glasses than in crystals, with unusual site geometries such as 5-coordination. These sites may correspond to different structural positions. Network forming and networking situations illustrate the existence of a well-defined relationship with the glassy network, with cations improving glass stability. The complementary charge-compensation may sometimes give rise to a competition between cations. In that case, the cation may lose its stabilizing character and become a nucleating agent, as observed for “chameleon” elements, the coordination of which and hence the structural properties may change as a function of glass composition. Eventually, at the mesoscale, the heterogeneous distribution of cations has been recently visualized, providing keys to understand the nucleation processes in glasses.']",https://hal.sorbonne-universite.fr/hal-01104152,"['0.phys', '1.phys.cond', '2.phys.cond.cm-ms']"
"['Gleb S Pokrovski', 'Maria A Kokh', 'Elsa Desmaele', 'Clément Laskar', 'Elena F Bazarkina', 'Anastassia y Borisova', 'Denis Testemale', 'Jean-Louis F Hazemann', 'Rodolphe Vuilleumier', 'Guillaume Ferlat', 'Antonino Marco Saitta']","[749067, 791219, 1230340, 5875, 172032, 847969, 756213, 175134]","['gleb-pokrovski', 'claskar', 'denis-testemale', 'jean-louis-hazemann', 'rodolphe-vuilleumier', 'antonino-marco-saitta']",The trisulfur radical ion S 3 •− controls platinum transport by hydrothermal fluids,hal-03323512,2021,10.1073/pnas.2109768118,"['Trisulfur ion', 'Platinum group elements', 'Hydrothermal fluid', 'Sulfur', 'Platinum']","['Platinum group elements (PGE) are considered to be very poorly soluble in aqueous fluids in most natural hydrothermal–magmatic contexts and industrial processes. Here, we combined in situ X-ray absorption spectroscopy and solubility experiments with atomistic and thermodynamic simulations to demonstrate that the trisulfur radical ion S 3 •− forms very stable and soluble complexes with both Pt II and Pt IV in sulfur-bearing aqueous solution at elevated temperatures (∼300 °C). These Pt-bearing species enable (re)mobilization, transfer, and focused precipitation of platinum up to 10,000 times more efficiently than any other common inorganic ligand, such as hydroxide, chloride, sulfate, or sulfide. Our results imply a far more important contribution of sulfur-bearing hydrothermal fluids to PGE transfer and accumulation in the Earth’s crust than believed previously. This discovery challenges traditional models of PGE economic concentration from silicate and sulfide melts and provides new possibilities for resource prospecting in hydrothermal shallow crust settings. The exceptionally high capacity of the S 3 •− ion to bind platinum may also offer new routes for PGE selective extraction from ore and hydrothermal synthesis of noble metal nanomaterials.']",https://hal.science/hal-03323512,"['0.sdu', '1.sdu.stu', '2.sdu.stu.gc', '0.chim', '1.chim.coor', '0.chim', '1.chim.inor', '0.phys', '1.phys.cond', '2.phys.cond.cm-ms', '0.phys', '1.phys.phys', '2.phys.phys.phys-chem-ph', '0.sdu', '1.sdu.stu', '2.sdu.stu.mi']"
"['Gleb Pokrovski', 'Elsa Desmaele', 'Clément Laskar', 'Elena Bazarkina', 'Denis Testemale', 'Jean-Louis F Hazemann', 'Rodolphe Vuilleumier', 'Ari Paavo Seitsonen', 'Guillaume Ferlat', 'Antonino Marco Saitta']","[749067, 1230340, 5875, 172032]","['gleb-pokrovski', 'claskar', 'denis-testemale', 'jean-louis-hazemann']",Gold speciation in hydrothermal fluids revealed by in situ high energy resolution X-ray absorption spectroscopy,cea-04074998,2022,10.2138/am-2022-8008,"['Gold', 'Sulfur', 'Trisulfur radical ion', 'Hydrothermal fluid', 'Ore deposit', 'High energy resolution fluorescence detection X-ray absorption spectroscopy HERFD-XAS', 'X-ray absorption near edge structure XANES', 'Solubility', 'Density functional theory DFT', 'First-principles molecular dynamics FPMD']","['Abstract Gold mobilization, transfer, and concentration in the Earth’s crust are controlled by hydrothermal sulfur- and chloride-bearing fluids. Yet the exact chemical identity, structure, and stability of Au-bearing species and, in particular, the respective contributions of the sulfide (HS−) and trisulfur ion (S3⋅−) ligands to Au transport lack direct in situ evidence. Here we employed high energy resolution fluorescence detection X-ray absorption spectroscopy (HERFD-XAS) on aqueous sulfate/sulfide/S3⋅−-bearing solutions at typical hydrothermal temperatures and pressures (T = 350 °C, P = 600 bar) to reveal differences in dissolved Au spectral signatures indicative of contrasting fluid-phase Au speciation as a function of acidity and redox conditions. Combined with in situ Au solubility measurements and quantum-chemical and thermodynamic modeling, our spectroscopic data provide direct evidence for the Au(HS)S3− and Au(HS)2− complexes predominant at acidic-to-neutral and alkaline conditions, respectively. Our findings thus directly confirm a recent speciation scheme for Au in aqueous S-bearing fluids established using less direct methods, and highlight an important role of the trisulfur ion in gold mobilization and concentration in hydrothermal-magmatic deposits associated with subduction zones. More generally, our results show that HERFD-XAS enables the identification of structural and coordination features in metal complexes virtually unresolvable using classical XAS techniques. By avoiding limitations of less direct techniques, our integrated high-resolution spectroscopic approach opens perspectives for studies of the speciation and solubility of gold and other metals in high T-P fluids, and potentially silicate melts, inaccessible to direct observation in nature.']",https://cea.hal.science/cea-04074998,['0.phys']
"['Etienne Mangaud', 'Amine Jaouadi', 'Alex Chin', 'Michèle Desouter-Lecomte']","[764028, 1117117]",['michele-desouter-lecomte'],Survey of the hierarchical equations of motion in tensor-train format for non-Markovian quantum dynamics,hal-04217280,2023,10.1140/epjs/s11734-023-00919-0,"['Open quantum systems', 'Hierarchical equations of motion', 'Tensor trains']","['This work is a pedagogical survey about the hierarchical equations of motion and their implementation with the tensor-train format. These equations are a great standard in non-perturbative non-Markovian open quantum systems. They are exact for harmonic baths in the limit of relevant truncation of the hierarchy. We recall the link with the perturbative second-order time convolution equations also known as the Bloch–Redfield equations. Some theoretical tools characterizing non-Markovian dynamics such as the non-Markovianity measures or the dynamical map are also briefly discussed in the context of HEOM simulations. The main points of the tensor-train expansion are illustrated in an example with a qubit interacting with a bath described by a Lorentzian spectral density. Finally, we give three illustrative applications in which the system–bath coupling operator is similar to that of the analytical treatment. The first example revisits a model in which population-to-coherence transfer via the bath creates a long-lasting coherence between two states. The second one is devoted to the computation of stationary absorption and emission spectra. We illustrate the link between the spectral density and the Stokes shift in situations with and without nonadiabatic interaction. Finally, we simulate an excitation transfer when the spectral density is discretized by undamped modes to illustrate a situation in which the TT formulation is more efficient than the standard one.']",https://hal.science/hal-04217280v2,"['0.phys', '1.phys.phys', '2.phys.phys.phys-chem-ph']"
"['Fabrice Carrat', 'Elisabeta Vergu', 'Neil M. Ferguson', 'Magali Lemaitre', 'Simon Cauchemez', 'Steve Leach', 'Alain-Jacques Valleron']","[181388, 1086782]","['fabrice-carrat', 'simon-cauchemez']",Time lines of infection and disease in human influenza: a review of volunteer challenge studies,hal-02668741,2008,10.1093/aje/kwm375,"['INFLUENZA HUMAN', 'SIGN AND SYMPTOM', 'VIRUS SHEDDING', 'EPIDEMIOLOGIE HUMAINE']","['The dynamics of viral shedding and symptoms following influenza virus infection are key factors when considering epidemic control measures. The authors reviewed published studies describing the course of influenza virus infection in placebo-treated and untreated volunteers challenged with wild-type influenza virus. A total of 56 different studies with 1,280 healthy participants were considered. Viral shedding increased sharply between 0.5 and 1 day after challenge and consistently peaked on day 2. The duration of viral shedding averaged over 375 participants was 4.80 days (95% confidence interval: 4.31, 5.29). The frequency of symptomatic infection was 66.9% (95% confidence interval: 58.3, 74.5). Fever was observed in 37.0% of A/H1N1, 40.6% of A/H3N2 (p = 0.86), and 7.5% of B infections (p = 0.001). The total symptoms scores increased on day 1 and peaked on day 3. Systemic symptoms peaked on day 2. No such data exist for children or elderly subjects, but epidemiologic studies suggest that the natural history might differ. The present analysis confirms prior expert opinion on the duration of viral shedding or the frequency of asymptomatic influenza infection, extends prior knowledge on the dynamics of viral shedding and symptoms, and provides original results on the frequency of respiratory symptoms or fever']",https://hal.inrae.fr/hal-02668741,"['0.math', '0.info']"
"['Christophe Hézode', 'Hélène Fontaine', 'Céline Dorival', 'Dominique Larrey', 'Fabien Zoulim', 'Valérie Canva', 'Victor de Ledinghen', 'Thierry Poynard', 'Didier Samuel', 'Marc Bourlière', 'Jean-Pierre Zarski', 'Jean-Jacques Raabe', 'Laurent Alric', 'Patrick Marcellin', 'Ghassan Riachi', 'Pierre Paul Bernard', 'Véronique Loustaud-Ratti', 'Sophie Métivier', 'Albert Tran', 'Lawrence Serfaty', 'Armand Abergel', 'Xavier Causse', 'Vincent Di Martino', 'Dominique Guyader', 'Damien Lucidarme', 'Véronique Grando-Lemaire', 'Patrick Hillon', 'Cyrille Feray', 'Thong Dao', 'Patrice Cacoub', 'Isabelle Rosa', 'Pierre Attali', 'Ventzislava Petrov-Sanchez', 'Yoann Barthe', 'Jean-Michel Pawlotsky', 'Stanislas Pol', 'Fabrice Carrat', 'Jean-Pierre Bronowicki']","[755798, 759679, 890662, 756883, 881462, 918150, 862090, 760409, 763073, 757059, 759698, 757187, 181388]","['fabien-zoulim', 'fabrice-carrat']",Triple therapy in treatment-experienced patients with HCV-cirrhosis in a multicentre cohort of the French Early Access Programme (ANRS CO20-CUPIC) – NCT01514890,hal-01708037,2013,10.1016/j.jhep.2013.04.035,"['Chronic hepatitis C', 'Cirrhosis', 'Treatment', 'Boceprevir', 'Telaprevir', 'Safety']","['Background & AimsIn phase III trials, the safety profile of triple therapy (pegylated interferon/ribavirin with boceprevir or telaprevir) seems to be similar in HCV treatment-experienced cirrhotic and non-cirrhotic patients, but few cirrhotics were included. We report the week 16 safety and efficacy analysis in a cohort of compensated cirrhotics treated in the French Early Access Programme.Methods674 genotype 1 patients, prospectively included, received 48 weeks of triple therapy. The analysis is restricted to 497 patients reaching week 16.ResultsA high incidence of serious adverse events (40.0%), and of death and severe complications (severe infection or hepatic decompensation) (6.4%), and a difficult management of anaemia (erythropoietin and transfusion use in 50.7% and 12.1%) were observed. Independent predictors of anaemia <8 g/dl or blood transfusion were: female gender (OR 2.19, 95% CI 1.11–4.33, p = 0.024), no lead-in phase (OR 2.25, 95% CI 1.15–4.39, p = 0.018), age ⩾65 years (OR 3.04, 95% CI 1.54–6.02, p = 0.0014), haemoglobin level (⩽12 g/dl for females, ⩽13 g/dl for males) (OR 5.30, 95% CI 2.49–11.5, p = 0.0001). Death or severe complications were related to platelets count ⩽100,000/mm3 (OR 3.11, 95% CI 1.30–7.41, p = 0.0105) and albumin <35 g/dl (OR 6.33, 95% CI 2.66–15.07, p = 0.0001), with a risk of 44.1% in patients with both. However, the on-treatment virological response was high.ConclusionsThe safety profile was poor and patients with platelet count ⩽100,000/mm3 and serum albumin <35 g/L should not be treated with the triple therapy.']",https://hal.univ-lorraine.fr/hal-01708037,['0.sdv']
"['Luca Arcaini', 'Caroline Besson', 'Marco Frigeni', 'Hélène Fontaine', 'Maria Goldaniga', 'Milvia Casato', 'Marcella Visentini', 'Harrys A. Torres', 'Veronique Loustaud-Ratti', 'Jan Peveling-Oberhag', 'Paolo Fabris', 'Roberto Rossotti', 'Francesco Zaja', 'Luigi Rigacci', 'Sara Rattotti', 'Raffaele Bruno', 'Michele Merli', 'Céline Dorival', 'Laurent Alric', 'Arnaud Jaccard', 'Stanislas Pol', 'Fabrice Carrat', 'Virginia Valeria Ferretti', 'Carlo Visco', 'Olivier Hermine']","[758397, 755798, 881462, 755799, 181388, 756140]",['fabrice-carrat'],Interferon-free antiviral treatment in B-cell lymphoproliferative disorders associated with hepatitis C virus infection,hal-03169846,2016,10.1182/blood-2016-05-714667,"['Antiviral agents', 'B-lymphocytes', 'Hepatitis c', 'Human leukocyte interferon', 'Interferons', 'Lymphoma', 'Lymphoproliferative disorders', 'Virology', 'Hepatitis c virus', 'Small cell lymphoma']","['Regression of hepatitis C virus (HCV)-associated lymphoma with interferon (IFN)-based antiviral treatment supports an etiological link between lymphoma and HCV infection. In addition, a favorable impact of antiviral treatment on overall survival of patients with HCV-related lymphoma has been reported. Data on IFN-free regimens combining direct-acting antivirals (DAAs) in HCV-associated lymphoproliferative disorders are scanty. We analyzed the virological and lymphoproliferative disease response (LDR) of 46 patients with indolent B-cell non-Hodgkin lymphomas (NHLs) or chronic lymphocytic leukemia (CLL) and chronic HCV infection treated with DAAs. The histological distribution was 37 marginal zone lymphomas (MZLs), 2 lymphoplasmacytic lymphomas, 2 follicular lymphomas, 4 CLL/small lymphocytic lymphomas (CLL/SLLs), and 1 low-grade NHL not otherwise specified. Thirty-nine patients received a sofosbuvir-based regimen and 7 patients received other DAAs. The median duration of DAA therapy was 12 weeks (range, 6-24 weeks). A sustained virological response at week 12 after finishing DAAs was obtained in 45 patients (98%); the overall LDR rate was 67%, including 12 patients (26%) who achieved a complete response. The LDR rate was 73% among patients with MZL, whereas no response was observed in CLL/SLL patients. Seven patients cleared cryoglobulins out of 15 who were initially positive. After a median follow-up of 8 months, 1-year progression-free and overall survival rates were 75% (95% confidence interval [CI], 51-88] and 98% [95% CI, 86-100], respectively. DAA therapy induces a high LDR rate in HCV-associated indolent lymphomas. These data provide a strong rationale for prospective trials with DAAs in this setting.']",https://ut3-toulouseinp.hal.science/hal-03169846,['0.sdv']
"['Henrik Salje', 'Cécile Tran Kiem', 'Noémie Lefrancq', 'Noémie Courtejoie', 'Paolo Bosetti', 'Juliette Paireau', 'Alessio Andronico', 'Nathanaël Hoze', 'Jehanne Richet', 'Claire-Lise Dubost', 'Yann Le Strat', 'Justin Lessler', 'Daniel Levy Bruhl', 'Arnaud Fontanet', 'Lulla Opatowski', 'Pierre-Yves Boëlle', 'Simon Cauchemez']","[993786, 800314, 184157, 17613, 776966, 1212900, 907941, 908680, 172531, 1086782]","['noemie-lefrancq', 'juliette-paireau', 'nathanael-hoze', 'pierre-yves-boelle', 'simon-cauchemez']",Estimating the burden of SARS-CoV-2 in France,pasteur-02548181,2020,10.1126/science.abc3517,"['Epidemiology', 'COVID-19', 'SARS-CoV-2', 'Modeling Method']","['France has been heavily affected by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic and went into lockdown on 17 March 2020. Using models applied to hospital and death data, we estimate the impact of the lockdown and current population immunity. We find that 2.9% of infected individuals are hospitalized and 0.5% of those infected die (95% credible interval: 0.3 to 0.9%), ranging from 0.001% in those under 20 years of age to 8.3% in those 80 years of age or older. Across all ages, men are more likely to be hospitalized, enter intensive care, and die than women. The lockdown reduced the reproductive number from 2.90 to 0.67 (77% reduction). By 11 May 2020, when interventions are scheduled to be eased, we project that 3.5 million people (range: 2.1 million to 6.0 million), or 5.3% of the population (range: 3.3 to 9.3%), will have been infected. Population immunity appears to be insufficient to avoid a second wave if all control measures are released at the end of the lockdown.']",https://pasteur.hal.science/pasteur-02548181v2,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.me', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.mi', '0.sdv', '1.sdv.spee', '0.stat', '0.info', '1.info.info-mo']"
"['Laura Di Domenico', 'Giulia Pullano', 'Chiara E Sabbatini', 'Pierre-Yves Boëlle', 'Vittoria Colizza']","[1246443, 1368090, 172531, 908587]",['pierre-yves-boelle'],Impact of lockdown on COVID-19 epidemic in Île-de-France and possible exit strategies,hal-02932156,2020,10.1186/s12916-020-01698-4,"['COVID-19', 'Exit strategies', 'Lockdown', 'Mathematical modeling', 'Non-pharmaceutical interventions', 'Reproductive number', 'Social distancing']","['Background: More than half of the global population is under strict forms of social distancing. Estimating the expected impact of lockdown and exit strategies is critical to inform decision makers on the management of the COVID-19 health crisis. Methods: We use a stochastic age-structured transmission model integrating data on age profile and social contacts in Île-de-France to (i) assess the epidemic in the region, (ii) evaluate the impact of lockdown, and (iii) propose possible exit strategies and estimate their effectiveness. The model is calibrated to hospital admission data before lockdown. Interventions are modeled by reconstructing the associated changes in the contact matrices and informed by mobility reductions during lockdown evaluated from mobile phone data. Different types and durations of social distancing are simulated, including progressive and targeted strategies, with large-scale testing. Results: We estimate the reproductive number at 3.18 [3.09, 3.24] (95% confidence interval) prior to lockdown and at 0.68 [0.66, 0.69] during lockdown, thanks to an 81% reduction of the average number of contacts. Model predictions capture the disease dynamics during lockdown, showing the epidemic curve reaching ICU system capacity, largely strengthened during the emergency, and slowly decreasing. Results suggest that physical contacts outside households were largely avoided during lockdown. Lifting the lockdown with no exit strategy would lead to a second wave overwhelming the healthcare system, if conditions return to normal. Extensive case finding and isolation are required for social distancing strategies to gradually relax lockdown constraints. Conclusions: As France experiences the first wave of COVID-19 pandemic in lockdown, intensive forms of social distancing are required in the upcoming months due to the currently low population immunity. Extensive case finding and isolation would allow the partial release of the socio-economic pressure caused by extreme measures, while avoiding healthcare demand exceeding capacity. Response planning needs to urgently prioritize the logistics and capacity for these interventions.']",https://hal.sorbonne-universite.fr/hal-02932156,"['0.sdv', '1.sdv.spee', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.mi', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.me']"
"['Thomas Obadia', 'Romana Haneef', 'Pierre-Yves Boëlle']","[184834, 937422, 172531]","['thomas-obadia', 'pierre-yves-boelle']",The R0 package: a toolbox to estimate reproduction numbers for epidemic outbreaks.,inserm-00794981,2012,10.1186/1472-6947-12-147,"['Epidemics', 'Software', 'Reproduction number', 'Estimation', 'R package']","['BACKGROUND: Several generic methods have been proposed to estimate transmission parameters during an outbreak, especially the reproduction number. However, as of today, no dedicated software exists that implements these methods and allow comparisons. RESULTS: A review of generic methods used to estimate transmissibility parameters during outbreaks was carried out. Most methods used the epidemic curve and the generation time distribution. Two categories of methods were available: those estimating the initial reproduction number, and those estimating a time dependent reproduction number. We implemented five methods as an R library, developed sensitivity analysis tools for each method and provided numerical illustrations of their use. A comparison of the performance of the different methods on simulated datasets is reported. CONCLUSIONS: This software package allows a standardized and extensible approach to the estimation of the reproduction number and generation interval distribution from epidemic curves.']",https://inserm.hal.science/inserm-00794981,"['0.sdv', '1.sdv.bibs', '0.info', '1.info.info-bi']"
"['Linus Bengtsson', 'Jean Gaudart', 'Xin Lu', 'Sandra Moore', 'Erik Wetter', 'Kankoe Sallah', 'Stanislas Rebaudet', 'Renaud Piarroux']","[5302, 775398]",['jean-gaudart'],Using Mobile Phone Data to Predict the Spatial Spread of Cholera,hal-01218137,2015,10.1038/srep08923,"['PANDEMIC INFLUENZA', 'INFECTIOUS-DISEASE', 'EPIDEMIC CHOLERA', 'UNITED-STATES', 'HAITI', 'TRANSMISSION', 'HIERARCHIES', 'SANITATION', 'STRATEGIES', 'MORTALITY']","['Effective response to infectious disease epidemics requires focused control measures in areas predicted to be at high risk of new outbreaks. We aimed to test whether mobile operator data could predict the early spatial evolution of the 2010 Haiti cholera epidemic. Daily case data were analysed for 78 study areas from October 16 to December 16, 2010. Movements of 2.9 million anonymous mobile phone SIM cards were used to create a national mobility network. Two gravity models of population mobility were implemented for comparison. Both were optimized based on the complete retrospective epidemic data, available only after the end of the epidemic spread. Risk of an area experiencing an outbreak within seven days showed strong dose-response relationship with the mobile phone-based infectious pressure estimates. The mobile phone-based model performed better (AUC 0.79) than the retrospectively optimized gravity models (AUC 0.66 and 0.74, respectively). Infectious pressure at outbreak onset was significantly correlated with reported cholera cases during the first ten days of the epidemic (p < 0.05). Mobile operator data is a highly promising data source for improving preparedness and response efforts during cholera outbreaks. Findings may be particularly important for containment efforts of emerging infectious diseases, including high-mortality influenza strains.']",https://amu.hal.science/hal-01218137,"['0.sdv', '1.sdv.spee']"
"['François Peyron', ""Coralie L'Ollivier"", 'Laurent Mandelbrot', 'Martine Wallon', 'Renaud Piarroux', 'Francois Kieffer', 'Eve Hadjadj', 'Luc Paris', 'Patricia Garcia -Meric']","[1044242, 757956, 1008610, 1218234, 1216744, 1044192, 1044243]",,Maternal and Congenital Toxoplasmosis: Diagnosis and Treatment Recommendations of a French Multidisciplinary Working Group,inserm-02070252,2019,10.3390/pathogens8010024,"['Treatment of fetal infections', 'Follow-up of congenital infection', 'Congenital toxoplasmosis', 'Guidelines']","['Women infected with toxoplasmosis during pregnancy do not present symptoms in most cases, but the consequences of the congenital infection may be severe for the unborn child. Fetal damage can range from asymptomatic to severe neurological alterations to retinal lesions prone to potential flare up and relapses lifelong. Despite the possible severity of outcome, congenital toxoplasmosis (CT) is a neglected disease. There is no consensus regarding screening during pregnancy, prenatal/postnatal treatment or short or medium term follow-up. Since 1992, France has offered systematic serological testing to non-immune pregnant women, monthly until delivery. Any maternal infection is thus detected; moreover, diagnosis of congenital infection can be made at birth and follow-up can be provided. ""Guidelines"" drawn up by a multidisciplinary group are presented here, concerning treatment, before and after birth. The recommendations are based on the regular analysis of the literature and the results of the working group. The evaluation of the recommendations takes into account the robustness of the recommendation and the quality of the evidence.']",https://inserm.hal.science/inserm-02070252,"['0.sdv', '1.sdv.bibs']"
"['Mallory Vacheyrou', 'Anne-Cecile Normand', 'Philippe Guyot', 'Carole Cassagne', 'Renaud Piarroux', 'Yvette Bouton']","[782210, 1136641]",,Cultivable microbial communities in raw cow milk and potential transfers from stables of sixteen French farms,hal-02643826,2011,10.1016/j.ijfoodmicro.2011.02.033,"['Milk', 'Microbial diversity', 'Farm', 'SPECIES-SPECIFIC PRIMERS', 'LISTERIA-MONOCYTOGENES', 'MESOPHILIC LACTOBACILLI', 'BACTERIAL COMMUNITIES', 'SEQUENCE-ANALYSIS', 'ACBACTERIA', 'COMTE CHEESE', 'DAIRY-COWS', 'GOAT MILK', 'Microbial transfer', 'BACILLUS-CEREUS SPORES']","['The indigenous microflora in raw milk plays an important role in the diversity of cheese flavours and may protect against the growth of pathogens, but the sources of contamination and the factors that might affect the microbial communities in milk are not well known. The objectives of this study were to broaden knowledge of the microbial composition of milk and to assess microbial transfers from the stable to the milk. Air (collected in milking parlour and stable), dust (passively collected using plastic box), cow teat surface, and hay and milk samples were collected in 16 French farms with either stanchion barn or freestall barn configurations and plated on various culture media. Bacterial and fungal colonies were identified using phenotypic and DNA sequencing methods. Results showed that most of the fungal species and environmental bacteria found in the milk were also found in the stable and the milking parlour environments, indicating large microbial transfer from stable to milking parlour then to milk. However, milk from the stanchion barns were more contaminated than milk from freestall barns. Contrasting with other bacterial and fungal species, useful cheese-making bacteria lactobacilli and P- were frequently identified in the milk and on the teat surface but were rarely found in other environments. In conclusion, milk contamination by the stable environment is considerable, even if it is lower in farms with a milking parlour. Besides this environmental contamination, the teat surface remains the main source of useful cheese-making bacteria. (c) 2011 Elsevier B.V. All rights reserved.']",https://hal.inrae.fr/hal-02643826,"['0.sdv', '1.sdv.ida', '0.spi', '1.spi.gproc']"
"['Stéphane Ranque', 'Anne-Cecile Normand', 'Carole Cassagne', 'Jean-Benjamin Murat', 'Nathalie Bourgeois', 'Frédéric Dalle', 'Martine Gari-Toussaint', 'Patrick Fourquet', 'Marijke Hendrickx', 'Renaud Piarroux']","[8429, 782210]",['stephane-ranque'],MALDI-TOF mass spectrometry identification of filamentous fungi in the clinical laboratory.,hal-02638210,2014,10.1111/myc.12115,"['MALDI-TOF', 'Identification', 'Routine laboratory', 'Filamentous fungi']","[""This study aimed to validate the effectiveness of a standardised procedure for the MALDI-TOF mass spectrometry (MS)-based identification on a large sample of filamentous fungi routinely identified in university hospitals' laboratories. Non-dermatophyte filamentous fungi prospectively isolated in the routine activity of five teaching hospitals in France were first identified by conventional methods in each laboratory and then by MS in one centre. DNA sequence-based identification resolved discrepancies between both methods. In this study, of the 625 analysed filamentous fungi of 58 species, 501 (80%) and 556 (89%) were correctly identified by conventional methods and MS respectively. Compared with the conventional method, MS dramatically enhanced the performance of the identification of the non-Aspergillus filamentous fungi with a 31-61% increase in correct identification rate. In conclusion, this study on a large sample of clinical filamentous fungi taxa demonstrates that species identification is significantly improved by MS compared with the conventional method. The main limitation is that MS identification is possible only if the species is included in the reference spectra library. Nevertheless, for the routine clinical laboratory, MS provides the means to attain markedly accurate results in filamentous fungi identification, which was previously restricted to only a few reference laboratories.""]",https://hal.inrae.fr/hal-02638210,"['0.sdv', '1.sdv.mp']"
"['Enrico Daga', 'Marilena Daquino', ""Raphaël Fournier-S'Niehotta"", 'Christophe Guillotel-Nothmann', 'Andrea Scharnhorst']","[1355260, 1355261, 11604, 1355262]",['christophe-guillotel-nothmann'],Documenting the research process. Opportunities and challenges for Bibliometrics and Information Retrieval,hal-04470786,2023,10.5281/zenodo.10529114,"['Ontology engineering', 'Knowledge organisation', 'Interdisciplinary collaboration', 'Project-based research', ""Information retrieval S'niehotta 0000-0002-3184-5407 E Daga 0000-0002-1113-7550 M Daquino 0000-0002-9137-8011 R Fournier-S'niehotta 0000-0002-4817-3686 C Guillotel-Nothmann 0000-0001-8879-8798 A Scharnhorst"", ""Information retrieval S'niehotta 0000-0002-3184-5407 E Daga"", '0000-0002-1113-7550 M Daquino', ""0000-0002-9137-8011 R Fournier-S'niehotta"", '0000-0002-4817-3686 C Guillotel-Nothmann', '0000-0001-8879-8798 A Scharnhorst', 'Research ecosystem', 'Semantic web', 'Knowledge graph']","['This paper reports about knowledge management experiences in the EC funded project Polifonia\xa0(Research and Innovation Action funding scheme). Polifonia is a challenging project which aims at\xa0developing a methodological framework for musical heritage information. The project encompasses\xa0sources from text, sound, scores, settings (buildings), and experiences. It is organized around 10 Pilots\xa0which cover various actions such as preserving, studying, managing and interacting with musical heritage.\xa0Its advantage is that it uses semantic web technologies (ontologies and resulting knowledge graphs)\xa0as lingua franca binding the different Pilot data together. More specifically and additionally to the\xa0common use of GitHub repositories in research projects, Polifonia adds an additional organizational\xa0structure, what we call a Research Ecosystem. The Polifonia Research Ecosystem documents project\xa0outputs and their mutual dependencies as semantic artifacts, developing annotations for both (output\xa0and dependencies). This paper details the design and implementation of such a Research Ecosystem as a\xa0specific approach to effectively coordinate collaboration and related software production. Using the case\xa0of the Polifonia project, the paper reflects on the opportunities and challenges arising when it comes\xa0to formalize best practices to execute innovative research processes. Finally, we discuss the potential\xa0impact that such developments could have on future bibliometrics and information retrieval practices.']",https://hal.science/hal-04470786,"['0.info', '1.info.info-ir']"
"['Christophe Guillotel-Nothmann', 'Anne-Emmanuelle Ceulemans']","[11604, 1045502]",['christophe-guillotel-nothmann'],Praetorius’ Polyhymnia caduceatrix (1619): Diatonische Logik und Skalenlogik in mehrchörigen und konzertierenden Werken des Frühbarocks,hal-03087350,2020,10.31751/i.50,"['Praetorius', 'Polyhymnia caduceatrix', 'Modalität', 'Tonalität', 'Skalenlogik', 'Diatonische Logik', 'Generalbass', 'Oktavregel', 'Praetorius', 'Polyhymnia caduceatrix', 'Modality', 'Tonality', 'Diatonic logic', 'Scale logic', 'Thoroughbass', 'Octave rule']","['Dieser Beitrag untersucht die ConcertGesänge in Michael Praetorius’ Polyhymnia caduceatrix (1619) im Hinblick auf ihre modal-tonalen Eigenschaften. Nach einem historischen Überblick fokussiert der Artikel die Rolle, Bezifferung und Aussetzung des in der Sammlung obligaten Bassus generalis. Zu diesem Zweck werden Harmonisierungsregeln aus der Musiktheorie des 17. und 18. Jahrhunderts mit einer computergestützten Analyse der ConcertGesänge konfrontiert. Die Gegenüberstellung zeigt, wie die im Generalbass subsumierten harmonischen und melodischen Eigenschaften zwischen diatonischer Logik und Skalenlogik oszillieren. Aus den Analysen treten Harmonisierungspattern zutage, die erst ein knappes Jahrhundert später, insbesondere im Kontext der ›Oktavregel‹, vom theoretischen Diskurs vollständig erfasst werden.', 'This contribution examines the ConcertGesänge in Michael Praetorius’ Polyhymnia caduceatrix (1619) in terms of their modal-tonal properties. After a historical survey, the study focuses on the bassus generalis, used throughout the collection, with regards to its role, figuring and realisation. Therefore, harmonisation rules derived from 17th and 18th century music theory are confronted with a computer-assisted analysis of the ConcertGesänge. The comparison shows how the harmonic and melodic characteristics subsumed in the thoroughbass oscillate between diatonic and scale logic. The analyses uncover harmonic pattern which are only fully grasped almost a century later by theoretical discourse, especially in the context of the ›octave rule‹.']",https://hal.science/hal-03087350,"['0.shs', '1.shs.musiq']"
"['Killian Martin', 'Francesca M Cornero', 'Nicola S Clayton', 'Olivier Adam', 'Nicolas Obin', 'Valérie Dufour']","[1169469, 1338313, 1338314, 1105709, 7042, 741515]","['kimartin', 'nicolas-obin', 'valerie-dufour']","Vocal complexity in a socially complex corvid: gradation, diversity and lack of common call repertoire in male rooks",hal-04405101,2024,10.1098/rsos.231713,"['Bird', 'Repertoire', 'Heterogeneity', 'Clustering', 'Bioacoustics']","['Vocal communication is widespread in animals, with vocal repertoires of varying complexity. The social complexity hypothesis predicts that species may need high vocal complexity to deal with complex social organization (e.g. have a variety of different interindividual relations). We quantified the vocal complexity of two geographically distant captive colonies of rooks, a corvid species with complex social organization and cognitive performances, but understudied vocal abilities. We quantified the diversity and gradation of their repertoire, as well as the inter-individual similarity at the vocal unit level. We found that males produced call units with lower diversity and gradation than females, while song units did not differ between sexes. Surprisingly, while females produced highly similar call repertoires, even between colonies, each individual male produced almost completely different call repertoires from any other individual. These findings question the way male rooks communicate with their social partners. We suggest that each male may actively seek to remain vocally distinct, which could be an asset in their frequently changing social environment. We conclude that inter-individual similarity, an understudied aspect of vocal repertoires, should also be considered as a measure of vocal complexity.']",https://hal.science/hal-04405101,['0.sdv']
"['Mireille Fares', 'Catherine Pelachaud', 'Nicolas Obin']",[179912],['catherine-pelachaud'],Zero-shot style transfer for gesture animation driven by text and speech using adversarial disentanglement of multimodal style encoding,hal-04293262,2023,10.3389/frai.2023.1142997,"['Multimodal gesture synthesis', 'Zero-shot style transfer', 'Embodied conversational agents', 'Multimodal behavior style', 'Transformers']","[""Modeling virtual agents with behavior style is one factor for personalizing human-agent interaction. We propose an efficient yet effective machine learning approach to synthesize gestures driven by prosodic features and text in the style of different speakers including those unseen during training. Our model performs zero-shot multimodal style transfer driven by multimodal data from the PATS database containing videos of various speakers. We view style as being pervasive; while speaking, it colors the communicative behaviors expressivity while speech content is carried by multimodal signals and text. This disentanglement scheme of content and style allows us to directly infer the style embedding even of a speaker whose data are not part of the training phase, without requiring any further training or fine-tuning. The first goal of our model is to generate the gestures of a source speaker based on the content of two input modalities–Mel spectrogram and text semantics. The second goal is to condition the source speaker's predicted gestures on the multimodal behavior style embedding of a target speaker. The third goal is to allow zero-shot style transfer of speakers unseen during training without re-training the model. Our system consists of two main components: (1) a speaker style encoder network that learns to generate a fixed-dimensional speaker embedding style from a target speaker multimodal data (mel-spectrogram, pose, and text) and (2) a sequence-to-sequence synthesis network that synthesizes gestures based on the content of the input modalities—text and mel-spectrogram—of a source speaker and conditioned on the speaker style embedding. We evaluate that our model is able to synthesize gestures of a source speaker given the two input modalities and transfer the knowledge of target speaker style variability learned by the speaker style encoder to the gesture generation task in a zero-shot setup, indicating that the model has learned a high-quality speaker representation. We conduct objective and subjective evaluations to validate our approach and compare it with baselines.""]",https://hal.science/hal-04293262,"['0.info', '1.info.info-hc', '0.info', '1.info.info-lg']"
"['Philippe Esling', 'Carlos Agon']",[14916],['philippe-esling'],Time-series data mining,hal-01577883,2012,10.1145/2379776.2379788,"['Stream analysis', 'Similarity measures', 'Distance measures', 'Data indexing', 'Data mining', 'Query by content', 'Sequence matching', 'Temporal analysis', 'Time series']","['In almost every scientific field, measurements are performed over time. These observations lead to a collection of organized data called time series. The purpose of time-series data mining is to try to extract all meaningful knowledge from the shape of data. Even if humans have a natural capacity to perform these tasks, it remains a complex problem for computers. In this article we intend to provide a survey of the techniques applied for time-series data mining. The first part is devoted to an overview of the tasks that have captured most of the interest of researchers. Considering that in most cases, time-series task relies on the same components for implementation, we divide the literature depending on these common aspects, namely representation techniques, distance measures, and indexing methods. The study of the relevant literature has been categorized for each individual aspects. Four types of robustness could then be formalized and any kind of distance could then be classified. Finally, the study submits various research trends and avenues that can be explored in the near future. We hope that this article can provide a broad and deep understanding of the time-series data mining research field.']",https://hal.science/hal-01577883,['0.info']
"['X. Pochon', 'S A Wood', 'N B Keeley', 'F Lejzerowicz', 'Philippe Esling', 'J Drew', 'J Pawlowski']",[14916],['philippe-esling'],Accurate assessment of the impact of salmon farming on benthic sediment enrichment using foraminiferal metabarcoding,hal-01577894,2015,10.1016/j.marpolbul.2015.08.022,"['Foraminifera', 'Benthic ecology', 'Biomonitoring', 'Aquaculture', 'High-throughput sequencing', 'Metabarcoding']","['Assessing the environmental impact of salmon farms on benthic systems is traditionally undertaken using biotic indices derived from microscopic analyses of macrobenthic infaunal (MI) communities. In this study, we tested the applicability of using foraminiferal-specific high-throughput sequencing (HTS) metabarcoding for monitoring these habitats. Sediment samples and physico-chemical data were collected along an enrichment gradient radiating out from three Chinook salmon (Oncorhynchus tshawytscha) farms in New Zealand. HTS of environmental DNA and RNA (eDNA/eRNA) resulted in 1,875,300 sequences that clustered into 349 Operational Taxonomic Units. Strong correlations were observed among various biotic indices calculated from MI data and normalized fourth-root transformed HTS data. Correlations were stronger using eRNA compared to eDNA data. Quantile regression spline analyses identified 12 key foraminiferal taxa that have potential to be used as bioindicator species. This study demonstrates the huge potential for using this method for biomonitoring of fish-farming and other marine industrial activities.']",https://hal.science/hal-01577894,"['0.sde', '0.sdv', '1.sdv.bid', '0.sdv', '1.sdv.ee']"
"['Franck Lejzerowicz', 'Philippe Esling', 'Wojciech Majewski', 'Witold Szczucinski', 'Johan Decelle', 'Cyril Obadia', 'Pedro Martinez Arbizu', 'Jan Pawlowski']","[973982, 14916, 940691, 880486]",['philippe-esling'],Ancient DNA complements microfossil record in deep-sea subsurface sediments,hal-01258222,2013,10.1098/rsbl.2013.0283,"['Ancient DNA', 'Deep-sea sediments', 'Palaeogenomics', 'Microfossils', 'Next-generation sequencing']","['Deep-sea subsurface sediments are the most important archives of marine biodiversity. Until now, these archives were studied mainly using the microfossil record, disregarding large amounts of DNA accumulated on the deep-sea floor. Accessing ancient DNA (aDNA) molecules preserved down-core would offer unique insights into the history of marine biodiversity, including both fossilized and non-fossilized taxa. Here, we recover aDNA of eukaryotic origin across four cores collected at abyssal depths in the South Atlantic, in up to 32.5 thousand-year-old sediment layers. Our study focuses on Foraminifera and Radiolaria, two major groups of marine microfossils also comprising diverse non-fossilized taxa. We describe their assemblages in down-core sediment layers applying both micropalaeontological and environmental DNA sequencing approaches. Short fragments of the foraminiferal and radiolarian small subunit rRNA gene recovered from sedimentary DNA extracts provide evidence that eukaryotic aDNA is preserved in deep-sea sediments encompassing the last glacial maximum. Most aDNA were assigned to non-fossilized taxa that also dominate in molecular studies of modern environments. Our study reveals the potential of aDNA to better document the evolution of past marine ecosystems and opens new horizons for the development of deep-sea palaeogenomics.']",https://hal.science/hal-01258222,"['0.sdv', '0.sde']"
"['Jan Pawlowski', 'Philippe Esling', 'Franck Lejzerowicz', 'Tristan Cordier', 'Joana A. Visco', 'Catarina I.M. Martins', 'Arne Kvalvik', 'Knut Staven', 'Tomas Cedhagen']","[764498, 14916, 973982, 778544]",['philippe-esling'],Benthic monitoring of salmon farms in Norway using foraminiferal metabarcoding,hal-01341949,2016,10.3354/aei00182,"['Finfish farming', 'Biomonitoring', 'Environmental DNA', 'Next-generation sequencing', 'NGS', 'DNA barcoding', 'Foraminifera']","['The rapid growth of the salmon industry necessitates the development of fast and accurate tools to assess its environmental impact. Macrobenthic monitoring is commonly used to measure the impact of organic enrichment associated with salmon farm activities. However, classical benthic monitoring can hardly answer the rapidly growing demand because the morphological identification of macro-invertebrates is time-consuming, expensive and requires taxonomic expertise. Environmental DNA (eDNA) metabarcoding of meiofauna-sized organisms, such as Foraminifera, was proposed to overcome the drawbacks of macrofauna-based benthic monitoring. Here, we tested the application of foraminiferal metabarcoding to benthic monitoring of salmon farms in Norway. We analysed 140 samples of eDNA and environmental RNA (eRNA) extracted from surface sediment samples collected at 4 salmon farming sites in Norway. We sequenced the variable region 37f of the 18S rRNA gene specific to Foraminifera. We compared our data to the results of macrofaunal surveys of the same sites and tested the congruence between various diversity indices inferred from metabarcoding and morphological data. The results of our study confirm the usefulness of Foraminifera as bioindicators of organic enrichment associated with salmon farming. The foraminiferal diversity increased with the distance to fish cages, and metabarcoding provides an assessment of the ecological quality comparable to the morphological analyses. The foraminiferal metabarcoding approach appears to be a promising alternative to classical benthic monitoring, providing a solution to the morpho-taxonomic bottleneck of macrofaunal surveys.']",https://hal.sorbonne-universite.fr/hal-01341949,"['0.sdv', '1.sdv.sa', '2.sdv.sa.spa', '0.sdv', '1.sdv.gen', '2.sdv.gen.ga']"
"['Stéphane Doncieux', 'David Filliat', 'Natalia Díaz-Rodríguez', 'Timothy Hospedales', 'Richard Duro', 'Alexandre Coninx', 'Diederik M. Roijers', 'Benoît Girard', 'Nicolas Perrin', 'Olivier Sigaud']","[3909, 45, 170998, 184690, 1537, 741992, 14932]","['stephane-doncieux', 'david-filliat', 'natalia-diaz-rodriguez', 'alex-coninx', 'benoit-girard', 'nicolas-perrin-gilbert', 'olivier-sigaud']",Open-Ended Learning: A Conceptual Framework Based on Representational Redescription,hal-01889947,2018,10.3389/fnbot.2018.00059,"['State representation learning', 'Reinforcement learning', 'Developmental robotics', 'Actions and goals', 'Representational redescription', 'Skills', 'Open-ended learning']","['Reinforcement learning (RL) aims at building a policy that maximizes a task-related reward within a given domain. When the domain is known, i.e., when its states, actions and reward are defined, Markov Decision Processes (MDPs) provide a convenient theoretical framework to formalize RL. But in an open-ended learning process, an agent or robot must solve an unbounded sequence of tasks that are not known in advance and the corresponding MDPs cannot be built at design time. This defines the main challenges of open-ended learning: how can the agent learn how to behave appropriately when the adequate states, actions and rewards representations are not given? In this paper, we propose a conceptual framework to address this question. We assume an agent endowed with low-level perception and action capabilities. This agent receives an external reward when it faces a task. It must discover the state and action representations that will let it cast the tasks as MDPs in order to solve them by RL. The relevance of the action or state representation is critical for the agent to learn efficiently. Considering that the agent starts with a low level, task-agnostic state and action spaces based on its low-level perception and action capabilities, we describe open-ended learning as the challenge of building the adequate representation of states and actions, i.e., of redescribing available representations. We suggest an iterative approach to this problem based on several successive Representational Redescription processes, and highlight the corresponding challenges in which intrinsic motivations play a key role.']",https://hal.sorbonne-universite.fr/hal-01889947,"['0.info', '1.info.info-rb']"
"['Stephane Doncieux', 'Alban Laflaquière', 'Alexandre Coninx']","[3909, 184690]","['stephane-doncieux', 'alex-coninx']",Novelty search: a Theoretical Perspective,hal-02561846,2019,10.1145/3321707.3321752,"['Evolutionary robotics', 'Neural networks', 'Novelty search', 'Behavior space']","['Novelty Search is an exploration algorithm driven by the novelty of a behavior. The same individual evaluated at different generations has different fitness values. The corresponding fitness landscape is thus constantly changing and if, at the scale of a single generation , the metaphor of a fitness landscape with peaks and valleys still holds, this is not the case anymore at the scale of the whole evolutionary process. How does this kind of algorithms behave? Is it possible to define a model that would help understand how it works? This understanding is critical to analyse existing Novelty Search variants and design new and potentially more efficient ones. We assert that Novelty Search asymptotically behaves like a uniform random search process in the behavior space. This is an interesting feature, as it is not possible to directly sample in this space: the algorithm has a direct access to the genotype space only, whose relationship to the behavior space is complex. We describe the model and check its consistency on a classical Novelty Search experiment. We also show that it sheds a new light on results of the literature and suggests future research work.']",https://hal.science/hal-02561846,"['0.info', '1.info.info-rb', '0.info', '1.info.info-ai', '0.info', '1.info.info-lg', '0.info', '1.info.info-ne', '0.scco', '1.scco.comp']"
"['Alexandre Coninx', 'Georges-Pierre Bonneau', 'Jacques Droulez', 'Guillaume Thibault']","[184690, 17497, 828342]","['alex-coninx', 'georges-pierre-bonneau']",Visualization of uncertain scalar data fields using color scales and perceptually adapted noise,inria-00600161,2011,10.1145/2077451.2077462,"['Scientific visualization', 'Uncertainty visualization', 'Computer graphics', 'Perlin noise', 'Psychophysics', 'Contrast sensitivity']","['We present a new method to visualize uncertain scalar data fields by combining color scale visualization techniques with animated, perceptually adapted Perlin noise. The parameters of the Perlin noise are controlled by the uncertainty information to produce animated patterns showing local data value and quality. In order to precisely control the perception of the noise patterns, we perform a psychophysical evaluation of contrast sensitivity thresholds for a set of Perlin noise stimuli. We validate and extend this evaluation using an existing computational model. This allows us to predict the perception of the uncertainty noise patterns for arbitrary choices of parameters. We demonstrate and discuss the efficiency and the benefits of our method with various settings, color maps and data sets.']",https://inria.hal.science/inria-00600161v2,"['0.info', '1.info.info-gr', '0.scco', '1.scco.psyc']"
"['Stephane Doncieux', 'Giuseppe Paolo', 'Alban Laflaquière', 'Alexandre Coninx']","[3909, 735825, 184690]","['stephane-doncieux', 'gpaolo', 'alex-coninx']",Novelty Search makes Evolvability Inevitable,hal-02561763,2020,10.1145/3377930.3389840,"['Novelty search', 'Behavior space', 'Evolutionary robotics', 'Evolvability', 'Neural networks']","['Evolvability is an important feature that impacts the ability of evolutionary processes to find interesting novel solutions and to deal with changing conditions of the problem to solve. The estimation of evolvability is not straightforward and is generally too expensive to be directly used as selective pressure in the evolutionary process. Indirectly promoting evolvability as a side effect of other easier and faster to compute selection pressures would thus be advantageous. In an unbounded behavior space, it has already been shown that evolvable individuals naturally appear and tend to be selected as they are more likely to invade empty behavior niches. Evolvability is thus a natural byproduct of the search in this context. However, practical agents and environments often impose limits on the reach-able behavior space. How do these boundaries impact evolvability? In this context, can evolvability still be promoted without explicitly rewarding it? We show that Novelty Search implicitly creates a pressure for high evolvability even in bounded behavior spaces, and explore the reasons for such a behavior. More precisely we show that, throughout the search, the dynamic evaluation of novelty rewards individuals which are very mobile in the behavior space, which in turn promotes evolvability.']",https://hal.science/hal-02561763,"['0.info', '1.info.info-rb', '0.info', '1.info.info-ai', '0.info', '1.info.info-lg', '0.info', '1.info.info-ne', '0.scco', '1.scco.comp']"
"['Kristina Höök', 'Baptiste Caramiaux', 'Cumhur Erkut', 'Jodi Forlizzi', 'Nassrin Hajinejad', 'Michael Haller', 'Caroline C M Hummels', 'Katherine Isbister', 'Martin Jonsson', 'George Khut', 'Lian Loke', 'Danielle Lottridge', 'Patrizia Marti', 'Edward Melcer', 'Florian Floyd Müller', 'Marianne Graves Petersen', 'Thecla Schiphorst', 'Elena Márquez Segura', 'Anna Ståhl', 'Dag Svanaes', 'Jakob Tholander', 'Helena Tobiasson']","[179793, 1027393, 1004967, 1027394, 1000283, 1027395, 1027396, 1027397, 1027398, 1027399, 1027400, 1027401, 1027402, 1027403]",['baptiste-caramiaux'],Embracing First-Person Perspectives in Soma-Based Design,hal-01699005,2018,10.3390/informatics5010008,"['Somatics', 'Aesthetics', 'Somaesthetic design', 'First-person perspective', 'Movement-based interaction']","['A set of prominent designers embarked on a research journey to explore aesthetics in movement-based design. Here we unpack one of the design sensitivities unique to our practice: a strong first person perspective—where the movements, somatics and aesthetic sensibilities of the designer, design researcher and user are at the forefront. We present an annotated portfolio of design exemplars and a brief introduction to some of the design methods and theory we use, together substantiating and explaining the first-person perspective. At the same time, we show how this felt dimension, despite its subjective nature, is what provides rigor and structure to our design research. Our aim is to assist researchers in soma-based design and designers wanting to consider the multiple facets when designing for the aesthetics of movement. The applications span a large field of designs, including slow introspective, contemplative interactions, arts, dance, health applications, games, work applications and many others.']",https://hal.science/hal-01699005,"['0.info', '1.info.info-hc']"
"['Marco Gillies', 'Rebecca Fiebrink', 'Atau Tanaka', 'Baptiste Caramiaux', 'Jérémie Garcia', 'Frédéric Bevilacqua', 'Alexis Heloir', 'Fabrizio Nunnari', 'Wendy Mackay', 'Saleema Amershi', 'Bongshin Lee', ""Nicolas D 'Alessandro"", 'Joëlle Tilmanne', 'Todd Kulesza']","[739851, 179793, 23, 14805, 1219408, 7073, 998453]","['atau-tanaka', 'baptiste-caramiaux', 'jeremie-garcia', 'frederic-bevilacqua', 'alexisheloir', 'wendy-mackay']",Human-Centered Machine Learning,hal-01437057,2016,10.1145/2851581.2856492,"['Machine learning', 'User centered design', 'Data']","['Machine learning is one of the most important and successful techniques in contemporary computer science. It involves the statistical inference of models (such as classifiers) from data. It is often conceived in a very impersonal way, with algorithms working autonomously on passively collected data. However, this viewpoint hides considerable human work of tuning the algorithms, gathering the data, and even deciding what should be modeled in the first place. Examining machine learning from a human-centered perspective includes explicitly recognising this human work, as well as reframing machine learning workflows based on situated human working practices, and exploring the co-adaptation of humans and systems. A human-centered understanding of machine learning in human context can lead not only to more usable machine learning tools, but to new ways of framing learning computationally. This workshop will bring together researchers to discuss these issues and suggest future research questions aimed at creating a human-centered approach to machine learning.']",https://inria.hal.science/hal-01437057,"['0.info', '1.info.info-hc']"
"['Oleksandra Vereschak', 'Gilles Bailly', 'Baptiste Caramiaux']","[1102939, 10738, 179793]","['gilles-bailly', 'baptiste-caramiaux']","How to Evaluate Trust in AI-Assisted Decision Making? A Survey of Empirical Methodologies, Comment évaluer la confiance dans la prise de décision assistée par l'IA ? Une enquête sur les méthodologies empiriques",hal-03280969,2021,10.1145/3476068,"['Trust', 'Artificial intelligence', 'Decision making', 'Methodology', 'Trust']","['The spread of AI-embedded systems involved in human decision making makes studying human trust in these systems critical. However, empirically investigating trust is challenging. One reason is the lack of standard protocols to design trust experiments. In this paper, we present a survey of existing methods to empirically investigate trust in AI-assisted decision making and analyse the corpus along the constitutive elements of an experimental protocol. We find that the definition of trust is not commonly integrated in experimental protocols, which can lead to findings that are overclaimed or are hard to interpret and compare across studies. Drawing from empirical practices in social and cognitive studies on human-human trust, we provide practical guidelines to improve the methodology of studying Human-AI trust in decision-making contexts. In addition, we bring forward research opportunities of two types: one focusing on further investigation regarding trust methodologies and the other on factors that impact Human-AI trust. CCS Concepts: • Human-centered computing → HCI theory, concepts and models.']",https://hal.sorbonne-universite.fr/hal-03280969v2,"['0.info', '1.info.info-hc', '0.info', '1.info.info-ai', '0.shs']"
"['Jean-Philippe Rivière', 'Sarah Fdili Alaoui', 'Baptiste Caramiaux', 'Wendy Mackay']","[1328317, 179793, 7073]","['jean-phi-riviere', 'baptiste-caramiaux', 'wendy-mackay']",Capturing Movement Decomposition to Support Learning and Teaching in Contemporary Dance,hal-02378487,2019,10.1145/3359188,"['Empirical studies in collabo- rative and social computing Additional Key Words and Phrases Learning Dance', 'CCS Concepts • Human-centered computing → Empirical studies in HCI', 'Technology Probe', 'Qualitative Methods', 'Movement Decomposition']","[""Our goal is to understand how dancers learn complex dance phrases. We ran three workshops where dancers learned dance fragments from videos. In workshop 1, we analyzed how dancers structure their learning strategies by decomposing movements. In workshop 2, we introduced MoveOn, a technology probe that lets dancers decompose video into short, repeatable clips to support their learning. This served as an effective analysis tool for identifying the changes in focus and understanding their decomposition and recomposition processes. In workshop 3, we compared the teacher's and dancers' decomposition strategies, and how dancers learn on their own compared to teacher-created decompositions. We found that they all ungroup and regroup dance fragments, but with different foci of attention, which suggests that teacher-imposed decomposition is more effective for introductory dance students, whereas personal decomposition is more suitable for expert dancers. We discuss the implications for designing technology to support analysis, learning and teaching of dance through movement decomposition.""]",https://hal.science/hal-02378487,"['0.info', '1.info.info-hc']"
"['Marie Avril', 'Chloë Leclère', 'Sylvie Viaux', 'Stéphane Michelet', 'Catherine Achard', 'Sylvain Missonnier', 'Miri Keren', 'David Cohen', 'Mohamed Chetouani']","[771537, 182097, 179406, 756279, 179528]","['catherine-achard', 'sylvain-missonnier', 'mohamed-chetouani']",Social signal processing for studying parent–infant interaction,hal-01324725,2014,10.3389/fpsyg.2014.01437,"['Early parent–infant interaction', 'Feature extraction', 'Multimodal computational analysis', 'RGB-D sensor', 'Synchrony', 'Social signal processing']","['Studying early interactions is a core issue of infant development and psychopathology. Automatic social signal processing theoretically offers the possibility to extract and analyze communication by taking an integrative perspective, considering the multimodal nature and dynamics of behaviors (including synchrony).This paper proposes an explorative method to acquire and extract relevant social signals from a naturalistic early parent–infant interaction. An experimental setup is proposed based on both clinical and technical requirements. We extracted various cues from body postures and speech productions of partners using the IMI2S (Interaction, Multimodal Integration, and Social Signal) Framework. Preliminary clinical and computational results are reported for two dyads (one pathological in a situation of severe emotional neglect and one normal control) as an illustration of our cross-disciplinary protocol. The results from both clinical and computational analyzes highlight similar differences: the pathological dyad shows dyssynchronic interaction led by the infant whereas the control dyad shows synchronic interaction and a smooth interactive dialog.The results suggest that the current method might be promising for future studies.']",https://hal.sorbonne-universite.fr/hal-01324725,"['0.scco', '1.scco.psyc', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.ped', '0.shs', '1.shs.psy']"
"['Karim Slimani', 'Brahim Tamadazte', 'Catherine Achard']",[178670],['brahim-tamadazte'],RoCNet: 3D robust registration of points clouds using deep learning,hal-04661985,2024,10.1007/s00138-024-01584-6,"['Points cloud Registration', 'Deep Learning', 'Attention Mechanism', 'Pose Estimation']","['This paper introduces a new method for 3D points cloud registration based on deep learning. The architecture is composed of three distinct blocs: (i) an encoder with a convolutional graph-based descriptor that encodes the immediate neighborhood of each point and an attention mechanism that encodes the variations of the surface normals. Such descriptors are refined by highlighting attention between the points of the same set (source and target) and then between the points of the two sets. (ii) a matching process that estimates a matrix of correspondences using the Sinkhorn algorithm. (iii) Finally, the rigid transformation between the two points clouds is calculated by RANSAC using the best scores of the correspondence matrix. We conduct experiments on the ModelNet40 and real-world Bunny datasets, and our proposed architecture shows promising results, outperforming state-of-the-art methods in most simulated configurations.']",https://hal.science/hal-04661985,"['0.info', '1.info.info-ai']"
"['Jörg Müller', 'Robert Walter', 'Gilles Bailly', 'Michael Nischt', 'Florian Alt']","[1028805, 1011670, 10738, 1020099]",['gilles-bailly'],Looking Glass: A Field Study on Noticing Interactivity of a Shop Window,hal-01894214,2012,10.1145/2207676.2207718,"['Interactivity', 'Noticing Interactivity', 'Public Displays', 'User Representation']","['In this paper we present our findings from a lab and a field study investigating how passers-by notice the interactivity of public displays. We designed an interactive installation that uses visual feedback to the incidental movements of passers-by to communicate its interactivity. The lab study reveals: (1) Mirrored user silhouettes and images are more effective than avatar-like representations. (2) It takes time to notice the interactivity (approximately 1.2s). In the field study, three displays were installed during three weeks in shop windows, and data about 502 interaction sessions were collected. Our observations show: (1) Significantly more passers-by interact when immediately showing the mirrored user image (+90%) or silhouette (+47%) compared to a traditional attract sequence with call-to-action. (2) Passers-by often notice inter-activity late and have to walk back to interact (the landing effect). (3) If somebody is already interacting, others begin interaction behind the ones already interacting, forming multiple rows (the honeypot effect). Our findings can be used to design public display applications and shop windows that more effectively communicate interactivity to passers-by.']",https://hal.sorbonne-universite.fr/hal-01894214,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'Jörg P. Müller', 'Michael Rohs', 'Daniel J. Wigdor', 'Sven Kratz']","[10738, 1028805, 1026389, 941263]",['gilles-bailly'],ShoeSense: A New Perspective on Hand Gestures and Wearable Applications,hal-01894218,2012,10.1145/2207676.2208576,"['Human Factors', 'Experimentation', 'Mobile', 'Wearable', 'Gestures', 'Gesture set', 'Shoe', 'Sensor placement']","['When the user is engaged with a real-world task it can be inappropriate or difficult to use a smartphone. To address this concern, we developed ShoeSense, a wearable system consisting in part of a shoe-mounted depth sensor pointing upward at the wearer. ShoeSense recognizes relaxed and discreet as well as large and demonstrative hand gestures. In particular, we designed three gesture sets (Triangle, Radial, and Finger-Count) for this setup, which can be performed without visual attention. The advantages of ShoeSense are illustrated in five scenarios: (1) quickly performing frequent operations without reaching for the phone, (2) discreetly performing operations without disturbing others, (3) enhancing operations on mobile devices, (4) supporting accessibility, and (5) artistic performances. We present a proof-of-concept, wearable implementation based on a depth camera and report on a lab study comparing social acceptability, physical and mental demand, and user preference. A second study demonstrates a 94-99% recognition rate of our recognizers.']",https://hal.sorbonne-universite.fr/hal-01894218,"['0.info', '1.info.info-hc']"
"['Maurice ten Koppel', 'Gilles Bailly', 'Jörg Müller', 'Robert Walter']","[10738, 1028805, 1011670]",['gilles-bailly'],Chained displays,hal-01894211,2012,10.1145/2207676.2207720,"['Public displays', 'Form factor', 'Chained displays', 'Field study']","['Most interactive public displays currently rely on flat screens. This form factor impacts how users (1) notice the public display (2) develop motivation and (3) (socially) interact with the public display. In this paper, we present Chained Displays, a combination of several screens to create different form factors for interactive public displays. We also present a design space based on two complementary concepts, Focus and Nimbus, to describe and compare chained display configurations. Finally, we performed a field study comparing three chained displays: Flat, Concave, and Hexagonal. Results show that Flat triggers the strongest honeypot effect, Hexagonal causes low social learning, and Concave triggers the smallest amount of simultaneously interacting users among other findings.']",https://hal.sorbonne-universite.fr/hal-01894211,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'Antti Oulasvirta', 'Timo Kötzing', 'Sabrina Hoppe']",[10738],['gilles-bailly'],MenuOptimizer: interactive optimization of menu systems,hal-01528320,2013,10.1145/2501988.2502024,"['Predictive models', 'Interactive optimization ACM Classification Keywords H5m Information interfaces and presentation eg', 'HCI Miscellaneous']","[""Menu systems are challenging to design because design spaces are immense, and several human factors affect user behavior. This paper contributes to the design of menus with the goal of interactively assisting designers with an optimizer in the loop. To reach this goal, 1) we extend a predictive model of user performance to account for expectations as to item groupings; 2) we adapt an ant colony optimizer that has been proven efficient for this class of problems; and 3) we present MenuOptimizer, a set of interactions integrated into a real interface design tool (QtDe-signer). MenuOptimizer supports designers' abilities to cope with uncertainty and recognize good solutions. It allows designers to delegate combinatorial problems to the optimizer, which should solve them quickly enough without disrupting the design process. We show evidence that satisfactory menu designs can be produced for complex problems in minutes.""]",https://hal.sorbonne-universite.fr/hal-01528320,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'Éric Lecolinet', 'Laurence Nigay']","[10738, 174384, 9671]","['gilles-bailly', 'eric-lecolinet', 'laurence-nigay']",Visual Menu Techniques,hal-01258368,2017,10.1145/3002171,"['Menus', 'Menu techniques', 'Menu selection', 'Interaction techniques', 'HCI']","['Menus are used for exploring and selecting commands in interactive applications. They are widespread in current systems and used by a large variety of users. As a consequence, they have motivated many studies in Human-Computer Interaction (HCI). Facing the large variety of menus, it is difficult to have a clear understanding of the design possibilities and to ascertain their similarities and differences. In this article, we address a main challenge of menu design: the need to characterize the design space of menus. To do this, we propose a taxonomy of menu properties that structures existing work on visual menus. In order to highlight the impact of the properties on performance, we begin by refining performance through a list of quality criteria and by reviewing existing analytical and empirical methods for quality evaluation. The taxonomy of menu properties is an unavoidable step toward the elaboration of advanced predictive models of menu performance and the optimization of menus. A key point of this work is to focus both on menus and on the properties of menus, to enable a fine-grained analysis in terms of performance.']",https://hal.science/hal-01258368v2,"['0.info', '1.info.info-hc']"
"['Katta Spiel', 'Emeline Brulé', 'Christopher Frauenberger', 'Gilles Bailly', 'Geraldine Fitzpatrick']","[6180, 1034518, 10738, 1018519]","['emeline-brule', 'gilles-bailly']",Micro-Ethics for Participatory Design with Marginalised Children,hal-01839208,2018,10.1145/3210586.3210603,"['Children', 'Participatory Research', 'Ethics', 'HCI-Sorbonne', 'Marginalisation', 'Accessibility theory', 'Design']","['Marginalised children are uniquely vulnerable within western societies. Conducting participatory design research with them comes with particular ethical challenges, some of which we illustrate in this paper. Through several examples across two different partic-ipatory design projects (one with autistic children, another with visually impaired children), we reflect on the often overlooked tensions on the level of micro-ethics. We argue we are often required to rely on multiple moral frames of references. We discuss issues that the immediate interaction between researchers and marginalised children in participatory projects can bring and offer an understanding of how micro-ethics manifest in these collaborations. We contribute to a theoretical exploration of ethical encounters based on empirical grounds, which can guide other researchers in their participatory endeavours.']",https://hal.science/hal-01839208,"['0.shs', '1.shs.edu', '0.shs', '1.shs.info', '0.shs', '1.shs.socio']"
"['Gilles Bailly', 'Eric Lecolinet', 'Laurence Nigay']","[10738, 174384, 9671]","['gilles-bailly', 'eric-lecolinet', 'laurence-nigay']","Flower Menus: A New Type of Marking Menu with Large Menu Breadth, Within groups and Efficient Expert Mode Memorization",hal-01894182,2008,10.1145/1385569.1385575,"['H52 User Interfaces Interaction styles I36 Methodology and Techniques Interaction techniques General Terms Design', 'Human Factors', 'Marking menus', 'Polygon menus', 'Flower menus', 'Within groups', 'Curved gestures', 'Novice mode', 'Expert mode', 'Learning performance']","['This paper presents Flower menu, a new type of Marking menu that does not only support straight, but also curved gestures for any of the 8 usual orientations. Flower menus make it possible to put many commands at each menu level and thus to create as large a hierarchy as needed for common applications. Indeed our informal analysis of menu breadth in popular applications shows that a quarter of them have more than 16 items. Flower menus can easily contain 20 items and even more (theoretical maximum of 56 items). Flower menus also support within groups as well as hierarchical groups. They can thus favor breadth organization (within groups) or depth organization (hierarchical groups): as a result, the designers can lay out items in a very flexible way in order to reveal meaningful item groupings. We also investigate the learning performance of the expert mode of Flower menus. A user experiment is presented that compares linear menus (baseline condition), Flower menus and Polygon menus, a variant of Marking menus that supports a breadth of 16 items. Our experiment shows that Flower menus are more efficient than both Polygon and Linear menus for memorizing command activation in expert mode.']",https://hal.sorbonne-universite.fr/hal-01894182,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'Antti Oulasvirta', 'Duncan P. Brumby', 'Andrew Howes']","[10738, 1026404, 1006487]",['gilles-bailly'],Model of visual search and selection time in linear menus,hal-01820441,2014,10.1145/2556288.2557093,"['Linear menus', 'User Performance', 'Mathematical predictive models', 'Visual search', 'Eye-tracking']","['This paper presents a novel mathematical model for visual search and selection time in linear menus. Assuming two visual search strategies, serial and directed, and a pointing sub-task, it captures the change of performance with five factors: 1) menu length, 2) menu organization, 3) target position , 4) absence/presence of target, and 5) practice. The novel aspect is that the model is expressed as probability density distribution of gaze, which allows for deriving total selection time. We present novel data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking and mouse tracking to confirm model predictions. The same parametrization yielded a high fit to both menu selection time and gaze distributions. The model has the potential to improve menu designs by helping designers identify more effective solutions without conducting empirical studies.']",https://hal.sorbonne-universite.fr/hal-01820441,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'Thomas Pietrzak', 'Jonathan Deber', 'Daniel J. Wigdor']","[10738, 1575, 941262, 941263]","['gilles-bailly', 'thomaspietrzak']",Metamorphe: Augmenting Hotkey Usage with Actuated Keys,hal-00822359,2013,10.1145/2470654.2470734,"['User-Defined Gestures', 'Shape-Changing Interface', 'Hotkeys', 'Height-Changing keys', 'Augmented keyboard', 'Human - Computer Interaction']","['Hotkeys are an efficient method of selecting commands on a keyboard. However, these shortcuts are often underused by users. We present Metamorphe, a novel keyboard with keys that can be individually raised and lowered to promote hotkeys usage. MÃ©tamorphe augments the output of traditional keyboards with haptic and visual feedback, and offers a novel design space for user input on raised keys (e.g., gestures such as squeezing or pushing the sides of a key). We detail the implementation of Metamorphe and discuss design factors. We also report two user studies. The first is a user-defined interface study that shows that the new input vocabulary is usable and useful, and provides insights into the mental models that users associate with raised keys. The second user study shows improved eyes-free selection performance for raised keys as well as the surrounding unraised keys.']",https://inria.hal.science/hal-00822359,"['0.info', '1.info.info-hc', '0.info', '1.info.info-dl']"
"['Sylvain Malacria', 'Gilles Bailly', 'Joel Harrison', 'Andy Cockburn', 'Carl Gutwin']","[6822, 10738, 1016856]","['sylvain-malacria', 'gilles-bailly']",Promoting Hotkey Use through Rehearsal with ExposeHK,hal-01894253,2013,10.1145/2470654.2470735,"['Keyboard Shortcuts', 'Author Keywords Hotkeys', 'Shortcuts', 'Rehearsal', 'Menus', 'Expert Mode', 'Novice Mode', 'Command Selection', 'Keyboard Shortcuts']","['Keyboard shortcuts allow fast interaction, but they are known to be infrequently used, with most users relying heavily on traditional pointer-based selection for most commands. We describe the goals, design, and evaluation of ExposeHK, a new interface mechanism that aims to increase hotkey use. ExposeHK’s four key design goals are: 1) enable users to browse hotkeys; 2) allow non-expert users to issue hotkey commands as a physical rehearsal of expert performance; 3) exploit spatial memory to assist non-expert users in identifying hotkeys; and 4) maximise expert performance by using consistent shortcuts in a flat command hierarchy. ExposeHK supports these objectives by displaying hotkeys overlaid on their associated commands when a modifier key is pressed. We evaluated ExposeHK in three empirical studies using toolbars, menus, and a tabbed ‘ribbon’ toolbar. Results show that participants used more hotkeys, and used them more often, with ExposeHK than with other techniques; they were faster with ExposeHK than with either pointing or other hotkey methods; and they strongly preferred ExposeHK. Our research shows that ExposeHK can substantially improve the user’s transition from a ‘beginner mode’ of interaction to a higher level of expertise.']",https://hal.science/hal-01894253,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'Eric Lecolinet', 'Yves Guiard']","[10738, 174384, 173797]","['gilles-bailly', 'eric-lecolinet', 'yves-guiard']",Finger-Count & Radial-Stroke Shortcuts: Two Techniques for Augmenting Linear Menus on Multi-Touch Surfaces,hal-01894198,2010,10.1145/1753326.1753414,"['Menu techniques', 'Multi-touch', 'Multi-finger interaction', 'Two-handed interaction']","['Figure 1: Left: Finger-Count Shortcuts: the non-dominant hand (NDH) selects the pulldown menu in the menubar while the dominant hand (DH) selects the item. Favorite Menus (resp. items) are selected according to the number of fingers of the NDH (resp. DH) that are pressed on the surface. Right: Radial-Stroke Shortcuts: at least two fingers of the NDH are pressed to activate the menubar mode while one finger of the DH performs a multi-stroke radial gesture. ABSTRACT We propose Radial-Stroke and Finger-Count Shortcuts, two techniques aimed at augmenting the menubar on multi-touch surfaces. We designed these multi-finger two-handed interaction techniques in an attempt to overcome the limitations of direct pointing on interactive surfaces, while maintaining compatibility with traditional interaction techniques. While Radial-Stroke Shortcuts exploit the well-known advantages of Radial Strokes, Finger-Count Shortcuts exploit multi-touch by simply counting the number of fingers of each hand in contact with the surface. We report the results of an experimental evaluation of our technique, focusing on expert-mode performance. Finger-Count Shortcuts outperformed Radial-Stroke Shortcuts in terms of both easiness of learning and performance speed.']",https://hal.sorbonne-universite.fr/hal-01894198,"['0.info', '1.info.info-hc']"
"['Gilles Bailly', 'J. Müller', 'Eric Lecolinet']","[10738, 174384]","['gilles-bailly', 'eric-lecolinet']",Design and Evaluation of Finger-Count Interaction: Combining multitouch gestures and menus,hal-00830056,2012,10.1016/j.ijhcs.2012.05.006,"['Two-handed interaction', 'Multi-finger interaction', 'Menu techniques', 'Multi-touch']","['Selecting commands on multi-touch displays is still a challenging problem. While a number of gestural vocabularies have been proposed, these are generally restricted to one or two fingers or can be difficult to learn. We introduce Finger-Count gestures, a coherent set of multi-finger and two-handed gestures. Finger-Count gestures are simple, robust, expressive and fast to perform. In order to make these gestures self-revealing and easy to learn, we propose the Finger-Count menu, a menu technique and teaching method for implicitly learning Finger-Count gestures. We discuss the properties, advantages and limitations of Finger-Count interaction from the gesture and menu technique perspectives as well as its integration into three applications. We present alternative designs to increase the number of commands and to enable multi-user scenarios. Following a study which shows that Finger-Count is as easy to learn as radial menus, we report the results of an evaluation investigating which gestures are easier to learn and which finger chords people prefer. Finally, we present Finger-Count for in-the-air gestures. Thereby, the same gesture set can be used from a distance as well as when touching the surface.']",https://imt.hal.science/hal-00830056,"['0.info', '1.info.info-hc']"
"['Sven Kratz', 'Michael Rohs', 'Dennis Guse', 'Jörg Müller', 'Gilles Bailly', 'Michael Nischt']","[1026389, 1037398, 1028805, 10738]",['gilles-bailly'],PalmSpace: Continuous Around-Device Gestures vs. Multitouch for 3D Rotation Tasks on Mobile Devices,hal-01894225,2012,10.1145/2254556.2254590,"['Around-device interaction', 'Depth camera', 'Mobile interaction', '3D user interfaces', '3D Rotation', 'Input devices']","[""Rotating 3D objects is a dicult task on mobile devices, because the task requires 3 degrees of freedom and (multi-)touch input only allows for an indirect mapping. We propose a novel style of mobile interaction based on mid-air gestures in proximity of the device to increase the number of DOFs and alleviate the limitations of touch interaction with mobile devices. While one hand holds the device, the other hand performs mid-air gestures in proximity of the device to control 3D objects on the mobile device's screen. A flat hand pose defines a virtual surface which we refer to as the PalmSpace for precise and intuitive 3D rotations. We constructed several hardware prototypes to test our interface and to simulate possible future mobile devices equipped with depth cameras. We conducted a user study to compare 3D rotation tasks using the most promising two designs for the hand location during interaction-behind and beside the device-with the virtual trackball, which is the current state-of-art technique for orientation manipulation on touch-screens. Our results show that both variants of PalmSpace have significantly lower task completion times in comparison to the virtual trackball. Figure 1: Using the pose of the flat hand behind the device to freely rotate a 3D object. A depth camera is used to determine the hand posture.""]",https://hal.sorbonne-universite.fr/hal-01894225,"['0.info', '1.info.info-hc']"
"['Marc Teyssier', 'Gilles Bailly', 'Catherine Pelachaud', 'Eric Lecolinet', 'Andrew R. Conn', 'Anne Roudaut']","[996809, 10738, 179912, 174384, 990894]","['gilles-bailly', 'catherine-pelachaud', 'eric-lecolinet']",Skin-On Interfaces: A Bio-Driven Approach for Artificial Skin Design to Cover Interactive Devices,hal-02340056,2019,10.1145/3332165.3347943,"['Skin', 'Deformable', 'Sensing', 'Peau', 'Malleable', 'Artificial Skin', 'Skin-on', 'Skin']","['We propose a paradigm called Skin-On interfaces, in which interactive devices have their own (artificial) skin, thus enabling new forms of input gestures for end-users (e.g. twist, scratch). Our work explores the design space of Skin-On interfaces by following a bio-driven approach: (1) From a sensory point of view, we study how to reproduce the look and feel of the human skin through three user studies; (2) From a gestural point of view, we explore how gestures naturally performed on skin can be transposed to Skin-On interfaces; (3) From a technical point of view, we explore and discuss different ways of fabricating interfaces that mimic human skin sensitivity and can recognize the gestures observed in the previous study; (4) We assemble the insights of our three exploratory facets to implement a series of Skin-On interfaces and we also contribute by providing a toolkit that enables easy reproduction and fabrication.']",https://telecom-paris.hal.science/hal-02340056,"['0.info', '1.info.info-hc']"
"['Aymeric Becq', 'Jérôme Szewczyk', 'Grégoire Salin', 'Marion Chartier', 'Ulriikka Chaput', 'Romain Leenhardt', 'Xavier Dray', 'Lionel Arrive', 'Marine Camus']",[1101513],,ERCP 2.0: Biliary 3D-reconstruction in patients with malignant hilar stricture,hal-04156125,2023,10.1016/j.clinre.2023.102172,"['ERCP', 'MRCP', 'Segmentation', '3d reconstruction', 'Malignant hilar stricture']","['Background: Endoscopic retrograde cholangiopancreatography (ERCP) for malignant hilar strictures is challenging. The correlation between Magnetic resonance cholangiopancreatography (MRCP) and per ERCP 2D fluoroscopic images is not obvious. The aim of this study was to evaluate the feasibility and potential usefulness of MRCP-based handmade biliary 3D reconstruction in this setting. Methods: Methods Patients who underwent MRCP followed by ERCP for biliary drainage of a malignant hilar stricture at our institution between 2018 and 2020 were reviewed. A handmade 3D segmentation using 3D slicerÓ (Kitware, France) was fashioned and reviewed with an expert radiologist. The primary outcome was the feasibility of biliary segmentation. Results: A total of 16 patients were included. The mean age was 70.1 (+/-8.6) years-old and 68.8% had hilar cholangiocarcinoma. Handmade segmentation was successful in all cases. The agreement between the MRCP interpretation and the 3D reconstruction was 37.5%, as per the Bismuth classification. 3D reconstruction available prior to ERCP could have helped guide for better stent placement in 11 cases (68.8%). Conclusions: MRCP-based biliary 3D segmentation-reconstruction, in patients with malignant hilar stricture is feasible and seems to provide a better anatomical understanding compared to MRCP and could help improve endoscopic management.']",https://hal.sorbonne-universite.fr/hal-04156125,['0.sdv']
"['Lynda Tamine', 'Laure Soulier', 'Lamjed Ben Jabeur', 'Frédéric Amblard', 'Chihab Hanachi', 'Gilles Hubert', 'Camille Roth']","[744669, 8070, 935223, 10741, 980773, 737483, 1042429]","['lynda-tamine-lechani', 'soulierl', 'frederic-amblard', 'ghubert', 'camille-roth']",Social Media-Based Collaborative Information Access: Analysis of Online Crisis-Related Twitter Conversations,hal-03597237,2016,10.1145/2914586.2914589,"['Collaboration', 'Information Access', 'Twitter', 'Topic Mod-els', 'Social Networks']","['The notion of implicit (or explicit) collaborative information access refers to systems and practices allowing a group of users to unintentionally (respectively intentionally) seek, share and retrieve information to achieve similar (respectively shared) information-related goals. Despite an increasing adoption in social environments, collaboration behavior in information seeking and retrieval is mainly limited to small-sized groups, generally restricted to working spaces. Much remains to be learned about collaborative information seeking within open web social spaces. This paper is an attempt to better understand either implicit or explicit collaboration by studying Twitter, one of the most popular and widely used social networks. We study in particular the complex intertwinement of human interactions induced by both collaboration and social networking. We empirically explore explicit collaborative interactions based on focused conversation streams during two crisis. We identify structural patterns of temporally representative conversation subgraphs and represent their topics using Latent Dirichlet Allocation (LDA) modeling. Our main findings suggest that: 1) the critical mass of collaboration is generally limited to small-sized flat networks, with or without an influential user, 2) users are active as members of weakly overlapping groups and engage in numerous collaborative search and sharing tasks dealing with different topics, and 3) collaborative group ties evolve within the time-span of conversations.']",https://sciencespo.hal.science/hal-03597237,"['0.info', '1.info.info-wb', '0.info', '1.info.info-si', '0.info', '1.info.info-tt', '0.info', '1.info.info-hc', '0.shs', '1.shs.socio']"
"['Gia-Hung Nguyen', 'Lynda Tamine', 'Laure Soulier', 'Nathalie Bricon-Souf']","[986757, 744669, 8070, 742823]","['lynda-tamine-lechani', 'soulierl', 'nathalie-souf']",Learning Concept-Driven Document Embeddings for Medical Information Search,hal-01517094,2017,10.1007/978-3-319-59758-4_17,"['Medical concepts', 'Representation learning', 'Medical information search', 'Knowl- edge resource']","['Many medical tasks such as self-diagnosis, health-care assessment , and clinical trial patient recruitment involve the usage of information access tools. A key underlying step to achieve such tasks is the document-to-document matching which mostly fails to bridge the gap identified between raw level representations of information in documents and high-level human interpretation. In this paper, we study how to optimize the document representation by leveraging neural-based approaches to capture latent representations built upon both validated medical concepts specified in an external resource as well as the used words. We experimentally show the effectiveness of our proposed model used as a support of two different medical search tasks, namely health search and clinical search for cohorts.']",https://hal.sorbonne-universite.fr/hal-01517094,"['0.info', '1.info.info-ir']"
"['Laure Soulier', 'Lynda Tamine', 'Gia-Hung Nguyen']","[8070, 744669, 986757]","['soulierl', 'lynda-tamine-lechani']",Answering Twitter Questions: a Model for Recommending Answerers through Social Collaboration,hal-01353587,2016,10.1145/2983323.2983771,"['Social Network Question-Answering', 'Social information retrieval', 'Collaborative group recommen-dation']","['In this paper, we specifically consider the challenging task of solving a question posted on Twitter. The latter generally remains unanswered and most of the replies, if any, are only from members of the questioner\'s neighborhood. As outlined in previous work related to community Q&A, we believe that question-answering is a collaborative process and that the relevant answer to a question post is an aggregation of answer nuggets posted by a group of relevant users. Thus, the problem of identifying the relevant answer turns into the problem of identifying the right group of users who would provide useful answers and would possibly be willing to collaborate together in the long-term. Accordingly, we present a novel method, called CRAQ, that is built on the collaboration paradigm and formulated as a group entropy optimization problem. To optimize the quality of the group, an information gain measure is used to select the most likely "" informative "" users according to topical and collaboration likelihood predictive features. Crowd-based experiments performed on two crisis-related Twitter datasets demonstrate the effectiveness of our collaborative-based answering approach.']",https://hal.sorbonne-universite.fr/hal-01353587,"['0.info', '1.info.info-ir']"
"['Nam Le Hai', 'Thomas Gerald', 'Thibault Formal', 'Jian-Yun Nie', 'Benjamin Piwowarski', 'Laure Soulier']","[1217894, 1105732, 993095, 9362, 8070]","['thomasgerald', 'benjamin-piwowarski', 'soulierl']",CoSPLADE: Contextualizing SPLADE for Conversational Information Retrieval,hal-04168526,2023,10.1007/978-3-031-28244-7_34,"['Information retrieval', 'Conversational search', 'First-stage ranking']","['Conversational search is a difficult task as it aims at retrieving documents based not only on the current user query but also on the full conversation history. Most of the previous methods have focused on a multi-stage ranking approach relying on query reformulation, a critical intermediate step that might lead to a sub-optimal retrieval. Other approaches have tried to use a fully neural IR first-stage, but are either zero-shot or rely on full learning-to-rank based on a dataset with pseudo-labels. In this work, leveraging the CANARD dataset, we propose an innovative lightweight learning technique to train a first-stage ranker based on SPLADE. By relying on SPLADE sparse representations, we show that, when combined with a second-stage ranker based on T5Mono, the results are competitive on the TREC']",https://hal.science/hal-04168526,"['0.info', '1.info.info-ir', '0.info', '1.info.info-ai', '0.info', '1.info.info-tt']"
"['Laure Soulier', 'Lynda Tamine', 'Wahiba Bahsoun']","[8070, 744669, 935224]","['soulierl', 'lynda-tamine-lechani']",On Domain Expertise-based Roles in Collaborative Information Retrieval,hal-01118658,2014,10.1016/j.ipm.2014.04.002,"['Collaborative Information Retrieval', 'Ranking Model', 'Domain Expertise', 'Learning-Method']","['Collaborative information retrieval involves retrieval settings in which a group of users collaborates to satisfy the same underlying need. One core issue of collaborative IR models involves either supporting collaboration with adapted tools or developing IR models for a multiple-user context and pro-viding a ranked list of documents adapted for each collaborator. In this paper, we introduce the first document-ranking model supporting collab-oration between two users characterized by roles relying on different do-main expertise levels. Specifically, we propose a two-step ranking model: we first compute a document-relevance score, taking into consideration do-main expertise-based roles. We introduce specificity and novelty factors into language-model smoothing, and then we assign, via an Expectation-Maximization algorithm, documents to the best-suited collaborator. Our experiments employ a simulation-based framework of collaborative informa-tion retrieval and show the significant effectiveness of our model at different search levels.']",https://hal.science/hal-01118658v2,"['0.info', '1.info.info-ir', '0.info', '1.info.info-it']"
"['Mathias Vast', 'Yuxuan Zong', 'Benjamin Piwowarski', 'Laure Soulier']","[1366751, 1366752, 9362, 8070]","['benjamin-piwowarski', 'soulierl']","Simple Domain Adaptation for Sparse Retrievers, Adaptation de Domaine Simple pour la Recherche Parcimonieuse",hal-04517668,2024,10.1007/978-3-031-56063-7_32,"['Pretrained Language Models', 'Cross-Topic Adaptation', 'Zero-Shot']","['n Information Retrieval, and more generally in Natural Language Processing, adapting models to specific domains is conducted through fine-tuning. Despite the successes achieved by this method and its versa- tility, the need for human-curated and labeled data makes it impractical to transfer to new tasks, domains, and/or languages when training data doesn’t exist. Using the model without training (zero-shot) is another option that however suffers an effectiveness cost, especially in the case of first-stage retrievers. Numerous research directions have emerged to tackle these issues, most of them in the context of adapting to a task or a language. However, the literature is scarcer for domain (or topic) adaptation. In this paper, we address this issue of cross-topic discrepancy for a sparse first-stage retriever by transposing a method initially designed for language adaptation. By leveraging pre-training on the target data to learn domain-specific knowledge, this technique alleviates the need for annotated data and expands the scope of domain adaptation. Despite their relatively good generalization ability, we show that even sparse retrievers can benefit from our simple domain adaptation method.', 'Dans le cadre de la Recherche d\'Information (RI), l\'apprentissage des modèles repose fortement sur l\'approche ""pré-entraîner puis affiner"". Malgré ses très bons résultats, cette méthode nécessite d\'avoir accès à un jeu de données labellisées ce qui complique son application à de nouveaux domaines ou langues, en particulier si ceux-ci sont faiblement fournis. Cet article propose une solution simple au transfert d\'un modèle de recherche parcimonieux, SPLADE, vers des domaines sans données labellisées.']",https://hal.sorbonne-universite.fr/hal-04517668,"['0.info', '1.info.info-ir']"
"['Eléonore Ferrier-Barbut', 'Ignacio Avellino', 'Geoffroy Canlorbe', 'Marie-Aude Vitrani', 'Vanda Luengo']","[22148, 1387051, 4559, 13359]","['ignacio-avellino', 'vitrani', 'vanda-luengo']",Learning With Pedagogical Models: Videos As Adjuncts to Apprenticeship for Surgical Training,hal-04017134,2023,10.1145/3579615,"['Video-based learning', 'Conceptual Fields theory', 'Surgery', 'Guided practice']","['Videos are a powerful media to learn activities through guided physical training such as surgery, especially when they are produced following human learning models and not as ""how-to"" videos. However, their success greatly depends on how they are integrated into the extensive curricula of domains where learning occurs through guided practice. In this work, we investigate the impact of integrating video as a learning tool into the learning curricula of surgery. We created a pedagogical video on surgical hysterectomy through a model based on the Conceptual Fields theory (Vergnaud) and performed two rounds of interviews with seven medical residents, who watched the video freely during their residency in gynecology-obstetrics as they trained with experts. We fnd that videos can complement guided physical training, as they can provide the rationale behind expert action, something that is difcult to explicit during guided training. Still, their linear and static nature limits their integration as true adjuncts. We discuss our vision of moving towards interactive videos created with an ontological approach, developed in a workshop with four expert surgeons, which involves the ability to navigate through levels of information and layers of representations, so that experts can represent information to learners according to pedagogical models that complement their complex and extensive learning curricula.']",https://hal.science/hal-04017134,"['0.info', '1.info.info-hc']"
"['Eléonore Ferrier-Barbut', 'Ignacio Avellino', 'Marie-Aude Vitrani', 'Geoffroy Canlorbe']","[1111369, 22148, 4559, 1387051]","['ignacio-avellino', 'vitrani']","Head Mounted Displays in Surgical Training and Planning: A Literature Review, Les Visiocasques dans la Formation et la Planification Chirurgicales : Une Revue de la Littérature",hal-04019531,2023,10.1145/3583961.3583973,"['Head Mounted Displays', 'Mixed Reality', 'Surgical Training', 'Surgical Planning', 'Visiocasques', 'Réalité Mixte', 'Formation Chirurgicale', 'Planification Chirurgicale']","['Training and planning are two important preclinical activities when preparing for surgery. Although Head Mounted Displays (HMDs) are progressively being studied for training and planning in Mixed Reality (MR), clinicians need scientific evidence before making decisions when institutionalizing the technology. We investigate the up-to-date demonstrated benefits of MR-HMDs for preclinical activities through a systematic literature review using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The results indicate little evidence-based findings. Only twelve studies were eligible, nine Randomized Controlled Studies (RCT), and three non-RCT comparative studies. Regarding training, even if there is evidence demonstrating learning benefits, these do not seem to transpose to real environments. Regarding planning, we see little-to-no evidence supporting MR-HMDs compared with traditional methods. We discuss possible directions so that future studies can increase the level of evidence, as well as how the technology can evolve to better support the particular needs of surgery.', ""L'apprentissage et la planification sont deux activités précliniques importantes lors de la préparation d’une intervention chirurgicale. Bien que les visiocasques (HMDs) soient progressivement étudiés pour la formation et la planification en Réalité Mixte (RM), les cliniciens ont besoin de preuves scientifiques avant de prendre des décisions concernant l’institutionnalisation de cette technologie dans les programmes de formation. Nous étudions les avantages actuellement démontrés des HMD-RM pour les activités précliniques par le biais d’une revue systématique de la littérature en utilisant les directives PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses). Les résultats indiquent peu de résultats basés sur la preuve. Seules douze études étaient admissibles, neuf études contrôlées randomisées (ECR) et trois études comparatives non-ECR. En ce qui concerne la formation, il existe des preuves démontrant les avantages de l’apprentissage, mais celles-ci ne semblent pas se transposer aux environnements réels. En ce qui concerne la planification, il n’existe que peu ou pas de preuves de l’utilité des HMDs-RM par rapport aux méthodes traditionnelles. Nous discutons des orientations possibles pour les études futures afin d’augmenter la qualité des études menées et de faire évoluer la technologie pour mieux répondre aux besoins particuliers de la chirurgie.""]",https://hal.science/hal-04019531,"['0.info', '1.info.info-hc', '0.info', '1.info.eiah', '0.info', '1.info.info-gr', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.chi']"
"['Marie-Aude Vitrani', 'Anja Marx', 'Razvan Iordache', 'Serge Muller', 'Guillaume Morel']","[4559, 756208, 745060]","['vitrani', 'guillaume-morel']",Robot guidance of an ultrasound probe toward a 3D region of interest detected through X-ray mammography,hal-01170661,2015,10.1007/s11548-015-1244-8,"['Comanipulation', 'Human-robot collaboration', 'Breast cancer detection', 'Assisted gesture']","[""Purpose: This research is situated in the context of breast cancer detection where the standard procedure is the succession of an initial mammography (MX) examination and a supplementary Ultrasound (US) scan. One major difficulty of this procedure results from the fact that breast geometry changes between both examinations due to different patient's positions. The proposed system facilitates this combined examination by keeping the breast geometry and by adding a US probe guidance robot to the mammography system. Methods: A co-manipulation system is set up where the robot and user simultaneously manipulate the probe towards the target previously localized in MX images. Calibration procedures and robot control are detailed. Results: A test protocol was presented to conduct two tests that are both related to the medical application. The first tests aims at evaluating robot guidance for localizing a lesion which was previously defined in the X-ray images. The second tests aims at quantifying robot influence when scanning a target lesion. The studied task consists of a pointing/scanning exercise, where the US beam intersects a breast lesion. Conclusions: The experiments show a significant increase in examination quality when using robot guidance as compared to the non-assisted examination.""]",https://hal.science/hal-01170661,['0.spi']
"['Charline Grossard', 'Ouriel Grynszpan', 'Sylvie Serret', 'Anne-Lise Jouen', 'Kevin Bailly', 'David Cohen']","[181765, 746498]","['kevin-bailly', 'david-cohen']",Serious games to teach social interactions and emotions to individuals with autism spectrum disorders (ASD),hal-01525828,2017,10.1016/j.compedu.2017.05.002,"['Evidence-based medicine', 'Serious games', 'Autism', 'Information communication technologies', 'Social skills']","['The use of information communication technologies (ICTs) in therapy offers new perspectives for treating many domains in individuals with autism spectrum disorders (ASD) because they can be used in many different ways and settings and they are attractive to the patients. We reviewed the available literature on serious games that are used to teach social interactions to individuals with ASD. After screening the Medline, Science Direct and ACM Digital Library databases, we found a total of 31 serious games: 16 that targeted emotion recognition or production and 15 that targeted social skills. There was a significant correlation between the number of reports per year and the year of publication. Serious games appeared promising because they can support training on many different skills and they favour interactions in diverse contexts and situations, some of which may resemble real life. However, the currently available serious games exhibit some limitations: (i) most of them are developed for High-Functioning individuals; (ii) their clinical validation has rarely met the evidence-based medicine standards; (iii) the game design is not usually described; and, (iv) in many cases, the clinical validation and playability/game design are not compatible.']",https://hal.sorbonne-universite.fr/hal-01525828,"['0.info', '1.info.info-ai', '0.info', '1.info.eiah', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.psm']"
"['Ferdinand Dhombres', 'Jules Bonnard', 'Kevin Bailly', 'Paul Maurice', 'Aris Papageorghiou', 'Jean-Marie Jouannic']","[14980, 825398, 181765, 804586, 756873, 980060]","['dhombres-ferdinand', 'kevin-bailly', 'jean-marie-jouannic']",Contributions of Artificial Intelligence Reported in Obstetrics and Gynecology Journals: Systematic Review,hal-03648171,2022,10.2196/35465,"['Gynaecology', 'Knowledge bases', 'Machine learning', 'Medical informatics', 'Obstetrics', 'Perinatology', 'Systematic review', 'Artificial intelligence']","['Background The applications of artificial intelligence (AI) processes have grown significantly in all medical disciplines during the last decades. Two main types of AI have been applied in medicine: symbolic AI (eg, knowledge base and ontologies) and nonsymbolic AI (eg, machine learning and artificial neural networks). Consequently, AI has also been applied across most obstetrics and gynecology (OB/GYN) domains, including general obstetrics, gynecology surgery, fetal ultrasound, and assisted reproductive medicine, among others. Objective The aim of this study was to provide a systematic review to establish the actual contributions of AI reported in OB/GYN discipline journals. Methods The PubMed database was searched for citations indexed with “artificial intelligence” and at least one of the following medical subject heading (MeSH) terms between January 1, 2000, and April 30, 2020: “obstetrics”; “gynecology”; “reproductive techniques, assisted”; or “pregnancy.” All publications in OB/GYN core disciplines journals were considered. The selection of journals was based on disciplines defined in Web of Science. The publications were excluded if no AI process was used in the study. Review, editorial, and commentary articles were also excluded. The study analysis comprised (1) classification of publications into OB/GYN domains, (2) description of AI methods, (3) description of AI algorithms, (4) description of data sets, (5) description of AI contributions, and (6) description of the validation of the AI process. Results The PubMed search retrieved 579 citations and 66 publications met the selection criteria. All OB/GYN subdomains were covered: obstetrics (41%, 27/66), gynecology (3%, 2/66), assisted reproductive medicine (33%, 22/66), early pregnancy (2%, 1/66), and fetal medicine (21%, 14/66). Both machine learning methods (39/66) and knowledge base methods (25/66) were represented. Machine learning used imaging, numerical, and clinical data sets. Knowledge base methods used mostly omics data sets. The actual contributions of AI were method/algorithm development (53%, 35/66), hypothesis generation (42%, 28/66), or software development (3%, 2/66). Validation was performed on one data set (86%, 57/66) and no external validation was reported. We observed a general rising trend in publications related to AI in OB/GYN over the last two decades. Most of these publications (82%, 54/66) remain out of the scope of the usual OB/GYN journals. Conclusions In OB/GYN discipline journals, mostly preliminary work (eg, proof-of-concept algorithm or method) in AI applied to this discipline is reported and clinical validation remains an unmet prerequisite. Improvement driven by new AI research guidelines is expected. However, these guidelines are covering only a part of AI approaches (nonsymbolic) reported in this review; hence, updates need to be considered.']",https://hal.science/hal-03648171,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.geo', '0.info', '1.info.info-ai', '0.info', '1.info.info-im']"
"['Mehdi Khamassi', 'Mark D. Humphries']",[186],['mehdi-khamassi'],Integrating cortico-limbic-basal ganglia architectures for learning model-based and model-free navigation strategies,hal-01219958,2012,10.3389/fnbeh.2012.00079,"['Reinforcement learning', 'Habit', 'Stimulus-response', 'Action-outcome', 'Nucleus accumbens']","['Behavior in spatial navigation is often organized into map-based (place-driven) vs. map-free (cue-driven) strategies; behavior in operant conditioning research is often organized into goal-directed vs. habitual strategies. Here we attempt to unify the two. We review one powerful theory for distinct forms of learning during instrumental conditioning, namely model-based (maintaining a representation of the world) and model-free (reacting to immediate stimuli) learning algorithms. We extend these lines of argument to propose an alternative taxonomy for spatial navigation, showing how various previously identified strategies can be distinguished as "" model-based "" or "" model-free "" depending on the usage of information and not on the type of information (e.g., cue vs. place). We argue that identifying "" model-free "" learning with dorsolateral striatum and "" model-based "" learning with dorsomedial striatum could reconcile numerous conflicting results in the spatial navigation literature. From this perspective, we further propose that the ventral striatum plays key roles in the model-building process. We propose that the core of the ventral striatum is positioned to learn the probability of action selection for every transition between states of the world. We further review suggestions that the ventral striatal core and shell are positioned to act as "" critics "" contributing to the computation of a reward prediction error for model-free and model-based systems, respectively.']",https://hal.science/hal-01219958,"['0.sdv', '1.sdv.neu']"
"['Nicolas P. Rougier', 'Konrad Hinsen', 'Frédéric Alexandre', 'Thomas Arildsen', 'Lorena Barba', 'Fabien C. Y. Benureau', 'C. Titus Brown', 'Pierre de Buyl', 'Ozan Caglayan', 'Andrew P. Davison', 'Marc André Delsuc', 'Georgios Detorakis', 'Alexandra K. Diem', 'Damien Drix', 'Pierre Enel', 'Benoît Girard', 'Olivia Guest', 'Matt G. Hall', 'Rafael Neto Henriques', 'Xavier Hinaut', 'Kamil S Jaron', 'Mehdi Khamassi', 'Almar Klein', 'Tiina Manninen', 'Pietro Marchesi', 'Dan Mcglinn', 'Christoph Metzner', 'Owen L. Petchey', 'Hans Ekkehard Plesser', 'Timothée Poisot', 'Karthik Ram', 'Yoav Ram', 'Etienne Roesch', 'Cyrille Rossant', 'Vahid Rostami', 'Aaron Shifman', 'Jemma Stachelek', 'Marcel Stimberg', 'Frank Stollmeier', 'Federico Vaggi', 'Guillaume Viejo', 'Julien Vitay', 'Anya Vostinar', 'Roman Yurchak', 'Tiziano Zito']","[524, 173458, 2476, 16995, 741237, 742230, 1537, 8171, 186, 783969, 17136, 755601]","['nicolas-p-rougier', 'konrad-hinsen', 'frederic-alexandre', 'ozan-caglayan', 'andrew-davison', 'marc-andredelsuc', 'benoit-girard', 'xavier-hinaut', 'mehdi-khamassi', 'cyrille-rossant', 'marcel-stimberg']",Sustainable computational science: the ReScience initiative,hal-01592078,2017,10.7717/peerj-cs.142,"['Publication', 'Journal', 'Replicability', 'Reproducibility', 'Open Science', 'Computational Science']","['Computer science offers a large set of tools for prototyping, writing, running, testing, validating, sharing and reproducing results, however computational science lags behind. In the best case, authors may provide their source code as a compressed archive and they may feel confident their research is reproducible. But this is not exactly true. James Buckheit and David Donoho proposed more than two decades ago that an article about computational results is advertising, not scholarship. The actual scholarship is the full software environment, code, and data that produced the result. This implies new workflows, in particular in peer-reviews. Existing journals have been slow to adapt: source codes are rarely requested, hardly ever actually executed to check that they produce the results advertised in the article. ReScience is a peer-reviewed journal that targets computational research and encourages the explicit replication of already published research, promoting new and open-source implementations in order to ensure that the original research can be replicated from its description. To achieve this goal, the whole publishing chain is radically different from other traditional scientific journals. ReScience resides on GitHub where each new implementation of a computational study is made available together with comments, explanations, and software tests.']",https://inria.hal.science/hal-01592078,"['0.info', '1.info.info-dl']"
"['Raja Chatila', 'Erwan Renaudo', 'Mihai Andries', 'Omar Ricardo Chavez-Garcia', 'Pierre Luce-Vayrac', 'Raphaël Gottstein', 'Rachid Alami', 'Aurélie Clodic', 'Sandra Devin', 'Benoît Girard', 'Mehdi Khamassi']","[174618, 8523, 3319, 992539, 992540, 3186, 8444, 1290342, 1537, 186]","['raja-chatila', 'erwanrenaudo', 'mihai-andries', 'rachid-alami', 'aurelie-clodic', 'benoit-girard', 'mehdi-khamassi']",Toward Self-Aware Robots,hal-01856931,2018,10.3389/frobt.2018.00088,"['Self-awareness', 'Planning', 'Affordance', 'Cognitive architecture', 'Decision-making', 'Human-robot interaction', 'Learning', 'Markovian processes']","['Despite major progress in Robotics and AI, robots are still basically "" zombies "" repeatedly achieving actions and tasks without understanding what they are doing. Deep-Learning AI programs classify tremendous amounts of data without grasping the meaning of their inputs or outputs. We still lack a genuine theory of the underlying principles and methods that would enable robots to understand their environment, to be cognizant of what they do, to take appropriate and timely initiatives, to learn from their own experience and to show that they know that they have learned and how. The rationale of this paper is that the understanding of its environment by an agent (the agent itself and its effects on the environment included) requires its self-awareness, which actually is itself emerging as a result of this understanding and the distinction that the agent is capable to make between its own mind-body and its environment. The paper develops along five issues: agent perception and interaction with the environment; learning actions; agent interaction with other agents—specifically humans; decision-making; and the cognitive architecture integrating these capacities.']",https://hal.science/hal-01856931,"['0.info', '1.info.info-ai', '0.info', '1.info.info-ne', '0.info', '1.info.info-rb', '0.scco', '1.scco.neur']"
"['Florian Lesaint', 'Olivier Sigaud', 'Shelly B. Flagel', 'Terry E. Robinson', 'Mehdi Khamassi']","[952858, 14932, 186]","['olivier-sigaud', 'mehdi-khamassi']",Modelling Individual Differences in the Form of Pavlovian Conditioned Approach Responses: A Dual Learning Systems Approach with Factored Representation,hal-00947727,2014,10.1371/journal.pcbi.1003466,"['Goal-Trackers', 'Pavlovian conditioning', 'Dopamine', 'Reinforcement Learning', 'Conditioned Approach', 'Model-Free Reinforcement Learning', 'Model-Based Reinforcement Learning', 'Autoshaping', 'Sign-Trackers', 'Factored representations']","['Reinforcement Learning has greatly influenced models of conditioning, providing powerful explanations of acquired behaviour and underlying physiological observations. However, in recent autoshaping experiments in rats, variation in the form of Pavlovian conditioned responses (CRs) and associated dopamine activity, have questioned the classical hypothesis that phasic dopamine activity corresponds to a reward prediction error-like signal arising from a classical Model-Free system, necessary for Pavlovian conditioning. Over the course of Pavlovian conditioning using food as the unconditioned stimulus (US), some rats (sign-trackers) come to approach and engage the conditioned stimulus (CS) itself - a lever - more and more avidly, whereas other rats (goal-trackers) learn to approach the location of food delivery upon CS presentation. Importantly, although both sign-trackers and goal-trackers learn the CS-US association equally well, only in sign-trackers does phasic dopamine activity show classical reward prediction error-like bursts. Furthermore, neither the acquisition nor the expression of a goal-tracking CR is dopamine-dependent. Here we present a computational model that can account for such individual variations. We show that a combination of a Model-Based system and a revised Model-Free system can account for the development of distinct CRs in rats. Moreover, we show that revising a classical Model-Free system to individually process stimuli by using factored representations can explain why classical dopaminergic patterns may be observed for some rats and not for others depending on the CR they develop. In addition, the model can account for other behavioural and pharmacological results obtained using the same, or similar, autoshaping procedures. Finally, the model makes it possible to draw a set of experimental predictions that may be verified in a modified experimental protocol. We suggest that further investigation of factored representations in computational neuroscience studies may be useful.']",https://hal.science/hal-00947727,"['0.scco', '1.scco.neur']"
"['Mehdi Khamassi', 'René Quilodran', 'Pierre Enel', 'Peter Dominey', 'Emmanuel Procyk']","[186, 742047, 740049]","['mehdi-khamassi', 'pfdominey', 'emmanuel-procyk']",Behavioral Regulation and the Modulation of Information Coding in the Lateral Prefrontal and Cingulate Cortex,hal-01219972,2015,10.1093/cercor/bhu114,"['Feedback', 'Decision', 'Reinforcement-learning', 'Reward', 'Adaptation', 'Cingulate']","[""To explain the high level of flexibility in primate decision-making, theoretical models often invoke reinforcement-based mechanisms, performance monitoring functions, and core neural features within frontal cortical regions. However, the underlying biological mechanisms remain unknown. In recent models, part of the regulation of behavioral control is based on meta-learning principles, e.g. driving exploratory actions by varying a meta-parameter, the inverse temperature, which regulates the contrast between competing action probabilities. Here we investigate how complementary processes between lateral prefrontal cortex (LPFC) and dorsal anterior cingulate cortex (dACC) implement decision regulation during exploratory and exploitative behaviors. Model-based analyses of unit activity recorded in these two areas in monkeys first revealed that adaptation of the decision function is reflected in a covariation between LPFC neural activity and the control level estimated from the animal's behavior. Second, dACC more prominently encoded a reflection of outcome uncertainty useful for control regulation based on task monitoring. Model-based analyses also revealed higher information integration before feedback in LPFC, and after feedback in dACC. Overall the data support a role of dACC in integrating reinforcement-based information to regulate decision functions in LPFC. Our results thus provide biological evidence on how prefrontal cortical subregions may cooperate to regulate decision-making.""]",https://hal.science/hal-01219972,"['0.sdv', '1.sdv.neu']"
"['Mehdi Khamassi', 'Stéphane Lallée', 'Pierre Enel', 'Emmanuel Procyk', 'Peter Dominey']","[186, 885338, 740049, 742047]","['mehdi-khamassi', 'emmanuel-procyk', 'pfdominey']",Robot cognitive control with a neurophysiologically inspired reinforcement learning model,hal-00688931,2011,10.3389/fnbot.2011.00001,"['ICub', 'Humanoid robot', 'Reinforcement learning', 'Meta-learning', 'Bio-inspiration', 'Prefrontal cortex']","['A major challenge in modern robotics is to liberate robots from controlled industrial settings, and allow them to interact with humans and changing environments in the real world. The current research attempts to determine if a neurophysiologically motivated model of cortical function in the primate can help to address this challenge. Primates are endowed with cognitive systems that allow them to maximize the feedback from their environment by learning the values of actions in diverse situations and by adjusting their behavioral parameters (i.e. cognitive control) to accommodate unexpected events. In such contexts uncertainty can arise from at least two distinct sources - expected uncertainty resulting from noise during sensory-motor interaction in a known context, and unexpected uncertainty resulting from the changing probabilistic structure of the environment. However, it is not clear how neurophysiological mechanisms of reinforcement learning and cognitive control integrate in the brain to produce efficient behavior. Based on primate neuroanatomy and neurophysiology, we propose a novel computational model for the interaction between lateral prefrontal and anterior cingulate cortex (LPFC and ACC) reconciling previous models dedicated to these two functions. We deployed the model in two robots and demonstrate that, based on adaptive regulation of a meta-parameter β that controls the exploration rate, the model can robustly deal with the two kinds of uncertainties in the real world. In addition the model could reproduce monkey behavioral performance and neurophysiological data in two problem-solving tasks. A last experiment extends this to human-robot interaction with the iCub humanoid, and novel sources of uncertainty corresponding to ""cheating"" by the human. The combined results provide concrete evidence for the ability of neurophysiologically inspired cognitive systems to control advanced robots in the real world.']",https://hal.science/hal-00688931,"['0.sdv', '1.sdv.neu', '0.info', '1.info.info-rb', '0.info', '1.info.info-lg']"
"['Camille Lakhlifi', 'François-Xavier Lejeune', 'Marion Rouault', 'Mehdi Khamassi', 'Benjamin Rohaut']","[1249177, 774782, 186, 14536]","['mehdi-khamassi', 'benjamin-rohaut']","Illusion of knowledge in statistics among clinicians: evaluating the alignment between objective accuracy and subjective confidence, an online survey",hal-04076913,2023,10.1186/s41235-023-00474-1,"['Statistical illiteracy', 'Metacognition', 'Overconfidence bias', 'Sensitivity', 'Calibration', 'Discrimination', 'Decision-making', 'Medical context', 'Conditional probabilities', 'Natural frequencies']","[""Healthcare professionals' statistical illiteracy can impair medical decision quality and compromise patient safety. Previous studies have documented clinicians' insufficient proficiency in statistics and a tendency in overconfidence. However, an underexplored aspect is clinicians' awareness of their lack of statistical knowledge that precludes any corrective intervention attempt. Here, we investigated physicians' , residents' and medical students' alignment between subjective confidence judgments and objective accuracy in basic medical statistics. We also examined how gender, profile of experience and practice of research activity affect this alignment, and the influence of problem framing (conditional probabilities, CP vs. natural frequencies, NF). Eight hundred ninety-eight clinicians completed an online survey assessing skill and confidence on three topics: vaccine efficacy, p value and diagnostic test results interpretation. Results evidenced an overall consistent poor proficiency in statistics often combined with high confidence, even in incorrect answers. We also demonstrate that despite overconfidence bias, clinicians show a degree of metacognitive sensitivity, as their confidence judgments discriminate between their correct and incorrect answers. Finally, we confirm the positive impact of the more intuitive NF framing on accuracy. Together, our results pave the way for the development of teaching recommendations and pedagogical interventions such as promoting metacognition on basic knowledge and statistical reasoning as well as the use of NF to tackle statistical illiteracy in the medical context.""]",https://hal.sorbonne-universite.fr/hal-04076913,['0.scco']
"['Jean-Arcady Meyer', 'Agnès Guillot', 'Benoît Girard', 'Mehdi Khamassi', 'Patrick Pirim', 'Alain Berthoz']","[1537, 186, 828347]","['benoit-girard', 'mehdi-khamassi']",The Psikharpax project: Towards building an artificial rat,hal-00016391,2005,10.1016/j.robot.2004.09.018,"['Artificial rat', 'Navigation', 'Action selection', 'Learning']","[""Drawing inspiration from biology, the Psikharpax project aims at endowing a robot with a sensori-motor equipment and a neural control architecture that will afford some of the capacities of autonomy and adaptation that are exhibited by real rats. The paper summarizes the current state of achievement of the project. It successively describes the robot's future sensors and actuators, and several biomimetic models of the anatomy and physiology of structures in the rat's brain, like the hippocampus and the basal ganglia, which have already been at work on various robots, and that make navigation and action selection possible. Preliminary results on the implementation of learning mechanisms in these structures are also presented. Finally, the article discusses the potential benefits that a biologically-inspired approach affords to traditional autonomous robotics.""]",https://hal.science/hal-00016391,"['0.scco', '1.scco.neur', '0.info', '1.info.info-ai', '0.info', '1.info.info-ro']"
"['Guillaume Viejo', 'Mehdi Khamassi', 'Andrea Brovelli', 'Benoît Girard']","[971628, 186, 184498, 1537]","['mehdi-khamassi', 'andrea-brovelli', 'benoit-girard']",Modeling choice and reaction time during arbitrary visuomotor learning through the coordination of adaptive working memory and reinforcement learning,hal-01215419,2015,10.3389/fnbeh.2015.00225,"['Behavior', 'Action selection', 'Decision-making', 'Working-memory', 'Reinforcement learning', 'Reaction times', 'Multi-objective optimization']","[""Current learning theory provides a comprehensive description of how humans and other animals learn, and places behavioral flexibility and automaticity at heart of adaptive behaviors. However, the computations supporting the interactions between goal-directed and habitual decision-making systems are still poorly understood. Previous functional magnetic resonance imaging (fMRI) results suggest that the brain hosts complementary computations that may differentially support goal-directed and habitual processes in the form of a dynamical interplay rather than a serial recruitment of strategies. To better elucidate the computations underlying flexible behavior, we develop a dual-system computational model that can predict both performance (i.e., participants' choices) and modulations in reaction times during learning of a stimulus–response association task. The habitual system is modeled with a simple Q-Learning algorithm (QL). For the goal-directed system, we propose a new Bayesian Working Memory (BWM) model that searches for information in the history of previous trials in order to minimize Shannon entropy. We propose a model for QL and BWM coordination such that the expensive memory manipulation is under control of, among others, the level of convergence of the habitual learning. We test the ability of QL or BWM alone to explain human behavior, and compare them with the performance of model combinations, to highlight the need for such combinations to explain behavior. Two of the tested combination models are derived from the literature, and the latter being our new proposal. In conclusion, all subjects were better explained by model combinations, and the majority of them are explained by our new coordination proposal.""]",https://hal.sorbonne-universite.fr/hal-01215419,"['0.sdv', '1.sdv.neu']"
"['Romain Cazé', 'Mehdi Khamassi', 'Lise Aubin', 'Benoît Girard']","[1035553, 186, 786111, 1537]","['mehdi-khamassi', 'benoit-girard']",Hippocampal replays under the scrutiny of reinforcement learning models,hal-02323528,2018,10.1152/jn.00145.2018,"['Place cells', 'Hippocampus', 'Activity replay', 'Sleep', 'Computational modeling', 'Reinforcement learning', 'Model-free / Model-based']","['Multiple in vivo studies have shown that place cells from the hippocampus replay previously experienced trajectories. These replays are commonly considered to mainly reflect memory consolidation processes. Some data, however , have highlighted a functional link between replays and reinforcement learning (RL). This theory, extensively used in machine learning, has introduced efficient algorithms and can explain various behavioral and physiological measures from different brain regions. RL algorithms could constitute a mechanistic description of replays, and explain how replays can reduce the number of iterations required to explore the environment during learning. We review here the main findings concerning the different hippocampal replay types and the possible associated RL models (either model-based, model-free or hybrid model types). We conclude by tying these frameworks together. We illustrate the link between data and RL through a series of model simulations. This review, at the frontier between informatics and biology, paves the way for future work on replays.']",https://hal.science/hal-02323528,"['0.sdv', '1.sdv.neu']"
"['Mehdi Khamassi', 'Loïc Lachèze', 'Benoît Girard', 'Alain Berthoz', 'Agnès Guillot']","[186, 1537, 828347]","['mehdi-khamassi', 'benoit-girard']",Actor-critic models of reinforcement learning in the basal ganglia: From natural to artificial rats,hal-00016390,2005,10.1177/105971230501300205,"['Animat approach', 'TD learning', 'Actor–Critic model', 'S–R task', 'Taxon navigation']","[""Since 1995, numerous Actor–Critic architectures for reinforcement learning have been proposed as models of dopamine-like reinforcement learning mechanisms in the rat's basal ganglia. However, these models were usually tested in different tasks, and it is then difficult to compare their efficiency for an autonomous animat. We present here the comparison of four architectures in an animat as it per forms the same reward-seeking task. This will illustrate the consequences of different hypotheses about the management of different Actor sub-modules and Critic units, and their more or less autono mously determined coordination. We show that the classical method of coordination of modules by mixture of experts, depending on each module's performance, did not allow solving our task. Then we address the question of which principle should be applied efficiently to combine these units. Improve ments for Critic modeling and accuracy of Actor–Critic models for a natural task are finally discussed in the perspective of our Psikharpax project—an artificial rat having to survive autonomously in unpredictable environments.""]",https://hal.science/hal-00016390v2,"['0.scco', '1.scco.neur', '0.info', '1.info.info-ai', '0.info', '1.info.info-ro']"
"['Nathanaël Jarrassé', 'Tommaso Proietti', 'Vincent Crocher', 'Johanna Robertson', 'Anis Sahbani', 'Guillaume Morel', 'Agnès Roby-Brami']","[12286, 2111, 745060, 744243]","['nathanael-jarrasse', 'vcrocher', 'guillaume-morel', 'agnes-roby-brami']",Robotic exoskeletons: a perspective for the rehabilitation of arm coordination in stroke patients,hal-01320175,2014,10.3389/fnhum.2014.00947,"['Rehabilitation robotics', 'Exoskeleton', 'Upper-limb', 'Synergies', 'Arm coordination control']","['Upper-limb impairment after stroke is caused by weakness, loss of individual joint control, spasticity, and abnormal synergies. Upper-limb movement frequently involves abnormal, stereotyped, and fixed synergies, likely related to the increased use of sub-cortical networks following the stroke. The flexible coordination of the shoulder and elbow joints is also disrupted. New methods for motor learning, based on the stimulation of activity-dependent neural plasticity have been developed. These include robots that can adaptively assist active movements and generate many movement repetitions. However, most of these robots only control the movement of the hand in space. The aim of the present text is to analyze the potential of robotic exoskeletons to specifically rehabilitate joint motion and particularly inter-joint coordination. First, a review of studies on upper-limb coordination in stroke patients is presented and the potential for recovery of coordination is examined. Second, issues relating to the mechanical design of exoskeletons and the transmission of constraints between the robotic and human limbs are discussed. The third section considers the development of different methods to control exoskeletons: existing rehabilitation devices and approaches to the control and rehabilitation of joint coordinations are then reviewed, along with preliminary clinical results available. Finally, perspectives and future strategies for the design of control mechanisms for rehabilitation exoskeletons are discussed.']",https://hal.sorbonne-universite.fr/hal-01320175,"['0.sdv', '1.sdv.neu', '0.spi', '1.spi.auto']"
"['Yanan Li', 'Gowrishankar Ganesh', 'Nathanaël Jarrassé', 'Sami Haddadin', 'Alin Albu-Schaeffer', 'Etienne Burdet']","[741528, 12286]","['ganesh-gowrishankar', 'nathanael-jarrasse']","Force, Impedance, and Trajectory Learning for Contact Tooling and Haptic Identification",hal-02049408,2018,10.1109/tro.2018.2830405,"['Adaptive control', 'Biological systems control', 'Contact tasks', 'Force control', 'Iterative learning control', 'Robot control']","[""Humans can skilfully use tools and interact with the environment by adapting their movement trajectory, contact force, and impedance. Motivated by the human versatility, we develop here a robot controller that concurrently adapts feedforward force, impedance, and reference trajectory when interacting with an unknown environment. In particular, the robot's reference trajectory is adapted to limit the interaction force and maintain it at a desired level, while feedforward force and impedance adaptation compensates for the interaction with the environment. An analysis of the interaction dynamics using Lyapunov theory yields the conditions for convergence of the closed-loop interaction mediated by this controller. Simulations exhibit adaptive properties similar to human motor adaptation. The implementation of this controller for typical interaction tasks including drilling, cutting, and haptic exploration shows that this controller can outperform conventional controllers in contact tooling.""]",https://hal.science/hal-02049408,"['0.spi', '1.spi.auto']"
"['Charlotte Marchand', 'Jozina B de Graaf', 'Nathanaël Jarrassé']",[12286],['nathanael-jarrasse'],Measuring mental workload in assistive wearable devices: a review,hal-03418729,2021,10.1186/s12984-021-00953-w,"['Mental workload', 'Prosthesis', 'Exoskeleton']","['As wearable assistive devices, such as prostheses and exoskeletons, become increasingly sophisticated and effective, the mental workload associated with their use remains high and becomes a major challenge to their ecological use and long-term adoption. Numerous methods of measuring mental workload co-exist, making analysis of this research topic difficult. The aim of this review is to examine how mental workload resulting from the use of wearable assistive devices has been measured, in order to gain insight into the specific possibilities and limitations of this field. Literature searches were conducted in the main scientific databases and 60 articles measuring the mental workload induced by the use of a wearable assistive device were included in this study. Three main families of methods were identified, the most common being ’dual task’ and ’subjective assessment’ methods, followed by those based on ’physiological measures’, which included a wide variety of methods. The variability of the measurements was particularly high, making comparison difficult. There is as yet no evidence that any particular method of measuring mental workload is more appropriate to the field of wearable assistive devices. Each method has intrinsic limitations such as subjectivity, imprecision, robustness or complexity of implementation or interpretation. A promising metric seems to be the measurement of brain activity, as it is the only method that is directly related to mental workload. Finally, regardless of the measurement method chosen, special attention should be paid to the measurement of mental workload in the context of wearable assistive devices. In particular, certain practical considerations, such as ecological situations and environments or the level of expertise of the participants tested, may be essential to ensure the validity of the mental workload assessed.']",https://hal.science/hal-03418729,['0.spi']
"['Stephane Doncieux', 'Nicolas Bredeche', 'Jean-Baptiste Mouret', 'Gusz Ae Eiben']","[3909, 184446, 1495]","['stephane-doncieux', 'nicolas-bredeche', 'jb-mouret']","Evolutionary robotics: what, why, and where to",hal-01131267,2015,10.3389/frobt.2015.00004,"['Embodied intelligence', 'Evolutionary biology', 'Robotics', 'Evolutionary algorithms', 'Evolutionary robotics']","['Evolutionary robotics applies the selection, variation, and heredity principles of natural evolution to the design of robots with embodied intelligence. It can be considered as a subfield of robotics that aims to create more robust and adaptive robots. A pivotal feature of the evolutionary approach is that it considers the whole robot at once, and enables the exploitation of robot features in a holistic manner. Evolutionary robotics can also be seen as an innovative approach to the study of evolution based on a new kind of experimentalism. The use of robots as a substrate can help to address questions that are difficult, if not impossible, to investigate through computer simulations or biological studies. In this paper, we consider the main achievements of evolutionary robotics, focusing particularly on its contributions to both engineering and biology. We briefly elaborate on methodological issues, review some of the most interesting findings, and discuss important open issues and promising avenues for future work.']",https://hal.science/hal-01131267,"['0.info', '1.info.info-ai', '0.info', '1.info.info-lg', '0.info', '1.info.info-rb']"
"['Nicolas Bredeche', 'Evert Haasdijk', 'Abraham Prieto']",[184446],['nicolas-bredeche'],Embodied Evolution in Collective Robotics: A Review,hal-03313845,2018,10.3389/frobt.2018.00012,"['Embodied evolution', 'Online distributed evolution', 'Collective robotics', 'Evolutionary robotics', 'Collective adaptive systems']","['This article provides an overview of evolutionary robotics techniques applied to online distributed evolution for robot collectives, namely, embodied evolution. It provides a definition of embodied evolution as well as a thorough description of the underlying concepts and mechanisms. This article also presents a comprehensive summary of research published in the field since its inception around the year 2000, providing various perspectives to identify the major trends. In particular, we identify a shift from considering embodied evolution as a parallel search method within small robot collectives (fewer than 10 robots) to embodied evolution as an online distributed learning method for designing collective behaviors in swarm-like collectives. This article concludes with a discussion of applications and open questions, providing a milestone for past and an inspiration for future research.']",https://hal.sorbonne-universite.fr/hal-03313845,"['0.info', '1.info.info-rb', '0.info', '1.info.info-ai', '0.info', '1.info.info-lg', '0.info', '1.info.info-ma', '0.info', '1.info.info-ne']"
"['Leo Cazenille', 'Bertrand Collignon', 'Yohann Chemtob', 'Frank Bonnet', 'Alexey Gribovskiy', 'Francesco Mondada', 'Nicolas Bredeche', 'José Halloy']","[1094048, 1232653, 1232649, 184446, 735536]","['nicolas-bredeche', 'jhalloy']",How mimetic should a robotic fish be to socially integrate into zebrafish groups?,hal-03313840,2018,10.1088/1748-3190/aa8f6a,"['Zebrafish', 'Biohybrid systems', 'Collective behaviour', 'Biomimetic robotics', 'Social biohybrid system', 'Animal robot', 'Mixed-groups']","['Biomimetic robots are promising tools in animal behavioural studies. If they are socially integrated in a group of animals, they can produce calibrated social stimuli to test the animal responses. However, the design of such social robots is challenging as it involves both a luring capability including appropriate robot behaviours, and the acceptation of the robots by the animals as social companions. Here, we investigate the integration of a biomimetic robot driven by biomimetic behavioural models into a group of zebrafish (Danio rerio). The robot behaviours are based on a stochastic model linking zebrafish visual perception to individual behaviour and calibrated experimentally to correspond to the behaviour of zebrafish. We show that our robot can be integrated into a group of zebrafish, mimic their behaviour and exhibit similar collective dynamics compared to fish-only groups. This study shows that an autonomous biomimetic robot was enhanced by a biomimetic behavioural model so that it can socially integrate into groups of fish']",https://hal.sorbonne-universite.fr/hal-03313840,"['0.info', '1.info.info-rb', '0.info', '1.info.info-ai']"
"['Nicolas Bredeche', 'Nicolas Fontbonne']","[184446, 754562]","['nicolas-bredeche', 'nicolas-fontbonne']",Social learning in swarm robotics,hal-03500739,2022,10.1098/rstb.2020.0309,"['Collective robotics', 'Evolutionary robotics', 'On-line distributed reinforcement learning', 'Social learning', 'Swarm robotics']","['In this paper, we present an implementation of social learning for swarm robotics. We consider social learning as a distributed online reinforcement learning method applied to a collective of robots where sensing, acting and coordination are performed on a local basis. While some issues are specific to artificial systems, such as the general objective of learning efficient (and ideally, optimal) behavioural strategies to fulfill a task defined by a supervisor, some other issues are shared with social learning in natural systems. We discuss some of these issues, paving the way towards cumulative cultural evolution in robot swarms, which could enable complex social organization necessary to achieve challenging robotic tasks. This article is part of a discussion meeting issue ‘The emergence of collective knowledge and cumulative culture in animals, humans and machines’.']",https://hal.sorbonne-universite.fr/hal-03500739,"['0.info', '1.info.info-ai', '0.info', '1.info.info-rb']"
"['Matan Yah Ben Zion', 'Jeremy Fersula', 'Nicolas Bredeche', 'Olivier Dauchot']","[1231312, 1358006, 184446, 10897]","['nicolas-bredeche', 'olivier-dauchot']",Morphological computation and decentralized learning in a swarm of sterically interacting robots,hal-03840764,2023,10.1126/scirobotics.abo6140,"['Swarm robotics', 'Evolutionary robotics', 'Active matter', 'Machine learning']","['While naturally occurring swarms thrive when crowded, physical interactions in robotic swarms are either avoided or carefully controlled, thus limiting their operational density. In this paper, we explicitly consider dense swarms of robots where physical interactions are inevitable. By leveraging collisions, we offer new applications in collective self-organization using a morpho-functional design. We demonstrate experimentally that an a priori minor difference in the mechanical design of the robots leads to major differences in their collective behavior when they evolve in crowded environments. We design Morphobots, which are Kilobots augmented with a 3D-printed exoskeleton. The exoskeleton not only significantly improves the motility and stability of the Kilobots, it also allows to encode two contrasting dynamical behaviors in response to an external force or a collision. This difference translates into distinct performances at the individual and collective behaviour. These include response to an external force, interaction with a stationary wall, alignment with a movable obstacle, stabilization on a dynamically tilting plane, and self-organized aggregation when addressing a phototactic task. Enabling collisions also fluidizes the ensemble allowing the implementation of a decentralized on-line evolutionary reinforcement learning algorithm in a swarm of Morphobots. Finally we present a kinetic model that links the reward function to an effective phototactic policy. Our results are of relevance for the deployment of robust swarms of robots in a real environment, where robots are deemed to collide, and to be exposed to external forces.']",https://hal.science/hal-03840764,"['0.info', '1.info.info-lg', '0.info', '1.info.info-ma', '0.info', '1.info.info-rb', '0.phys', '1.phys.cond', '2.phys.cond.cm-sm']"
"['Michael Blot', 'David Picard', 'Nicolas Thome', 'Matthieu Cord']","[741, 181803, 13617]","['david-picard', 'nicolas-thome', 'matthieucord']",Distributed Optimization for Deep Learning with Gossip Exchange,hal-01930346,2019,10.1016/j.neucom.2018.11.002,"['Optimization', 'Distributed gradient descent', 'Neural networks', 'Learning', 'Deep', 'Gossip']","['We address the issue of speeding up the training of convolutional neural networks by studying a distributed method adapted to stochastic gradient descent. Our parallel optimization setup uses several threads, each applying individual gradient descents on a local variable. We propose a new way of sharing information between different threads based on gossip algorithms that show good consensus convergence properties. Our method called GoSGD has the advantage to be fully asynchronous and decentralized.']",https://hal.science/hal-01930346,"['0.info', '1.info.info-ts', '0.info', '1.info.info-ne']"
"['Alejandro Lopez-Rincon', 'Alberto Tonda', 'Mohamed Elati', 'Olivier Schwander', 'Benjamin Piwowarski', 'Patrick Gallinari']","[182104, 16120, 14377, 9362, 751615]","['alberto-tonda', 'mohamed-elati', 'olivier-schwander', 'benjamin-piwowarski', 'patrick-gallinari']",Evolutionary optimization of convolutional neural networks for cancer miRNA biomarkers classification,hal-01700622,2018,10.1016/j.asoc.2017.12.036,"['MiRNA biomarker', 'Tensorflow', 'Convolutional neural networks', 'Cancer classification', 'Evolutionary algorithms']","['Cancer diagnosis is currently undergoing a paradigm shift with the incorporation of molecular biomarkers as part of routine diagnostic panel. This breakthrough discovery directs researches to examine the role of microRNA in cancer, since its deregulation is often associated with almost all human tumors. Such differences frequently recur in tumor-specific microRNA signatures, which are helpful to diagnose tissue of origin and tumor subtypes. Nonetheless, the resulting classification problem is far from trivial, as there are hundreds of microRNA types, and tumors are non-linearly correlated to the presence of several overexpressions. In this paper, we propose to apply an evolutionary optimized convolutional neural network classifier to this complex task. The presented approach is compared against 21 state-of-the-art classifiers, on a real-world dataset featuring 8129 patients, for 29 different classes of tumors, using 1046 different biomarkers. As a result of the comparison, we also present a meta-analysis on the dataset, identifying the classes on which the collective performance of the considered classifiers is less effective, and thus possibly singling out types of tumors for which biomarker tests might be less reliable.']",https://hal.sorbonne-universite.fr/hal-01700622,"['0.info', '1.info.info-ir', '0.info', '1.info.info-ai', '0.info', '1.info.info-lg', '0.info', '1.info.info-tt']"
"['Thomas Gerald', 'Hadi Zaatiti', 'Hatem Hajri', 'Nicolas Baskiotis', 'Olivier Schwander']","[1217894, 16945, 888500, 13841, 14377]","['thomasgerald', 'hadi-zaatiti', 'baskiotisn', 'olivier-schwander']",A hyperbolic approach for learning communities on graphs,hal-04022426,2023,10.1007/s10618-022-00902-8,"['Manifolds', 'Representation learning', 'Graph-structured data', 'Hyperbolic space', 'Community embedding']","['Detecting communities on graphs has received significant interest in recent literature. Current state-of-the-art approaches tackle this problem by coupling Euclidean graph embedding with community detection. Considering the success of hyperbolic representations of graph-structured data in the last years, an ongoing challenge is to set up a hyperbolic approach to the community detection problem. The present paper meets this challenge by introducing a Riemannian geometry based framework for learning communities on graphs. The proposed methodology combines graph embedding on hyperbolic spaces with Riemannian K-means or Riemannian mixture models to perform community detection. The usefulness of this framework is illustrated through several experiments on generated community graphs and real-world social networks as well as comparisons with the most powerful baselines. The code implementing hyperbolic community embedding is available online https://www.github.com/tgeral68/HyperbolicGraphAndGMM.']",https://hal.science/hal-04022426,"['0.stat', '1.stat.ml']"
"['Daniel Brooks', 'Olivier Schwander', 'Frédéric Barbaresco', 'Jean-Yves Schneider', 'Matthieu Cord']","[1054344, 14377, 913777, 13617]","['olivier-schwander', 'matthieucord']",Second-order networks in PyTorch,hal-02290841,2019,10.1007/978-3-030-26980-7_78,"['SPD matrix', 'Covariance', 'Second-order neural network', 'Rie- mannian machine learning']","['Classification of Symmetric Positive Definite (SPD) matrices is gaining momentum in a variety machine learning application fields. In this work we propose a Python library which implements neural networks on SPD matrices, based on the popular deep learning framework Pytorch.']",https://hal.science/hal-02290841,"['0.info', '1.info.info-ai']"
"['Olivier Sigaud', 'Camille Salaün', 'Vincent Padois']","[14932, 899378, 10610]","['olivier-sigaud', 'vincent-padois']",On-line regression algorithms for learning mechanical models of robots: a survey,hal-00629133,2011,10.1016/j.robot.2011.07.006,"['Adaptive and learning systems', 'Adaptive control', 'Mechanical models']","['With the emergence of more challenging contexts for robotics, the mechanical design of robots is becoming more and more complex. Moreover, their missions often involve unforeseen physical interactions with the environment. To deal with these difficulties, endowing the controllers of the robots with the capability to learn a model of their kinematics and dynamics under changing circumstances is becoming mandatory. This emergent necessity has given rise to a significant amount of research in the Machine Learning community, generating algorithms that address more and more sophisticated on-line modeling questions. In this paper, we provide a survey of the corresponding literature with a focus on the methods rather than on the results. In particular, we provide a unified view of all recent algorithms that outlines their distinctive features and provides a framework for their combination. Finally, we give a prospective account of the evolution of the domain towards more challenging questions.']",https://hal.science/hal-00629133,"['0.info', '1.info.info-rb']"
"['Olivier Sigaud', 'Freek Stulp']","[14932, 1420]","['olivier-sigaud', 'freek-stulp']",Policy search in continuous action domains: An overview,hal-02182466,2019,10.1016/j.neunet.2019.01.011,"['Policy search', 'Sample efficiency', 'Deep reinforcement learning', 'Deep neuroevolution']","['Continuous action policy search is currently the focus of intensive research, driven both by the recent success of deep reinforcement learning algorithms and the emergence of competitors based on evolutionary algorithms. In this paper, we present a broad survey of policy search methods, providing a unified perspective on very different approaches, including also Bayesian Optimization and directed exploration methods. The main message of this overview is in the relationship between the families of methods, but we also outline some factors underlying sample efficiency properties of the various approaches.']",https://hal.sorbonne-universite.fr/hal-02182466,"['0.info', '1.info.info-lg']"
"['Alain Droniou', 'Serena Ivaldi', 'Olivier Sigaud']","[1519, 14932]","['serena-ivaldi', 'olivier-sigaud']","Deep unsupervised network for multimodal perception, representation and classification",hal-01083521,2015,10.1016/j.robot.2014.11.005,"['Multimodal perception', 'Deep Learning', 'Unsupervised learning', 'Developmental robotics']","['In this paper, we tackle the problem of multimodal learning for autonomous robots.Autonomous robots interacting with humans in an evolving environment need the ability to acquire knowledge from their multiple perceptual channels in an unsupervised way.Most of the approaches in the literature exploit engineered methods to process each perceptual modality. In contrast, robots should be able to acquire their own features from the raw sensors, leveraging the information elicited by interaction with their environment: learning from their sensorimotor experience would result in a more efficient strategy in a life-long perspective.To this end, we propose an architecture based on deep networks, which is used by the humanoid robot iCub to learn a task from multiple perceptual modalities (proprioception, vision, audition).By structuring high-dimensional, multimodal information into a set of distinct sub-manifolds in a fully unsupervised way, it performs a substantial dimensionality reduction by providing both a symbolic representation of data and a fine discrimination between two similar stimuli. Moreover, the proposed network is able to exploit multimodal correlations to improve the representation of each modality alone.']",https://hal.sorbonne-universite.fr/hal-01083521,"['0.info', '1.info.info-rb', '0.info', '1.info.info-ne']"
"['Pascale Lherminier', 'Herlé Mercier', 'Thierry Huck', 'Claire Gourcuff', 'Fiz F. Perez', 'Pascal Morin', 'Artem Sarafanov', 'Anastasia Falina']","[742367, 178236]","['herle-mercier', 'thierry-huck']",The Atlantic Meridional Overturning Circulation and the subpolar gyre observed at the A25-OVIDE section in June 2002 and 2004,hal-00581670,2010,10.1016/j.dsr.2010.07.009,"['North Atlantic', 'Subpolar gyre', 'Meridional Overturning Circulation', 'OVIDE', 'Hydrology', 'ADCP']","['The horizontal circulation of the subpolar gyre and the Meridional Overturning Circulation (MOC) are investigated here by comparing two snapshots of the North Atlantic as delivered by two hydrographic sections between Greenland and Portugal. The corresponding cruises were carried out in June-July 2002 and June-July 2004 on R/V Thalassa within the framework of the Ovide project. The absolute transports in June 2004 are described in detail, and then compared with transports in June 2002. The MOC (in density coordinates), driven by the volume balance between the northward North Atlantic Current (NAC) and the net southward export of dense water from the subpolar gyre, did not change: MOCσ=16.3±2.4 Sv (1 Sv=106 m3 s−1). Its upper limb, above σ1=32.1, is decomposed into two main branches, the Eastern NAC (ENAC) and the Western NAC (WNAC), that transport about 8 Sv each. In the lower limb of the MOC, we find a 4-5 Sv increase in the cyclonic circulation of the subpolar gyre between June 2002 and 2004, affecting mainly the intermediate water without changing the MOCσ amplitude. Accordingly, the 14±2 Sv transport over Reykjanes Ridge in June 2004 (between 58°50′N and Iceland) is estimated to have been 4-5 Sv stronger than in June 2002. Sustaining this observation, a relatively warm and salty anomaly coming from the Iceland Basin was found in the East Greenland-Irminger Current (EGIC) in June 2004, along with a modified vertical structure of the transport that shows a 4-5 Sv intensification of the net southward flow in the corresponding layer. Overall, in June 2004, the EGIC (from the surface to σ0=27.8) is found at 23.7±1.4 Sv in June 2004, and the Deep Western Boundary Current (DWBC) below sums up to 11.2±1.7 Sv, so that the western boundary current ~5 Sv stronger than in June 2002.']",https://hal.science/hal-00581670,"['0.sdu', '1.sdu.stu', '2.sdu.stu.oc']"
"['A. Leboyer', 'Gildas Cambon', 'Nathalie Daniault', 'S. Herbette', 'Bernard Le Cann', 'L. Marie', 'Pascal Morin']","[900077, 735543, 860428]",['bernard-le-cann'],Observations of the Ushant tidal front in September 2007,hal-00385151,2009,10.1016/j.csr.2008.12.020,"['Shelf dynamics', 'Tidal mixing front', 'Hydrology', 'HF radars', 'Drifters', 'Nutrients']","[""The Ushant tidal front is the dominant feature of the summer season hydrological structure of the Iroise Sea. It separates tidally mixed coastal waters from thermally stratified open Celtic Seawaters. This article reports on observations made in September 2007 during two short cruises that took place aboard R/V ''Côtes de la Manche'', and gives a general account of the physical structure of the front along one cross-frontal transect. The data set comprises data from a 4 month ADCP mooring, short CTD/fluorescence/nutrients transects, Lagrangian drifter trajectories, and HF radar surface current measurements. One finding is that the surface and bottom fronts, being affected by different dynamical influences, are not necessarily coincident in the vertical. This entails that the opposite density gradients located above and below the thermocline depth do not necessarily compensate, and can each be associated with a significant surface geostrophic expression. A second finding is that mixing effects bear a very strong influence on the thermal structure of the warm-water intrusions associated with frontal cyclonic eddies of the kind described by Pingree [1978. Cyclonic eddies and cross-frontal mixing. Journal of the Marine Biological Association of the United Kingdom 58 (4), 955-963].""]",https://hal.science/hal-00385151,"['0.sdu', '1.sdu.stu', '2.sdu.stu.oc']"
"['Essyllt Louarn', 'Pascal Morin']","[1239018, 745127]","['elouarn', 'pascal-morin-50-69']",Antarctic Intermediate Water influence on Mediterranean Sea Water outflow,hal-01251678,2011,10.1016/j.dsr.2011.05.009,"['Mediterranean Sea Water', 'Formation', 'Gulf of Cadiz', 'Antarctic Intermediate Waters']","[""This study of the mixing of Mediterranean Sea Water (MW) with the surrounding waters was made possible by the Semane 2002 cruise (Sortie des Eaux Mediterraneennes dans l'Atlantique Nord-Est) that took place in the Gulf of Cadiz in July 2002. Potential temperature, salinity, oxygen, nutrients and CFC data are used to describe the water masses present in the Gulf. In the southern part of the basin, a water mass characterised by low oxygen, high nutrient and low CFC concentrations occurs along the African continental slope. This water has been identified as the modified Antarctic Intermediate Water (AAIW). It has been previously observed south of this section, at the latitude of the Canary Islands, as a northward flow between the African shelf and the islands. The modified AAIW found in the Gulf of Cadiz is situated at a density of 27.5 kg m(-3). Above, at 27.3 kg m(-3), the lower limb of the North Atlantic Central Water is observed as a salinity minimum. The modified AAIW enters the Gulf of Cadiz along the south-western part of the continental shelf. It flows cyclonically and exits north-westward. In the northern part of the gulf, due to the presence of the Mediterranean Undercurrent (MU), the AAIW flows off the coast. An optimum multiparameter analysis was conducted to evaluate the influence of the AAIW on the MW northwest of the basin. We show that the AAIW is present in the lower core of the MU at a proportion of 12.9 +/- 8.2% and is absent in the upper core. Crown Copyright (C) 2011 Published by Elsevier Ltd. All rights reserved.""]",https://hal.science/hal-01251678,"['0.sdv', '0.sde']"
"['Paul Tréguer', 'Eric Goberville', 'Nicolas Barrier', ""Stéphane L'Helguen"", 'Pascal Morin', 'Yann Bozec', 'Peggy Rimmelin-Maury', 'Marie Czamanski', 'Emilie Grossteffan', 'Thierry Cariou', 'Michel Repecaud', 'Loic Quéméner']","[182125, 176103, 4476, 177974, 912803, 1381085, 771952]","['paul-treguer', 'eric-goberville', 'nicolas-barrier', 'stephane-lhelguen', 'yann-bozec', 'emilie-grossteffan']",Large and local-scale influences on physical and chemical characteristics of coastal waters of Western Europe during winter,hal-02330574,2014,10.1016/j.jmarsys.2014.05.019,"['ACL', 'Coastal systems', 'Climate variability', 'Large-scale hydro-climatic indices', 'River inputs', 'Time-series', 'Weather regimes']","['There is now a strong scientific consensus that coastal marine systems of Western Europe are highly sensitive to the combined effects of natural climate variability and anthropogenic climate change. However, it still remains challenging to assess the spatial and temporal scales at which climate influence operates. While large-scale hydro-climatic indices, such as the North Atlantic Oscillation (NAO) or the East Atlantic Pattern (EAP) and the weather regimes such as the Atlantic Ridge (AR), are known to be relevant predictors of physical processes, changes in coastal waters can also be related to local hydro-meteorological and geochemical forcing. Here, we study the temporal variability of physical and chemical characteristics of coastal waters located at about 48°N over the period 1998-2013 using (1) sea surface temperature, (2) sea surface salinity and (3) nutrient concentration observations for two coastal sites located at the outlet of the Bay of Brest and off Roscoff, (4) river discharges of the major tributaries close to these two sites and (5) regional and local precipitation data over the region of interest. Focusing on the winter months, we characterize the physical and chemical variability of these coastal waters and document changes in both precipitation and river runoffs. Our study reveals that variability in coastal waters is connected to the large-scale North Atlantic atmospheric circulation but is also partly explained by local river influences. Indeed, while the NAO is strongly related to changes in sea surface temperature at the Brest and Roscoff sites, the EAP and the AR have a major influence on precipitations, which in turn modulate river discharges that impact sea surface salinity at the scale of the two coastal stations.']",https://hal.univ-brest.fr/hal-02330574,"['0.sde', '0.sdu', '1.sdu.stu', '2.sdu.stu.oc', '0.sdu', '1.sdu.envi', '0.sdu', '1.sdu.ocean', '0.sde', '1.sde.be']"
"['Clément Moulin-Frier', 'Julien Diard', 'Jean-Luc Schwartz', 'Pierre Bessière']","[563, 172176, 1160, 3434]","['clement-moulin-frier', 'julien-diard', 'jean-luc-schwartz', 'pierre-bessiere']",COSMO (“Communicating about Objects using Sensory–Motor Operations”): A Bayesian modeling framework for studying speech communication and the emergence of phonological systems,hal-01230175,2015,10.1016/j.wocn.2015.06.001,"['Bayesian programming', 'Speech sound systems', 'Language evolution', 'Phonology', 'Cognitive modelling', 'Self-organization']","[""While the origin of language remains a somewhat mysterious process, understanding how human language takes specific forms appears to be accessible by the experimental method. Languages, despite their wide variety, display obvious regularities. In this paper, we attempt to derive some properties of phonological systems (the sound systems for human languages) from speech communication principles. We introduce a model of the cognitive architecture of a communicating agent, called COSMO (for “Communicating about Objects using Sensory–Motor Operations') that allows a probabilistic expression of the main theoretical trends found in the speech production and perception literature. This enables a computational comparison of these theoretical trends, which helps us to identify the conditions that favor the emergence of linguistic codes. We present realistic simulations of phonological system emergence showing that COSMO is able to predict the main regularities in vowel, stop consonant and syllable systems in human languages.""]",https://hal.science/hal-01230175,"['0.scco', '1.scco.comp', '0.info', '1.info.info-lg', '0.info', '1.info.info-ma', '0.scco']"
"['Clément Moulin-Frier', 'Raphaël Laurent', 'Pierre Bessière', 'Jean-Luc Schwartz', 'Julien Diard']","[563, 941928, 3434, 1160, 172176]","['clement-moulin-frier', 'pierre-bessiere', 'jean-luc-schwartz', 'julien-diard']","Adverse conditions improve distinguishability of auditory, motor and perceptuo-motor theories of speech perception: an exploratory Bayesian modeling study",hal-01059179,2012,10.1080/01690965.2011.645313,"['Model distin-guishability', 'Speech perception in adverse conditions', 'Bayesian modeling', 'Auditory', 'Motor and Perceptuo-motor theories of speech communication']","[""In this paper, we put forward a computational framework for the comparison between motor, auditory, and perceptuo-motor theories of speech communication. We first recall the basic arguments of these three sets of theories, either applied to speech perception or to speech production. Then we expose a unifying Bayesian model able to express each theory in a probabilistic way. Focusing on speech perception, we demonstrate that under two hypotheses, regarding communication noise and inter-speaker variability, providing perfect conditions for speech communication, motor, and auditory theories are indistinguishable. We then degrade successively each hypothesis to study the distinguish- ability of the different theories in ''adverse'' conditions. We first present simulations on a simplified implementation of the model with mono-dimensional sensory and motor variables, and secondly we consider a simulation of the human vocal tract providing more realistic auditory and articulatory variables. Simulation results allow us to emphasise the respective roles of motor and auditory knowledge in various conditions of speech perception in adverse conditions, and to suggest some guidelines for future studies aiming at assessing the role of motor knowledge in speech perception.""]",https://hal.science/hal-01059179,"['0.scco', '1.scco.comp', '0.scco', '1.scco.ling', '0.scco', '1.scco.psyc', '0.info', '1.info.info-mo']"
"['Rubén Laplaza', 'Francesca Peccati', 'Roberto A. Boto', 'Chaoyu Quan', 'Alessandra Carbone', 'Jean-Philip Piquemal', 'Yvon Maday', 'Julia Contreras‐garcía']","[795655, 1050932, 10690, 926099, 7807, 1208540, 739065]","['chaoyu-quan', 'alessandra-carbone', 'jean-philip-piquemal', 'julia-contreras-garcia']",NCIPLOT and the analysis of noncovalent interactions using the reduced density gradient,hal-02921299,2021,10.1002/wcms.1497,"['NCI', 'NCIPLOT', 'Intermolecular interactions', 'Quantum chemistry']","['Noncovalent interactions are of utmost importance. However, their accurate treatment is still difficult. This is partially induced by the coexistence of many types of interactions and physical phenomena, which hampers generality in simple treatments. The NCI index has been successfully used for nearly over 10\u2009years in order to identify, analyze, and understand noncovalent interactions in a wide variety of systems, ranging from proteins to molecular crystals. In this work, the development and implications of the method will be reviewed, and modern implementations will be presented. Afterward, some sophisticated examples will be given that showcase the current advances toward the fast, robust, and intuitive identification of noncovalent interactions in real space. We review the developments of NCI since its introduction 10 years ago paying attention to the identification, analysis and quantification of noncovalent interactions in a wide variety of systems, from proteins to molecular crystals.']",https://hal.science/hal-02921299,"['0.chim', '1.chim.theo']"
"['Elodie Laine', 'Isaure Chauvot de Beauchêne', 'David Perahia', 'Christian Auclair', 'Luba Tchertanov']","[1102065, 14814, 849432, 741074]","['elodie-laine', 'isaure-chauvot-de-beauchene', 'tchertanov']",Mutation D816V alters the internal structure and dynamics of c-KIT receptor cytoplasmic region: implications for dimerization and activation mechanisms,hal-01505755,2011,10.1371/journal.pcbi.1002068,"['Molecular dynamics simulation', 'KIT', 'Tyrosine-kinase', 'D816V']","['The type III receptor tyrosine kinase (RTK) KIT plays a crucial role in the transmission of cellular signals through phosphorylation events that are associated with a switching of the protein conformation between inactive and active states. D816V KIT mutation is associated with various pathologies including mastocytosis and cancers. D816V-mutated KIT is constitutively active, and resistant to treatment with the anti-cancer drug Imatinib. To elucidate the activating molecular mechanism of this mutation, we applied a multi-approach procedure combining molecular dynamics (MD) simulations, normal modes analysis (NMA) and binding site prediction. Multiple 50-ns MD simulations of wild-type KIT and its mutant D816V were recorded using the inactive auto-inhibited structure of the protein, characteristic of type III RTKs. Computed free energy differences enabled us to quantify the impact of D816V on protein stability in the inactive state. We evidenced a local structural alteration of the activation loop (A-loop) upon mutation, and a long-range structural re-organization of the juxta-membrane region (JMR) followed by a weakening of the interaction network with the kinase domain. A thorough normal mode analysis of several MD conformations led to a plausible molecular rationale to propose that JMR is able to depart its auto-inhibitory position more easily in the mutant than in wild-type KIT and is thus able to promote kinase mutant dimerization without the need for extra-cellular ligand binding. Pocket detection at the surface of NMA-displaced conformations finally revealed that detachment of JMR from the kinase domain in the mutant was sufficient to open an access to the catalytic and substrate binding sites.']",https://hal.science/hal-01505755,"['0.sdv', '1.sdv.bbm', '2.sdv.bbm.bm', '0.info', '1.info.info-bi']"
"['Arian Allain', 'Isaure Chauvot de Beauchêne', 'Florent Langenfeld', 'Yann Guarracino', 'Elodie Laine', 'Luba Tchertanov']","[14814, 775402, 1102065, 741074]","['isaure-chauvot-de-beauchene', 'elodie-laine', 'tchertanov']",Allosteric pathway identification through network analysis: from molecular dynamics simulations to interactive 2d and 3d graphs,hal-01505837,2014,10.1039/c4fd00024b,"['Allostery', 'Molecular modeling', 'MONETA']","['Allostery is a universal phenomenon that couples the information induced by a local perturbation (effector) in a protein to spatially distant regulated sites. Such an event can be described in terms of a large scale transmission of information (communication) through a dynamic coupling between structurally rigid (minimally frustrated) and plastic (locally frustrated) clusters of residues. To elaborate a rational description of allosteric coupling, we propose an original approach - MOdular NETwork Analysis (MONETA) - based on the analysis of inter-residue dynamical correlations to localize the propagation of both structural and dynamical effects of a perturbation throughout a protein structure. MONETA uses inter-residue cross-correlations and commute times computed from molecular dynamics simulations and a topological description of a protein to build a modular network representation composed of clusters of residues (dynamic segments) linked together by chains of residues (communication pathways). MONETA provides a brand new direct and simple visualization of protein allosteric communication. A GEPHI module implemented in the MONETA package allows the generation of 2D graphs of the communication network. An interactive PyMOL plugin permits drawing of the communication pathways between chosen protein fragments or residues on a 3D representation. MONETA is a powerful tool for on-the-fly display of communication networks in proteins. We applied MONETA for the analysis of communication pathways (i) between the main regulatory fragments of receptors tyrosine kinases (RTKs), KIT and CSF-1R, in the native and mutated states and (ii) in proteins STAT5 (STAT5a and STAT5b) in the phosphorylated and the unphosphorylated forms. The description of the physical support for allosteric coupling by MONETA allowed a comparison of the mechanisms of (a) constitutive activation induced by equivalent mutations in two RTKs and (b) allosteric regulation in the activated and non-activated STAT5 proteins. Our theoretical prediction based on results obtained with MONETA was validated for KIT by in vitro experiments. MONETA is a versatile analytical and visualization tool entirely devoted to the understanding of the functioning/malfunctioning of allosteric regulation in proteins - a crucial basis to guide the discovery of next-generation allosteric drugs.']",https://hal.science/hal-01505837,"['0.info', '1.info.info-bi', '0.sdv', '1.sdv.bbm', '2.sdv.bbm.bp', '0.sdv', '1.sdv.bbm', '2.sdv.bbm.bc']"
"['Ariane Allain', 'Isaure Chauvot de Beauchêne', 'Nicolas Panel', 'Elodie Laine', 'Alain Trouvé', 'Patrice Dubreuil', 'Luba Tchertanov']","[14814, 1219225, 1102065, 840465, 863869, 741074]","['isaure-chauvot-de-beauchene', 'elodie-laine', 'tchertanov']",Hotspot mutations in KIT receptor differentially modulate its allosterically coupled conformational dynamics: impact on activation and drug sensitivity,hal-01505833,2014,10.1371/journal.pcbi.1003749,"['Tyrosine-kinase', 'Allostery', 'KIT', 'Point mutation', 'Cell communication', 'Biochemical simulations', 'Substitution mutation', 'Allosteric regulation', 'Principal component analysis', 'Tyrosine kinases', 'Simulation and modeling']","['Receptor tyrosine kinase KIT controls many signal transduction pathways and represents a typical allosterically regulated protein. The mutation-induced deregulation of KIT activity impairs cellular physiological functions and causes serious human diseases. The impact of hotspots mutations (D816H/Y/N/V and V560G/D) localized in crucial regulatory segments, the juxtamembrane region (JMR) and the activation (A-) loop, on KIT internal dynamics was systematically studied by molecular dynamics simulations. The mutational outcomes predicted in silico were correlated with in vitro and in vivo activation rates and drug sensitivities of KIT mutants. The allosteric regulation of KIT in the native and mutated forms is described in terms of communication between the two remote segments, JMR and A-loop. A strong correlation between the communication profile and the structural and dynamical features of KIT in the native and mutated forms was established. Our results provide new insight on the determinants of receptor KIT constitutive activation by mutations and resistance of KIT mutants to inhibitors. Depiction of an intra-molecular component of the communication network constitutes a first step towards an integrated description of vast communication pathways established by KIT in physiopathological contexts.']",https://hal.science/hal-01505833,"['0.info', '1.info.info-bi', '0.sdv', '1.sdv.bbm', '2.sdv.bbm.bm']"
"['Raphaël Champeimont', 'Elodie Laine', 'Shuang-Wei Hu', 'Francois Penin', 'Alessandra Carbone']","[982489, 926099]",['alessandra-carbone'],Coevolution analysis of Hepatitis C virus genome to identify the structural and functional dependency network of viral proteins,hal-01320023,2016,10.1038/srep26401,"['Computational biology and bioinformatics', 'Hepatitis C virus']","['A novel computational approach of coevolution analysis allowed us to reconstruct the protein-protein interaction network of the Hepatitis C Virus (HCV) at the residue resolution. For the first time, coevolution analysis of an entire viral genome was realized, based on a limited set of protein sequences with high sequence identity within genotypes. The identified coevolving residues constitute highly relevant predictions of protein-protein interactions for further experimental identification of HCV protein complexes. The method can be used to analyse other viral genomes and to predict the associated protein interaction networks.']",https://hal.sorbonne-universite.fr/hal-01320023,"['0.sdv', '1.sdv.bbm']"
"['Elodie Laine', 'Alessandra Carbone']",[926099],['alessandra-carbone'],Protein social behavior makes a stronger signal for partner identification than surface geometry,hal-01400887,2016,10.1002/prot.25206,"['Protein–protein interaction', 'Geometrical docking', 'Partner identification', 'Binding site', 'Complete cross-docking', 'Interface prediction']","['Cells are interactive living systems where proteins movements, interactions and regulation are substantially free from centralized management. How protein physico-chemical and geometrical properties determine who interact with whom remains far from fully understood. We show that characterizing how a protein behaves with many potential interactors in a complete cross-docking study leads to a sharp identification of its cellular/true/native partner(s). We define a sociability index, or S-index, reflecting whether a protein likes or not to pair with other proteins. Formally, we propose a suitable normalization function that accounts for protein sociability and we combine it with a simple interface-based (ranking) score to discriminate partners from non-interactors. We show that sociability is an important factor and that the normalization permits to reach a much higher discriminative power than shape complementarity docking scores. The social effect is also observed with more sophisticated docking algorithms. Docking conformations are evaluated using experimental binding sites. These latter approximate in the best possible way binding sites predictions, which have reached high accuracy in recent years. This makes our analysis helpful for a global understanding of partner identification and for suggesting discriminating strategies. These results contradict previous findings claiming the partner identification problem being solvable solely with geometrical docking.']",https://hal.sorbonne-universite.fr/hal-01400887,"['0.sdv', '1.sdv.bibs']"
"['Yasaman Karami', 'Tristan Bitard-Feildel', 'Elodie Laine', 'Alessandra Carbone']","[776565, 926099]","['yasaman-karami', 'alessandra-carbone']",“Infostery” analysis of short molecular dynamics simulations identifies highly sensitive residues and predicts deleterious mutations,hal-01911176,2018,10.1038/s41598-018-34508-2,"['Computational biology and bioinformatics', 'Mathematics and computing']","['Characterizing a protein mutational landscape is a very challenging problem in Biology. Many disease-associated mutations do not seem to produce any effect on the global shape nor motions of the protein. Here, we use relatively short all-atom biomolecular simulations to predict mutational outcomes and we quantitatively assess the predictions on several hundreds of mutants. We perform simulations of the wild type and 175 mutants of PSD95’s third PDZ domain in complex with its cognate ligand. By recording residue displacements correlations and interactions, we identify “communication pathways” and quantify them to predict the severity of the mutations. Moreover, we show that by exploiting simulations of the wild type, one can detect 80% of the positions highly sensitive to mutations with a precision of 89%. Importantly, our analysis describes the role of these positions in the inter-residue communication and dynamical architecture of the complex. We assess our approach on three different systems using data from deep mutational scanning experiments and high-throughput exome sequencing. We refer to our analysis as “infostery”, from “info” - information - and “steric” - arrangement of residues in space. We provide a fully automated tool, COMMA2 (www.lcqb.upmc.fr/COMMA2), that can be used to guide medicinal research by selecting important positions/mutations.']",https://hal.sorbonne-universite.fr/hal-01911176,"['0.info', '1.info.info-bi']"
"['Thomas Gueudré', 'Carlo Baldassi', 'Marco Zamparo', 'Martin Weigt', 'Andrea Pagnani']",[976468],['martin-weigt'],Simultaneous identification of specifically interacting paralogs and interprotein contacts by direct coupling analysis.,hal-01567010,2016,10.1073/pnas.1607570113,"['Coevolution', 'Direct coupling analysis', 'Paralog matching', 'Protein−protein interaction networks', 'Statistical inference']","['Understanding protein-protein interactions is central to our understanding of almost all complex biological processes. Computational tools exploiting rapidly growing genomic databases to characterize protein-protein interactions are urgently needed. Such methods should connect multiple scales from evolutionary conserved interactions between families of homologous proteins, over the identification of specifically interacting proteins in the case of multiple paralogs inside a species, down to the prediction of residues being in physical contact across interaction interfaces. Statistical inference methods detecting residue-residue coevolution have recently triggered considerable progress in using sequence data for quaternary protein structure prediction; they require, however, large joint alignments of homologous protein pairs known to interact. The generation of such alignments is a complex computational task on its own; application of coevolutionary modeling has, in turn, been restricted to proteins without paralogs, or to bacterial systems with the corresponding coding genes being colocalized in operons. Here we show that the direct coupling analysis of residue coevolution can be extended to connect the different scales, and simultaneously to match interacting paralogs, to identify interprotein residue-residue contacts and to discriminate interacting from noninteracting families in a multiprotein system. Our results extend the potential applications of coevolutionary analysis far beyond cases treatable so far.']",https://hal.sorbonne-universite.fr/hal-01567010,"['0.phys', '0.sdv']"
"['Igor V. Chilingarian', 'Paola Di Matteo', 'Françoise Combes', 'Anne-Laure Melchior', 'Benoît Semelin']",,,The GalMer database: galaxy mergers in the virtual observatory,hal-03784969,2010,10.1051/0004-6361/200912938,['PADC'],"['We present the GalMer database, a library of galaxy merger simulations, that has been produced and made available to users by means of tools compatible with the Virtual Observatory (VO) standards adapted specially for this theoretical database. To investigate the physics of galaxy formation through hierarchical merging, it is necessary to simulate galaxy interactions varying a large number of parameters, e.g. morphological types, mass ratios, orbital configurations. On the one hand, these simulations have to be performed in a cosmological context, capable of providing a large number of galaxy pairs, with boundary conditions given by the large-scale simulation. On the other hand, the resolution has to be high enough on galaxy scales, to provide realistic physics. The GalMer database is a library of thousands of simulations of galaxy mergers at moderate spatial resolution and represents a compromise between considering a diverse range of initial conditions and optimising the details of underlying physics. We provide all coordinates and data of simulated particles in FITS binary tables. The main advantages of the database are VO access interfaces and value-added services that allow users to compare the results of the simulations directly to observations: stellar population modelling, dust extinction, spectra, images, visualisation using dedicated VO tools. The GalMer value-added services can be used as a virtual telescope producing broadband images, 1D spectra, 3D spectral datacubes, thus enhancing the utility of our database to observers. We present several examples of the GalMer database scientific usage obtained by analyzing simulations and modelling their stellar population properties, including: (1) studies of the star formation efficiency in interactions; (2) creation of old counter-rotating components; (3) reshaping metallicity profiles in elliptical galaxies; (4) orbital to internal angular momentum transfer; (5) reproducing observed colour bimodality of galaxies.']",https://hal.science/hal-03784969,"['0.phys', '1.phys.astr']"
"['Hayato Shimabukuro', 'Benoit Semelin']",,,Analysing the 21 cm signal from the epoch of reionization with artificial neural networks,hal-01554641,2017,10.1093/mnras/stx734,"['Intergalactic medium', 'Dark ages', 'Reionization', 'First stars', 'Cosmology theory']","['The 21\xa0cm signal from the epoch of reionization should be observed within the next decade. While a simple statistical detection is expected with Square Kilometre Array (SKA) pathfinders, the SKA will hopefully produce a full 3D mapping of the signal. To extract from the observed data constraints on the parameters describing the underlying astrophysical processes, inversion methods must be developed. For example, the Markov Chain Monte Carlo method has been successfully applied. Here, we test another possible inversion method: artificial neural networks (ANNs). We produce a training set that consists of 70 individual samples. Each sample is made of the 21\xa0cm power spectrum at different redshifts produced with the 21cmFast code plus the value of three parameters used in the seminumerical simulations that describe astrophysical processes. Using this set, we train the network to minimize the error between the parameter values it produces as an output and the true values. We explore the impact of the architecture of the network on the quality of the training. Then we test the trained network on the new set of 54 test samples with different values of the parameters. We find that the quality of the parameter reconstruction depends on the sensitivity of the power spectrum to the different parameters at a given redshift, that including thermal noise and sample variance decreases the quality of the reconstruction and that using the power spectrum at several redshifts as an input to the ANN improves the quality of the reconstruction. We conclude that ANNs are a viable inversion method whose main strength is that they require a sparse exploration of the parameter space and thus should be usable with full numerical simulations.']",https://hal.science/hal-01554641,"['0.phys', '1.phys.astr']"
"['Fragkoudi Francesca', 'Paola Di Matteo', 'Misha Haywood', 'Gómez Anita', 'Françoise Combes', 'David Katz', 'Benoit Semelin']",[736013],['francoise-combes'],Bars and boxy/peanut bulges in thin and thick discs,hal-02191447,2017,10.1051/0004-6361/201630244,"['Methods numerical', 'Galaxies kinematics and dynamics', 'Galaxies structure', 'Galaxies spiral', 'Galaxies bulges']","['We explore trends in the morphology and line-of-sight (los) velocity of stellar populations in the inner regions of disc galaxies using N-body simulations with a thin (kinematically cold) and a thick (kinematically hot) disc which form a bar and a boxy/peanut (b/p) bulge. The bar in the thin disc component is ~50% stronger than the thick disc bar and is more elongated, with an axis ratio almost half that of the thick disc bar. The thin disc b/p bulge has a pronounced X-shape, while the thick disc b/p is weaker with a rather boxy shape. This leads to the signature of the b/p bulge in the thick disc being weaker and further away from the plane than in the thin disc. Regarding the kinematics, we find that the los velocity of thick disc stars in the outer parts of the b/p bulge can be higher than that of thin disc stars, by up to 40% and 20% for side-on and Milky Way-like orientations of the bar, respectively. This is due to the different orbits followed by thin and thick disc stars in the bar-b/p region, which are affected by two factors. First, thin disc stars are trapped more efficiently in the bar-b/p instability and thus lose more angular momentum than their thick disc counterparts and second, thick disc stars have large radial excursions and therefore stars from large radii with high angular momenta can be found in the bar region. We also find that the difference between the los velocities of the thin and thick disc in the b/p bulge (Δvlos) correlates with the initial difference between the radial velocity dispersions of the two discs (Δσ). We therefore conclude that stars in the bar-b/p bulge will have considerably different morphologies and kinematics depending on the kinematic properties of the disc population they originate from.']",https://hal.science/hal-02191447,"['0.phys', '1.phys.astr', '0.phys', '1.phys.astr']"
"['Ingrid Jean-Baptiste', 'Paola Di Matteo', 'Misha Haywood', 'Gómez Anita', 'M. Montuori', 'Françoise Combes', 'Benoit Semelin']","[780892, 736013]",['francoise-combes'],On the kinematic detection of accreted streams in the Gaia era: a cautionary tale,hal-02191657,2017,10.1051/0004-6361/201629691,"['Galaxy disk', 'Galaxy halo', 'Galaxy formation', 'Galaxy evolution', 'Galaxy kinematics and dynamics', 'Methods numerical']","['The ΛCDM cosmological scenario predicts that our Galaxy should contain hundreds of stellar streams in the solar vicinity, fossil relics of the merging history of the Milky Way and more generally of the hierarchical growth of galaxies. Because of the mixing time scales in the inner Galaxy, it has been claimed that these streams should be difficult to detect in configuration space but can still be identifiable in kinematic-related spaces like the energy/angular momenta spaces, E − Lz and L⊥ − Lz, or spaces of orbital/velocity parameters. By means of high-resolution, dissipationless N-body simulations containing between 25 × 106 and 35 × 106 particles, we model the accretion of a series of up to four 1:10 mass ratio satellites then up to eight 1:100 satellites and search systematically for the signature of accretions in these spaces. The novelty of this work with respect to the majority of those already published is our analysis of fully consistent models, where both the satellite(s) and the Milky Way galaxy are “live” systems, which can react to the interaction and experience kinematical heating, tidal effects and dynamical friction (the latter, a process often neglected in previous studies). We find that, in agreement with previous works, all spaces are rich in substructures, but that, contrary to previous works, the origin of these substructures – accreted or in-situ – cannot be determined for the following reasons. In all spaces considered (1) each satellite provides the origin of several independent over-densities; (2) over-densities of multiple satellites overlap; (3) satellites of different masses can produce similar substructures; (4) the overlap between the in-situ and the accreted population is considerable everywhere; and (5) in-situ stars also form substructures in response to the satellite(s’) accretion. These points are valid even if the search is restricted to kinematically-selected halo stars only. As we are now entering the “Gaia era”, our results warn that extreme caution must be employed before interpreting over-densities in any of those spaces as evidence of relics of accreted satellites. Reconstructing the accretion history of our Galaxy will require a substantial amount of accurate spectroscopic data, that, complemented by the kinematic information, will possibly allow us to (chemically) identify accreted streams and measure their orbital properties.']",https://hal.science/hal-02191657,"['0.phys', '1.phys.astr']"
"['Benoit Semelin', 'Evan Eames', 'Florian Bolgar', 'Michel Caillat']",,,21SSD: a public data base of simulated 21-cm signals from the epoch of reionization,hal-01645670,2017,10.1093/mnras/stx2274,"['Radiative transfer', 'Methods numerical', 'Dark ages', 'Reionization', 'First stars']","['The 21-cm signal from the epoch of reionization (EoR) is expected to be detected in the next few years, either with existing instruments or by the upcoming SKA and HERA projects. In this context, there is a pressing need for publicly available high-quality templates covering a wide range of possible signals. These are needed both for end-to-end simulations of the up-coming instruments and to develop signal analysis methods. We present such a set of templates, publicly available, for download at 21ssd.obspm.fr. The data base contains 21-cm brightness temperature lightcones at high and low resolution, and several derived statistical quantities for 45 models spanning our choice of 3D parameter space. These data are the result of fully coupled radiative hydrodynamic high-resolution (1024^3) simulations performed with the licorice code. Both X-ray and Lyman line transfer are performed to account for heating and Wouthuysen–Field coupling fluctuations. We also present a first exploitation of the data using the power spectrum and the pixel distribution function (PDF) computed from lightcone data. We analyse how these two quantities behave when varying the model parameters while taking into account the thermal noise expected of a typical SKA survey. Finally, we show that the noiseless power spectrum and PDF have different – and somewhat complementary – abilities to distinguish between different models. This preliminary result will have to be expanded to the case including thermal noise. This type of results opens the door to formulating an optimal sampling of the parameter space, dependent on the chosen diagnostics.']",https://hal.science/hal-01645670,"['0.phys', '1.phys.astr']"
"['Rennan Barkana', 'Mark Bentum', 'Gianni Bernardi', 'Albert-Jan Boonstra', 'Judd Bowman', 'Jack Burns', 'Xuelei Chen', 'Abhirup Datta', 'Heino Falcke', 'Anastasia Fialkov', 'Bharat Gehlot', 'Leonid Gurvits', 'Vibor Jelić', 'Marc Klein-Wolt', 'Leon Koopmans', 'Joseph Lazio', 'Daan Meerburg', 'Garrelt Mellema', 'Florent Mertens', 'Andrei Mesinger', 'André Offringa', 'Jonathan Pritchard', 'Benoit Semelin', 'Ravi Subrahmanyan', 'Joseph Silk', 'Cathryn Trott', 'Harish Vedantham', 'Licia Verde', 'Saleem Zaroubi', 'Philippe Zarka']","[783168, 749640, 797652, 755767]",['florent-mertens'],Peering into the Dark (Ages) with Low-Frequency Space Interferometers: Using the 21-cm signal of Neutral Hydrogen from the Infant Universe to probe Fundamental (Astro)Physics,hal-02327765,2021,10.1007/s10686-021-09743-7,"['21-cm cosmology', 'Dark ages', 'Cosmic dawn', 'Epoch of reionization', 'Space or lunar-based radio telescopes']","['Neutral hydrogen pervades the infant Universe, and its redshifted 21-cm signal allows one to chart the Universe. This signal allows one to probe astrophysical processes such as the formation of the first stars, galaxies, (super)massive black holes and enrichment of the pristine gas from z~6 to z~30, as well as fundamental physics related to gravity, dark matter, dark energy and particle physics at redshifts beyond that. As one enters the Dark Ages (z>30), the Universe becomes pristine. Ground-based low-frequency radio telescopes aim to detect the spatial fluctuations of the 21-cm signal. Complementary, global 21-cm experiments aim to measure the sky-averaged 21-cm signal. Escaping RFI and the ionosphere has motivated space-based missions, such as the Dutch-Chinese NCLE instrument (currently in lunar L2), the proposed US-driven lunar or space-based instruments DAPPER and FARSIDE, the lunar-orbit interferometer DSL (China), and PRATUSH (India). To push beyond the current z~25 frontier, though, and measure both the global and spatial fluctuations (power-spectra/tomography) of the 21-cm signal, low-frequency (1-100MHz; BW~50MHz; z>13) space-based interferometers with vast scalable collecting areas (1-10-100 km2), large filling factors (~1) and large fields-of-view (4pi sr.) are needed over a mission lifetime of >5 years. In this ESA White Paper, we argue for the development of new technologies enabling interferometers to be deployed, in space (e.g. Earth-Sun L2) or in the lunar vicinity (e.g. surface, orbit or Earth-Moon L2), to target this 21-cm signal. This places them in a stable environment beyond the reach of most RFI from Earth and its ionospheric corruptions, enabling them to probe the Dark Ages as well as the Cosmic Dawn, and allowing one to investigate new (astro)physics that is inaccessible in any other way in the coming decades. [Abridged]']",https://hal.science/hal-02327765,"['0.phys', '1.phys.phys', '2.phys.phys.phys-ins-det']"
"['Jan H. Orkisz', 'Jérôme Pety', 'Maryvonne Gerin', 'Emeric Bron', 'Viviana V. Guzmán', 'Sébastien Bardeau', 'Javier R. Goicoechea', 'P. Gratier', 'Franck Le Petit', 'François Levrier', 'Harvey Liszt', 'Karin Öberg', 'Nicolas Peretto', 'Evelyne Roueff', 'Albrecht Sievers', 'Pascal Tremblin']","[174652, 169617, 15636, 170072, 950936, 15173]","['jerome-pety', 'gerin', 'emeric-bron', 'pierre-gratier', 'francois-levrier', 'pascal-tremblin']",Turbulence and star formation efficiency in molecular clouds: solenoidal versus compressive motions in Orion B,hal-01434996,2017,10.1051/0004-6361/201629220,['Astrophysics - Astrophysics of Galaxies'],"[""The nature of turbulence in molecular clouds is one of the key parameters that control star formation efficiency: compressive motions, as opposed to solenoidal motions, can trigger the collapse of cores, or mark the expansion of Hii regions. We try to observationally derive the fractions of momentum density ($\\rho v$) contained in the solenoidal and compressive modes of turbulence in the Orion B molecular cloud and relate these fractions to the star formation efficiency in the cloud. The implementation of a statistical method developed by Brunt & Federrath (2014), applied to a $^{13}$CO(J=1-0) datacube obtained with the IRAM-30m telescope, allows us to retrieve 3-dimensional quantities from the projected quantities provided by the observations, yielding an estimate of the compressive versus solenoidal ratio in various regions of the cloud. Despite the Orion B molecular cloud being highly supersonic (mean Mach number $\\sim$ 6), the fractions of motion in each mode diverge significantly from equipartition. The cloud's motions are on average mostly solenoidal (excess > 8 % with respect to equipartition), which is consistent with its low star formation rate. On the other hand, the motions around the main star-forming regions (NGC 2023 and NGC 2024) prove to be strongly compressive. We have successfully applied to observational data a method that was so far only tested on simulations, and have shown that there can be a strong intra-cloud variability of the compressive and solenoidal fractions, these fractions being in turn related to the star formation efficiency. This opens a new possibility for star-formation diagnostics in galactic molecular clouds.""]",https://hal.science/hal-01434996,"['0.sdu', '1.sdu.astr', '2.sdu.astr.co', '0.sdu', '1.sdu.astr']"
"['Jérôme Pety', 'Viviana V. Guzmán', 'Jan H. Orkisz', 'Harvey S. Liszt', 'Maryvonne Gerin', 'Emeric Bron', 'Sébastien Bardeau', 'Javier R. Goicoechea', 'P. Gratier', 'Franck Le Petit', 'François Levrier', 'Karin I. Oberg', 'Evelyne Roueff', 'Albrecht Sievers']","[174652, 169617, 15636, 170072, 950936]","['jerome-pety', 'gerin', 'emeric-bron', 'pierre-gratier', 'francois-levrier']",The anatomy of the Orion B giant molecular cloud: A local template for studies of nearby galaxies,hal-01400616,2017,10.1051/0004-6361/201629862,"['Astrophysics - Astrophysics of Galaxies', 'Galaxies ISM', 'ISM clouds', 'HII regions', 'Radio lines galaxies', 'Astrochemistry']","['Context. Molecular lines and line ratios are commonly used to infer properties of extra-galactic star forming regions. The new generation of millimeter receivers almost turns every observation into a line survey. Full exploitation of this technical advancement in extra-galactic study requires detailed bench-marking of available line diagnostics.Aims. We aim to develop the Orion\u2009B giant molecular cloud (GMC) as a local template for interpreting extra-galactic molecular line observations.Methods. We use the wide-band receiver at the IRAM-30\u2009m to spatially and spectrally resolve the Orion\u2009B GMC. The observations cover almost 1 square degree at 26′′ resolution with a bandwidth of 32 GHz from 84 to 116 GHz in only two tunings. Among the mapped spectral lines are the 12CO, 13CO, C18O, C17O, HCN, HNC, 12CN, C2H, HCO+, N2H+(1−0), and 12CS, 32SO, SiO, c - C3H2, CH3OH (2−1) transitions.Results. We introduce the molecular anatomy of the Orion\u2009B GMC, including relationships between line intensities and gas column density or far-UV radiation fields, and correlations between selected line and line ratios. We also obtain a dust-traced gas mass that is less than approximately one third the CO-traced mass, using the standard XCO conversion factor. The presence of over-luminous CO can be traced back to the dependence of the CO intensity on UV illumination. As a matter of fact, while most lines show some dependence on the UV radiation field, CN and C2H are the most sensitive. Moreover, dense cloud cores are almost exclusively traced by N2H+. Other traditional high-density tracers, such as HCN(1−0), are also easily detected in extended translucent regions at a typical density of ~500\u2009H2 cm-3. In general, we find no straightforward relationship between line critical density and the fraction of the line luminosity coming from dense gas regions.Conclusions. Our initial findings demonstrate that the relationships between line (ratio) intensities and environment in GMCs are more complicated than often assumed. Sensitivity (i.e., the molecular column density), excitation, and, above all, chemistry contribute to the observed line intensity distributions, and they must be considered together when developing the next generation of extra-galactic molecular line diagnostics of mass, density, temperature, and radiation field.']",https://hal.science/hal-01400616,"['0.phys', '1.phys.astr', '0.phys', '0.phys', '1.phys.astr']"
"['Jan H. Orkisz', 'Nicolas Peretto', 'Jerome Pety', 'Maryvonne Gerin', 'François Levrier', 'Emeric Bron', 'Sebastien Bardeau', 'Javier R. Goicoechea', 'P. Gratier', 'Viviana V. Guzmán', 'Annie Hughes', 'David Languignon', 'Franck Le Petit', 'Harvey S. Liszt', 'Karin Danielsson Öberg', 'Evelyne Roueff', 'Albrecht Sievers', 'Pascal Tremblin']","[174652, 169617, 950936, 15636, 170072, 771535, 832246, 1004206, 833795, 15173]","['jerome-pety', 'gerin', 'francois-levrier', 'emeric-bron', 'pierre-gratier', 'pascal-tremblin']","A dynamically young, gravitationally stable network of filaments in Orion B",hal-02013389,2019,10.1051/0004-6361/201833410,"['Astrophysics - Astrophysics of Galaxies', 'ISM clouds', 'ISM structure', 'ISM kinematics and dynamics', 'Methods data analysis', 'Radio lines ISM', 'ISM individual objects Orion B']","['Context. Filaments are a key step on the path that leads from molecular clouds to star formation. However, their characteristics, for instance their width, are heavily debated and the exact processes that lead to their formation and fragmentation into dense cores still remain to be fully understood.Aims. We aim at characterising the mass, kinematics, and stability against gravitational collapse of a statistically significant sample of filaments in the Orion B molecular cloud, which is renown for its very low star formation efficiency.Methods. We characterised the gas column densities and kinematics over a field of 1.9 deg2, using C18O (J = 1−0) data from the IRAM 30 m large programme ORION-B at angular and spectral resolutions of 23.5″ and 49.5 kHz, respectively. Using two different Hessian-based filters, we extracted and compared two filamentary networks, each containing over 100 filaments.Results. Independent of the extraction method, the filament networks have consistent characteristics. The filaments have widths of ~0.12 ± 0.04 pc and show a wide range of linear (~1−100\xa0M⊙ pc−1) and volume densities (~2 × 103−2 × 105 cm−3). Compared to previous studies, the filament population is dominated by low-density, thermally sub-critical structures, suggesting that most of the identified filaments are not collapsing to form stars. In fact, only ~1% of the Orion B cloud mass covered by our observations can be found in super-critical, star-forming filaments, explaining the low star formation efficiency of the region. The velocity profiles observed across the filaments show quiescence in the centre and coherency in the plane of the sky, even though these profiles are mostly supersonic.Conclusions. The filaments in Orion B apparently belong to a continuum which contains a few elements comparable to already studied star-forming filaments, for example in the IC 5146, Aquila or Taurus regions, as well as many lower density, gravitationally unbound structures. This comprehensive study of the Orion B filaments shows that the mass fraction in super-critical filaments is a key factor in determining star formation efficiency.']",https://hal.science/hal-02013389,"['0.phys', '1.phys.astr']"
"['Lucas Einig', 'Jérôme Pety', 'Antoine Roueff', 'Paul Vandame', 'Jocelyn Chanussot', 'Maryvonne Gerin', 'Jan H. Orkisz', 'Pierre Palud', 'Miriam G. Santa-Maria', 'Victor de Souza Magalhaes', 'Ivana Bešlić', 'Sébastien Bardeau', 'Emeric E. Bron', 'Pierre Chainais', 'Javier R Goicoechea', 'Pierre Gratier', 'Viviana Guzman Veloso', 'Annie Hughes', 'Jouni Kainulainen', 'David Languignon', 'Rosine Lallement', 'François Levrier', 'Dariuscz C. Lis', 'Harvey Liszt', 'Jacques Le Bourlot', 'Franck Le Petit', 'Karin Danielsson Öberg', 'Nicolas Peretto', 'Evelyne Roueff', 'Albrecht Sievers', 'Pierre-Antoine Thouvenin', 'Pascal Tremblin']","[1218799, 174652, 1271865, 1271819, 21313, 169617, 1171239, 1218750, 817927, 15636, 17431, 960814, 170072, 953067, 771535, 915617, 950936, 833792, 960821, 832246, 1004206, 965998, 833795, 184412, 15173]","['lucas-einig', 'jerome-pety', 'antoine-roueff', 'jocelyn-chanussot', 'gerin', 'pierre-palud', 'miriam-g-santa-maria', 'emeric-bron', 'pierre-chainais', 'pierre-gratier', 'francois-levrier', 'pierre-antoine-thouvenin', 'pascal-tremblin']",Deep learning denoising by dimension reduction: Application to the ORION-B line cubes,hal-04167877,2023,10.1051/0004-6361/202346064,"['ISM clouds', 'Radio lines ISM', 'Techniques image processing', 'Techniques imaging spectroscopy', 'Methods data analysis', 'Methods statistical']","['The availability of large bandwidth receivers for millimeter radio telescopes allows the acquisition of position-position-frequency data cubes over a wide field of view and a broad frequency coverage. These cubes contain much information on the physical, chemical, and kinematical properties of the emitting gas. However, their large size coupled with inhomogenous signal-to-noise ratio (SNR) are major challenges for consistent analysis and interpretation. We search for a denoising method of the low SNR regions of the studied data cubes that would allow to recover the low SNR emission without distorting the signals with high SNR. We perform an in-depth data analysis of the 13 CO and C 17 O (1 − 0) data cubes obtained as part of the ORION-B large program performed at the IRAM 30m telescope. We analyse the statistical properties of the noise and the evolution of the correlation of the signal in a given frequency channel with that of the adjacent channels. This allows us to propose significant improvements of typical autoassociative neural networks, often used to denoise hyperspectral Earth remote sensing data. Applying this method to the 13 CO (1 − 0) cube, we compare the denoised data with those derived with the multiple Gaussian fitting algorithm ROHSA, considered as the state of the art procedure for data line cubes. The nature of astronomical spectral data cubes is distinct from that of the hyperspectral data usually studied in the Earth remote sensing literature because the observed intensities become statistically independent beyond a short channel separation. This lack of redundancy in data has led us to adapt the method, notably by taking into account the sparsity of the signal along the spectral axis. The application of the proposed algorithm leads to an increase of the SNR in voxels with weak signal, while preserving the spectral shape of the data in high SNR voxels. The proposed algorithm that combines a detailed analysis of the noise statistics with an innovative autoencoder architecture is a promising path to denoise radio-astronomy line data cubes.']",https://hal.science/hal-04167877v2,"['0.phys', '1.phys.astr', '2.phys.astr.co']"
"['Emeric E. Bron', 'Chloé Daudon', 'Jérôme Pety', 'François Levrier', 'Maryvonne Gerin', 'P. Gratier', 'Jan H. Orkisz', 'Viviana Guzman', 'Sebastien Bardeau', 'Javier R. Goicoechea', 'Harvey S. Liszt', 'Karin Danielsson Öberg', 'Nicolas Peretto', 'Albrecht Sievers', 'Pascal Tremblin']","[15636, 174652, 950936, 169617, 170072, 847276, 1004206, 965998, 15173]","['emeric-bron', 'jerome-pety', 'francois-levrier', 'gerin', 'pierre-gratier', 'pascal-tremblin']",Clustering the Orion B giant molecular cloud based on its molecular emission,hal-01621390,2018,10.1051/0004-6361/201731833,"['Astrochemistry', 'ISM molecules', 'ISM clouds', 'ISM structure', 'Methods statistical', 'ISM individual objects Orion B']","['Context. Previous attempts at segmenting molecular line maps of molecular clouds have focused on using position-position-velocity data cubes of a single molecular line to separate the spatial components of the cloud. In contrast, wide field spectral imaging over a large spectral bandwidth in the (sub)mm domain now allows one to combine multiple molecular tracers to understand the different physical and chemical phases that constitute giant molecular clouds (GMCs). Aims. We aim at using multiple tracers (sensitive to different physical processes and conditions) to segment a molecular cloud into physically/chemically similar regions (rather than spatially connected components), thus disentangling the different physical/chemical phases present in the cloud. Methods. We use a machine learning clustering method, namely the Meanshift algorithm, to cluster pixels with similar molecular emission, ignoring spatial information. Clusters are defined around each maximum of the multidimensional probability density function (PDF) of the line integrated intensities. Simple radiative transfer models were used to interpret the astrophysical informationuncovered by the clustering analysis. Results. A clustering analysis based only on the $J$ = 1–0 lines of three isotopologues of CO proves sufficient to reveal distinct density/column density regimes ($n_H$ ∼ 100 cm$^{−3}$, ∼500 cm$^{−3}$, and >1000 cm$^{−3}$), closely related to the usual definitions of diffuse, translucent and high-column-density regions. Adding two UV-sensitive tracers, the $J$ = 1–0 line of HCO$^+$ and the $N$ = 1–0 line of CN, allows us to distinguish two clearly distinct chemical regimes, characteristic of UV-illuminated and UV-shielded gas. The UV-illuminated regime shows overbright HCO$^+$ and CN emission, which we relate to a photochemical enrichment effect. We also find a tail of high CN/HCO$^+$ intensity ratio in UV-illuminated regions. Finer distinctions in density classes ($n_H$ ∼ 7 × 10$^3$ cm$^{−3}$ , ∼4 × 10$^4$ cm$^{−3}$) for the densest regions are also identified, likely related to the higher critical density of the CN and HCO$^+$ (1–0) lines. These distinctions are only possible because the high-density regions are spatially resolved. Conclusions. Molecules are versatile tracers of GMCs because their line intensities bear the signature of the physics and chemistry at play in the gas. The association of simultaneous multi-line, wide-field mapping and powerful machine learning methods such as the Meanshift clustering algorithm reveals how to decode the complex information available in these molecular tracers.']",https://hal.science/hal-01621390,"['0.sdu', '1.sdu.astr', '2.sdu.astr.ga']"
"['Mathilde Gaudel', 'Jan H. Orkisz', 'Maryvonne Gerin', 'Jérôme Pety', 'Antoine Roueff', 'Antoine Marchal', 'François Levrier', 'Marc-Antoine Miville-Deschênes', 'Javier R. Goicoechea', 'Evelyne Roueff', 'Franck Le Petit', 'Victor de Souza Magalhaes', 'Pierre Palud', 'Miriam G. Santa-Maria', 'Maxime Vono', 'Sébastien Bardeau', 'Emeric Bron', 'Pierre Chainais', 'Jocelyn Chanussot', 'Pierre Gratier', 'Viviana Guzman', 'Annie Hughes', 'Jouni Kainulainen', 'David Languignon', 'Jacques Le Bourlot', 'Harvey Liszt', 'Karin Öberg', 'Nicolas Peretto', 'Albrecht Sievers', 'Pascal Tremblin']","[1271865, 950936, 741816, 1218750, 1108309, 21313]","['antoine-roueff', 'francois-levrier', 'marc-antoine-miville-deschenes', 'miriam-g-santa-maria', 'jocelyn-chanussot']",Gas kinematics around filamentary structures in the Orion B cloud,obspm-03994002,2022,10.1051/0004-6361/202142109,"['Astrophysics', 'Astrophysics of Galaxies']","['Understanding the initial properties of star-forming material and how they affect the star formation process is key. From an observational point of view, the feedback from young high-mass stars on future star formation properties is still poorly constrained. In the framework of the IRAM 30m ORION-B large program, we obtained observations of the translucent and moderately dense gas, which we used to analyze the kinematics over a field of 5 deg^2 around the filamentary structures. We used the ROHSA algorithm to decompose and de-noise the C18O(1-0) and 13CO(1-0) signals by taking the spatial coherence of the emission into account. We produced gas column density and mean velocity maps to estimate the relative orientation of their spatial gradients. We identified three cloud velocity layers at different systemic velocities and extracted the filaments in each velocity layer. The filaments are preferentially located in regions of low centroid velocity gradients. By comparing the relative orientation between the column density and velocity gradients of each layer from the ORION-B observations and synthetic observations from 3D kinematic toy models, we distinguish two types of behavior in the dynamics around filaments: (i) radial flows perpendicular to the filament axis that can be either inflows (increasing the filament mass) or outflows and (ii) longitudinal flows along the filament axis. The former case is seen in the Orion B data, while the latter is not identified. We have also identified asymmetrical flow patterns, usually associated with filaments located at the edge of an HII region. This is the first observational study to highlight feedback from HII regions on filament formation and, thus, on star formation in the Orion B cloud. This simple statistical method can be used for any molecular cloud to obtain coherent information on the kinematics.']",https://hal-obspm.ccsd.cnrs.fr/obspm-03994002,"['0.phys', '1.phys.astr']"
"['Antoine Roueff', 'Maryvonne Gerin', 'Pierre Gratier', 'François Levrier', 'Jérôme Pety', 'Mathilde Gaudel', 'Javier R. Goicoechea', 'Jan H. Orkisz', 'Victor de Souza Magalhaes', 'Maxime Vono', 'Sébastien Bardeau', 'Emeric Bron', 'Jocelyn Chanussot', 'Pierre Chainais', 'Viviana V. Guzman', 'Annie Hughes', 'Jouni Kainulainen', 'David Languignon', 'Jacques Le Bourlot', 'Franck Le Petit', 'Harvey S. Liszt', 'Antoine Marchal', 'Marc-Antoine Miville-Deschênes', 'Nicolas Peretto', 'Evelyne Roueff', 'Albrecht Sievers']","[1271865, 169617, 170072, 950936, 174652, 1108309, 21313, 771535, 773069, 741816]","['antoine-roueff', 'gerin', 'pierre-gratier', 'francois-levrier', 'jerome-pety', 'jocelyn-chanussot', 'marc-antoine-miville-deschenes']","C18O, 13CO, and 12CO abundances and excitation temperatures in the Orion B molecular cloud",hal-02570214,2021,10.1051/0004-6361/202037776,"['ISM molecules', 'ISM clouds', 'Radiative transfer', 'Methods data analysis', 'Methods statistical']","['Context. CO isotopologue transitions are routinely observed in molecular clouds for the purpose of probing the column density of the gas and the elemental ratios of carbon and oxygen, in addition to tracing the kinematics of the environment.Aims. Our study is aimed at estimating the abundances, excitation temperatures, velocity field, and velocity dispersions of the three main CO isotopologues towards a subset of the Orion B molecular cloud, which includes IC 434, NGC 2023, and the Horsehead pillar.Methods. We used the Cramer Rao bound (CRB) technique to analyze and estimate the precision of the physical parameters in the framework of local-thermodynamic-equilibrium (LTE) excitation and radiative transfer with added white Gaussian noise. We propose a maximum likelihood estimator to infer the physical conditions from the 1–0 and 2–1 transitions of CO isotopologues. Simulations show that this estimator is unbiased and proves efficient for a common range of excitation temperatures and column densities (Tex > 6 K, N > 1014−1015 cm−2).Results. Contrary to general assumptions, the various CO isotopologues have distinct excitation temperatures and the line intensity ratios between different isotopologues do not accurately reflect the column density ratios. We find mean fractional abundances that are consistent with previous determinations towards other molecular clouds. However, significant local deviations are inferred, not only in regions exposed to the UV radiation field, but also in shielded regions. These deviations result from the competition between selective photodissociation, chemical fractionation, and depletion on grain surfaces. We observe that the velocity dispersion of the C18O emission is 10% smaller than that of 13CO. The substantial gain resulting from the simultaneous analysis of two different rotational transitions of the same species is rigorously quantified.Conclusions. The CRB technique is a promising avenue for analyzing the estimation of physical parameters from the fit of spectral lines. Future works will generalize its application to non-LTE excitation and radiative transfer methods.']",https://hal.science/hal-02570214v2,"['0.phys', '1.phys.astr', '0.info']"
"['Philippe Zarka', 'J.-L. Bougeret', 'Cyril Briand', 'B. Cecconi', 'Heino Falcke', 'J. Girard', 'Jean-Mathias Griessmeier', 'Sebastien Hess', 'Marc Klein-Wolt', 'A. Konovalenko', 'L. Lamy', 'D. Mimoun', 'A. Aminaei']","[935210, 1119381, 755196, 737206, 21228, 767634]","['baptiste-cecconi', 'jean-mathias-griessmeier', 'laurent-lamy']",Planetary and exoplanetary low frequency radio observations from the Moon,hal-00772931,2012,10.1016/j.pss.2012.08.004,"['Saturn', 'Jupiter', 'Planets', 'Lunar radio array', 'Hot Jupiters', 'Exoplanets', 'Neptune', 'Uranus', 'Radioastronomy', 'Moon', 'Radio emission', 'Goniopolarimetry', 'Galactic background', 'Thermal noise', 'Lightning', 'Magnetosphere', 'Aurora']","['We analyze the planetary and exoplanetary science that can be carried out with precursor as well as future low frequency radio instruments on the Moon, assessing the limiting noise sources, comparing them to the average and peak spectra of all planetary radio components as they will be seen from the Lunar surface or orbit. We identify which objectives will be accessible with each class of instrument, and discuss the interest of these observations compared to observations by planetary probes and to ground-based observations by large low-frequency radio arrays. The interest of goniopolarimetry is emphasized for pathfinder missions.']",https://hal.science/hal-00772931,"['0.sdu', '1.sdu.astr', '2.sdu.astr.ep', '0.phys', '1.phys.astr', '2.phys.astr.ep']"
"['Vincent Génot', 'E. Budnik', 'C. Jacquey', 'M. Bouchemit', 'B. Renard', 'N. Dufourg', 'N. André', 'Baptiste Cecconi', 'H. Si Hadj Mohand', 'C. Tao', 'B. Besson', 'D. Heulet', 'D. Boucon', 'J. Durand', 'N. Bourrel', 'Q. Brzustowski', 'N. Jourdane', 'R. Hitier', 'P. Garnier', 'B. Grison', 'N. Aunai', 'A. Jeandet', 'F. Cabrolie']","[944147, 1119381, 736383, 735823]","['vincent-genot', 'baptiste-cecconi', 'nicolas-aunai', 'alexis-jeandet']",Automated Multi-Dataset Analysis (AMDA): An on-line database and analysis tool for heliospheric and planetary plasma data,insu-03195355,2021,10.1016/j.pss.2021.105214,"['Space plasmas', 'Analysis tool', 'Database', 'Interoperability']","['Accessing, visualizing and analyzing heterogeneous plasma datasets has always been a tedious task that hindered students and senior researchers as well. Offering user friendly and versatile tools to perform basic research tasks is therefore pivotal for data centres including the Centre de Données de la Physique des Plasmas (CDPP http://www.cdpp.eu/) which holds a large variety of plasma data from various Earth, planetary and heliophysics missions and observatories in plasma physics. This clearly helps gaining increased attention, relevant feedback, and enhanced science return on data. These are the key ideas that crystallized at CDPP more than 15 years ago and resulted in the lay-out of the concepts, and then development, of AMDA, the Automated Multi-Dataset Analysis software (http://amda.cdpp.eu/). This paper gives a description of the architecture of AMDA, describes its functionalities, presents some use cases taken from the literature or fruitful collaborations and shows how it offers unique capabilities for educational purposes.']",https://insu.hal.science/insu-03195355v2,"['0.sdu', '1.sdu.astr', '0.phys', '1.phys.phys', '2.phys.phys.phys-space-ph']"
"['Jaime Álvarez-Muñiz', 'Rafael Alves Batista', 'Aswathi Balagopal V.', 'Julien Bolmont', 'Mauricio Bustamante', 'Washington Carvalho', 'Didier Charrier', 'Ismaël Cognard', 'Valentin Decoene', 'Peter Denton', 'Sijbrand de Jong', 'Krijn de Vries', 'Ralph Engel', 'Ke Fang', 'Chad Finley', 'Stefano Gabici', 'Quanbu Gou', 'Junhua Gu', 'Claire Guepin', 'Hongbo Hu', 'Yan Huang', 'Kumiko Kotera', 'Sandra Le Coz', 'Jean-Philippe Lenain', 'Guoliang Lü', 'Olivier Martineau-Huynh', 'Miguel Mostafá', 'Fabrice Mottez', 'Kohta Murase', 'Valentin Niess', 'Foteini Oikonomou', 'Tanguy Pierog', 'Xiangli Qian', 'Bo Qin', 'Duan Ran', 'Nicolas Renault-Tinacci', 'Markus Roth', 'Frank Schröder', 'Fabian Schüssler', 'Cyril Tasse', 'Charles Timmermans', 'Matías Tueros', 'Xiangping Wu', 'Philippe Zarka', 'Andreas Zech', 'B. Theodore Zhang', 'Jianli Zhang', 'Yi Zhang', 'Qian Zheng', 'Anne Zilles']","[832087, 4850, 749308, 737743, 738386, 832019, 838290, 755767]","['didier-charrier', 'ismael-cognard', 'valentin-decoene', 'jlenain', 'valentin-niess']",The Giant Radio Array for Neutrino Detection (GRAND): Science and design,hal-02392018,2020,10.1007/s11433-018-9385-7,"['Neutrino UHE', 'Cosmic radiatio', 'Observatory', 'Showers atmosp', 'Sensitivity', 'Performance', 'Air', 'Modular', 'Gamma ray', 'Radio wave det']","['The Giant Radio Array for Neutrino Detection (GRAND) is a planned large-scale observatory of ultra-high-energy (UHE) cosmic particles, with energies exceeding 108 GeV. Its goal is to solve the long-standing mystery of the origin of UHE cosmic rays. To do this, GRAND will detect an unprecedented number of UHE cosmic rays and search for the undiscovered UHE neutrinos and gamma rays associated to them with unmatched sensitivity. GRAND will use large arrays of antennas to detect the radio emission coming from extensive air showers initiated by UHE particles in the atmosphere. Its design is modular: 20 separate, independent sub-arrays, each of 10000 radio antennas deployed over 10000 km2. A staged construction plan will validate key detection techniques while achieving important science goals early. Here we present the science goals, detection strategy, preliminary design, performance goals, and construction plans for GRAND.']",https://hal.science/hal-02392018,"['0.phys', '1.phys.astr', '2.phys.astr.ep', '0.sdu', '1.sdu.astr']"
"['L. K. Morabito', 'N. J. Jackson', 'S. Mooney', 'F. Sweijen', 'S. Badole', 'P. Kukreti', 'D. Venkattu', 'C. Groeneveld', 'A. Kappes', 'E. Bonnassieux', 'A. Drabent', 'M. Iacobelli', 'J. H. Croston', 'P. N. Best', 'M. Bondi', 'J. R. Callingham', 'J. E. Conway', 'A. T. Deller', 'M. J. Hardcastle', 'J. P. Mckean', 'G. K. Miley', 'J. Moldon', 'H. J. A. Röttgering', 'C. Tasse', 'T. W. Shimwell', 'R. J. van Weeren', 'J. M. Anderson', 'A. Asgekar', 'I. M. Avruch', 'I. M. van Bemmel', 'M. J. Bentum', 'A. Bonafede', 'W. N. Brouw', 'H. R. Butcher', 'B. Ciardi', 'A. Corstanje', 'A. Coolen', 'S. Damstra', 'F. de Gasperin', 'S. Duscha', 'J. Eislöffel', 'D. Engels', 'H. Falcke', 'M. A. Garrett', 'Jean-Mathias Griessmeier', 'A. W. Gunst', 'M. P. van Haarlem', 'M. Hoeft', 'A. J. van Der Horst', 'E. Jütte', 'M. Kadler', 'L. V. E. Koopmans', 'A. Krankowski', 'G. Mann', 'A. Nelles', 'J. B. R. Oonk', 'E. Orru', 'H. Paas', 'V. N. Pandey', 'R. F. Pizzo', 'M. Pandey-Pommier', 'W. Reich', 'H. Rothkaehl', 'M. Ruiter', 'D. J. Schwarz', 'A. Shulevski', 'M. Soida', 'Michel Tagger', 'C. Vocks', 'R. A. M. J. Wijers', 'S. J. Wijnholds', 'O. Wucknitz', 'Philippe Zarka', 'P. Zucca']","[774611, 755966, 766668, 766669, 761407, 737206, 760232, 4538, 935210]","['jean-mathias-griessmeier', 'michel-tagger']",Sub-arcsecond imaging with the International LOFAR Telescope. I. Foundational calibration strategy and pipeline,insu-03611703,2022,10.1051/0004-6361/202140649,"['Techniques high angular resolution', 'Radiation mechanisms non-thermal', 'Galaxies active', 'Galaxies jets', 'Astrophysics - Instrumentation and Methods for Astrophysics', 'Astrophysics - Astrophysics of Galaxies']","[""The International LOFAR Telescope is an interferometer with stations spread across Europe. With baselines of up to ~2000 km, LOFAR has the unique capability of achieving sub-arcsecond resolution at frequencies below 200 MHz. However, it is technically and logistically challenging to process LOFAR data at this resolution. To date only a handful of publications have exploited this capability. Here we present a calibration strategy that builds on previous high-resolution work with LOFAR. It is implemented in a pipeline using mostly dedicated LOFAR software tools and the same processing framework as the LOFAR Two-metre Sky Survey (LoTSS). We give an overview of the calibration strategy and discuss the special challenges inherent to enacting high-resolution imaging with LOFAR, and describe the pipeline, which is publicly available, in detail. We demonstrate the calibration strategy by using the pipeline on P205+55, a typical LoTSS pointing with an 8 h observation and 13 international stations. We perform in-field delay calibration, solution referencing to other calibrators in the field, self-calibration of these calibrators, and imaging of example directions of interest in the field. We find that for this specific field and these ionospheric conditions, dispersive delay solutions can be transferred between calibrators up to ~1.5° away, while phase solution transferral works well over ~1°. We also demonstrate a check of the astrometry and flux density scale with the in-field delay calibrator source. Imaging in 17 directions, we find the restoring beam is typically ~0.3'' ×0.2'' although this varies slightly over the entire 5 deg<SUP>2</SUP> field of view. We find we can achieve ~80-300 μJy bm<SUP>−1</SUP> image rms noise, which is dependent on the distance from the phase centre; typical values are ~90 μJy bm<SUP>−1</SUP> for the 8 h observation with 48 MHz of bandwidth. Seventy percent of processed sources are detected, and from this we estimate that we should be able to image roughly 900 sources per LoTSS pointing. This equates to ~ 3 million sources in the northern sky, which LoTSS will entirely cover in the next several years. Future optimisation of the calibration strategy for efficient post-processing of LoTSS at high resolution makes this estimate a lower limit.""]",https://insu.hal.science/insu-03611703,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Lucie Guilbaud', 'Delphine Beghin', 'Ferdinand Dhombres', 'Eléonore Blondiaux', 'Stéphanie Friszer', 'Hubert Ducou Le Pointe', 'Elisabeth Elefant', 'Jean-Marie Jouannic']","[750020, 1327160, 14980, 980060]","['lucie-guilbaud', 'delphine-beghin', 'dhombres-ferdinand', 'jean-marie-jouannic']",Pregnancy outcome after first trimester exposure to ionizing radiations,hal-02314031,2019,10.1016/j.ejogrb.2018.11.001,"['Teratogenesis', 'Fetal exposure', 'Ionizing radiations', 'Pregnancy', 'Diagnostic radiations']","['OBJECTIVE: To evaluate the effects of ionizing radiation exposure during the first trimester of pregnancy in usual clinical situations. STUDY DESIGN: We conducted a prospective observational cohort study using data collected between 1987 and 2014. This database was authorized by the French ""Commission Nationale de l\'Informatique et des Libertés"". The exposed group consisted of 319 pregnant women exposed to sub diaphragmatic ionizing radiations for diagnostic purposes, during the first trimester of pregnancy, and the control group consisted of 319 pregnant women without any exposure or exposed to non-teratogenic agents. Data on maternal history and radiations exposure were collected on first contact, and pregnancy outcomes were documented at follow-up. An univariate analysis was performed to compare both groups for the main outcomes. RESULTS: Exposure to sub diaphragmatic ionizing radiation for diagnosis purpose (median fetal dose of 3.1\u2009mGy [0.2-130.0]) during the first trimester of pregnancy was not significantly associated with an increased risk of malformations (1.5% vs 1.8%, p\u2009=\u20091.00), miscarriage (7.8% vs 7.2%, p\u2009=\u20090.88), in utero fetal death (0.3% vs 0%, p\u2009=\u20091.00) or fetal growth restriction (5.4% vs 3.5%, p\u2009=\u20090.62). CONCLUSION: Pregnant women exposed to irradiant diagnostic procedures do not present a higher risk of malformations, miscarriage, in utero fetal death or fetal growth restriction and should be reassured, even if the examination focused on the pelvis.']",https://hal.sorbonne-universite.fr/hal-02314031,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.geo', '0.sdv', '1.sdv.spee']"
"['Paul Kuentz', 'Sylvie Fraitag', 'Marie Gonzales', 'Ferdinand Dhombres', 'Judith Saint-Onge', 'Yannis Duffourd', 'N. Joyé', 'Jean-Marie Jouannic', 'Arnaud Picard', 'Nathalie Marle', 'Julien Thevenon', 'Chrytel Thauvin-Robinet', 'Laurence Faivre', 'Jean-Baptiste Rivière', 'Pierre Vabres']","[995003, 14980, 994653, 994654, 980060, 995626, 995281, 995304, 856301, 994656, 899466]","['dhombres-ferdinand', 'jean-marie-jouannic']",Mosaic-activating FGFR2 mutation in two fetuses with papillomatous pedunculated sebaceous naevus,hal-01412205,2016,10.1111/bjd.14681,"['PPSN', 'Papillomatous', 'Naevus']","[""Papillomatous pedunculated sebaceous naevus (PPSN) has been described as a subtype of sebaceous naevus (SN), typically affecting the scalp and face. In contrast with Schimmelpenning syndrome, no cerebral, ocular or skeletal anomalies have hitherto been reported. We report two unrelated fetuses with PPSN, one with large pink exophytic tumours, the other with minor features but similar microscopic findings. We performed whole-exome sequencing in affected skin tissue from fetus 1, which identified a postzygotic de novo FGFR2 c.1144T>C (p.Cys382Arg) mutation in 34[middle dot]6% of reads which was absent in the parents' blood. Targeted deep sequencing of FGFR2 confirmed its mosaic status in additional affected skin from fetus 1, and identified the same substitution in 26% of reads in affected skin from fetus 2. FGFR2 p.Cys382Arg is a known somatic driver mutation in human cancer, previously reported to result in activation of RAS signalling. A similar paralogous missense mutation in the transmembrane domain of FGFR3 (p.Gly380Arg) has been reported in keratinocytic epidermal naevi. Our findings define a distinct clinical and molecular subgroup of SN, beside HRAS or KRAS-related SN, and expand the spectrum of mosaic skin conditions associated with receptor tyrosine kinase mutations.,""]",https://u-bourgogne.hal.science/hal-01412205,"['0.sdv', '1.sdv.mhep']"
"['Ferdinand Dhombres', 'Paul Maurice', 'Lucie Guilbaud', 'Loriane Franchinard', 'Barbara Dias', 'Jean Charlet', 'Eléonore Blondiaux', 'Babak Khoshnood', 'Davor Jurkovic', 'Eric Jauniaux', 'Jean-Marie Jouannic']","[14980, 999828, 750020, 182018, 837943, 999834, 999833, 980060]","['dhombres-ferdinand', 'lucie-guilbaud', 'jean-charlet', 'jean-marie-jouannic']",A Novel Intelligent Scan Assistant System for Early Pregnancy Diagnosis by Ultrasound: Clinical Decision Support System Evaluation Study,hal-02273256,2019,10.2196/14286,"['Decision support system', 'Ectopic pregnancy', 'Knowledge base', 'Medical ultrasound', 'Ontology', 'Decision support system']","['BACKGROUND: Early pregnancy ultrasound scans are usually performed by nonexpert examiners in obstetrics/gynecology (OB/GYN) emergency departments. Establishing the precise diagnosis of pregnancy location is key for appropriate management of early pregnancies, and experts are usually able to locate a pregnancy in the first scan. A decision-support system based on a semantic, expert-validated knowledge base may improve the diagnostic performance of nonexpert examiners for early pregnancy transvaginal ultrasound. OBJECTIVE: This study aims to evaluate a novel Intelligent Scan Assistant System for early pregnancy ultrasound to diagnose the pregnancy location and determine the image quality. METHODS: Two trainees performed virtual transvaginal ultrasound examinations of early pregnancy cases with and without the system. The ultrasound images and reports were blindly reviewed by two experts using scoring methods. A diagnosis of pregnancy location and ultrasound image quality were compared between scans performed with and without the system. RESULTS: Each trainee performed a virtual vaginal examination for all 32 cases with and without use of the system. The analysis of the 128 resulting scans showed higher quality of the images (quality score: +23%; P<.001), less images per scan (4.6 vs 6.3 [without the CDSS]; P<.001), and higher confidence in reporting conclusions (trust score: +20%; P<.001) with use of the system. Further, use of the system cost an additional 8 minutes per scan. We observed a correct diagnosis of pregnancy location in 39 (61%) and 52 (81%) of 64 scans in the nonassisted mode and assisted mode, respectively. Additionally, an exact diagnosis (with precise ectopic location) was made in 30 (47%) and 49 (73%) of the 64 scans without and with use of the system, respectively. These differences in diagnostic performance (+20% for correct location diagnosis and +30% for exact diagnosis) were both statistically significant (P=.002 and P<.001, respectively). CONCLUSIONS: The Intelligent Scan Assistant System is based on an expert-validated knowledge base and demonstrates significant improvement in early pregnancy scanning, both in diagnostic performance (pregnancy location and precise diagnosis) and scan quality (selection of images, confidence, and image quality).']",https://hal.sorbonne-universite.fr/hal-02273256,"['0.sdv', '1.sdv.ib', '2.sdv.ib.ima', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.geo']"
"['Marie-Christine Jaulent', 'Damien Leprovost', 'Jean Charlet', 'Remy Choquet']","[1160040, 3452, 182018]","['marie-christine-jaulent', 'damien-leprovost', 'jean-charlet']",Semantic interoperability challenges to process large amount of data perspectives in forensic and legal medicine,hal-01431816,2016,10.1016/j.jflm.2016.10.002,"['Variety in Big Data', 'Knowledge Engineering', 'Semantic Interoperability', 'Ontology', 'Forensic Science']","['Although the Big Data approach seems promising in various analytic uses, sharing or integrating data within the same analysis space remains a complex task as existing data is highly heterogeneous and difficult to compare. In this position paper, we address the Variety and Veracity dimensions of Big Data when integrating, sharing and reusing large amount of heterogeneous data for data analysis and decision making applications in the healthcare domain. Many issues are raised by the necessity to conform Big Data to standards in order to make data more interoperable both by humans or computations such as data mining. In this paper, we discuss how ontologies (computerized meaning) can contribute to the improvement of information sharing and address the problem of data sharing together with semantic interoperability data frameworks. We then introduce the main steps required for building domain ontologies as they could be implemented in the context of Forensic and Legal medicine. We conclude with a particular emphasis on the current limitations in healthcare data standardization and the importance of knowledge formalisation. for the coming years, in order to maximise data re-use in forensic and legal medicine.']",https://hal.sorbonne-universite.fr/hal-01431816,"['0.sdv', '1.sdv.mhep']"
"['Ferdinand Dhombres', 'Paul Maurice', 'Stéphanie Friszer', 'Lucie Guilbaud', 'Nathalie Lelong', 'Babak Khoshnood', 'Jean Charlet', 'Nicolas Perrot', 'Eric Jauniaux', 'Davor Jurkovic', 'Jean-Marie Jouannic']","[14980, 999828, 999829, 750020, 912598, 896886, 182018, 999832, 999833, 999834, 980060]","['dhombres-ferdinand', 'lucie-guilbaud', 'jean-charlet', 'jean-marie-jouannic']",Developing a knowledge base to support the annotation of ultrasound images of ectopic pregnancy,inserm-01450080,2016,10.1186/s13326-017-0117-1,"['Application ontology', 'Knowledge base', 'Ectopic pregnancy']","['AbstractBackgroundEctopic pregnancy is a frequent early complication of pregnancy associated with significant rates of morbidly and mortality. The positive diagnosis of this condition is established through transvaginal ultrasound scanning. The timing of diagnosis depends on the operator expertise in identifying the signs of ectopic pregnancy, which varies dramatically among medical staff with heterogeneous training. Developing decision support systems in this context is expected to improve the identification of these signs and subsequently improve the quality of care. In this article, we present a new knowledge base for ectopic pregnancy, and we demonstrate its use on the annotation of clinical images.ResultsThe knowledge base is supported by an application ontology, which provides the taxonomy, the vocabulary and definitions for 24 types and 81 signs of ectopic pregnancy, 484 anatomical structures and 32 technical elements for image acquisition. The knowledge base provides a sign-centric model of the domain, with the relations of signs to ectopic pregnancy types, anatomical structures and the technical elements. The evaluation of the ontology and knowledge base demonstrated a positive feedback from a panel of 17 medical users. Leveraging these semantic resources, we developed an application for the annotation of ultrasound images. Using this application, 6 operators achieved a precision of 0.83 for the identification of signs in 208 ultrasound images corresponding to 35 clinical cases of ectopic pregnancy.ConclusionsWe developed a new ectopic pregnancy knowledge base for the annotation of ultrasound images. The use of this knowledge base for the annotation of ultrasound images of ectopic pregnancy showed promising results from the perspective of clinical decision support system development. Other gynecological disorders and fetal anomalies may benefit from our approach.']",https://inserm.hal.science/inserm-01450080,['0.sdv']
"['Xavier Aimé', 'Lamine Traoré', 'Amina Chniti', 'Eric Sadou', 'David Ouagne', 'Jean Charlet', 'Marie-Christine Jaulent', 'Stefan Darmoni', 'Nicolas Griffon', 'Florence Amardeilh', 'Lydia Bascarane', 'Eric Lepage', 'Christel Daniel']","[3957, 964233, 182018, 1160040, 180619, 1216904, 839966]","['xavier-aime', 'jean-charlet', 'marie-christine-jaulent', 'stefan-darmoni', 'nicolas-griffon']",Semantic interoperability platform for Healthcare Information Exchange,hal-01120299,2015,10.1016/j.irbm.2015.01.003,"['Semantic interoperability', 'Health information systems', 'Information model', 'Reference terminology', 'Semantic web', 'Interface terminology']","[""Objectives: An important barrier to electronic healthcare information exchanges (HIE) is the lack of interoperability between information systems especially on the semantic level. In the scope of the ANR (Agence Nationale pour la Recherche)/TeRSan (Terminology and Data Elements Repositories for Healthcare Interoperability) project, we propose to set and use a semantic interoperability platform, based on semantic web technologies, in order to facilitate standardized healthcare information exchanges between heterogeneous Electronic Healthcare Records (EHRs) in different care settings. Material and methods: The platform is a standard-based expressive and scalable semantic interoperability framework. It includes centrally managed Common Data Elements bounded to international/national reference terminologies such as ICD10, CCAM, SNOMED CT, ICD-O, LOINC and PathLex. It offers semantic services such as dynamic mappings between reference and local terminologies. Results: A pilot implementation of semantic services was developed and evaluated within an HIE prototype in telepathology for remote expert advice. The semantic services developed for transcoding local terms into reference terms take into account the type of message and the exchange context defined within standard-based integration profiles. Conclusion: The TeRSan platform is an innovative semantic interoperability framework that (1) provides standard-based semantic services applicable to any HIE infrastructure and (2) preserves the use of local terminologies and local models by end users (health professionals' priority).""]",https://hal.sorbonne-universite.fr/hal-01120299,"['0.info', '1.info.info-hc', '0.sdv', '1.sdv.mhep']"
"['Emmanuelle Kempf', 'Guillaume Lamé', 'Richard Layese', 'Sonia Priou', 'Gilles Chatellier', 'Hedi Chaieb', 'Marc-Antoine Benderra', 'Ali Bellamine', 'Romain Bey', 'Stéphane Bréant', 'Gilles Galula', 'Namik Taright', 'Xavier Tannier', 'Thomas Guyet', 'Elisa Salamanca', 'Etienne Audureau', 'Christel Daniel', 'Christophe Tournigand']","[752391, 4734, 775541, 752157, 757348, 18076, 4817, 1278482]","['emmanuelle-kempf', 'guillaume-lame', 'sonia-priou', 'xtannier', 'thomas-guyet']",New cancer cases at the time of SARS-Cov2 pandemic and related public health policies: A persistent and concerning decrease long after the end of national lockdown,hal-03172913,2021,10.1016/j.ejca.2021.02.015,"['Incidence', 'Early detection of cancer', 'Health policy', 'COVID-19']","['Introduction The dissemination of SARS-Cov2 may have delayed the diagnosis of new cancers. This study aimed at assessing the number of new cancers during and after the lockdown. Methods We prospectively collected the clinical data of the 11.4 million patients referred to the Assistance Publique Hôpitaux de Paris Teaching Hospital. We identified new cancer cases between 1st January 2018 and 31st September 2020 and compared indicators for 2018 and 2019 to 2020 with a focus on the French lockdown (17th March to 11th May 2020) across cancer types and patient age classes. Results Between January and September, 28,348, 27,272 and 23,734 new cancer cases were identified in 2018, 2019 and 2020, respectively. The monthly median number of new cases reached 3168 (interquartile range, IQR, 3027; 3282), 3054 (IQR 2945; 3127) and 2723 (IQR 2085; 2,863) in 2018, 2019 and 2020, respectively. From March 1st to May 31st, new cancer decreased by 30% in 2020 compared to the 2018–19 average; then by 9% from 1st June to 31st September. This evolution was consistent across all tumour types: −30% and −9% for colon, −27% and −6% for lung, −29% and −14% for breast, −33% and −12% for prostate cancers, respectively. For patients aged <70 years, the decrease of colorectal and breast new cancers in April between 2018 and 2019 average and 2020 reached 41% and 39%, respectively. Conclusion The SARS-Cov2 pandemic led to a substantial decrease in new cancer cases. Delays in cancer diagnoses may affect clinical outcomes in the coming years.']",https://hal.science/hal-03172913,"['0.info', '1.info.info-cl', '0.sdv', '1.sdv.can', '0.sdv', '1.sdv.spee']"
"['Ivan Lerner', 'Nicolas Paris', 'Xavier Tannier']","[799102, 18076]",['xtannier'],Terminologies augmented recurrent neural network model for clinical named entity recognition,hal-02428771,2020,10.1016/j.jbi.2019.103356,"['APcNER', 'Clinical natural language processing', 'Information extraction', 'Machine learning', 'Named entity recognition']","[""OBJECTIVE:We aimed to enhance the performance of a supervised model for clinical named-entity recognition (NER) using medical terminologies. In order to evaluate our system in French, we built a corpus for 5 types of clinical entities.METHODS:We used a terminology-based system as baseline, built upon UMLS and SNOMED. Then, we evaluated a biGRU-CRF, and a hybrid system using the prediction of the terminology-based system as feature for the biGRU-CRF. In French, we built APcNER, a corpus of 147 documents annotated for 5 entities (Drug names, Signs or symptoms, Diseases or disorders, Diagnostic procedures or lab tests and Therapeutic procedures). We evaluated each NER systems using exact and partial match definition of F-measure for NER. The APcNER contains 4,837 entities, which took 28 h to annotate. The inter-annotator agreement as measured by Cohen's Kappa was substantial for non-exact match (Κ = 0.61) and moderate considering exact match (Κ = 0.42). In English, we evaluated the NER systems on the i2b2-2009 Medication Challenge for Drug name recognition, which contained 8,573 entities for 268 documents, and i2b2-small a version reduced to match APcNER number of entities.RESULTS:For drug name recognition on both i2b2-2009 and APcNER, the biGRU-CRF performed better that the terminology-based system, with an exact-match F-measure of 91.1% versus 73% and 81.9% versus 75% respectively. For i2b2-small and APcNER, the hybrid system outperformed the biGRU-CRF, with an exact-match F-measure of 87.8% versus 85.6% and 86.4% versus 81.9% respectively. On APcNER corpus, the micro-average F-measure of the hybrid system on the 5 entities was 69.5% in exact match and 84.1% in non-exact match.CONCLUSION:APcNER is a French corpus for clinical-NER of five types of entities which covers a large variety of document types. The extension of the supervised model with terminology has allowed an easy increase in performance, especially for rare entities, and established near state of the art results on the i2b2-2009 corpus.""]",https://hal.science/hal-02428771,"['0.info', '1.info.info-cl']"
"['Emmanuelle Kempf', 'Sonia Priou', 'Guillaume Lamé', 'Christel Daniel', 'Ali Bellamine', 'Daniele Sommacale', 'Yazid Belkacemi', 'Romain Bey', 'Gilles Galula', 'Namik Taright', 'Xavier Tannier', 'Bastien Rance', 'Rémi Flicoteaux', 'François Hemery', 'Etienne Audureau', 'Gilles Chatellier', 'Christophe Tournigand']","[752391, 752157, 4734, 18076, 170889, 757348, 1278482]","['emmanuelle-kempf', 'sonia-priou', 'guillaume-lame', 'xtannier', 'bastien-rance']","Impact of two waves of Sars‐Cov2 outbreak on the number, clinical presentation, care trajectories and survival of patients newly referred for a colorectal cancer: A French multicentric cohort study from a large group of University hospitals",hal-03519085,2022,10.1002/ijc.33928,"['Delivery of Health Care', 'Health Services Research', 'Colorectal Neoplasms', 'Quality of Health Care', 'COVID-19']","['The SARS-Cov2 may have impaired care trajectories, patient overall survival (OS), tumor stage at initial presentation for new colorectal cancer (CRC) cases. This study aimed at assessing those indicators before and after the beginning of the pandemic in France. In this retrospective cohort study, we collected prospectively the clinical data of the 11.4 million of patients referred to the Greater Paris University Hospitals (AP HP). We identified new CRC cases between January first 2018 and December 31st 2020, and compared indicators for 2018-2019 to 2020. pTNM tumor stage was extracted from postoperative pathology reports for localized colon cancer, and metastatic status was extracted from CT-scan baseline text reports. Between 2018 and 2020, 3602 and 1083 new colon and rectal cancers were referred to the APHP, respectively. The 1-year OS rates reached 94%, 93% and 76% for new CRC patients undergoing a resection of the primary tumor, in 2018-2019, in 2020 without any Sars-Cov2 infection and in 2020 with a Sars-Cov2 infection, respectively (HR 3.78, 95%CI 2.1-7.1). For patients undergoing other kind of anticancer treatment, the percentages are 64%, 66% and 27% (HR 2.1, 95%CI 1.4-3.3). Tumor stage at initial presentation, emergency level of primary tumor resection, delays between the first multidisciplinary meeting and the first anticancer treatment did not differ over time. The SARS-Cov2 pandemic has been associated with less newly diagnosed CRC patients and worse 1-yr OS rates attributable to the infection itself rather than to its impact on hospital care delivery or tumor stage at initial presentation.']",https://hal.science/hal-03519085,"['0.sdv', '1.sdv.can', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg', '0.sdv', '1.sdv.spee']"
"['Perceval Wajsbürt', 'Arnaud Sarfati', 'Xavier Tannier']","[751196, 18076]","['percevalw', 'xtannier']",Medical concept normalization in French using multilingual terminologies and contextual embeddings,hal-03127411,2021,10.1016/j.jbi.2021.103684,"['Information extraction', 'Medical concept normalization', 'Multilingual representation', 'Natural language processing']","['Introduction: Concept normalization is the task of linking terms from textual medical documents to their concept in terminologies such as the UMLS®. Traditional approaches to this problem depend heavily on the coverage of available resources, which poses a problem for languages other than English. Objective: We present a system for concept normalization in French. We consider textual mentions already extracted and labeled by a named entity recognition system, and we classify these mentions with a UMLS concept unique identifier. We take advantage of the multilingual nature of available terminologies and embedding models to improve concept normalization in French without translation nor direct supervision. Materials and methods: We consider the task as a highly-multiclass classification problem. The terms are encoded with contextualized embeddings and classified via cosine similarity and softmax. A first step uses a subset of the terminology to finetune the embeddings and train the model. A second step adds the entire target terminology, and the model is trained further with hard negative selection and softmax sampling. Results: On two corpora from the Quaero FrenchMed benchmark, we show that our approach can lead to good results even with no labeled data at all; and that it outperforms existing supervised methods with labeled data. Discussion: Training the system with both French and English terms improves by a large margin the performance of the system on a French benchmark, regardless of the way the embeddings were pretrained (French, English, multilingual). Our distantly supervised method can be applied to any kind of documents or medical domain, as it does not require any concept-labeled documents. Conclusion: These experiments pave the way for simpler and more effective multilingual approaches to processing medical texts in languages other than English.']",https://hal.science/hal-03127411,"['0.info', '1.info.info-cl']"
"['Maria Paola Tramonti Fantozzi', 'Ugo Faraguna', 'Adrien Ugon', 'Gastone Ciuti', 'Andrea Pinna']",[817471],,Automatic Cyclic Alternating Pattern (CAP) analysis: Local and multi-trace approaches,hal-03464976,2021,10.1371/journal.pone.0260984,"['Algorithms', 'Sleep', 'Electroencephalography', 'Signal filtering', 'Sleep disorders', 'Bandpass filters', 'Support vector machines', 'Visual inspection']","['The Cyclic Alternating Pattern (CAP) is composed of cycles of two different electroencephalographic features: an activation A-phase followed by a B-phase representing the background activity. CAP is considered a physiological marker of sleep instability. Despite its informative nature, the clinical applications remain limited as CAP analysis is a time-consuming activity. In order to overcome this limit, several automatic detection methods were recently developed. In this paper, two new dimensions were investigated in the attempt to optimize novel, efficient and automatic detection algorithms: 1) many electroencephalographic leads were compared to identify the best local performance, and 2) the global contribution of the concurrent detection across several derivations to CAP identification. The developed algorithms were tested on 41 polysomnographic recordings from normal (n = 8) and pathological (n = 33) subjects. In comparison with the visual CAP analysis as the gold standard, the performance of each algorithm was evaluated. Locally, the detection on the F4-C4 derivation showed the best performance in comparison with all other leads, providing practical suggestions of electrode montage when a lean and minimally invasive approach is preferable. A further improvement in the detection was achieved by a multi-trace method, the Global Analysis-Common Events, to be applied when several recording derivations are available. Moreover, CAP time and CAP rate obtained with these algorithms positively correlated with the ones identified by the scorer. These preliminary findings support efficient automated ways for the evaluation of the sleep instability, generalizable to both normal and pathological subjects affected by different sleep disorders.']",https://hal.sorbonne-universite.fr/hal-03464976,['0.info']
"['Quentin Angermann', 'Aymeric Histace', 'Olivier Romain', 'Xavier Dray', 'Andrea Pinna', 'Bertrand Granado']","[8193, 1028, 4376, 934208, 934207, 9619]","['quentin-angermann', 'aymeric-histace', 'romain-etis', 'bertrand-granado']",Smart Videocapsule for Early Diagnosis of Colorectal Cancer: Toward Embedded Image Analysis,hal-01150094,2015,10.1007/978-3-319-20071-2_12,"['Polyp Localization', 'Embedded Detection', 'Videocapsule', 'Colorectal Cancer', 'Energy Performance']","['For the last 20 years, wireless videocapsule technology has triggered a lot of interest in the gastroenterologist community for the non-invasive early detection of various gastrointestinal pathologies (ulcers, Chrones disease, polyp detection, etc.). Nevertheless, in most of the European countries videocapsules are not yet considered as a systematic valid alternative to classic endoscopies and colonoscopies. Main reasons are in the existing technological limitations of videocapsules that are of two kinds: (i) A limited battery life-time (8 hours usually ensured by the manufacturer) that does not allow a complete imaging of the gastro intestinal tract, and (ii) the limited performance of the device in terms of detection rate of particular structures like polyps for instance which degenerations are at the origin of colorectal cancer. To overpass these limitations, main idea of our work is to develop a generation of smart videocapsules that takes advantage of the constant progress in electronics and most precisely in embedded signal processing tasks. In this Chapter, we give first a detailed overview of the most recent state-of-the-art related to videocapsules from the technological perspective in order to clearly positioned our work among the existing products and on going projects. In a second time, we propose a synthetic recall of the Cyclope project in the framework of which we are studying different strategies to improve the performance of current videocapsules in the particular context of the early diagnosis of colorectal cancer (polyp detection). We then propose a particular focus on the design optimization of the proposed algorithms from an electronic perspective. Most precisely, we give concrete elements and quantitative estimation (time processing, embedding performance, etc.) to show that embedding of the signal processing IP inside the videocapsule is feasible considering the most recent FPGA-platform performance, and that such an integration can bring a positive balance in terms of energy consumption by drastically reducing the amount of transmitted data.']",https://hal.science/hal-01150094,"['0.info', '1.info.info-ti', '0.spi', '1.spi.signal', '0.spi', '0.spi', '1.spi.tron']"
"['Bruno Blanchet', 'Patrick Cousot', 'Radhia Cousot', 'Jerôme Feret', 'Laurent Mauborgne', 'Antoine Miné', 'David Monniaux', 'Xavier Rival']","[16135, 837875, 749591, 837876, 2206, 9093, 6633]","['bruno-blanchet', 'jerome-feret', 'antoine-mine', 'david-monniaux', 'xavier-rival']",A Static Analyzer for Large Safety-Critical Software,hal-00128135,2003,10.1145/781131.781153,"['Abstract Interpretation', 'Abstract Domains', 'Static Analysis', 'Verification', 'Floating Point', 'Embedded', 'Reactive', 'Real-Time', 'Safety-Critical Software']","['We show that abstract interpretation-based static program analysis can be made efficient and precise enough to formally verify a class of properties for a family of large programs with few or no false alarms. This is achieved by refinement of a general purpose static analyzer and later adaptation to particular programs of the family by the end-user through parametrization. This is applied to the proof of soundness of data manipulation operations at the machine level for periodic synchronous safety critical embedded software. The main novelties are the design principle of static analyzers by refinement and adaptation through parametrization, the symbolic manipulation of expressions to improve the precision of abstract transfer functions, the octagon, ellipsoid, and decision tree abstract domains, all with sound handling of rounding errors in floating point computations, widening strategies (with thresholds, delayed) and the automatic determination of the parameters (parametrized packing).']",https://hal.science/hal-00128135,"['0.info', '1.info.info-pl', '0.info', '1.info.info-pf']"
"['Patrick Cousot', 'Radhia Cousot', 'Jérôme Feret', 'Laurent Mauborgne', 'Antoine Miné', 'Xavier Rival']","[837875, 749591, 837876, 2206, 6633]","['jerome-feret', 'antoine-mine', 'xavier-rival']",Why does Astrée scale up?,inria-00528582,2009,10.1007/s10703-009-0089-6,"['Abstract Interpretation', 'Embedded critical software', 'Formal methods', 'Safety', 'Scalability', 'Static analysis tool', 'Verification']","['Astrée was the first static analyzer able to prove automatically the total absence of runtime errors of actual industrial programs of hundreds of thousand lines. What makes Astrée such an innovative tool is its scalability, while retaining the required precision, when it is used to analyze a specific class of programs: that of reactive control-command software. In this paper, we discuss the important choice of algorithms and data-structures we made to achieve this goal. However, what really made this task possible was the ability to also take semantic decisions, without compromising soundness, thanks to the abstract interpretation framework. We discuss the way the precision of the semantics was tuned in Astrée in order to scale up, the differences with some more academic approaches and some of the dead-ends we explored. In particular, we show a development process which was not specific to the particular usage Astrée was built for, hoping that it might prove helpful in building other scalable static analyzers.']",https://inria.hal.science/inria-00528582,"['0.info', '1.info.info-oh']"
"['Patrick Cousot', 'Radhia Cousot', 'Jérôme Feret', 'Laurent Mauborgne', 'Antoine Miné', 'David Monniaux', 'Xavier Rival']","[749591, 837876, 2206, 9093, 6633]","['jerome-feret', 'antoine-mine', 'david-monniaux', 'xavier-rival']",Combination of Abstractions in the ASTRÉE Static Analyzer,inria-00528571,2006,10.1007/978-3-540-77505-8_23,"['Abstract Interpretation', 'Static Analysis', 'Runtime Error', 'Abstract Domain', 'Reduced product', 'Widening', 'Narrowing', 'Verification']","['We describe the structure of the abstract domains in the ASTRÉE static analyzer, their modular organization into a hierarchical network, their cooperation to over-approximate the conjunction/reduced product of different abstractions and to ensure termination using collaborative widenings and narrowings. This separation of the abstraction into a combination of cooperative abstract domains makes ASTRÉE extensible, an essential feature to cope with false alarms and ultimately provide sound formal verification of the absence of runtime errors in very large software.']",https://inria.hal.science/inria-00528571,"['0.info', '1.info.info-oh']"
['Antoine Miné'],[2206],['antoine-mine'],Relational thread-modular static value analysis by abstract interpretation,hal-00925713,2014,10.1007/978-3-642-54013-4_3,"['Static analysis', 'Abstract interpretation', 'Verification', 'Safety', 'Concurrency', 'Embedded programs', 'Rely-guarantee methods']","['We study thread-modular static analysis by abstract interpretation to infer the values of variables in concurrent programs. We show how to go beyond the state of the art and increase an analysis precision by adding the ability to infer some relational and history-sensitive properties of thread interferences. The fundamental basis of this work is the formalization by abstract interpretation of a rely-guarantee concrete semantics which is thread-modular, constructive, and complete for safety properties. We then show that previous analyses based on non-relational interferences can be retrieved as coarse computable abstractions of this semantics; additionally, we present novel abstraction examples exploiting our ability to reason more precisely about interferences, including domains to infer relational lock invariants and the monotonicity of counters. Our method and domains have been implemented in the AstréeA static analyzer that checks for run-time errors in embedded concurrent C programs, where they enabled a significant reduction of the number of false alarms.']",https://inria.hal.science/hal-00925713,"['0.info', '1.info.info-dc', '0.info', '1.info.info-pf', '0.info', '1.info.info-fl']"
['Antoine Miné'],[2206],['antoine-mine'],Static Analysis of Run-Time Errors in Embedded Critical Parallel C Programs,hal-00648038,2011,10.1007/978-3-642-19718-5_21,"['Run-time errors', 'Parallel programs', 'Static analysis', 'Abstract Interpretation']","['We present a static analysis by Abstract Interpretation to check for run-time errors in parallel C programs. Following our work on Astrée, we focus on embedded critical programs without recursion nor dynamic memory allocation, but extend the analysis to a static set of threads. Our method iterates a slightly modified non-parallel analysis over each thread in turn, until thread interferences stabilize. We prove the soundness of the method with respect to a sequential consistent semantics and a reasonable weakly consistent memory semantics. We then show how to take into account mutual exclusion and thread priorities through partitioning over the scheduler state. We present preliminary experimental results analyzing a real program with our prototype, Thésée, and demonstrate the scalability of our approach.']",https://inria.hal.science/hal-00648038,"['0.info', '1.info.info-pf']"
"['Béatrice Bérard', 'Serge Haddad', 'Mathieu Sassolas']","[778970, 745039, 923034]",['serge-haddad'],Interrupt Timed Automata: verification and expressiveness,hal-00683279,2012,10.1007/s10703-011-0140-2,"['Hybrid automata', 'Timed automata', 'Multi-task systems', 'Interrupts', 'Decidability of reachability', 'Model checking', 'Real-time properties']","['We introduce the class of Interrupt Timed Automata (ITA), a subclass of hybrid automata well suited to the description of timed multi-task systems with interruptions in a single processor environment. While the reachability problem is undecidable for hybrid automata we show that it is decidable for ITA. More precisely we prove that the untimed language of an ITA is regular, by building a finite automaton as a generalized class graph. We then establish that the reachability problem for ITA is in NEXPTIME and in PTIME when the number of clocks is fixed. To prove the first result, we define a subclass ITA− of ITA, and show that (1) any ITA can be reduced to a language-equivalent automaton in ITA− and (2) the reachability problem in this subclass is in NEXPTIME (without any class graph). In the next step, we investigate the verification of real time properties over ITA. We prove that model checking SCL, a fragment of a timed linear time logic, is undecidable. On the other hand, we give model checking procedures for two fragments of timed branching time logic. We also compare the expressive power of classical timed automata and ITA and prove that the corresponding families of accepted languages are incomparable. The result also holds for languages accepted by controlled real-time automata (CRTA), that extend timed automata. We finally combine ITA with CRTA, in a model which encompasses both classes and show that the reachability problem is still decidable. Additionally we show that the languages of ITA are neither closed under complementation nor under intersection.']",https://hal.science/hal-00683279,"['0.info', '1.info.info-mo', '0.info', '1.info.info-fl']"
"['Alexandre Brière', 'Eren Unlu', 'Julien Denoulet', 'Andrea Pinna', 'Bertrand Granado', 'Francois Pêcheux', 'Yves Louët', 'Christophe Moy']","[970712, 738737, 955698, 9619, 11096, 10216]","['eren-unlu', 'bertrand-granado', 'yves-louet', 'christophe-moy']",A Dynamically Reconfigurable RF NoC for Many-Core,hal-01166859,2015,10.1145/2742060.2742082,"['Reconfigurable', 'Many-Core', 'NoC', 'RF', 'Dynamic']","['With the growing number of cores on chips, conventional electrical interconnects reach scalability limits, leading the way for alternatives like Radio Frequency (RF), optical and 3D. Due to the variability of applications, communication needs change over time and across regions of the chip. To address these issues, a dynamically reconfigurable Network on Chip (NoC) is proposed. It uses RF and Orthogonal Frequency Division Multiple Access (OFDMA) to create communication channels whose allocation allows dynamic recon-figuration. We describe the NoC architecture and the distributed mechanism of dynamic allocation. We study the feasibility of the NoC based on state of the art components and analyze its performances. Static analysis shows that, for point to point communications, its latency is comparable with a 256-node electrical mesh and becomes lower for wider networks. A major feature of this architecture is its broadcast capacity. The RF NoC becomes faster with 32 nodes, achieving a ×3 speedup with 1024. Under realistic traffic models, its dynamic reconfigurability provides up to ×6 lower latency while ensuring fairness.']",https://hal.science/hal-01166859,"['0.info', '1.info.info-ar', '0.info', '1.info.info-ao']"
"['Nicolas Bourgeois', 'Bruno Escoffier', 'Vangelis Paschos', 'Johan van Rooij']","[751739, 775336, 946990]",['nbourgeo'],Fast Algorithms for max independent set,hal-01509542,2012,10.1007/s00453-010-9460-7,"['Max independent set', 'Bottom-up method', 'Exact algorithms']","['We first propose a method, called “bottom-up method” that, informally, “propagates” improvement of the worst-case complexity for “sparse” instances to “denser” ones and we show an easy though non-trivial application of it to the min set cover problem. We then tackle max independent set. Here, we propagate improvements of worst-case complexity from graphs of average degree d to graphs of average degree greater than d. Indeed, using algorithms for max independent set in graphs of average degree 3, we successively solve max independent set in graphs of average degree 4, 5 and 6. Then, we combine the bottom-up technique with measure and conquer techniques to get improved running times for graphs of maximum degree 5 and 6 but also for general graphs. The computation bounds obtained for max independent set are O ∗(1.1571 n ), O ∗(1.1895 n ) and O ∗(1.2050 n ), for graphs of maximum (or more generally average) degree 4, 5 and 6 respectively, and O ∗(1.2114 n ) for general graphs. These results improve upon the best known results for these cases for polynomial space algorithms.']",https://hal.science/hal-01509542,['0.info']
"['Edouard Bonnet', 'Bruno Escoffier', 'Eunjung Kim', 'Vangelis Paschos']","[171728, 5124, 938795, 946990]","['edouard-bonnet', 'brunoescoffier']",On Subexponential and FPT-Time Inapproximability,hal-01099850,2015,10.1007/s00453-014-9889-1,"['Approximation algorithms', 'Exponential time algorithms', 'FPT algorithms']","['Fixed-parameter algorithms, approximation algorithms and moderately exponential algorithms are three major approaches to algorithm design. While each of them being very active in its own, there is an increasing attention to the connection between these different frameworks. In particular, whether Independent Set would be better approximable once endowed with subexponential-time or FPT-time is a central question. In this article, we provide new insights to this question using two complementary approaches; the former makes a strong link between the linear PCP conjecture and inapproximability; the latter builds a class of equivalent problems under approximation in subexponential time.']",https://hal.science/hal-01099850,['0.info']
"['Bruno Escoffier', 'Laurent Gourvès', 'Jérôme Monnot']","[775336, 178759]",['jerome-monnot'],Fair solutions for some multiagent optimization problems,hal-01508747,2013,10.1007/s10458-011-9188-z,"['Multiagent optimization', 'Combinatorial optimization', 'Fairness']","['We consider optimization problems in a multiagent setting where a solution is evaluated with a vector. Each coordinate of this vector represents an agent’s utility for the solution. Due to the possible conflicts, it is unlikely that one feasible solution is optimal for all agents. Then, a natural aim is to find solutions that maximize the satisfaction of the least satisfied agent, where the satisfaction of an agent is defined as his relative utility, i.e., the ratio between his utility for the given solution and his maximum possible utility. This criterion captures a classical notion of fairness since it focuses on the agent with lowest relative utility. We study worst-case bounds on this ratio: for which ratio a feasible solution is guaranteed to exist, i.e., to what extend can we find a solution that satisfies all agents? How can we build these solutions in polynomial time? For several optimization problems, we give polynomial-time deterministic algorithms which (almost always) achieve the best possible ratio.']",https://hal.science/hal-01508747,['0.info']
"['Edouard Bonnet', 'Bruno Escoffier', 'Vangelis Paschos', 'Emeric Tourniaire']","[171728, 5124, 946990, 947021]","['edouard-bonnet', 'brunoescoffier']",Multi-parameter Analysis for Local Graph Partitioning Problems: Using Greediness for Parameterization,hal-01200582,2015,10.1007/s00453-014-9920-6,"['Parameterized complexity', 'Branching', 'Local partitioning problems']","['We study the parameterized complexity of a broad class of problems called “local graph partitioning problems” that includes the classical fixed cardinality problems as max k-vertex cover, k-densest subgraph, etc. By developing a technique that we call “greediness-for-parameterization”, we obtain fixed parameter algorithms with respect to a pair of parameters k, the size of the solution (but not its value) and Δ, the maximum degree of the input graph. In particular, greediness-for-parameterization improves asymptotic running times for these problems upon random separation (that is a special case of color coding) and is more intuitive and simple. Then, we show how these results can be easily extended for getting standard-parameterization results (i.e., with parameter the value of the optimal solution) for a well known local graph partitioning problem.']",https://hal.science/hal-01200582,['0.info']
"['Jacob de Nobel', 'Furong Ye', 'Diederick Vermetten', 'Hao Wang', 'Carola Doerr', 'Thomas Bäck']",[1290],['carola-doerr'],IOHexperimenter: Benchmarking Platform for Iterative Optimization Heuristics,hal-04180576,2024,10.1162/evco_a_00342,"['Iterative Optimization Heuristics', 'Benchmarking', 'Algorithm Comparison']","['We present IOHexperimenter, the experimentation module of the IOHprofiler project. IOHexperimenter aims at providing an easy-to-use and customizable toolbox for benchmarking iterative optimization heuristics such as local search, evolutionary and genetic algorithms, and Bayesian optimization techniques. IOHexperimenter can be used as a stand-alone tool or as part of a benchmarking pipeline that uses other modules of the IOHprofiler environment. IOHexperimenter provides an efficient interface between optimization problems and their solvers while allowing for granular logging of the optimization process. Its logs are fully compatible with existing tools for interactive data analysis, which significantly speeds up the deployment of a benchmarking pipeline. The main components of IOHexperimenter are the environment to build customized problem suites and the various logging options that allow users to steer the granularity of the data records.']",https://hal.sorbonne-universite.fr/hal-04180576,['0.info']
"['Christophe Denis', 'Mohamed Hebiri']",[1036220],['christophedenisuge'],Consistency of plug-in confidence sets for classification in semi-supervised learning,hal-01180363,2015,10.1080/10485252.2019.1689241,"['Classification', 'Classification with reject option', 'Conformal predictors', 'Confidence sets', 'Plug-in confidence sets']","['Confident prediction is highly relevant in machine learning; for example, in applications such as medical diagnoses, wrong prediction can be fatal. For classification, there already exist procedures that allow to not classify data when the confidence in their prediction is weak. This approach is known as classification with reject option. In the present paper, we provide new methodology for this approach. Predicting a new instance via a confidence set, we ensure an exact control of the probability of classification. Moreover, we show that this methodology is easily implementable and entails attractive theoretical and numerical properties.']",https://hal.science/hal-01180363,"['0.math', '1.math.math-st']"
"['Christophe Denis', 'Charlotte Dion', 'Miguel Martinez']","[1036220, 1228277, 1287307]","['christophedenisuge', 'miguel-martinez']",CONSISTENT PROCEDURES FOR MULTICLASS CLASSIFICATION OF DISCRETE DIFFUSION PATHS,hal-01869545,2019,10.1111/sjos.12415,"['Multiclass classification', 'Diffusion paths', 'Plug-in estimators', 'Drift estimation', 'Empirical risk minimization', 'Empirical risk minimization AMS Subject Classification 62M05', '62H30', '62F12']",['The recent advent of modern technology has generated a large number of datasets which can be frequently modeled as functional data. This paper focuses on the problem of multiclass classification for stochastic diffusion paths. In this context we establish a closed formula for the optimal Bayes rule. We provide new statistical procedures which are built either on the plug-in principle or on the empirical risk minimization principle. We show the consistency of these procedures under mild conditions. We apply our methodologies to the parametric case and illustrate their accuracy with a simulation study through examples.'],https://hal.science/hal-01869545v2,"['0.stat', '1.stat.th']"
"['Djes-Frésy Bilenga Moukodouma', 'Donald Romarick ROTIMBO MBOUROU', 'Christiane Atteke Nkoulembene', 'Christophe Denis']","[1275736, 1275737, 1015029, 176586]",['christophe-denis'],"A temperatures variation favor human-elephant conflict in Gabon's Lékédi National Park, Une variation de température favorisant le conflit homme-éléphant dans le parc national de la Lékédi au Gabon",hal-04180743,2023,10.22161/ijaers.108.2,"['Unavailability of Moabi tree fruit', 'Temperatures', 'Elephant movement', 'Lékédi National Park', 'Human-elephant conflict']","[""The purpose of the study, conducted from August 8 th to 12 th , 2022, in Gabon's Lékédi National Park, was to assess elephant movement in relation to the availability of Moabi tree fruit. The goal was to understand the close connection between fluctuating temperatures and elephant movement toward human habitations. A questionnaire was utilized to gather insights from 53 individuals, primarily adults residing around Lékédi National Park. Statistical analysis of the collected data revealed a significant correlation between the percentage of individuals noticing changes in Moabi tree productivity and variations in mean annual temperature. The mean annual temperature had increased by +0.06°C over the two consecutive 5-year intervals between 2011 and 2020 (study period). The survey indicated that 56.6% of respondents perceived the Moabi fruit harvest as average in the last two years, and around 90% of people had witnessed their own or a relative's field being devastated by elephants during the same period. Notably, 96.23% of respondents believed that present-day elephants are getting closer to human dwellings, compared to 3.77% who thought they were moving farther away. The lack of available Moabi fruit would encourage elephants to venture into secondary forests, thereby escalating the risk of human-elephant conflict."", ""L'objectif de cette étude, menée du 8 au 12 août 2022 dans le parc national de la Lékédi au Gabon, était d'évaluer les déplacements des éléphants en fonction de la disponibilité des fruits de l'arbre Moabi. L'objectif était de comprendre le lien étroit entre la fluctuation des températures et le déplacement des éléphants vers les habitations humaines. Un questionnaire a été utilisé pour recueillir des informations auprès de 53 personnes, principalement des adultes résidant autour du parc national de la Lékédi. L'analyse statistique des données recueillies a révélé une corrélation significative entre le pourcentage d'individus remarquant des changements dans la productivité des arbres Moabi et les variations de la température moyenne annuelle. La température moyenne annuelle a augmenté de +0,06°C au cours des deux intervalles consécutifs de 5 ans entre 2011 et 2020 (période d'étude). L'enquête a indiqué que 56,6% des personnes interrogées ont perçu la récolte de fruits Moabi comme moyenne au cours des deux dernières années, et environ 90% des personnes ont vu leur propre champ ou celui d'un parent être dévasté par les éléphants au cours de la même période. Notamment, 96,23% des personnes interrogées pensent que les éléphants actuels se rapprochent des habitations humaines, contre 3,77% qui pensent qu'ils s'en éloignent. Le manque de fruits Moabi disponibles encouragerait les éléphants à s'aventurer dans les forêts secondaires, augmentant ainsi le risque de conflit entre l'homme et l'éléphant.""]",https://hal.science/hal-04180743,"['0.sdv', '1.sdv.ee', '2.sdv.ee.ieo', '0.sde', '1.sde.be', '0.sdv', '1.sdv.ee', '2.sdv.ee.bio']"
"['Thibault Laugel', 'Marie-Jeanne Lesot', 'Christophe Marsala', 'Xavier Renard', 'Marcin Detyniecki']","[739174, 14208, 8248, 9375, 1081473]","['thibault-laugel', 'marie-jeanne-lesot', 'christophe-marsala', 'xavier-renard']",Comparison-based Inverse Classification for Interpretability in Machine Learning,hal-01905982,2018,10.1007/978-3-319-91473-2_9,"['Local explanation', 'Inverse classification', 'Post-hoc interpretability', 'Comparison-based']","['In the context of post-hoc interpretability, this paper addresses the task of explaining the prediction of a classifier, considering the case where no information is available, neither on the classifier itself , nor on the processed data (neither the training nor the test data). It proposes an inverse classification approach whose principle consists in determining the minimal changes needed to alter a prediction: in an instance-based framework, given a data point whose classification must be explained, the proposed method consists in identifying a close neighbor classified differently, where the closeness definition integrates a spar-sity constraint. This principle is implemented using observation generation in the Growing Spheres algorithm. Experimental results on two datasets illustrate the relevance of the proposed approach that can be used to gain knowledge about the classifier.']",https://hal.sorbonne-universite.fr/hal-01905982,"['0.info', '1.info.info-ai', '0.info', '1.info.info-lg']"
"['Khalil Laghmari', 'Christophe Marsala', 'Mohammed Ramdani']","[15113, 8248, 995798]","['khalil-laghmari', 'christophe-marsala']",An adapted incremental graded multi-label classification model for recommendation systems,cirad-01577274,2017,10.1007/s13748-017-0133-5,['Graded multi-label classification Recommender system Sparse data Incremental mode Concept drift'],"['Graded multi-label classification (GMLC) is the task of assigning to each data a set of relevant labels with corresponding membership grades. This paper is interested in GMLC for large and evolving datasets where data are collected from a possibly infinite stream. Many commercial and non-commercial websites acquire such data by giving users the opportunity to rank items any time using an ordinal scale like one-to-five star rating. Typically these collected data are sparse because users rank only a small subset of items. Websites rely on recommender systems to dynamically adapt the recommended item set for each user. Hence, the applied recommender system should remain scalable and efficient when dealing with sparse data. State-of-the-art methods related to GMLC were tested only in batch mode. Their performance in an incremental mode is not investigated, especially in presence of sparse data and concept drifts. This paper presents our proposed incremental GMLC method which answers the above challenges and can be applied to build a recommender system. This method is tested on the well-known MovieLens and Jester datasets, and it is able to adapt to concept drifts and maintain the Hamming loss at a low level.']",https://hal.science/cirad-01577274,"['0.info', '0.info', '1.info.info-lg', '0.info', '1.info.info-ai']"
"['Christophe Marsala', 'Bernadette Bouchon-Meunier']","[8248, 9708]","['christophe-marsala', 'bernadette-bouchon-meunier']",Fuzzy data mining and management of interpretable and subjective information,hal-01198847,2015,10.1016/j.fss.2015.08.021,"['Interpretable systems', 'Subjective information', 'Emotions', 'Fuzzy data mining']","['Fuzzy set theory offers an important contribution to data mining leading to fuzzy data mining. It enables the management of interpretable and subjective information in both input and output of the data mining process. In this paper, we discuss the notion of interpretability in fuzzy data mining and we present some references on the management of emotions as a particular kind of subjective information.']",https://hal.sorbonne-universite.fr/hal-01198847,['0.info']
"['Thibault Laugel', 'Adulam Jeyasothy', 'Marie-Jeanne Lesot', 'Christophe Marsala', 'Marcin Detyniecki']","[1151040, 1151039, 14208, 8248, 1081473]","['adulam-jeyasothy', 'marie-jeanne-lesot', 'christophe-marsala']",Achieving Diversity in Counterfactual Explanations: a Review and Discussion,hal-04104661,2023,10.1145/3593013.3594122,"['XAI', 'Counterfactual explanations', 'Actionable recourse', 'Explainability', 'Interpretability', 'Transparency', 'Survey', 'Review', 'Diversity']","['In the field of Explainable Artificial Intelligence (XAI), counterfactual examples explain to a user the predictions of a trained decision model by indicating the modifications to be made to the instance so as to change its associated prediction. These counterfactual examples are generally defined as solutions to an optimization problem whose cost function combines several criteria that quantify desiderata for a good explanation meeting user needs. A large variety of such appropriate properties can be considered, as the user needs are generally unknown and differ from one user to another; their selection and formalization is difficult. To circumvent this issue, several approaches propose to generate, rather than a single one, a set of diverse counterfactual examples to explain a prediction. This paper proposes a review of the numerous, sometimes conflicting, definitions that have been proposed for this notion of diversity. It discusses their underlying principles as well as the hypotheses on the user needs they rely on and proposes to categorize them along several dimensions (explicit vs implicit, universe in which they are defined, level at which they apply), leading to the identification of further research challenges on this topic.']",https://hal.science/hal-04104661,"['0.info', '1.info.info-ai']"
"['Adulam Jeyasothy', 'Thibault Laugel', 'Marie-Jeanne Lesot', 'Christophe Marsala', 'Marcin Detyniecki']",[1151039],['adulam-jeyasothy'],A General Framework for Personalising Post Hoc Explanations through User Knowledge Integration,hal-04337026,2023,10.1016/j.ijar.2023.108944,"['EXplainable Artificial Intelligence', 'XAI', 'User knowledge', 'Compatibility', 'Counterfactual explanation', 'Surrogate model explanations', 'Local feature importance']","['The field of XAI aims at providing explanations about the behavior of AI methods to a user. In particular, local post-hoc interpretability approaches aim at generating explanations for a particular prediction of a trained machine learning model. It is generally recognized that such explanations should be adapted to each user: integrating user knowledge and taking into account the user specificity allows to provide personalized explanations and to improve the explanation understandability. Yet these elements appear to be rarely taken into account, and only in specific configurations. In this paper, we propose a general framework to allow this integration of user knowledge in post-hoc interpretability methods, relying on the addition of a compatibility term in the cost function. We instantiate the proposed formalization in two scenarios, varying in the explanation form they propose, in the case where the available user knowledge provides information about the data features. As a result, two new explainability methods are proposed, respectively named Knowledge Integration in Counterfactual Explanation (KICE) and Knowledge Integration in Surrogate Model (KISM). These methods are experimentally studied on several benchmark data sets to characterize the explanations they generate as compared to reference methods.']",https://hal.science/hal-04337026,"['0.info', '1.info.info-ai']"
"['Evripidis Bampis', 'Alexander Kononov', 'Dimitrios Letsios', 'Giorgio Lucarelli', 'Ioannis Nemparis']","[855947, 936053, 919841, 5944]",['lucarelli-giorgio'],From preemptive to non-preemptive speed-scaling scheduling,hal-01082393,2015,10.1016/j.dam.2014.10.007,"['Approximation algorithms', 'Non-preemptive scheduling', 'Speed-scaling']","['We are given a set of jobs, each one specified by its release date, its deadline and its processing volume (work), and a single (or a set of) speed-scalable processor(s). We adopt the standard model in speed-scaling in which if a processor runs at speed . s then the energy consumption is . sα units of energy per time unit, where . α>1 is a small constant. Our goal is to find a schedule respecting the release dates and the deadlines of the jobs so that the total energy consumption to be minimized. While most previous works have studied the preemptive case of the problem, where a job may be interrupted and resumed later, we focus on the non-preemptive case where once a job starts its execution, it has to continue until its completion without any interruption. As the preemptive case is known to be polynomially solvable for both the single-processor and the multiprocessor case, we explore the idea of transforming an optimal preemptive schedule to a non-preemptive one. We prove that the preemptive optimal solution does not preserve enough of the structure of the non-preemptive optimal solution, and more precisely that the ratio between the energy consumption of an optimal non-preemptive schedule and the energy consumption of an optimal preemptive schedule can be very large even for the single-processor case. Then, we focus on some interesting families of instances: (i) equal-work jobs on a single-processor, and (ii) agreeable instances in the multiprocessor case. In both cases, we propose constant factor approximation algorithms. In the latter case, our algorithm improves the best known algorithm of the literature. Finally, we propose a (non-constant factor) approximation algorithm for general instances in the multiprocessor case.']",https://hal.science/hal-01082393,"['0.info', '1.info.info-mo']"
"['Evripidis Bampis', 'Dimitrios Letsios', 'Giorgio Lucarelli']","[855947, 919841, 5944]",['lucarelli-giorgio'],"Green scheduling, flows and matchings",hal-01366487,2015,10.1016/j.tcs.2015.02.020,"['Speed-scaling', 'Polynomial-time algorithms', 'Convex cost flows', 'Weighted matchings']","['Recently, optimal combinatorial algorithms have been presented for the energy minimization multiprocessor speed-scaling problem with migrations [5] and [7]. These algorithms use repeated maximum-flow computations that allow the partition of the set of jobs into subsets in which all the jobs are executed at the same speed. The optimality of these algorithms is based on a series of technical lemmas showing that this partition and the corresponding speeds lead to the minimization of the energy consumption. In this paper, we show that both the algorithms and their analysis can be greatly simplified. In order to do this, we formulate the problem as a convex cost flow problem in an appropriate flow network. Furthermore, we show that our approach is useful to solve other problems in the dynamic speed-scaling setting. As an example, we consider the preemptive open-shop speed-scaling problem and we propose a polynomial-time algorithm for finding an optimal solution based on the computation of convex cost flows. We also propose a polynomial-time algorithm for minimizing a linear combination of the sum of the completion times of the jobs and the total energy consumption, for the non-preemptive multiprocessor speed-scaling problem. Instead of using convex cost flows, our algorithm is based on the computation of a minimum weighted maximum matching in an appropriate bipartite graph.']",https://hal.science/hal-01366487,"['0.info', '1.info.info-ds']"
"['Eric Angel', 'Evripidis Bampis', 'Fanny Pascual']","[855946, 855947, 855950]",,Truthful algorithms for scheduling selfish tasks on parallel machines,hal-00341358,2006,10.1016/j.tcs.2006.07.057,"['Algorithmic game theory', 'Truthful algorithm', 'Scheduling', 'Coordination mechanism', 'Mechanism design']","['We consider the problem of designing truthful mechanisms for scheduling selfish tasks (or agents)—whose objective is the minimization of their completion times—on parallel identical machines in order to minimize the makespan . A truthful mechanism can be easily obtained in this context (if we, of course, assume that the tasks cannot shrink their lengths) by scheduling the tasks following the increasing order of their lengths. The quality of a mechanism is measured by its approximation factor (price of anarchy, in a distributed system) w.r.t. the social optimum. The previous mechanism, known as SPT, produces a (2-1/m)-approximate schedule, where m is the number of machines. The central question in this paper is the following: “Are there other truthful mechanisms with better approximation guarantee (price of anarchy) for the considered scheduling problem?” This question has been raised by Christodoulou et al. [Coordination mechanisms, in: Proc. of ICALP 2004, Lecture Notes in Computer Science, Vol. 3142, 345–357.] in the context of coordination mechanisms, but it is also relevant in centrally controlled systems. We present (randomized) truthful mechanisms for both the centralized and the distributed settings that improve the (expected) approximation guarantee (price of anarchy) of the SPT mechanism. Our centralized mechanism holds for any number of machines and arbitrary task lengths, while the coordination mechanism holds only for two machines and task lengths that are powers of a certain constant.']",https://hal.science/hal-00341358,"['0.scco', '1.scco.comp', '0.info', '1.info.info-ro', '0.info', '1.info.info-ds', '0.info', '1.info.info-dm', '0.info', '1.info.info-gt']"
"['Evripidis Bampis', 'Dimitrios Letsios', 'Ioannis Milis', 'Georgios Zois']","[855947, 919841, 947052]",,Speed Scaling for Maximum Lateness,hal-01366455,2016,10.1007/s00224-015-9622-8,['Energy efficiencySpeed scalingSchedulingMaximum lateness'],"['We consider the power-aware problem of scheduling non-preemptively a set of jobs on a single speed-scalable processor so as to minimize the maximum lateness, under a given budget of energy. In the offline setting, our main contribution is a combinatorial polynomial time algorithm for the case in which the jobs have common release dates. In the presence of arbitrary release dates, we show that the problem becomes strongly NP-hard. Moreover, we show that there is no O(1)-competitive deterministic algorithm for the online setting in which the jobs arrive over time. Then, we turn our attention to an aggregated variant of the problem, where the objective is to find a schedule minimizing a linear combination of maximum lateness and energy. As we show, our results for the budget variant can be adapted to derive a similar polynomial time algorithm and an NP-hardness proof for the aggregated variant in the offline setting, with common and arbitrary release dates respectively. More interestingly, for the online case, we propose a 2-competitive algorithm.']",https://hal.science/hal-01366455,"['0.info', '1.info.info-ds']"
"['Eric Angel', 'Evripidis Bampis', 'Fanny Pascual', 'Alex-Ariel Tchetgnia']","[855946, 855947, 855950]",,On truthfulness and approximation for scheduling selfish tasks,hal-00654128,2009,10.1007/s10951-009-0118-8,"['Truthfulness', 'Game theory', 'Approximation algorithms', 'Scheduling']","['We consider the problem of designing truthful mechanisms for scheduling n tasks on a set of m parallel related machines in order to minimize the makespan. In what follows, we consider that each task is owned by a selfish agent. This is a variant of the KP-model introduced by Koutsoupias and Papadimitriou (Proc. of STACS 1999, pp. 404-413, 1999) (and of the CKN-model of Christodoulou et al. in Proc. of ICALP 2004, pp. 345-357, 2004) in which the agents cannot choose the machine on which their tasks will be executed. This is done by a centralized authority, the scheduler. However, the agents may manipulate the scheduler by providing false information regarding the length of their tasks. We introduce the notion of increasing algorithm and a simple reduction that transforms any increasing algorithm into a truthful one. Furthermore, we show that some of the classical scheduling algorithms are indeed increasing: the LPT algorithm, the PTAS of Graham (SIAM J. Appl. Math. 17(2):416-429, 1969) in the case of two machines, as well as a simple PTAS for the case of m machines, with m a fixed constant. Our results yield a randomized r(1+ε)-approximation algorithm where r is the ratio between the largest and the smallest speed of the related machines. Furthermore, by combining our approach with the classical result of Shmoys et al. (SIAM J. Comput. 24(6):1313-1331, 1995), we obtain a randomized 2r(1+ε)-competitive algorithm. It has to be noticed that these results are obtained without payments, unlike most of the existing works in the field of Mechanism Design. Finally, we show that if payments are allowed then our approach gives a (1+ε)-algorithm for the off-line case with related machines.']",https://hal.science/hal-00654128,['0.info']
"['Siao-Leu Phouratsamay', 'Safia Kedad-Sidhoum', 'Fanny Pascual']","[8411, 855950]",['safia-kedad-sidhoum'],Two-level lot-sizing with inventory bounds,hal-01817667,2018,10.1016/j.disopt.2018.05.001,"['Dynamic lot-sizing', 'Dynamic programming', 'NP-hardness', 'Inventory bounds']","['We study a two-level uncapacitated lot-sizing problem with inventory bounds that occurs in a supply chain composed of a supplier and a retailer. The first level with the demands is the retailer level and the second one is the supplier level. The aim is to minimize the cost of the supply chain so as to satisfy the demands when the quantity of item that can be held in inventory at each period is limited. The inventory bounds can be imposed at the retailer level, at the supplier level or at both levels. We propose a polynomial dynamic programming algorithm to solve this problem when the inventory bounds are set on the retailer level. When the inventory bounds are set on the supplier level, we show that the problem is NP-hard. We give a pseudo-polynomial algorithm which solves this problem when there are inventory bounds on both levels. In the case where demand lot-splitting is not allowed, i.e. each demand has to be satisfied by a single order, we prove that the uncapacitated lot-sizing problem with inventory bounds is strongly NP-hard. This implies that the two-level lot-sizing problems with inventory bounds are also strongly NP-hard when demand lot-splitting is considered.']",https://hal.science/hal-01817667,"['0.info', '1.info.info-ro', '0.info', '0.info', '1.info.info-cc', '0.info', '1.info.info-ds', '0.info', '1.info.info-gt']"
"['Eric Angel', 'Evripidis Bampis', 'Fanny Pascual']","[855946, 855947, 855950]",,How good are SPT schedules for fair optimality criteria,hal-00341351,2008,10.1007/s10479-007-0267-0,"['Multiprocessor scheduling', 'SPT', 'Fairness measures', 'Approximation algorithms']","['We consider the following scheduling setting: a set of n tasks have to be executed on a set of m identical machines. It is well known that shortest processing time (SPT) schedules are optimal for the problem of minimizing the total sum of completion times of the tasks. In this paper, we measure the quality of SPT schedules, from an approximation point of view, with respect to the following optimality criteria: sum of completion times per machine, global fairness, and individual fairness.']",https://hal.science/hal-00341351,"['0.scco', '1.scco.comp', '0.info', '1.info.info-ro', '0.info', '1.info.info-ds', '0.info', '1.info.info-dm', '0.info', '1.info.info-gt']"
"['Eric Angel', 'Evripidis Bampis', 'Fanny Pascual']","[855946, 855947, 855950]",,An exponential (matching based) neighborhood for the vehicle routing problem,hal-00341352,2008,10.1007/s10878-007-9075-3,"['Matching', 'Vehicle routing problem', 'Exponential neighborhood', 'Local search']","[""We introduce an exponential neighborhood for the Vehicle Routing Problem (vrp) with unit customers' demands, and we show that it can be explored efficiently in polynomial time by reducing its exploration to a particular case of the Restricted Complete Matching (rcm) problem that we prove to be polynomial time solvable using flow techniques. Furthermore, we show that in the general case with non-unit customers' demands the exploration of the neighborhood becomes an NP-hard problem.""]",https://hal.science/hal-00341352,"['0.scco', '1.scco.comp', '0.info', '1.info.info-ro', '0.info', '1.info.info-ds', '0.info', '1.info.info-dm', '0.info', '1.info.info-gt']"
"['Johanne Cohen', 'Fanny Pascual']","[1009853, 855950]",,Scheduling tasks from selfish multi-tasks agents.,hal-01287277,2015,10.1007/978-3-662-48096-0_15,"['Scheduling', 'Algorithmic Game Theory']","['We are interested in scheduling tasks from several selfish agents on a set of parallel identical machines. A coordination mechanism consists in giving a scheduling policy to each machine. Given these policies, each agent chooses the machines on which she assigns her tasks, and her aim is to minimize the average completion times of her tasks. The aim of the system (social cost) is to minimize the average completion time of all the tasks. We focus on coordination mechanisms inducing Nash equilibria, and on the performance of such mechanisms. When the machines do not know the owners of the tasks, the classical coordination mecanisms used for single-task agents do not work anymore and we give necessary conditions to obtain coordination mechanisms that induce Nash equilibria. When each machine is able to know the owner of each task it has to schedule, we give coordination mechanisms which always induce Nash equilibria.']",https://hal.science/hal-01287277,"['0.scco', '1.scco.comp']"
"['Fanny Pascual', 'Krzysztof Rzadca']","[855950, 830231]",,Colocating tasks in data centers using a side-effects performance model,hal-01744684,2018,10.1016/j.ejor.2018.01.046,"['Combinatorial optimization', 'Scheduling', 'Data center', 'Heterogeneity', 'Colocation']","[""In data centers, many tasks (services, virtual machines or computational jobs) share a single physical machine. We explore a new resource management model for such colocation. Our model uses two parameters of a task—its size and its type—to characterize how a task influences the performance of the other tasks allocated on the same machine. As typically a data center hosts many similar, recurring tasks (e.g. a webserver, a database, a CPU-intensive computation), the resource manager should be able to construct these types and their performance interactions. In particular, we minimize the total cost in a model in which each task's cost is a function of the total sizes of tasks allocated on the same machine (each type is counted separately). We show that for a linear cost function the problem is strongly NP-hard, but polynomially-solvable in some particular cases. We propose an algorithm polynomial in the number of tasks (but exponential in the number of types and machines) and another algorithm polynomial in the number of tasks and machines (but exponential in the number of types and admissible sizes of tasks). We also propose a polynomial time approximation algorithm, and, in the case of a single type, a polynomial time exact algorithm. For convex costs, we prove that, even for a single type, the problem becomes NP-hard, and we propose an approximation algorithm. We experimentally verify our algorithms on instances derived from a real-world data center trace. While the exact algorithms are infeasible for large instances, the approximations and heuristics deliver reasonable performance.""]",https://hal.science/hal-01744684,"['0.info', '0.info', '1.info.info-cc', '0.info', '1.info.info-dc', '0.info', '1.info.info-ro']"
"['Carmen Brando', 'Francesca Frontini', 'Jean-Gabriel Ganascia']","[183296, 2695]","['carmen-brando', 'francesca-frontini']",REDEN: Named Entity Linking in Digital Literary Editions Using Linked Data Sets,hal-01396037,2016,10.7250/csimq.2016-7.04,"['Digital humanities', 'Named Entity Linking', 'Graph centrality', 'Linked data', 'Data fusion']","[""This paper proposes a graph-based Named Entity Linking (NEL) algorithm named REDEN for the disambiguation of authors' names in French literary criticism texts and scientific essays from the 19th and early 20th centuries. The algorithm is described and evaluated according to the two phases of NEL as reported in current state of the art, namely, candidate retrieval and candidate selection. REDEN leverages knowledge from different Linked Data sources in order to select candidates for each author mention, subsequently crawls data from other Linked Data sets using equivalence links (e.g., owl:sameAs), and, finally, fuses graphs of homologous individuals into a non-redundant graph well-suited for graph centrality calculation; the resulting graph is used for choosing the best referent. The REDEN algorithm is distributed in open-source and follows current standards in digital editions (TEI) and semantic Web (RDF). Its integration into an editorial workflow of digital editions in Digital humanities and cultural heritage projects is entirely plausible. Experiments are conducted along with the corresponding error analysis in order to test our approach and to help us to study the weaknesses and strengths of our algorithm, thereby to further improvements of REDEN.""]",https://hal.sorbonne-universite.fr/hal-01396037,"['0.info', '1.info.info-ai', '0.info', '1.info.info-cl', '0.info', '1.info.info-tt', '0.info', '1.info.info-ds']"
"['Jean-Gabriel Ganascia', 'Pierre Glaudes', 'Andrea Del Lungo']",[1174979],['andrea-del-lungo'],Automatic Detection of Reuses and Citations in Literary Texts,hal-00977310,2014,10.1093/llc/fqu020,"['Literary transformation', 'Imitation', 'Citation', 'Intertextuality', 'Reuse', 'Transtextuality', 'Literature']","['For more than forty years now, modern theories of literature (Compagnon, 1979) insist on the role of paraphrases, rewritings, citations, reciprocal borrowings and mutual contributions of any kinds. The notions of intertextuality, transtextuality, hypertextuality/hypotextuality, were introduced in the seventies and eighties to approach these phenomena. The careful analysis of these references is of particular interest in evaluating the distance that the creator voluntarily introduces with his/her masters. Phoebus is collaborative project that makes computer scientists from the University Pierre and Marie Curie (LIP6-UPMC) collaborate with the literary teams of Paris-Sorbonne University with the aim to develop efficient tools for literary studies that take advantage of modern computer science techniques. In this context, we have developed a piece of software that automatically detects and explores networks of textual reuses in classical literature. This paper describes the principles on which is based this program, the significant results that have already been obtained and the perspectives for the near future.']",https://hal.science/hal-00977310v2,"['0.shs', '1.shs.litt', '0.info', '1.info.info-ai']"
"['M. Olivier', 'S. Rey', 'D. Voilmy', 'Jean-Gabriel Ganascia', 'K. Lan Hing Ting']","[1121187, 18942, 1066078]","['marion-olivier', 'stephanie-rey']",Combining Cultural Probes and Interviews with Caregivers to Co-Design a Social Mobile Robotic Solution,hal-04025525,2023,10.1016/j.irbm.2022.06.004,"['Social robotics', 'Human–Robot interactions', 'Participatory design', 'Empirical analysis', 'Cultural probes']","['Objectives The objective of our research is to study the social organization within institutions welcoming dependent older adults and the potential impact of introducing a social robot. Materials and methods In a co-design approach with professionals, the observation of behaviors, regulated by social rules and norms, will allow, in a way coherent with our empirical approach, to question the conditions necessary for the design of an acceptable human–robot interaction. The ethnographic observations, which were cancelled due to the Covid crisis, led us to use the “cultural probes” method combined with interviews, to understand the daily work of health professionals better. Results The analysis of the collected data allows us to identify 5 recurrent themes – Time and personnel, the health situation,1 Communication/Attention, Guiding, Activities – for which we have listed, in this article, the issues encountered, the questions raised and ideas of potential solutions with the use of a social robot. Conclusion The Cultural Probes approach may seem time-consuming and requires a significant investment, but it has allowed us to maintain regular contact during the pandemic. In addition, the qualitative data collected proved to be a good discussion tool.']",https://hal.science/hal-04025525,['0.scco']
"['Carmen Brando', 'Francesca Frontini', 'Jean-Gabriel Ganascia']","[183296, 2695]","['carmen-brando', 'francesca-frontini']",Disambiguation of Named Entities in Cultural Heritage Texts Using Linked Data Sets,hal-01203784,2015,10.1007/978-3-319-23201-0_51,['Named-entity disambiguation Centrality Linked data Data fusion Digital humanities'],"['This paper proposes a graph-based algorithm baptized REDEN for the disambiguation of authors’ names in French literary criticism texts and scientific essays from the 19th century. It leverages knowledge from different Linked Data sources in order to select candidates for each author mention, then performs fusion of DBpedia and BnF individuals into a single graph, and finally decides the best referent using the notion of graph centrality. Some experiments are conducted in order to identify the best size of disambiguation context and to assess the influence on centrality of specific relations represented as edges. This work will help scholars to trace the impact of authors’ ideas across different works and time periods.']",https://hal.science/hal-01203784,"['0.shs', '1.shs.langue', '0.info', '1.info.info-cl']"
['Jean-Gabriel Ganascia'],,,"The New Ethical Trilemma: Security, Privacy and Transparency",hal-00610525,2011,10.1016/j.crhy.2011.07.002,"['Ethics', 'Nano-Panopticon', 'Nanotechnology', 'Panopticon', 'Privacy', 'Security', 'Sousveillance', 'Surveillance', 'Transparency']","['Numerous ethical and societal issues are related to the development of nanotechnology. Among them, the risk for privacy has long been discussed. Some people say that technology is neutral and that it does not really change the nature of problems, which are mainly political, while others state that its contemporary developments considerably amplify them; there are even persons who assert that it will make privacy protection obsolete. This paper discusses those different positions by making reference to the classical Panopticon that is an architecture for surveillance, which characterizes the total absence of privacy. It envisages the possible evolutions of the Panopticon due to the development of nanotechnologies. It shows that the influence of nanotechnology on privacy concerns cannot be dissociated from the influence of computers and biotechnologies, i.e. from what is currently called the NBIC convergence. Lastly, it concludes on the new ethical trade-off that has to be made between three contradictory requirements that are security, transparency and privacy.']",https://hal.science/hal-00610525,"['0.shs', '1.shs.phil']"
"['Milan Bhan', 'Jean-Noël Vittaut', 'Nicolas Chesneau', 'Marie-Jeanne Lesot']",,,TIGTEC : Token Importance Guided TExt Counterfactuals,hal-04311749,2023,10.1007/978-3-031-43418-1_30,"['XAI', 'NLP', 'Counterfactual examples', 'Local Feature Importance', 'Attention']","['Counterfactual examples explain a prediction by highlighting changes in an instance that flip the outcome of a classifier. This paper proposes TIGTEC, an efficient and modular method for generating sparse, plausible and diverse counterfactual explanations for textual data. TIGTEC is a text editing heuristic that targets and modifies words with high contribution using local feature importance. A new attention-based local feature importance is proposed. Counterfactual candidates are generated and assessed with a cost function integrating a semantic distance, while the solution space is efficiently explored in a beam search fashion. The conducted experiments show the relevance of TIGTEC in terms of success rate, sparsity, diversity and plausibility. This method can be used in both modelspecific or model-agnostic way, which makes it very convenient for generating counterfactual explanations.']",https://hal.science/hal-04311749,"['0.info', '1.info.info-ai']"
"['Milan Bhan', 'Jean-Noël Vittaut', 'Nicolas Chesneau', 'Marie-Jeanne Lesot']","[1317469, 17892, 1317470, 14208]","['jean-noel-vittaut', 'marie-jeanne-lesot']",Enhancing textual counterfactual explanation intelligibility through Counterfactual Feature Importance,hal-04311780,2023,10.18653/v1/2023.trustnlp-1.19,"['Counterfactual examples', 'Natural language processing', 'XAI', 'Local feature importance', 'Counterfactual feature importance']","['Textual counterfactual examples explain a prediction by modifying the tokens of an initial instance in order to flip the outcome of a classifier. Even under sparsity constraint, counterfactual generation can lead to numerous changes from the initial text, making the explanation hard to understand. We propose Counterfactual Feature Importance, a method to make non-sparse counterfactual explanations more intelligible. Counterfactual Feature Importance assesses token change importance between an instance to explain and its counterfactual example. We develop two ways of computing Counterfactual Feature Importance, respectively based on classifier gradient computation and counterfactual generator loss evolution during counterfactual search. Then we design a global version of Counterfactual Feature Importance, providing rich information about semantic fields globally impacting classifier predictions. Counterfactual Feature Importance enables to focus on impacting parts of counterfactual explanations, making counterfactual explanations involving numerous changes more understandable.']",https://hal.science/hal-04311780,"['0.info', '1.info.info-ai']"
"['Fanny Henriet', 'Stéphane Hallegatte', 'Lionel Tabourier']",[743086],['fanny-henriet'],Firm-network characteristics and economic robustness to natural disasters,hal-00716554,2012,10.1016/j.jedc.2011.10.001,"['Natural disasters', 'Economic impacts', 'Economic network']","['This article proposes a theoretical framework to investigate economic robustness to exogenous shocks such as natural disasters. It is based on a dynamic model that represents a regional economy as a network of production units through the disaggregation of sector-scale input-output tables. Results suggest that disaster-related output losses depend on direct losses heterogeneity and on the economic network structure. Two aggregate indexes - concentration and clustering - appear as important drivers of economic robustness, offering opportunities for robustness-enhancing strategies. Modern industrial organization seems to reduce short-term robustness in a trade-off against higher efficiency in normal times. (C) 2011 Published by Elsevier B.V.']",https://enpc.hal.science/hal-00716554,"['0.sde', '0.shs', '1.shs.eco']"
"['Lionel Tabourier', 'Anne-Sophie Libert', 'Renaud Lambiotte']",[965989],,Predicting links in ego-networks using temporal information,hal-01253822,2016,10.1140/epjds/s13688-015-0062-0,"['Link prediction', 'Ego networks', 'Social networks', 'Learning-to-rank']","[""Link prediction appears as a central problem of network science, as it calls for unfolding the mechanisms that govern the micro-dynamics of the network. In this work, we are interested in ego-networks, that is the mere information of interactions of a node to its neighbors, in the context of social relationships. As the structural information is very poor, we rely on another source of information to predict links among egos' neighbors: the timing of interactions. We define several features to capture different kinds of temporal information and apply machine learning methods to combine these various features and improve the quality of the prediction. We demonstrate the efficiency of this temporal approach on a cellphone interaction dataset, pointing out features which prove themselves to perform well in this context, in particular the temporal profile of interactions and elapsed time between contacts.""]",https://hal.sorbonne-universite.fr/hal-01253822,['0.info']
"['Keun-Woo Lim', 'Stefano Secci', 'Lionel Tabourier', 'Badis Tebbani']","[986271, 5055, 986272]",['stefano-secci'],Characterizing and predicting mobile application usage,hal-01345824,2016,10.1016/j.comcom.2016.04.026,"['Mobile applications', 'Data consumption behavior', 'Clustering', 'Data analytics']","['In this paper, we propose data clustering techniques to predict temporal characteristics of data consumption behavior of different mobile applications via wireless communications. While most of the research on mobile data analytics focuses on the analysis of call data records and mobility traces, our analysis concentrates on mobile application usages, to characterize them and predict their behavior. We exploit mobile application usage logs provided by a Wi-Fi local area network service provider to characterize temporal behavior of mobile applications. More specifically, we generate daily profiles of "" what "" types of mobile applications users access and "" when "" users access them. From these profiles, we create usage classes of mobile applications via aggregation of similar profiles depending on data consumption rate, using three clustering techniques that we compare. Furthermore, we show that we can utilize these classes to analyze and predict future usages of each mobile application through progressive comparison using distance and similarity comparison techniques. Finally, we also detect and exploit outlying behavior in application usage profiles and discuss methods to efficiently predict them.']",https://hal.science/hal-01345824,"['0.info', '1.info.info-ni', '0.info', '1.info.info-si']"
"['Bivas Mitra', 'Lionel Tabourier', 'Camille Roth']",[1042429],['camille-roth'],Intrinsically Dynamic Network Communities,halshs-00778666,2012,10.1016/j.comnet.2011.10.024,"['Community detection', 'Dynamic networks', 'Citation networks', 'Community quality metrics']","[""Community finding algorithms for networks have recently been extended to dynamic data. Most of these recent methods aim at exhibiting community partitions from successive graph snapshots and thereafter connecting or smoothing these partitions using clever time-dependent features and sampling techniques. These approaches are nonetheless achieving longitudinal rather than dynamic community detection. We assume that communities are fundamentally defined by the repetition of interactions among a set of nodes over time. According to this definition, analyzing the data by considering successive snapshots induces a significant loss of information: we suggest that it blurs essentially dynamic phenomena--such as communities based on repeated inter-temporal interactions, nodes switching from a community to another across time, or the possibility that a community survives while its members are being integrally replaced over a longer time period. We propose a formalism which aims at tackling this issue in the context of time-directed datasets (such as citation networks), and present several illustrations of both empirical and synthetic dynamic networks. We eventually introduce intrinsically dynamic metrics to qualify temporal community structure and emphasize their possible role as an estimator of the quality of the community detection--taking into account the fact that various empirical contexts may call for distinct 'community' definitions and detection criteria.""]",https://shs.hal.science/halshs-00778666,"['0.shs', '1.shs.socio', '0.info', '1.info.info-ai', '0.nlin', '1.nlin.nlin-ao', '0.info', '1.info.info-ni']"
"['Aurore Payen', 'Lionel Tabourier', 'Matthieu Latapy']","[1011156, 749042]",['matthieu-latapy'],"Spreading dynamics in a cattle trade network: Size, speed, typical profile and consequences on epidemic control strategies",hal-02165650,2019,10.1371/journal.pone.0217972,"['Centrality', 'Livestock', 'Network reciprocity', 'Network analysis', 'Directed graphs', 'Cattle', 'Veterinary diseases', 'Veterinary epidemiology']","['Infections can spread among livestock notably because infected animals can be brought to uncontaminated holdings, therefore exposing a new group of susceptible animals to the disease. As a consequence, the structure and dynamics of animal trade networks is a major focus of interest to control zoonosis. We investigate the impact of the chronology of animal trades on the dynamics of the process. Precisely, in the context of a basic SI model spreading , we measure on the French database of bovine transfers to what extent a snapshot-based analysis of the cattle trade networks overestimates the epidemic risks. We bring into light that an analysis taking into account the chronology of interactions would give a much more accurate assessment of both the size and speed of the process. For this purpose, we model data as a temporal network that we analyze using the link stream formalism in order to mix structural and temporal aspects. We also show that in this dataset, a basic SI spreading comes down in most cases to a simple two-phases scenario: a waiting period, with few contacts and low activity, followed by a linear growth of the number of infected holdings. Using this portrait of the spreading process, we identify efficient strategies to control a potential outbreak, based on the identification of specific elements of the link stream which have a higher probability to be involved in a spreading process.']",https://hal.sorbonne-universite.fr/hal-02165650,"['0.info', '1.info.info-mo', '0.sdv', '1.sdv.spee', '0.sdv', '1.sdv.ba', '2.sdv.ba.mvsa']"
"['Pedro Ramaciotti Morales', 'Robin Lamarche-Perrin', ""Raphaël Fournier-S'Niehotta"", 'Rémy Poulain', 'Lionel Tabourier', 'Fabien Tarissan']","[1125978, 4326, 5068]","['pedro-ramaciottimorales', 'raphaelfournier', 'fabien-tarissan']",Measuring diversity in heterogeneous information networks,hal-03608575,2021,10.1016/j.tcs.2021.01.013,"['Algorithms', 'Diversity', 'Heterogeneous information networks', 'Meta path', 'Axiomatic theories', 'Information theory']","['Diversity is a concept relevant to numerous domains of research varying from ecology, to information theory, and to economics, to cite a few. It is a notion that is steadily gaining attention in the information retrieval, network analysis, and artificial neural networks communities. While the use of diversity measures in network-structured data counts a growing number of applications, no clear and comprehensive description is available for the different ways in which diversities can be measured. In this article, we develop a formal framework for the application of a large family of diversity measures to heterogeneous information networks (HINs), a flexible, widely-used network data formalism. This extends the application of diversity measures, from systems of classifications and apportionments, to more complex relations that can be better modeled by networks. In doing so, we not only provide an effective organization of multiple practices from different domains, but also unearth new observables in systems modeled by heterogeneous information networks. We illustrate the pertinence of our approach by developing different applications related to various domains concerned by both diversity and networks. In particular, we illustrate the usefulness of these new proposed observables in the domains of recommender systems and social media studies, among other fields.']",https://hal.science/hal-03608575,"['0.info', '0.info', '1.info.info-it']"
"['Lionel Tabourier', 'Daniel F Bernardes', 'Anne-Sophie Libert', 'Renaud Lambiotte']",[1353387],,RankMerging: A supervised learning-to-rank framework to predict links in large social networks,hal-04462323,2019,10.1007/s10994-019-05792-4,"['Link prediction', 'Supervised learning', 'Learning to rank', 'Social networks', 'Complex networks', 'Large graphs']","['Uncovering unknown or missing links in social networks is a difficult task because of their sparsity and because links may represent different types of relationships, characterized by different structural patterns. In this paper, we define a simple yet efficient supervised learning-to-rank framework, called RankMerging, which aims at combining information provided by various unsupervised rankings. We illustrate our method on three different kinds of social networks and show that it substantially improves the performances of unsupervised methods of ranking as well as standard supervised combination strategies. We also describe various properties of RankMerging, such as its computational complexity, its robustness to feature selection and parameter estimation and discuss its area of relevance: the prediction of an adjustable number of links on large networks.']",https://hal.science/hal-04462323,"['0.info', '0.info', '1.info.info-ai', '0.info', '1.info.info-si']"
"['Laure Millet', 'Maria Potop-Butucaru', 'Nathalie Sznajder', 'Sébastien Tixeuil']","[7263, 841868, 5709, 9380]","['lmillet', 'sznajder-nathalie', 'tixeuil']",On the Synthesis of Mobile Robots Algorithms: the Case of Ring Gathering,hal-01016832,2014,10.1007/978-3-319-11764-5_17,"['Distributed Algorithms', 'Mobile robots', 'Ring Gathering', 'Algorithm synthesis']","['Recent advances in Distributed Computing highlight models and algorithms for autonomous swarms of mobile robots that self-organize and cooperate to solve global objectives. The overwhelming majority of works so far considers handmade algorithms and correctness proofs. This paper is the first to propose a formal framework to automatically design distributed algorithms that are dedicated to autonomous mobile robots evolving in a discrete space. As a case study, we consider the problem of gathering all robots at a particular location, not known beforehand. Our contribution is threefold. First, we propose an encoding of the gathering problem as a reachability game. Then, we automatically generate an optimal distributed algorithm for three robots evolving on a fixed size uniform ring. Finally, we prove by induction that the generated algorithm is also correct for any ring size except when an impossibility result holds (that is, when the number of robots divides the ring size).']",https://hal.science/hal-01016832v2,"['0.info', '1.info.info-mo', '0.info', '1.info.info-fl', '0.info', '1.info.info-ds']"
"['Siamak Solat', 'Maria Potop-Butucaru']","[998125, 858256]",,Brief Announcement: ZeroBlock: Timestamp-Free Prevention of Block-Withholding Attack in Bitcoin,hal-01310088,2017,10.1007/978-3-319-69084-1_25,"['Block-withholding', 'ZeroBlock', 'Selfish mining', 'Electronic Currency', 'Bitcoin', 'Cryptocurrency']","['Bitcoin was recently introduced as a peer-to-peer electronic currency in order to facilitate transactions outside the traditional financial system. The core of Bitcoin, the Blockchain, is the history of the transactions in the system maintained by all miners as a distributed shared register. New blocks in the Blockchain contain the last transactions in the system and are added by miners after a block mining process that consists in solving a resource consuming proof-of-work (cryptographic puzzle). The reward is a motivation for mining process but also could be an incentive for attacks such as selfish mining. In this paper we propose a solution for one of the major problems in Bitcoin : selfish mining or block-withholding attack. This attack is conducted by adversarial or selfish miners in order to either earn undue rewards or waste the computational power of honest miners. Contrary to recent solutions, our solution, ZeroBlock, prevents block-withholding using a technique free of timestamp that can be forged. Moreover, we show that our solution is compliant with nodes churn.']",https://hal.science/hal-01310088v3,"['0.info', '1.info.info-cr']"
"['Noga Alon', 'Hagit Attiya', 'Shlomi Dolev', 'Swan Dubois', 'Maria Potop-Butucaru', 'Sébastien Tixeuil']","[858263, 859941, 841868, 9380]",['tixeuil'],Practically stabilizing SWMR atomic memory in message passing systems,hal-01123697,2015,10.1016/j.jcss.2014.11.014,"['Self-stabilization', 'Fault-tolerance']","['A fault-tolerant and practically stabilizing simulation of an atomic register is presented. The simulation works in asynchronous message-passing systems, and allows a minority of processes to crash. The simulation stabilizes in a practically stabilizing manner, by reaching a long execution in which it runs correctly. A key element in the simulation is a new combinatorial construction of a bounded labeling scheme accommodating arbitrary labels, including those not generated by the scheme itself.']",https://hal.sorbonne-universite.fr/hal-01123697,"['0.info', '1.info.info-dc', '0.info', '1.info.info-cc', '0.info', '1.info.info-ds', '0.info', '1.info.info-ni']"
"['Léonard Lys', 'Arthur Micoulet', 'Maria Potop-Butucaru']","[1057805, 841868]",,R-SWAP: Relay Based Atomic Cross-Chain Swap Protocol,hal-04035440,2021,10.1007/978-3-030-93043-1_2,"['Blockchain', 'Atomic swap', 'Cross-chain', 'Relays']","['In this paper, we consider the problem of cross-chain transactions where parties that do not trust each other safely exchange digital assets across blockchains. Open blockchains models are decentralized ledgers that keep records of transactions. They are comparable with distributed account books. While they have proven their potential as a store of value, exchanging assets across several blockchains remains a challenge. Our paper proposes a new protocol, R-SWAP, for cross-chain swaps that outperforms existing solutions. Our protocol is built on top of two abstractions: relays and adapters that we formalize for the first time in this paper. Furthermore, we prove the correctness of R-SWAP and analytically evaluate its performances, in terms of cost and latency. Moreover, we evaluate the performances of R-SWAP in two case studies showing the generality of our approach: atomic swaps between Ethereum and Bitcoin (two popular permissionless blockchains) and atomic swaps between Ethereum and Tendermint (one permissionless and one permissioned blockchain).']",https://cnrs.hal.science/hal-04035440,['0.info']
"['Wafa Badreddine', 'Nesrine Khernane', 'Maria Potop-Butucaru', 'Claude Chaudet']","[17910, 975912, 8015]","['wafa-badreddine', 'claude-chaudet']",Convergecast in Wireless Body Area Networks,hal-01301773,2017,10.1016/j.adhoc.2017.08.008,"['WBAN', 'Convergecast', 'Mobility model', 'Omnet++']","['Wireless Body Area Networks (WBAN) is a recent challenging area in the domain of health monitoring. There are several concerns in this area ranging from energy efficient communication to designing delays efficient protocols that support nodes dynamicity induced by human body mobility. This paper focuses on the convergecast or data gathering protocols in WBAN. Our contribution is twofold. First, we extensively analyze the impact of postural body mobility on various classes of multi-hop convergecast strategies. Our study does not limit itself to the existing state-of-the-art in WBAN, we adapted to WBAN settings strategies from the areas of Delay Tolerant Networks (DTN) and Wireless Sensor Networks (WSN). We evaluate all these strategies via the OMNeT++ simulator that we enriched with realistic human body mobility models and channel models issued from the recent research on biomedical and health informatics. Our simulations show that existing results in DTN and WSN cannot be just extrapolated to WBAN without a deeper investigation. That is, existing convergecast strategies for DTN or WSN do not perform well with postural body movements because of the topological partitioning provoked by important link attenuations due to signal obstructions by clothes or body itself. Our extensive simulations give valuable insights and directions for designing efficient convergecast adaptive strategies in WBAN. Second, we propose and evaluate two novel classes of convergecast strategies. The first class integrates in the routing information the link attenuation while the second one exploits multi (pre-established) paths to the sink node. We stress all the strategies under a realistic channel model and present an extensive analysis in terms of resiliency to mobility, end-to-end delay and energy consumption for seven different mobility patterns. We advocate that, so far, there is no strategy for convergecast in WBAN that optimizes all the above criteria for all possible mobility patterns. However, each considered strategy can be a good candidate for a specific combination of parameters with a specific mobility pattern.']",https://hal.science/hal-01301773,"['0.info', '1.info.info-pf']"
"['Matthieu Latapy', 'Tiphaine Viard', 'Clémence Magnien']","[749042, 4259, 9355]","['matthieu-latapy', 'tiphaine-viard', 'clemence-magnien']",Stream Graphs and Link Streams for the Modeling of Interactions over Time,hal-01665084,2018,10.1007/s13278-018-0537-7,"['Temporal networks', 'Link streams', 'Stream graphs', 'Dynamic graphs', 'Time-varying graphs', 'Dynamic networks', 'Longitudinal networks', 'Interactions', 'Time', 'Graphs', 'Networks']","['Graph theory provides a language for studying the structure of relations, and it is often used to study interactions over time too. However, it poorly captures the both temporal and structural nature of interactions, that calls for a dedicated formalism. In this paper, we generalize graph concepts in order to cope with both aspects in a consistent way. We start with elementary concepts like density, clusters, or paths, and derive from them more advanced concepts like cliques, degrees, clustering coefficients, or connected components. We obtain a language to directly deal with interactions over time, similar to the language provided by graphs to deal with relations. This formalism is self-consistent: usual relations between different concepts are preserved. It is also consistent with graph theory: graph concepts are special cases of the ones we introduce. This makes it easy to generalize higher-level objects such as quotient graphs, line graphs, k-cores, and centralities. This paper also considers discrete versus continuous time assumptions, instantaneous links, and extensions to more complex cases.']",https://hal.science/hal-01665084,"['0.info', '0.info', '1.info.info-ni', '0.info', '1.info.info-si']"
"['Jean-Loup Guillaume', 'Matthieu Latapy']","[7655, 749042]","['jeanloupguillaume', 'matthieu-latapy']",Bipartite Structure of All Complex Networks,hal-00016855,2004,10.1016/j.ipl.2004.03.007,"['Graphs', 'Interconnection networks', 'Modelling', 'Bipartite graphs']","['The analysis and modelling of various complex networks has received much attention in the last few years. Some such networks display a natural bipartite structure: two kinds of nodes coexist with links only between nodes of different kinds. This bipartite structure has not been deeply studied until now, mainly because it appeared to be specific to only a few complex networks. However, we show here that all complex networks can be viewed as bipartite structures sharing some important statistics, like degree distributions. The basic properties of complex networks can be viewed as consequences of this underlying bipartite structure. This leads us to propose the first simple and intuitive model for complex networks which captures the main properties met in practice.']",https://hal.science/hal-00016855,"['0.info', '1.info.info-ni']"
"['Denis Cornaz', 'Lucie Galand', 'Olivier Spanjaard']","[743157, 14601]","['lucie-galand', 'olivier-spanjaard']",Bounded Single-Peaked Width and Proportional Representation,hal-01497136,2012,10.3233/978-1-61499-098-7-270,"['Election problem', 'Multi-winner', 'Proportional representation', 'Single-peaked']","['This paper is devoted to the proportional representation (PR) problem when the preferences are clustered single-peaked. PR is a “multi-winner” election problem, that we study in Chamberlin and Courant’s scheme [6]. We deﬁne clustered single-peakedness as a form of single-peakedness with respect to clusters of candidates, i.e. subsets of candidates that are consecutive (in arbitrary order) in the preferences of all voters. We show that the PR problem becomes polynomial when the size of the largest cluster of candidates (width) is bounded. Furthermore, we establish the polynomiality of determining the single-peaked width of a preference proﬁle (minimum width for a partition of candidates into clusters compatible with clustered single-peakedness) when the preferences are narcissistic (i.e., every candidate is the most preferred one for some voter).']",https://hal.science/hal-01497136,['0.info']
"['Bruno Escoffier', 'Olivier Spanjaard', 'Magdaléna Tydrichová']",[14601],['olivier-spanjaard'],"Euclidean preferences in the plane under $\ell_1$, $\ell_2$ and $\ell_\infty$ norms",hal-04561794,2024,10.1007/s00355-024-01525-2,"['Metric Geometry mathMG', 'Combinatorics mathCO', 'FOS Mathematics']","['We present various results about Euclidean preferences in the plane under $\\ell_1$, $\\ell_2$ and $\\ell_{\\infty}$ norms. When there are four candidates, we show that the maximal size (in terms of the number of pairwise distinct preferences) of Euclidean preference profiles in the plane under norm $\\ell_1$ or $\\ell_{\\infty}$ is 19. Whatever the number of candidates, we prove that at most four distinct candidates can be ranked in last position of a two-dimensional Euclidean preference profile under norm $\\ell_1$ or $\\ell_\\infty$, which generalizes the case of one-dimensional Euclidean preferences (for which it is well known that at most two candidates can be ranked last). We generalize this result to $2^d$ (resp. $2d$) for $\\ell_1$ (resp. $\\ell_\\infty$) for $d$-dimensional Euclidean preferences. We also establish that the maximal size of a two-dimensional Euclidean preference profile on $m$ candidates under norm $\\ell_1$ is in $Θ(m^4)$, i.e., the same order of magnitude as under norm $\\ell_2$. Finally, we provide a new proof that two-dimensional Euclidean preference profiles under norm $\\ell_2$ for four candidates can be characterized by three voter-maximal two-dimensional Euclidean profiles. This proof is a simpler alternative to that proposed by Kamiya et al. in Ranking patterns of unfolding models of codimension one, Advances in Applied Mathematics 47(2):379-400.']",https://hal.science/hal-04561794,"['0.info', '1.info.info-dm']"
"['Nawal Benabbou', 'Patrice Perny', 'Paolo Viappiani']","[5542, 9264, 9572]","['nawal-benabbou', 'patrice-perny', 'paolo-viappiani']","Incremental elicitation of choquet capacities for multicriteria choice, ranking and sorting problems",hal-01480147,2017,10.1016/j.artint.2017.02.001,"['Multicriteria decision making', 'Choquet integral', 'Capacity', 'Incremental elicitation', 'Minimax regret', 'Choice', 'Ranking', 'Sorting']","['This paper proposes incremental preference elicitation methods for multicri-teria decision making with a Choquet integral. The Choquet integral is an evaluation function that performs a weighted aggregation of criterion values using a capacity function assigning a weight to any coalition of criteria, thus enabling positive and/or negative interactions among them and covering an important range of possible decision behaviors. However, the specification of the capacity involves many parameters which raises challenging questions, both in terms of elicitation burden and guarantee on the quality of the final recommendation. In this paper, we investigate the incremental elicitation of the capacity through a sequence of preference queries (questions) selected one-by-one using a minimax regret strategy so as to progressively reduce the set of possible capacities until the regret (the worst-case "" loss "" due to reasoning with only partially specified capacities) is low enough. We propose a new approach designed to efficiently compute minimax regret for the Choquet model and we show how this approach can be used in different settings: 1) the problem of recommending a single alternative, 2) the problem of ranking alternatives from best to worst, and 3) sorting several alternatives into ordered categories. Numerical experiments are provided to demonstrate the practical efficiency of our approach for each of these situations.']",https://hal.sorbonne-universite.fr/hal-01480147v3,['0.info']
"['Christophe Gonzales', 'Patrice Perny']","[10817, 9264]","['christophe-gonzales', 'patrice-perny']","Multicriteria Decision Making, Décision Multicritère",hal-02860326,2020,10.1007/978-3-030-06164-7_16,"['Preference Aggregation', 'Multicriteria decision aid MCDA']","['This chapter aims to present the main models used for preference aggregation and decision support in a unified framework.After recalling the definition of a multicriteria decision making problem, we distinguish two approaches for preference aggregation:the compare then aggregate approach (denoted CA) and the aggregate then compare approach (denoted AC). We first present some procedures allowing the construction of an overall preference relation (e.g., a dominance or concordance relation) from several binary relations. Then we consider the AC approach and present some scalarizing functions allowing the definition of an overall score from partial numerical evaluations. In particular we review the min, Tchebycheff, OWA, WOWA aggregators and Choquet and Sugeno integrals.']",https://hal.science/hal-02860326,['0.info']
"['Didier Dubois', 'Hélène Fargier', 'Henri Prade', 'Patrice Perny']","[743301, 734843, 743299, 9264]","['didier-dubois', 'helene-fargier', 'henri-prade', 'patrice-perny']",Qualitative decision theory: from Savage's axioms to nonmonotonic reasoning,hal-01185798,2002,10.1145/581771.581772,"['Decision theory', 'Preference relations', 'Comparative uncertainty', 'Possibility theory', 'Nonmonotonic !reasoning']","[""This paper investigates to what extent a purely symbolic approach to decision making under uncertainty is possible, in the scope of artificial intelligence. Contrary to classical approaches to decision theory, we try to rank acts without resorting to any numerical representation of utility or uncertainty, and without using any scale on which both uncertainty and preference could be mapped. Our approach is a variant of Savage's where the setting is finite, and the strict preference on acts is a partial order. It is shown that although many axioms of Savage theory are preserved and despite the intuitive appeal of the ordinal method for constructing a preference over acts, the approach is inconsistent with a probabilistic representation of uncertainty. The latter leads to the kind of paradoxes encountered in the theory of voting. It is shown that the assumption of ordinal invariance enforces a qualitative decision procedure that presupposes a comparative possibility representation of uncertainty, originally due to Lewis, and usual in nonmonotonic reasoning. Our axiomatic investigation thus provides decision-theoretic foundations to the preferential inference of Lehmann and colleagues. However, the obtained decision rules are sometimes either not very decisive or may lead to overconfident decisions, although their basic principles look sound. This paper points out some limitations of purely ordinal approaches to Savage-like decision making under uncertainty, in perfect analogy with similar difficulties in voting theory.""]",https://hal.science/hal-01185798,['0.info']
"['George Tsatsaronis', 'Georgios Balikas', 'Prodromos Malakasiotis', 'Ioannis Partalas', 'Matthias Zschunke', 'Michael R Alvers', 'Dirk Weissenborn', 'Anastasia Krithara', 'Sergios Petridis', 'Dimitris Polychronopoulos', 'Yannis Almirantis', 'John Pavlopoulos', 'Nicolas Baskiotis', 'Patrick Gallinari', 'Thierry Artières', 'Axel-Cyrille Ngonga Ngomo', 'Norman Heino', 'Eric Gaussier', 'Liliana Barrio-Alvers', 'Michael Schroeder', 'Ion Androutsopoulos', 'Georgios Paliouras']","[966689, 13841, 751615, 5016, 182833, 936429]","['baskiotisn', 'patrick-gallinari', 'thierry-artieres', 'eric-gaussier']",An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition,hal-01156600,2015,10.1186/s12859-015-0564-6,"['Hierarchical Text Classification', 'BIOASQ Competition', 'Question answering', 'Information retrieval', 'Passage retrieval', 'ClassY', 'Semantic indexing', 'Multi-document text summarization']","['Background : This article provides an overview of the first BIOASQ challenge, a competition on large-scale biomedical semantic indexing and question answering (QA), which took place between March and September 2013. BIOASQ assesses the ability of systems to semantically index very large numbers of biomedical scientific articles, and to return concise and user-understandable answers to given natural language questions by combining information from biomedical articles and ontologies. Results : The 2013 BIOASQ competition comprised two tasks, Task 1a and Task 1b. In Task 1a participants were asked to automatically annotate new PUBMED documents with MESH headings. Twelve teams participated in Task 1a, with a total of 46 system runs submitted, and one of the teams performing consistently better than the MTI indexer used by NLM to suggest MESH headings to curators. Task 1b used benchmark datasets containing 29 development and 282 test English questions, along with gold standard (reference) answers, prepared by a team of biomedical experts from around Europe and participants had to automatically produce answers. Three teams participated in Task 1b, with 11 system runs. The BIOASQ infrastructure, including benchmark datasets, evaluation mechanisms, and the results of the participants and baseline methods, is publicly available. Conclusions : A publicly available evaluation infrastructure for biomedical semantic indexing and QA has been developed, which includes benchmark datasets, and can be used to evaluate systems that: assign MESH headings to published articles or to English questions; retrieve relevant RDF triples from ontologies, relevant articles and snippets from PUBMED Central; produce “exact” and paragraph-sized “ideal” answers (summaries). The results of the systems that participated in the 2013 BIOASQ competition are promising. In Task 1a one of the systems performed consistently better from the NLM’s MTI indexer. In Task 1b the systems received high scores in the manual evaluation of the “ideal” answers; hence, they produced high quality summaries as answers. Overall, BIOASQ helped obtain a unified view of how techniques from text classification, semantic indexing, document and passage retrieval, question answering, and text summarization can be combined to allow biomedical experts to obtain concise, user-understandable answers to questions reflecting their real information needs.']",https://hal.sorbonne-universite.fr/hal-01156600,"['0.info', '1.info.info-bi']"
"['Thibault Formal', 'Benjamin Piwowarski', 'Stéphane Clinchant']","[1105732, 9362, 1105733]",['benjamin-piwowarski'],SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking,hal-03290774,2021,10.1145/3404835.3463098,"['Neural networks', 'Indexing', 'Sparse representations', 'Regularization']","['In neural Information Retrieval, ongoing research is directed towards improving the first retriever in ranking pipelines. Learning dense embeddings to conduct retrieval using efficient approximate nearest neighbors methods has proven to work well. Meanwhile, there has been a growing interest in learning sparse representations for documents and queries, that could inherit from the desirable properties of bag-of-words models such as the exact matching of terms and the efficiency of inverted indexes. In this work, we present a new first-stage ranker based on explicit sparsity regularization and a log-saturation effect on term weights, leading to highly sparse representations and competitive results with respect to state-ofthe-art dense and sparse methods. Our approach is simple, trained end-to-end in a single stage. We also explore the trade-off between effectiveness and efficiency, by controlling the contribution of the sparsity regularization. CCS CONCEPTS • Information systems → Language models.']",https://hal.sorbonne-universite.fr/hal-03290774,['0.info']
"['Pierre Courtieu', 'Lionel Rieg', 'Sébastien Tixeuil', 'Xavier Urbain']","[6578, 21843, 9380, 7387]","['pierre-courtieu', 'lionel-rieg', 'tixeuil', 'xavier-urbain']","Impossibility of gathering, a certification",hal-01122869,2015,10.1016/j.ipl.2014.11.001,"['Theory of computation', 'Distributed computing', 'Computational geometry', 'Analysis of algorithms', 'Automatic theorem proving']","['Recent advances in Distributed Computing highlight models and algorithms for autonomous swarms of mobile robots that self-organise and cooperate to solve global objectives. The overwhelming majority of works so far considers handmade algorithms and proofs of correctness. This paper builds upon a previously proposed formal framework to certify the correctness of impossibility results regarding distributed algorithms that are dedicated to autonomous mobile robots evolving in a continuous space. As a case study, we consider the problem of gathering all robots at a particular location, not known beforehand. A fundamental (but not yet formally certified) result, due to Suzuki and Yamashita, states that this simple task is impossible for two robots executing deterministic code and initially located at distinct positions. Not only do we obtain a certified proof of the original impossibility result, we also get the more general impossibility of gathering with an even number of robots, when any two robots are possibly initially at the same exact location.']",https://hal.sorbonne-universite.fr/hal-01122869,['0.spi']
"['Stéphane Devismes', 'Franck Petit', 'Sébastien Tixeuil']","[738998, 778299, 9380]","['stephane-devismes', 'tixeuil']",Optimal probabilistic ring exploration by semi-synchronous oblivious robots,hal-00930045,2013,10.1016/j.tcs.2013.05.031,"['Probabilistic algorithm', 'Ring exploration', 'Obliviousness', 'Mobile robots']","['We consider a team of k identical, oblivious, and semi-synchronous mobile robots that are able to sense (i.e., view) their environment, yet are unable to communicate, and evolve on a constrained path. Previous results in this weak scenario show that initial symmetry yields high lower bounds when problems are to be solved by deterministic robots. In this paper, we initiate research on probabilistic bounds and solutions in this context, and focus on the exploration problem of anonymous unoriented rings of any size n. It is known that View the MathML source deterministic robots are necessary and sufficient to solve the problem, provided that k and n are coprime. By contrast, we show that four identical probabilistic robots are necessary and sufficient to solve the same problem, also removing the coprime constraint. Our positive results are constructive.']",https://hal.sorbonne-universite.fr/hal-00930045,"['0.info', '1.info.info-ds', '0.info', '1.info.info-dc', '0.info', '1.info.info-mc', '0.info', '1.info.info-ni', '0.info', '1.info.info-rb']"
"['Quentin Bramas', 'Anissa Lamani', 'Sébastien Tixeuil']",,,Stand Up Indulgent Gathering,hal-03975261,2023,10.1016/j.tcs.2022.10.015,"['Mobile robots', 'Gathering', 'Fault-tolerance']","['We consider a swarm of mobile robots evolving in a bidimensional Euclidean space. We study a variant of the crash-tolerant gathering problem: if no robot crashes, robots have to meet at the same arbitrary location, not known beforehand, in finite time; if one or several robots crash at the same location, the remaining correct robots gather at the crash location to rescue them. Motivated by impossibility results in the semi-synchronous setting, we present the first solution to the problem for the fully synchronous setting that operates in the vanilla Look-Compute-Move model with no additional hypotheses: robots are oblivious, disoriented, have no multiplicity detection capacity, and may start from arbitrary positions (including those with multiplicity points). We furthermore show that robots gather in a time that is proportional to the initial maximum distance between robots.']",https://hal.science/hal-03975261,"['0.info', '1.info.info-dc', '0.info', '1.info.info-ma']"
"['Xavier Défago', 'Adam Heriban', 'Sébastien Tixeuil', 'Koichi Wada']",,,Using model checking to formally verify rendezvous algorithms for robots with lights in Euclidean space,hal-04021057,2023,10.1016/j.robot.2023.104378,"['Autonomous mobile robots', 'Rendezvous', 'Lights', 'Model checking', 'Verification', 'Asynchrony', 'Continuous space']","['The paper details the first successful attempt at using model checking techniques to verify the correctness of distributed algorithms for robots evolving in a continuous environment. The study focuses on the problem of rendezvous of two robots with lights. There exist many different rendezvous algorithms that aim at finding the minimal number of colors needed to solve rendezvous in various synchrony models (e.g., FSYNC, SSYNC, ASYNC). While these rendezvous algorithms are typically very simple, their analysis and proof of correctness tend to be extremely complex, tedious, and error-prone as impossibility results are based on subtle interactions between the activation schedules of the robots. The paper presents a generic verification model that can be concretely expressed in available software model-checkers. In particular, we explain the subtle design decisions that allow to keep the search space finite and tractable, as well as prove several important theorems that support them. As a sanity check, we use the model to verify several known rendezvous algorithms in six different models of synchrony. In each case, we find that the results obtained from the model checker are consistent with the results known in the literature. The model checker outputs a counter-example execution in every case that is known to fail. In the course of developing and proving the validity of the model, we identified several fundamental theorems, including the ability for a well chosen algorithm and ASYNC scheduler to produce an emerging property of memory in a system of oblivious mobile robots, and why it is not a problem when robots executing the gathering algorithms are equipped with lights.']",https://hal.sorbonne-universite.fr/hal-04021057,"['0.info', '0.info', '1.info.info-cg', '0.info', '1.info.info-dc', '0.info', '1.info.info-ds', '0.info', '1.info.info-rb', '0.info', '1.info.info-fl']"
"['Spyros Angelopoulos', 'Fotis Kitsios', 'Petros Kofakis', 'Thanos Papadopoulos']",,,Emerging Barriers in E-Government Implementation,hal-01056585,2010,10.1007/978-3-642-14799-9_19,"['E-government', 'Public sector organisation', 'Digital strategy']","[""This study presents the outcomes of a qualitative case study of implementing e-government Information Systems within the national digital strategy in a governmental organisation, following action research. The results show that although e-government is a socio-technical process and has to accommodate the views of all stakeholders, this is questioned in practice. No matter if e-government needs to be a tool for decentralisation and democratisation, this scope may be rendered futile due to the fundamental role of the political support required to secure future funds for implementation. While focusing on the changes in business processes that have to be considered by governmental institutions to successfully implement e-government, the need for a holistic model, which can embrace the back- and front- office, and be linked to the real citizens' needs, arises.""]",https://inria.hal.science/hal-01056585,"['0.info', '1.info.info-dl']"
"['Spyros Angelopoulos', 'Shahin Kamali']",[738275],['spyros-angelopoulos'],Contract Scheduling with Predictions,hal-04032366,2023,10.1613/jair.1.14117,"['Scheduling', 'Planning', 'Resource-bounded reasoning', 'Uncertainty']","['Contract scheduling is a general technique that allows to design a system with interruptible capabilities, given an algorithm that is not necessarily interruptible. Previous work on this topic has largely assumed that the interruption is a worst-case deadline that is unknown to the scheduler. In this work, we study the setting in which there is a potentially erroneous prediction concerning the interruption. Specifically, we consider the setting in which the prediction describes the time that the interruption occurs, as well as the setting in which the prediction is obtained as a response to a single or multiple binary queries. For both settings, we investigate tradeoffs between the robustness (i.e., the worst-case performance assuming adversarial prediction) and the consistency (i.e, the performance assuming that the prediction is error-free), both from the side of positive and negative results.']",https://hal.science/hal-04032366v3,"['0.info', '1.info.info-ai']"
"['Spyros Angelopoulos', 'Kubra Canhilal', 'Matthew Hawkins']","[738577, 738824]","['s-kubra-canhilal', 'matthew-a-hawkins']",From Groups to Communities: A Resource Mobilization Theory Perspective on the Emergence of Communities,hal-04057372,2023,10.1007/s10796-023-10368-8,"['Community emergence', 'Resource mobilization theory topic modelling', 'Latent Dirichlet allocation', 'Network analysis', 'Community detection', 'Bipartite network']","['Abstract Groups and communities have been key topics in the information systems (IS) research agenda. While communities are assumed to emerge at the intersection of overlapping groups and their practices, prior research has mainly focused on their dynamics and evolution. This has resulted to limited empirical support regarding the emergence of communities. We address that lacuna by tracing the emergence of communities through the prism of resource mobilization theory. In doing so, we make use of a unique longitudinal dataset and incorporate Topic Modelling, Bipartite Network Analysis, and Community Detection. We show that new communities are formed at the intersection of overlapping groups and practices. In addition, we contribute to the IS literature by demonstrating that their emergence occurs due to resource mobilization that gives rise to a shared mindset. We also reveal that multiple resources are incorporated into the practices of an emerging community. By combining large datasets and innovative computational approaches, we help IS theory and practice to move away from traditional ""what"" questions towards the more insightful ""how"" ones. We discuss the theoretical and practical implications of our work and delineate an agenda for future research on the topic.']",https://hal.science/hal-04057372,"['0.shs', '1.shs.gestion']"
"['Guy Bernard', 'Jalel Ben-Othman', 'Luc Bouganim', 'Gérôme Canals', 'Sophie Chabridon', 'Bruno Defude', 'Jean Ferrié', 'Stéphane Gançarski', 'Rachid Guerraoui', 'Pascal Molli', 'Philippe Pucheral', 'Claudia Roncancio', 'Patricia Serrano-Alvarado', 'Patrick Valduriez']","[754300, 18231, 16400, 830484, 13678, 11938, 834400, 13308, 853670, 2355, 22063, 16964, 3952, 172604]","['bernard-guy', 'jbo', 'luc-bouganim', 'sophie-chabridon', 'bruno-defude', 'stephane-gancarski', 'pascal-molli', 'philippe-pucheral', 'claudiaroncancio', 'patricia-serrano-alvarado', 'patrick-valduriez']",Mobile Databases: a Selection of Open Issues and Research Directions,inria-00320861,2004,10.1145/1024694.1024708,"['Mobile databases', 'Bases de données', 'Mobilité', 'Mobile databases']","['This paper reports on the main results of a specific action on mobile databases conducted by CNRS in France from October 2001 to December 2002. The objective of this action was to review the state of progress in mobile databases and identify major research directions for the French database community. Rather than provide a survey of all important issues in mobile databases, this paper gives an outline of the directions in which the action participants are now engaged, namely: copy synchronization in disconnected computing, mobile transactions, database embedded in ultra-light devices, data confidentiality, P2P dissemination models and middleware adaptability.']",https://inria.hal.science/inria-00320861,"['0.info', '1.info.info-db']"
"['Rutian Liu', 'Eric Simon', 'Bernd Amann', 'Stéphane Gançarski']","[953249, 3057, 13308]","['bernd-amann', 'stephane-gancarski']",Discovering and merging related analytic datasets,hal-02459098,2020,10.1016/j.is.2020.101495,"['Schema augmentation', 'Schema complement', 'Data quality', 'SAP HANA']","['The production of analytic datasets is a significant big data trend and has gone well beyond the scope of traditional IT-governed dataset development. Analytic datasets are now created by data scientists and data analysts using big data frameworks and agile data preparation tools. However, despite the profusion of available datasets, it remains quite difficult for a data analyst to start from a dataset at hand and customize it with additional attributes coming from other existing datasets. This article describes a model and algorithms that exploit automatically extracted and user-defined semantic relationships for extending analytic datasets with new atomic or aggregated attribute values. Our framework is implemented as a REST service in the SAP HANA and includes a careful analysis and practical solutions for several complex data quality issues.']",https://hal.science/hal-02459098,"['0.info', '1.info.info-db']"
"['Philippe Dessus', 'Olivier Cosnefroy', 'Vanda Luengo']","[273, 13359]","['pdessus', 'vanda-luengo']",“Keep Your Eyes on ’em all!”: A Mobile Eye-Tracking Analysis of Teachers’ Sensitivity to Students,hal-01362185,2016,10.1007/978-3-319-45153-4_6,"['Mobile eye-tracking', 'Learning analytics', 'Classroom supervision', 'Teacher information taking', 'Classroom observation system', 'Visualization techniques']","[""This study aims at investigating which cues teachers detect and process from their students during instruction. This information capturing process depends on teachers' sensitivity, or awareness, to students' needs, which has been recognized as crucial for classroom management. We recorded the gaze behaviors of two pre-service teachers and two experienced teachers during a whole math lesson in primary classrooms. Thanks to a simple Learning Analyt-ics interface, the data analysis reports, firstly, which were the most often tracked students, in relation with their classroom behavior and performance; secondly, which relationships exist between teachers' attentional frequency distribution and lability, and the overall classroom climate they promote, measured by the Classroom Assessment Scoring System. Results show that participants' gaze patterns are mainly related to their experience. Learning Analytics use cases are eventually presented, enabling researchers or teacher trainers to further explore the eye-tracking data.""]",https://hal.science/hal-01362185,"['0.shs', '1.shs.edu']"
"['Jean-Marie Burkhardt', 'Valentin Corneloup', 'Catherine Garbay', 'Yannick Bourrier', 'Jambon Francis', 'Vanda Luengo', 'Anaïs Job', 'Philippe Cabon', 'Azzeddine Benabbou', 'Domitile Lourdeaux']","[752872, 173310, 172997, 13359, 10031, 8577]","['jean-marie-burkhardt', 'bourrier-yannick', 'francis-jambon', 'vanda-luengo', 'azzeddine-benabbou', 'domitile-lourdeaux']","Simulation and virtual reality-based learning of non-technical skills in driving: critical situations, diagnostic and adaptation",hal-01502327,2016,10.1016/j.ifacol.2016.12.191,"['Driving simulation', 'Human Factors', 'Intelligent Tutoring System', 'Educational Aids', 'Virtual Reality', 'Non-Technical Skills']","['Project MacCoy Critical aims to study and to improve training systems using simulation and virtual environments in medical education (obstetrics) and in driving education (novice drivers during the first months of autonomous driving). The paper describes and justifies the main concepts, the approach and the architecture elaborated from a multidisciplinary viewpoint in order to provide more appropriate and flexible Virtual Environments for Learning/Training to support the acquisition']",https://hal.sorbonne-universite.fr/hal-01502327,"['0.info', '1.info.eiah']"
"['Goel Gagan', 'Sébastien Lalle', 'Vanda Luengo']","[947309, 746698, 13359]","['sebastien-lalle', 'vanda-luengo']",Fuzzy Logic Representation for Student Modelling,hal-00873888,2012,10.1007/978-3-642-30950-2_55,"['Student model', 'Fuzzy inference system', 'Rule-base']","['Our aim is to develop a Fuzzy Logic based student model which removes the arbitrary specification of precise numbers and facilitates the modelling at a higher level of abstraction. Fuzzy Logic involves the use of natural language in the form of If-Then statements to demonstrate knowledge of domain experts and hence generates decisions and facilitates human reasoning based on imprecise information coming from the student-computer interaction. Our case study is in geometry. In this paper, we propose a fuzzy logic representation for student modelling and compare it with the Additive Factor Model (AFM) algorithm implemented on DataShop. Two rule-based fuzzy inference systems have been developed that ultimately predict the degree of error a student makes in the next attempt to the problem. Results indicate the rule-based systems achieve levels of accuracy matching that of the AFM algorithm.']",https://hal.science/hal-00873888,"['0.info', '1.info.eiah', '0.shs', '1.shs.edu']"
"['Sébastien Lallé', 'François Bouchet', 'Mélina Verger', 'Vanda Luengo']",[746698],['sebastien-lalle'],Fairness of MOOC Completion Predictions Across Demographics and Contextual Variables,hal-04631556,2024,10.1007/978-3-031-64302-6_27,"['Fairness', 'MOOCs', 'Machine Learning', 'Demographics']","['While machine learning (ML) has been extensively used in Massive Open Online Courses (MOOCs) to predict whether learners are at risk of dropping-out or failing, very few work has investigated the bias or possible unfairness of the predictions generated by these models. This is however important, because MOOCs typically engage very diverse audiences worldwide, and it is unsure whether the existing ML models will generate fair predictions to all learners. In this paper, we explore the fairness of ML models meant to predict course completion in a MOOC mostly offered in Europe an Africa. To do so, we leverage and compare ABROCA and MADD, two fairness metrics that have been proposed specifically in education. Our results show that some ML models are more likely to generate unfair predictions than others. Even in the fairest models, we found biases in their predictions related to how the learners’ enrolled as well as their country, gender, age and job status. These biases are particularly detrimental to African learners, which is a key finding as they are an understudied population in AI fairness analysis in education.']",https://hal.science/hal-04631556,['0.info']
"['Sébastien Lalle', 'Jack Mostow', 'Vanda Luengo', 'Nathalie Guin']","[746698, 946871, 13359, 4707]","['sebastien-lalle', 'vanda-luengo', 'nathalie-guin']",Comparing Student Models in Different Formalisms by Predicting their Impact on Help Success,hal-00871563,2013,10.1007/978-3-642-39112-5_17,"['Student models', 'Knowledge tracing', 'Classification', 'Help policy']","[""We describe a method to evaluate how student models affect ITS decision quality - their raison d'être. Given logs of randomized tutorial decisions and ensuing student performance, we train a classifier to predict tutor decision outcomes (success or failure) based on situation features, such as student and task. We define a decision policy that selects whichever tutor action the trained classifier predicts in the current situation is likeliest to lead to a successful outcome. The ideal but costly way to evaluate such a policy is to implement it in the tutor and collect new data, which may require months of tutor use by hundreds of students. Instead, we use historical data to simulate a policy by extrapolating its effects from the subset of randomized decisions that happened to follow the policy. We then compare policies based on alternative student models by their simulated impact on the success rate of tutorial decisions. We test the method on data logged by Project LISTEN's Reading Tutor, which chooses randomly which type of help to give on a word. We report the cross-validated accuracy of predictions based on four types of student models, and compare the resulting policies' expected success and coverage. The method provides a utility-relevant metric to compare student models expressed in different formalisms.""]",https://hal.science/hal-00871563,"['0.info', '1.info.eiah', '0.shs', '1.shs.edu']"
"['Pierre Jolivet', 'Frédéric Hecht', 'Frédéric Nataf', ""Christophe Prud'Homme""]","[1089743, 2210, 3257, 1108]","['frederic-hecht', 'frederic-nataf', 'christophe-prudhomme']",Scalable Domain Decomposition Preconditioners for Heterogeneous Elliptic Problems,hal-00939957,2013,10.1145/2503210.2503212,"['Divide and conquer', 'Linear solvers', 'Scalability']","['Domain decomposition methods are, alongside multigrid methods, one of the dominant paradigms in contemporary large-scale partial differential equation simulation. In this paper, a lightweight implementation of a theoretically and numerically scalable preconditioner is presented in the context of overlapping methods. The performance of this work is assessed by numerical simulations executed on thousands of cores, for solving various highly heterogeneous elliptic problems in both 2D and 3D with billions of degrees of freedom. Such problems arise in computational science and engineering, in solid and fluid mechanics. While focusing on overlapping domain decomposition methods might seem too restrictive, it will be shown how this work can be applied to a variety of other methods, such as non-overlapping methods and abstract deflation based preconditioners. It is also presented how multilevel preconditioners can be used to avoid communication during an iterative process such as a Krylov method.']",https://hal.science/hal-00939957,"['0.math', '1.math.math-ap']"
"['Julien Coulet', 'Isabelle Faille', 'Vivette Girault', 'Nicolas Guy', 'Frédéric Nataf']","[1040075, 4256, 1040076, 940493, 3257]","['isabelle-faille', 'frederic-nataf']",A fully coupled scheme using Virtual Element Method and Finite Volume for poroelasticity,hal-01947455,2020,10.1007/s10596-019-09831-w,"['Poroelasticity', 'Polyhedral grids', 'Finite volume methods', 'Geomechanics', 'Virtual element methods', 'Volumes finis', 'Méthode des éléments virtuels', 'Maillages polyédriques', 'Poroélasticité', 'Géomécanique']","['In this paper, we design and study a fully coupled numerical scheme for the poroelasticity problem modelled through Biot’s equations. The classical way to numerically solve this system is to use a finite element method for the mechanical equilibrium equation and a finite volume method for the fluid mass conservation equation. However, to capture specific properties of underground media such as heterogeneities, discontinuities and faults, meshing procedures commonly lead to badly shaped cells for finite element based modelling. Consequently, we investigate the use of the recent virtual element method which appears as a potential discretization method for the mechanical part and could therefore allow the use of a unique mesh for the both mechanical and fluid flow modelling. Starting from a first insight into virtual element method applied to the elastic problem in the context of geomechanical simulations, we apply in addition a finite volume method to take care of the fluid conservation equation. We focus on the first order virtual element method and the two point flux approximation for the finite volume part. A mathematical analysis of this original coupled scheme is provided, including existence and uniqueness results and a priori estimates. The method is then illustrated by some computations on two or three dimensional grids inspired by realistic application cases.']",https://ifp.hal.science/hal-01947455,"['0.math', '1.math.math-na', '0.info', '1.info.info-mo', '0.sdu', '1.sdu.stu', '2.sdu.stu.ag']"
"['Julien Brajard', 'Alberto Carrassi', 'Marc Bocquet', 'Laurent Bertino']","[13461, 778825, 15200, 755894]","['julien-brajard', 'marc-bocquet']",Combining data assimilation and machine learning to emulate a dynamical model from sparse and noisy observations: A case study with the Lorenz 96 model,hal-03147335,2020,10.1016/j.jocs.2020.101171,"['Data assimilation', 'Machine learning', 'Emulator', 'Dynamical model', 'Observations']","['A novel method, based on the combination of data assimilation and machine learning is introduced. The new hybrid approach is designed for a two-fold scope: (i) emulating hidden, possibly chaotic, dynamics and (ii) predicting their future states. The method consists in applying iteratively a data assimilation step, here an ensemble Kalman filter, and a neural network. Data assimilation is used to optimally combine a surrogate model with sparse noisy data. The output analysis is spatially complete and is used as a training set by the neural network to update the surrogate model. The two steps are then repeated iteratively. Numerical experiments have been carried out using the chaotic 40-variables Lorenz 96 model, proving both convergence and statistical skill of the proposed hybrid approach. The surrogate model shows short-term forecast skill up to two Lyapunov times, the retrieval of positive Lyapunov exponents as well as the more energetic frequencies of the power density spectrum. The sensitivity of the method to critical setup parameters is also presented: the forecast skill decreases smoothly with increased observational noise but drops abruptly if less than half of the model domain is observed. The successful synergy between data assimilation and machine learning, proven here with a low-dimensional system, encourages further investigation of such hybrids with more sophisticated dynamics.']",https://hal.science/hal-03147335,"['0.phys', '1.phys.phys', '2.phys.phys.phys-geo-ph']"
"['Vincent Bouget', 'Dominique Béréziat', 'Julien Brajard', 'Anastase Alexandre Charantonis', 'Arthur Filoche']","[1325537, 13461, 1107490, 1088611]",['julien-brajard'],Fusion of Rain Radar Images and Wind Forecasts in a Deep Learning Model Applied to Rain Nowcasting,hal-03112093,2021,10.3390/rs13020246,"['Radar data', 'Rain nowcasting', 'Deep learning']","['Short or mid-term rainfall forecasting is a major task with several environmental applications such as agricultural management or flood risk monitoring. Existing data-driven approaches, especially deep learning models, have shown significant skill at this task, using only rainfall radar images as inputs. In order to determine whether using other meteorological parameters such as wind would improve forecasts, we trained a deep learning model on a fusion of rainfall radar images and wind velocity produced by a weather forecast model. The network was compared to a similar architecture trained only on radar data, to a basic persistence model, and to an approach based on optical flow. Our network outperforms by 8% the F1-score calculated for the optical flow on moderate and higher rain events for forecasts at a horizon time of 30 minutes. Furthermore, it outperforms by 7% the same architecture trained using only rainfall radar images. Merging rain and wind data has also proven to stabilize the training process and enabled significant improvement especially on the difficult-to-predict high precipitation rainfalls.']",https://hal.sorbonne-universite.fr/hal-03112093,"['0.info', '1.info.info-ti', '0.info']"
"['Maike Sonnewald', 'Redouane Lguensat', 'Daniel C. Jones', 'Peter D. Dueben', 'Julien Brajard', 'V. Balaji']","[1106703, 177300, 777348, 13461]","['redouane-lguensat', 'julien-brajard']","Bridging observations, theory and numerical simulation of the ocean using machine learning",hal-03311328,2021,10.1088/1748-9326/ac0eb0,"['Ocean science', 'Physical oceanography', 'Observations', 'Theory', 'Modelling', 'Supervised machine learning', 'Unsupervised machine learning']","['Progress within physical oceanography has been concurrent with the increasing sophistication of tools available for its study. The incorporation of machine learning (ML) techniques offers exciting possibilities for advancing the capacity and speed of established methods and for making substantial and serendipitous discoveries. Beyond vast amounts of complex data ubiquitous in many modern scientific fields, the study of the ocean poses a combination of unique challenges that ML can help address. The observational data available is largely spatially sparse, limited to the surface, and with few time series spanning more than a handful of decades. Important timescales span seconds to millennia, with strong scale interactions and numerical modelling efforts complicated by details such as coastlines. This review covers the current scientific insight offered by applying ML and points to where there is imminent potential. We cover the main three branches of the field: observations, theory, and numerical modelling. Highlighting both challenges and opportunities, we discuss both the historical context and salient ML tools. We focus on the use of ML in situ sampling and satellite observations, and the extent to which ML applications can advance theoretical oceanographic exploration, as well as aid numerical simulations. Applications that are also covered include model error and bias correction and current and potential use within data assimilation. While not without risk, there is great interest in the potential benefits of oceanographic ML applications; this review caters to this interest within the research community.']",https://hal.science/hal-03311328,"['0.sdu', '1.sdu.ocean', '0.sdu', '1.sdu.envi']"
"['K.R. Mangalaa', 'Damien Cardinal', 'Julien Brajard', 'D.B. Rao', 'N.S. Sarma', 'Irina Djouraev', 'G. Chiranjeevulu', 'K. Narasimha Murty', 'V. V. S. S. Sarma']","[184611, 13461, 1034256]","['damien-cardinal', 'julien-brajard']",Silicon cycle in Indian estuaries and its control by biogeochemical and anthropogenic processes,hal-01651900,2017,10.1016/j.csr.2017.08.011,"['Amorphous silica', 'Diatoms', 'Land use', 'Weathering', 'Land-to-ocean continuum', 'Monsoon']","['We study the silicon biogeochemical cycle and its associated parameters in 24 and 18 Indian estuaries during dry and wet periods respectively. We focus more specifically on dissolved Si (DSi), amorphous Si (ASi,) lithogenic Si (LSi), Particulate Organic Carbon (POC), Total Suspended Material (TSM), Dissolved Inorganic Nitrogen (DIN), salinity and fucoxanthin, a marker pigment for diatoms. Overall, we show that the estuaries have strong inter and intra variability of their biogeochemical parameters both seasonally and along salinity gradients. Based on Principal Component Analysis and clustering of categorised (upper and lower) estuaries, we discuss the four major processes controlling the Si variability of Indian estuaries: 1) lithogenic supply, 2) diatom uptake, 3) mixing of sea water and, 4) land use. The influence of lithogenic control is significantly higher during the wet period than during the dry period, due to a higher particle supply through monsoonal discharge. A significant diatom uptake is only identified in the estuaries during dry period. By taking into account the non-conservative nature of Si and by extrapolating our results, we estimate the fluxes from the Indian subcontinent of DSi, ASi, LSi to the Bay of Bengal (211 ± 32, 10 ± 4.7, 2028 ± 317 Gmol) and Arabian Sea (80 ± 15, 7 ± 1.1, 1717 ± 932 Gmol). We show the impact of land use in watersheds with higher levels of agricultural activity amplifies the supply of Si to the coastal Bay of Bengal during the wet season. In contrast, forest cover and steep slopes cause less Si supply to the Arabian Sea by restricting erosion when entering the estuary. Finally, Si:N ratios show that nitrogen is always in deficit relative to silicon for diatom growth, these high Si:N ratios likely contribute to the prevention of eutrophication in the Indian estuaries and coastal sea.']",https://hal.sorbonne-universite.fr/hal-01651900,"['0.sdu', '1.sdu.stu', '2.sdu.stu.oc', '0.sdu', '1.sdu.envi']"
"['Georges Baaklini', 'Leila Issa', 'Milad Fakhri', 'Julien Brajard', 'Gina Fifani', 'Milena Menna', 'Isabelle Taupier-Letage', 'Anthony Bosse', 'Laurent Mortier']","[1121125, 13461, 1140012, 19224, 182590, 6424]","['julien-brajard', 'isabelle-taupier-letage', 'anthony-bosse', 'laurent-mortier']",Blending drifters and altimetric data to estimate surface currents: Application in the Levantine Mediterranean and objective validation with different data types,hal-03329128,2021,10.1016/j.ocemod.2021.101850,"['Altimetry', 'Lagrangian data', 'Data assimilation', 'Drifters', 'Surface velocity field', 'Levantine Mediterranean']","['An improved estimation of the surface currents in the Levantine Basin of the Mediterranean sea is crucial for a wide range of applications, including pollutants transport and nutrients distribution. This estimation remains challenging due to the scarcity or shortcomings of various data types used for this purpose. In this paper, we present an objective validation of a variational assimilation algorithm that blends geostrophic velocities derived from altimetry, wind-induced velocities, and drifter positions, to continuously obtain velocity corrections. The assessment of the validation impact was based on available independent in-situ data (current meters, gliders, and independent drifters) and satellite ocean color images. In all cases, the improvement was shown either qualitatively (position of the eddies) or quantitatively.']",https://hal.science/hal-03329128,"['0.sdu', '1.sdu.stu', '2.sdu.stu.oc']"
"['Sylvie Thiria', 'Charles Sorror', 'Théo Archambault', 'Anastase Alexandre Charantonis', 'Dominique Béréziat', 'Carlos Mejia', 'Jean-Marc Molines', 'Michel Crépon']","[924914, 1131599, 1107490, 1325537, 1355588, 1180665, 1231743]",['carlos-mejia'],Downscaling of ocean fields by fusion of heterogeneous observations using Deep Learning algorithms,hal-04006736,2023,10.1016/j.ocemod.2023.102174,"['Downscaling', 'Machine Learning', 'Altimeter', 'SST', 'Ocean currents']","['We present a deep learning method to downscale low-resolution geophysical fields by merging them with high-resolution data. The downscaling was performed using an ensemble of convolutional neural networks (CNNs), whose prediction values are the average values of the outputs of 20 CNNs. Academic experiments were conducted on simulated ocean data in the Gulf Stream region, given by the outputs of the NATL60 model. The CNNs forced with low-resolution (120 × 120 km) sea surface high (SSH) data and mesoscale resolution (12 × 12 km) sea surface temperature (SST) data allowed us to obtain mesoscale resolution sea surface currents with good accuracy. Sensitivity experiments have shown that taking SST into account significantly increases the accuracy of the high-resolution velocity retrieval, even when noise is added to the SSH data. The velocity information embedded in the transport equation modeling the SST advection is taken into account by the CNN, which greatly increases the resolution of ocean currents provided by SSH. In the present work, we only consider spatial downscaling by assuming that SSH and SST are daily observations. The method we developed is generic and can be used to improve the resolution of a wide variety of large-scale fields by merging them with high-resolution fields.']",https://hal.science/hal-04006736,['0.sdu']
"['François Kaly', 'Beatrice Marticorena', 'B. Chatenet', 'Jean-Louis Rajot', 'Serge Janicot', 'Awa Niang', 'Houda Yahi', 'Sylvie Thiria', 'A. Maman', 'A. Zakou', 'S. Coulibaly', 'M. Coulibaly', 'I. Koné', 'S. Traoré', 'Aliou Diallo', 'T. Ndiaye']","[964715, 179374, 758221, 1355628, 952123, 924914]","['beatrice-marticorena', 'jean-louis-rajot', 'serge-janicot']",Variability of mineral dust concentrations over West Africa monitored by the Sahelian Dust Transect,hal-01496768,2015,10.1016/j.atmosres.2015.05.011,"['Mineral dust aerosol', 'West Africa', 'Sahel', 'Spatiotemporal variability', 'PMsub10/sub', 'Aerosol']","['The ""Sahelian belt"" is known as a region where mineral dust content is among the highest in the world. In the framework of the AMMA international Program, a transect of three ground based stations, the ""Sahelian Dust Transect"" (SDT), has been deployed in order to obtain quantitative information on the mineral dust content over the Sahel. These three stations: Banizoumbou (Niger), Cinzana (Mali) and M\'Bour (Senegal) are aligned at 13 degrees N along the east-west main pathway of the Saharan and Sahelian dust toward the Atlantic Ocean. The SDT provides a set of aerosol measurements and local meteorological parameters to describe and understand the mechanisms that control the temporal and regional variability of mineral dust content in these regions. In this work we analyze the seasonal and diurnal variability of the dust concentrations over the period 2006-2010. The analysis of the dust concentrations measured between 2006 and 2010 confirmed a regional seasonal cycle characterized by a maximum in the dry season, with median concentration ranging from 205 mu g m(-3) at Banizoumbou to 144 mu g m(-3) at M\'Bour, and a minimum (11-32 mu g m(-3)) in the wet season. The five year data set allowed the quantification of the variability of the monthly concentrations. The range between the percentiles 75 and 25 varies linearly with the median concentration: it is of the same order than the median value in M\'Bour, 17% slightly higher in Cinzana and 50% higher in Banizoumbou. The range between the accepted maximum and minimum is also correlated with the median value, with slopes ranging from 14 in Banizoumbou to 7 in M\'Bour. Part of the variability of the concentration at the monthly scale is due to interannual variability. Extremely high or low monthly concentration can be recorded that significantly impacts the five year median concentration and its range. Compared to the 3-year data set analyzed by Marticorena et al. (2010), the two additional years used in this work appear as the less dusty year (2009) and one of the dustier years (2010). The sampling time step and the high recovery rates of the measurement stations allowed to investigate the diurnal cycle of the dust concentration for the first time. During the dry season, the hourly median concentrations range from 80 to 100 mu g m(-3) during the night to 100-160 mu g m(-3) during the day-time maximum. The diurnal cycle of the PM10 concentrations is phased with the diurnal cycle of the surface wind speed and thus modulated by the interactions between the nocturnal lower level jet (NLLJ) and the surface boundary layer. The NUJ appears as a major agent to transport Saharan dust toward the Sahel. During the wet season, the median PM10 concentrations are maximum at night-time (<50 mu g m(-3)). The night-time concentrations are associated with a large range of variability and coincide with the periods of higher occurrence of meso-scale convective systems. The amplitude of the diurnal cycle is of the order of 60 mu g m(-3) in the dry season and 20 mu g m(-3) in the wet season. Both in the dry and in the wet season, despite a month to month variability of the daily dust concentration, a typical diurnal pattern has been established suggesting that this temporal pattern is mainly driven by local meteorological conditions.']",https://hal.science/hal-01496768,"['0.phys', '1.phys.phys', '2.phys.phys.phys-geo-ph']"
"['Catherine Matias', 'Vincent Miele']","[6516, 178373]","['catherinematias', 'vincent-miele']",Statistical clustering of temporal networks through a dynamic stochastic block model,hal-01167837,2017,10.1111/rssb.12200,"['Stochastic block model', 'Dynamic random graph', 'Contact network', 'Graph clustering', 'Variational expectation maximization']","['Statistical node clustering in discrete time dynamic networks is an emerging field that raises many challenges. Here, we explore statistical properties and frequentist inference in a model that combines a stochastic block model (SBM) for its static part with independent Markov chains for the evolution of the nodes groups through time. We model binary data as well as weighted dynamic random graphs (with discrete or continuous edges values). Our approach, motivated by the importance of controlling for label switching issues across the different time steps, focuses on detecting groups characterized by a stable within group connectivity behavior. We study identifiability of the model parameters , propose an inference procedure based on a variational expectation maximization algorithm as well as a model selection criterion to select for the number of groups. We carefully discuss our initialization strategy which plays an important role in the method and compare our procedure with existing ones on synthetic datasets. We also illustrate our approach on dynamic contact networks, one of encounters among high school students and two others on animal interactions. An implementation of the method is available as a R package called dynsbm.']",https://hal.science/hal-01167837v2,"['0.math', '0.stat']"
"['Catherine Matias', 'Stéphane Robin']","[6516, 15469]","['catherinematias', 'scjrobin']",Modeling heterogeneity in random graphs through latent space models: a selective review,hal-00948421,2014,10.1051/proc/201447004,"['Stochastic block model', 'Graph clustering', 'Random graphs']",['We present a selective review on probabilistic modeling of heterogeneity in random graphs. We focus on latent space models and more particularly on stochastic block models and their extensions that have undergone major developments in the last five years.'],https://hal.science/hal-00948421v2,"['0.math', '1.math.math-st', '0.stat', '1.stat.th', '0.stat', '1.stat.me']"
"['Christophe Ambroise', 'Catherine Matias']","[1342328, 6516]","['christopheambroise', 'catherinematias']",New consistent and asymptotically normal parameter estimates for random-graph mixture models,hal-00647817,2012,10.1111/j.1467-9868.2011.01009.x,"['Composite likelihood', 'Mixture model', 'Random graph', 'Stochastic block model']","['Random-graph mixture models are very popular for modelling real data networks. Parameter estimation procedures usually rely on variational approximations, either combined with the expectation-maximization (EM) algorithm or with Bayesian approaches. Despite good results on synthetic data, the validity of the variational approximation is, however, not established. Moreover, these variational approaches aim at approximating the maximum likelihood or the maximum a posteriori estimators, whose behaviour in an asymptotic framework (as the sample size increases to ∞) remains unknown for these models. In this work, we show that, in many different affiliation contexts (for binary or weighted graphs), parameter estimators based either on moment equations or on the maximization of some composite likelihood are strongly consistent and √n convergent, when the number n of nodes increases to ∞. As a consequence, our result establishes that the overall structure of an affiliation model can be (asymptotically) caught by the description of the network in terms of its number of triads (order 3 structures) and edges (order 2 structures). Moreover, these parameter estimates are either explicit (as for the moment estimators) or may be approximated by using a simple EM algorithm, whose convergence properties are known. We illustrate the efficiency of our method on simulated data and compare its performances with other existing procedures. A data set of cross-citations among economics journals is also analysed.']",https://hal.science/hal-00647817,"['0.math', '1.math.math-st', '0.stat', '1.stat.th']"
"['Catherine Matias', 'Tabea Rebafka', 'Fanny Villers']","[6516, 897194, 944459]",['catherinematias'],A semiparametric extension of the stochastic block model for longitudinal networks,hal-01245867,2018,10.1093/biomet/asy016,"['Link stream', 'Integrated classification likelihood', 'Expectation-maximization algorithm', 'Dynamic interactions', 'Longitudinal network', 'Semiparametric model', 'Variational approximation', 'Temporal network']","['We propose an extension of the stochastic block model for recurrent interaction events in continuous time, where every individual belongs to a latent group and conditional interactions between two individuals follow an inhomogeneous Poisson process with intensity driven by the individuals’ latent groups. We show that the model is identifiable and estimate it with a semiparametric variational expectation-maximization algorithm. We develop two versions of the method, one using a nonparametric histogram approach with an adaptive choice of the partition size, and the other using kernel intensity estimators. We select the number of latent groups by an integrated classification likelihood criterion. We demonstrate the performance of our procedure on synthetic experiments, analyse two datasets to illustrate the utility of our approach, and comment on competing methods.']",https://hal.science/hal-01245867v3,"['0.stat', '1.stat.me']"
"['Christian Baudet', 'Béatrice Donati', 'Blerina Sinaimeri', 'Pierluigi Crescenzi', 'Christian Gautier', 'Catherine Matias', 'Marie-France Sagot']","[1598, 171307, 6516, 170068]","['christian-baudet', 'blerina-sinaimeri', 'catherinematias', 'marie-france-sagot']",Cophylogeny Reconstruction via an Approximate Bayesian Computation,hal-01092972,2015,10.1093/sysbio/syu129,"['Likelihood-free inference', 'Cophylogeny', 'Approximate Bayesian computation', 'Host/parasite systems']","['Despite an increasingly vast literature on cophylogenetic reconstructions for studying host-parasite associations, understanding the common evolutionary history of such systems remains a problem that is far from being solved. Most algorithms for host-parasite reconciliation use an event-based model, where the events include in general (a subset of) cospeciation, duplication, loss, and host-switch. All known parsimonious event-based methods then assign a cost to each type of event in order to find a reconstruction of minimum cost. The main problem with this approach is that the cost of the events strongly influences the reconciliation obtained.To deal with this problem, we developed an algorithm, called Coala, for estimating the frequency of the events based on an approximate Bayesian computation approach. The benefits of this method are twofold: (1) it provides more confidence in the set of costs to be used in a reconciliation, and (2) it allows estimation of the frequency of the events in cases where the dataset consists of trees with a large number of taxa.We evaluate our method on simulated and on biological datasets. We show that in both cases, for the same pair of host and parasite trees, different sets of frequencies for the events lead to equally probable solutions. Moreover, often these solutions differ greatly in terms of the number of inferred events. It appears crucial to take this into account before attempting any further biological interpretation of such reconciliations. More generally, we also show that the set of frequencies can vary widely depending on the input host and parasite trees. Indiscriminately applying a standard vector of costs may thus not be a good strategy.']",https://inria.hal.science/hal-01092972,"['0.info', '1.info.info-bi', '0.stat', '1.stat.ap', '0.sdv', '1.sdv.bid', '2.sdv.bid.spt']"
"['Julien Chiquet', 'Alexander Smith', 'Gilles Grasseau', 'Catherine Matias', 'Christophe Ambroise']","[15350, 900814, 6516, 1342328]","['julien-chiquet', 'catherinematias', 'christopheambroise']",SIMoNe: Statistical Inference for MOdular NEtworks.,hal-00592218,2009,10.1093/bioinformatics/btn637,"['Algorithms', 'Databases', 'Genetic', 'Gene Expression Profiling', 'Gene Regulatory Networks', 'Software', 'Computer Simulation']","['The R package SIMoNe (Statistical Inference for MOdular NEtworks) enables inference of gene-regulatory networks based on partial correlation coefficients from microarray experiments. Modelling gene expression data with a Gaussian graphical model (hereafter GGM), the algorithm estimates non-zero entries of the concentration matrix, in a sparse and possibly high-dimensional setting. Its originality lies in the fact that it searches for a latent modular structure to drive the inference procedure through adaptive penalization of the concentration matrix. AVAILABILITY: Under the GNU General Public Licence at http://cran.r-project.org/web/packages/simone']",https://hal.science/hal-00592218,"['0.sdv', '1.sdv.bibs', '0.sdv', '1.sdv.bbm', '2.sdv.bbm.gtp', '0.stat', '1.stat.ap']"
"['Vincent Miele', 'Stephane S. Robin', 'Catherine Matias', 'Stéphane Dray']","[178373, 15469, 6516, 21636]","['vincent-miele', 'scjrobin', 'catherinematias', 'stephane-dray']",Nine Quick Tips for Analyzing Network Data,hal-02089501,2019,10.1371/journal.pcbi.1007434,"['Foods', 'Models']",['These tips provide a quick and concentrated guide for beginners in the analysis of network data.'],https://hal.science/hal-02089501v2,"['0.stat', '1.stat.me', '0.stat', '1.stat.ap']"
"['Vincent Miele', 'Catherine Matias']","[178373, 6516]","['vincent-miele', 'catherinematias']",Revealing the hidden structure of dynamic ecological networks,hal-01426652,2017,10.1098/rsos.170251,"['Network clustering', 'Stochastic block model', 'Animal contact network', 'Trophic network', 'Dynamic networks']","['Recent technological advances and long-term data studies provide interaction data that can be modelled through dynamic networks, i.e a sequence of different snapshots of an evolving ecological network. Most often time is the parameter along which these networks evolve but any other one-dimensional gradient (temperature, altitude, depth, humidity, . . . ) could be considered. Here we propose a statistical tool to analyse the underlying structure of these networks and follow its evolution dynamics (either in time or any other one-dimensional factor). It consists in extracting the main features of these networks and summarise them into a high-level view. We analyse a dynamic animal contact network and a seasonal food web and in both cases we show that our approach allows for the identification of a backbone organisation as well as interesting temporal variations at the individual level. Our method, implemented into the R package dynsbm, can handle the largest ecological datasets and is a versatile and promising tool for ecologists that study dynamic interactions.']",https://hal.science/hal-01426652,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo', '0.math', '1.math.math-st']"
"['van Hanh Nguyen', 'Catherine Matias']","[915113, 6516]",['catherinematias'],On efficient estimators of the proportion of true null hypotheses in a multiple testing setup,hal-00647082,2014,10.1111/sjos.12091,"['Information bound', 'Asymptotic efficiency', 'False discovery rate', 'Efficient score', 'Multiple testing', '$p$-values', 'Semiparametric model', 'Semiparametric model']","['We consider the problem of estimating the proportion $\\theta$ of true null hypotheses in a multiple testing context. The setup is classically modeled through a semiparametric mixture with two components: a uniform distribution on interval $[0,1]$ with prior probability $\\theta$ and a nonparametric density $f$. We discuss asymptotic efficiency results and establish that two different cases occur whether $f$ vanishes on a set with non null Lebesgue measure or not. In the first case, we exhibit estimators converging at parametric rate, compute the optimal asymptotic variance and conjecture that no estimator is asymptotically efficient (\\emph{i.e.} attains the optimal asymptotic variance). In the second case, we prove that the quadratic risk of any estimator does not converge at parametric rate. We illustrate those results on simulated data.']",https://hal.science/hal-00647082v3,"['0.stat', '1.stat.ap']"
"['Pierre Andreoletti', 'Dasha Loukianova', 'Catherine Matias']","[836997, 858714, 6516]","['dasha-loukianova', 'catherinematias']",Hidden Markov model for parameter estimation of a random walk in a Markov environment,hal-01025035,2015,10.1051/ps/2015008,"['Random walk in random environment', 'Hidden Markov model', 'Maximum likelihood estimation']","['We focus on the parametric estimation of the distribution of a Markov environment from the observation of a single trajectory of a one-dimensional nearest-neighbor path evolving in this random environment. In the ballistic case, as the length of the path increases, we prove consistency, asymptotic normality and efficiency of the maximum likelihood estimator. Our contribution is two-fold: we cast the problem into the one of parameter estimation in a hidden Markov model (HMM) and establish that the bivariate Markov chain underlying this HMM is positive Harris recurrent. We provide different examples of setups in which our results apply, in particular that of DNA unzipping model, and we give a simple synthetic experiment to illustrate those results.']",https://hal.science/hal-01025035v3,"['0.math', '1.math.math-st', '0.stat', '1.stat.th', '0.math']"
"['Estelle Kuhn', 'Tabea Rebafka', 'Catherine Matias']","[172675, 897194, 6516]","['estellekuhn', 'catherinematias']",Properties of the Stochastic Approximation EM Algorithm with Mini-batch Sampling,hal-02189215,2020,10.1007/s11222-020-09968-0,"['Mini-batch sampling', 'Stochastic approximation', 'EM algorithm', 'Monte Carlo Markov chain', 'Monte Carlo Markov chain Mathematics Subject Classification 2010 65C60 · 62F12']","['To deal with very large datasets a mini-batch version of the Monte Carlo Markov Chain Stochastic Approximation Expectation-Maximization algorithm for general latent variable models is proposed. For exponential models the algorithm is shown to be convergent under classical conditions as the number of iterations increases. Numerical experiments illustrate the performance of the mini-batch algorithm in various models. In particular, we highlight that mini-batch sampling results in an important speed-up of the convergence of the sequence of estimators generated by the algorithm. Moreover, insights on the effect of the mini-batch size on the limit distribution are presented. Finally, we illustrate how to use mini-batch sampling in practice to improve results when a constraint on the computing time is given.']",https://hal.science/hal-02189215v3,"['0.stat', '1.stat.me', '0.stat', '1.stat.th']"
"['Veronica Poda', 'Catherine Matias']",[6516],['catherinematias'],Comparison of modularity-based approaches for nodes clustering in hypergraphs,hal-04414337,2024,10.24072/pcjournal.404,"['Community detection', 'Higher-order interaction', 'Hypergraph', 'Modularity', 'Node clustering']","[""Statistical analysis and node clustering in hypergraphs constitute an emerging topic suffering from a lack of standardization. In contrast to the case of graphs, the concept of nodes' community in hypergraphs is not unique and encompasses various distinct situations. In this work, we conducted a comparative analysis of the performance of modularity-based methods for clustering nodes in binary hypergraphs. To address this, we begin by presenting, within a unified framework, the various hypergraph modularity criteria proposed in the literature, emphasizing their differences and respective focuses. Subsequently, we provide an overview of the state-of-the-art codes available to maximize hypergraph modularities for detecting node communities in binary hypergraphs. Through exploration of various simulation settings with controlled ground truth clustering, we offer a comparison of these methods using different quality measures, including true clustering recovery, running time, (local) maximization of the objective, and the number of clusters detected. Our contribution marks the first attempt to clarify the advantages and drawbacks of these newly available methods. This effort lays the foundation for a better understanding of the primary objectives of modularity-based node clustering methods for binary hypergraphs.""]",https://hal.science/hal-04414337v3,"['0.info', '1.info.info-si', '0.math', '1.math.math-co', '0.phys', '1.phys.phys', '2.phys.phys.phys-data-an', '0.stat', '1.stat.ap']"
"['Aude Sportisse', 'Claire Boyer', 'Julie Josse']","[1041020, 175633, 872522]",['claire-boyer'],Imputation and low-rank estimation with Missing Not At Random data,hal-01964720,2020,10.1007/s11222-020-09963-5,"['Accelerated proximal gradient method', 'Matrix completion', 'Informative missing values', 'Nuclear norm penalty', 'Denoising', 'EM algorithm']","['Missing values challenge data analysis because many supervised and unsupervised learning methods cannot be applied directly to incomplete data. Matrix completion based on low-rank assumptions are very powerful solution for dealing with missing values. However, existing methods do not consider the case of informative missing values which are widely encountered in practice. This paper proposes matrix completion methods to recover Missing Not At Random (MNAR) data. Our first contribution is to suggest a model-based estimation strategy by modelling the missing mechanism distribution. An EM algorithm is then implemented, involving a Fast Iterative Soft-Thresholding Algorithm (FISTA). Our second contribution is to suggest a computationally efficient surrogate estimation by implicitly taking into account the joint distribution of the data and the missing mechanism: the data matrix is concatenated with the mask coding for the missing values; a low-rank structure for exponential family is assumed on this new matrix, in order to encode links between variables and missing mechanisms. The methodology that has the great advantage of handling different missing value mechanisms is robust to model specification errors. The performances of our methods are assessed on the real data collected from a trauma registry (TraumaBase ) containing clinical information about over twenty thousand severely traumatized patients in France. The aim is then to predict if the doctors should administrate tranexomic acid to patients with traumatic brain injury, that would limit excessive bleeding.']",https://hal.science/hal-01964720v3,"['0.stat', '1.stat.ml']"
"['Gérard Biau', 'Erwan Scornet']",[520],['erwan-scornet'],A random forest guided tour,hal-01307105,2016,10.1007/s11749-016-0481-7,"['Random forests', 'Randomization', 'Resampling', 'Parameter tuning', 'Variable importance']","['The random forest algorithm, proposed by L. Breiman in 2001, has been extremely successful as a general-purpose classification and regression method. The approach, which combines several randomized decision trees and aggregates their predictions by averaging, has shown excellent performance in settings where the number of variables is much larger than the number of observations. Moreover, it is versatile enough to be applied to large-scale problems, is easily adapted to various ad hoc learning tasks, and returns measures of variable importance. The present article reviews the most recent theoretical and methodological developments for random forests. Emphasis is placed on the mathematical forces driving the algorithm, with special attention given to the selection of parameters, the resampling mechanism, and variable importance measures. This review is intended to provide non-experts easy access to the main ideas.']",https://hal.sorbonne-universite.fr/hal-01307105,"['0.math', '1.math.math-st']"
"['Gérard Biau', 'Benoît Cadre']",[2447],['benoit-cadre'],Optimization by gradient boosting,hal-01562618,2021,10.1007/978-3-030-73249-3_2,"['Gradient boosting', 'Gradient descent', 'Convexity', 'Convergence']","['Gradient boosting is a state-of-the-art prediction technique that sequentially produces a model in the form of linear combinations of simple predictors---typically decision trees---by solving an infinite-dimensional convex optimization problem. We provide in the present paper a thorough analysis of two widespread versions of gradient boosting, and introduce a general framework for studying these algorithms from the point of view of functional optimization. We prove their convergence as the number of iterations tends to infinity and highlight the importance of having a strongly convex risk functional to minimize. We also present a reasonable statistical context ensuring consistency properties of the boosting predictors as the sample size grows. In our approach, the optimization procedures are run forever (that is, without resorting to an early stopping strategy), and statistical regularization is basically achieved via an appropriate $L^2$ penalization of the loss and strong convexity arguments.']",https://hal.science/hal-01562618,"['0.math', '1.math.math-st', '0.info', '1.info.info-lg']"
"['Idris Kharroubi', 'Nicolas Langrené', 'Huyên Pham']","[892809, 171091, 921733]",['nicolas-langrene'],A numerical algorithm for fully nonlinear HJB equations: an approach by control randomization,hal-00905899,2013,10.1515/mcma-2013-0024,"['Backward stochastic differential equations', 'Control randomization', 'HJB equation', 'Uncertain volatility', 'Empirical regressions', 'Monte-Carlo']","['We propose a probabilistic numerical algorithm to solve Backward Stochastic Differential Equations (BSDEs) with nonnegative jumps, a class of BSDEs introduced in [9] for representing fully nonlinear HJB equations. In particular, this allows us to numerically solve stochastic control problems with controlled volatility, possibly degenerate. Our backward scheme, based on least-squares regressions, takes advantage of high-dimensional properties of Monte-Carlo methods, and also provides a parametric estimate in feedback form for the optimal control. A partial analysis of the error of the scheme is provided, as well as numerical tests on the problem of superreplication of option with uncertain volatilities and/or correlations, including a detailed comparison with the numerical results from the alternative scheme proposed in [7].']",https://hal.science/hal-00905899,"['0.math', '1.math.math-pr', '0.qfin', '1.qfin.cp', '0.qfin', '1.qfin.pr']"
"['Idris Kharroubi', 'Thomas Lim', 'Armand Ngoupeyou']",[856121],,Mean-Variance Hedging on Uncertain Time Horizon in a Market with a Jump,hal-01103691,2013,10.1007/s00245-013-9213-5,"['93E20', '60H10', '60G57', 'Decomposition in the reference filtration AMS subject classifications 91B30', 'Pro-gressive enlargement of filtration', 'Jump processes', 'Backward SDE', 'Random horizon', 'Mean-variance hedging']","['In this work, we study the problem of mean-variance hedging with a random horizon T ∧ τ , where T is a deterministic constant and τ is a jump time of the underlying asset price process. We first formulate this problem as a stochastic control problem and relate it to a system of BSDEs with a jump. We then provide a verification theorem which gives the optimal strategy for the mean-variance hedging using the solution of the previous system of BSDEs. Finally, we prove that this system of BSDEs admits a solution via a decomposition approach coming from filtration enlargement theory.']",https://hal.science/hal-01103691,"['0.math', '1.math.math-pr']"
"['Romuald Elie', 'Idris Kharroubi']","[859378, 892809]",,Adding constraints to BSDEs with jumps: an alternative to multidimensional reflections,hal-01103771,2014,10.1051/ps/2013036,"['Stochastic control', 'Switching problems', 'BSDE with jumps', 'Reflected BSDE MSC Classification 2000 93E20', '60H30', '60J75']","['This paper is dedicated to the analysis of backward stochastic differential equations (BSDEs) with jumps, subject to an additional global constraint involving all the com-ponents of the solution. We study the existence and uniqueness of a minimal solution for these so-called constrained BSDEs with jumps via a penalization procedure. This new type of BSDE offers a nice and practical unifying framework to the notions of constrained BSDEs presented in [22] and BSDEs with constrained jumps introduced in [17]. More remarkably, the solution of a multidimensional Brownian reflected BSDE studied in [16] and [14] can also be represented via a well chosen one-dimensional con-strained BSDE with jumps. This last result is very promising from a numerical point of view for the resolution of high dimensional optimal switching problems and more generally for systems of coupled variational inequalities.']",https://hal.science/hal-01103771v4,"['0.math', '1.math.math-pr']"
"['Idris Kharroubi', 'Antonio Ocello']",[1142768],,A Stochastic Target Problem for Branching Diffusions,hal-03695036,2022,10.1016/j.spa.2023.104278,"['Stochastic control', 'Fintech', 'Cryptocurrencies options', 'Super-replication branching diffusion process', 'Dynamic programming principle', 'Hamilton-Jacobi-Bellman equation', 'Viscosity solution']","['We consider an optimal stochastic target problem for branching diffusion processes. This problem consists in finding the minimal condition for which a control allows the underlying branching process to reach a target set at a finite terminal time for each of its branches. This problem is motivated by an example from fintech where we look for the super-replication price of options on blockchain based cryptocurrencies. We first state a dynamic programming principle for the value function of the stochastic target problem. We then show that the value function can be reduced to a new function with a finite dimensional argument by a so called branching property. Under wide conditions, this last function is shown to be the unique viscosity solution to an HJB variational inequality.']",https://hal.science/hal-03695036v3,"['0.math', '1.math.math-pr', '0.math', '1.math.math-ap']"
"['Bruno Bouchard', 'Boualem Djehiche', 'Idris Kharroubi']","[1038139, 1038223]",,Quenched mass transport of particles towards a target,hal-01567312,2020,10.1007/s10957-020-01704-y,"['McKean-Vlasov SDEs', 'Dynamic programming', 'Stochastic target', 'Mass trans- portation', 'Viscosity solutions']","['We consider the stochastic target problem of finding the collection of initial laws of a mean-field stochastic differential equation such that we can control its evolution to ensure that it reaches a prescribed set of terminal probability distributions, at a fixed time horizon. Here, laws are considered conditionally to the path of the Brownian motion that drives the system. We establish a version of the geometric dynamic programming principle for the associated reachability sets and prove that the corresponding value function is a viscosity solution of a geometric partial differential equation. This provides a characterization of the initial masses that can be almost-surely transported towards a given target, along the paths of a stochastic differential equation. Our results extend [16] to our setting.']",https://hal.science/hal-01567312v3,"['0.math', '1.math.math-pr']"
"['Michel Faucheux', 'Rachid Hamidi', 'Marion Mercadal', 'Maud Thomas', 'Brigitte Frérot']","[13314, 804969]",['michel-faucheux'],"Antennal sensilla of male and female of the nut weevil, Curculio nucum Linnaeus, 1758 (Coleoptera: Curculionidae)",hal-03090987,2019,10.1080/00379271.2019.1649093,"['Nut weevil', 'Olfaction', 'Contact chemoreception', 'Scanning electron microscopy']","['The nut weevil, Curculio nucum (Linnaeus, 1758), is the main pest in hazelnut orchards (Corylus avellana L.). Semiochemicals are interesting bio control tools that could be used to manipulate the pest behaviour and to control pest populations. The study of the sensorial equipment of the insect antennae provides information on the importance of olfaction in the adult life for host plants and mate findings as well as on the putative other senses. Before electrophysiological investigation, the knowledge of antennae equipment is also necessary. The aim of this study is to determine the types, number and location of sensilla on the antennae of male and female adult C. nucum in order to determine their implication in seeking a sexual partner and a host plant. The 12-segmented antenna comprises a scape, a 7-segmented funicle and a 4-segmented club. Out of the nine sensillum types listed, three are present on the scape and the funicle and seven types on the club which gathers 71-73% of the total of sensilla. Tactile aporous sensilla chaetica C1, gustatory uniporous sensilla chaetica C2, olfactory multiporous sensilla basiconica B1 and B2 are found on both the dorsal and ventral surfaces of the club in both sexes. Thermo-hygroreceptive dome-shaped sensilla D, olfactory multiporous sensilla basiconica B3 and olfactory multiporous fluted sensilla basiconica F are found exclusively on the ventral surface of the club, suggesting that these sensilla are utilized in host plant acceptance during antennal tapping. The sexual dimorphism concerns only the numbers of sensilla chaetica C1 and sensilla basiconica B2.']",https://hal.inrae.fr/hal-03090987,"['0.shs', '1.shs.anthro-bio']"
"['Maxime Sangnier', 'Jérôme Gauthier', 'A. Rakotomamonjy']","[947472, 174806]",['arakotomamonjy'],Filter bank learning for signal classification,cea-01865050,2015,10.1016/j.sigpro.2014.12.028,"['Discriminative feature-extraction', 'Scattering', 'Recognition', 'Design', 'Signal classification', 'Optimization', 'Support vector machine', 'Kernel learning', 'Filter bank', 'SVM', 'Signal processing', 'Machine learning', 'Artificial intelligence', 'Classification']","['This paper addresses the problem of feature extraction for signal classification. It proposes to build features by designing a data-driven filter bank and by pooling the time-frequency representation to provide time-invariant features. For this purpose, our work tackles the problem of jointly learning the filters of a filter bank with a support vector machine. It is shown that, in a restrictive case (but consistent to prevent overfitting), the problem boils down to a multiple kernel learning instance with infinitely many kernels. To solve such a problem, we build upon existing methods and propose an active constraint algorithm able to handle a non-convex combination of an infinite number of kernels. Numerical experiments on both a brain-computer interface dataset and a scene classification problem prove empirically the appeal of our method.']",https://cea.hal.science/cea-01865050,"['0.info', '1.info.info-ts', '0.stat', '1.stat.ml', '0.stat', '1.stat.ap', '0.math', '1.math.math-mg']"
"['Olivier Lopez', 'Xavier Milhaud', 'Pierre-Emmanuel Thérond']","[21529, 171590, 1032]","['olopezclermont', 'xavier-milhaud', 'pierre-emmanuel-therond']",A tree-based algorithm adapted to microlevel reserving and long development claims,hal-01868744,2019,10.1017/asb.2019.12,"['Long-tail', 'Censoring', 'Reserving', 'Regression tree', 'Disability']","['In non-life insurance, business sustainability requires accurate and robust predictions of reserves related to unpaid claims. To this aim, two different approaches have historically been developed: aggregated loss triangles and individual claim reserving. The former has reached operational great success in the past decades, whereas the use of the latter still remains limited. Through two illustrative examples and introducing an appropriate tree-based algorithm, we show that individual claim reserving can be really promising, especially in the context of long-term risks.']",https://hal.science/hal-01868744v2,"['0.math', '1.math.math-st', '0.stat', '1.stat.ap']"
"['Caroline Hillairet', 'Olivier Lopez']","[1083560, 21529]",['olopezclermont'],Propagation of cyber incidents in an insurance portfolio: counting processes combined with compartmental epidemiological models,hal-02564462,2021,10.1080/03461238.2021.1872694,"['Cyber insurance', 'Emerging risks', 'Counting processes', 'Compartmental epi- demiological models', 'Risk theory', 'Compartmental epidemiological models']","['In this paper, we propose a general framework to design accumulation scenarios that can be used to anticipate the impact of a massive cyber attack on an insurance portfolio. The aim is also to emphasize the role of countermeasures in stopping the spread of the attack over the portfolio, and to quantify the benefits of implementing such strategies of response. Our approach consists of separating the global dynamic of the cyber event (that can be described through compartmental epidemiological models), the effect on the portfolio, and the response strategy. This general framework allows us to obtain Gaussian approximations for the corresponding processes, and sharp confidence bounds for the losses. A detailed simulation study, which mimics the effects of a Wannacry scenario, illustrates the practical implementation of the method.']",https://hal.science/hal-02564462v2,"['0.math', '1.math.math-st', '0.math', '1.math.math-pr', '0.qfin', '1.qfin.rm']"
"['Michel Delecroix', 'Olivier Lopez', 'Valentin Patilea']","[21529, 848073]",['olopezclermont'],Nonlinear censored regression using synthetic data,hal-00361261,2008,10.1111/j.1467-9469.2007.00591.x,"['Asymptotic normality', 'Consistency', 'Kaplan-Meier integral', 'Nonlinear regression', 'Right censoring', 'Synthetic data']","['The problem of estimating a nonlinear regression model, when the dependent variable is randomly censored, is considered. The parameter of the model is estimated by least squares using synthetic data. Consistency and asymptotic normality of the least squares estimators are derived. The proofs are based on a novel approach that uses i.i.d. representations of synthetic data through Kaplan-Meier integrals. The asymptotic results are supported by a small simulation study.']",https://hal.science/hal-00361261,"['0.math', '1.math.math-st']"
['Olivier Lopez'],[21529],['olopezclermont'],Single-index Regression models with right-censored responses,hal-00261412,2009,10.1016/j.jspi.2008.06.012,"['Single-index models', 'Semiparametric regression', 'Dimension reduction', 'Censored regression', 'Kaplan-Meier estimator', 'Single-index models']","['In this article, we propose some new generalizations of M-estimation procedures for single-index regression models in presence of randomly right-censored responses. We derive consistency and asymptotic normality of our estimates. The results are proved in order to be adapted to a wide range of techniques used in a censored regression framework (e.g. synthetic data or weighted least squares). As in the uncensored case, the estimator of the single-index parameter is seen to have the same asymptotic behavior as in a fully parametric scheme. We compare these new estimators with those based on the average derivative technique of Burke and Lu (2005) through a simulation study.']",https://hal.science/hal-00261412,"['0.math', '1.math.math-st', '0.stat', '1.stat.th']"
['Olivier Lopez'],[21529],['olopezclermont'],A censored copula model for micro-level claim reserving,hal-01706935,2019,10.1016/j.insmatheco.2019.04.001,"['Claim reserving', 'Copula models', 'Kaplan-Meier estimator', 'Censoring']","['In this paper, we consider the question of predicting the final amount of a claim and its distribution from micro-level data. A copula model is used to describe the dependence between the amount of a claim and its duration (that is the time between its occurence and its closure). Due to the presence of censoring, we adapt classical methodologies using a weighting scheme that corrects the bias caused by this in-completeness in the data. Theoretical results and simulation support the validity of the procedure. A real case coming from medical malpractice claims is presented.']",https://hal.science/hal-01706935,"['0.math', '1.math.math-st']"
"['Clément Julien', 'Emré Anakok', 'Xavier Treton', 'Maria Nachury', 'Stéphane Nancey', 'Anthony Buisson', 'Mathurin Fumery', 'Jérôme Filippi', 'Léon Maggiori', 'Yves Panis', 'Philippe Zerbib', 'Yves François', 'Anne Dubois', 'Charles Sabbagh', 'Amine Rahili', 'Philippe Seksik', 'Matthieu Allez', 'Jérémie Lefevre', 'Pierre Cattan', 'Mircea Chirica', 'Nicolas Munoz-Bongrand', 'Hélène Corte', 'Nathan Beaupel', 'Jonathan Catry', 'Jean-Marc Gornet', 'Clotilde Baudry', 'Nelson Lourenco', 'Mariane Maillet', 'My-Linh Tran-Minh', 'Victor Chardiny', 'Joelle Bonnet', 'Leila Chedouba', 'Andrée Nisard', 'Laurent Beaugerie', 'Anne Bourrier', 'Isabelle Nion-Larmurier', 'Julien Kirchgesner', 'Cécilia Landman', 'Elodie Quevrain', 'Loic Brot', 'Najim Chafai', 'Yann Parc', 'Clothilde Debove', 'Magali Svreck', 'Camille Vincent', 'Nathalie Guedj', 'Marianne Ferron', 'Yoram Bouhnik', 'Olivier Corcos', 'Carmen Stefanescu', 'Sarah Khabil', 'Philippe Marteau', 'Xavier Dray', 'Ulrika Chaput', 'Gilles Bommelaer', 'Marion Goutte', 'Jérémie Denizot', 'Nicolas Barnich', 'Dilek Coban', 'Pierre Desreumaux', 'Benjamin Pariente', 'Coralie Sommeville', 'Jean-Louis Dupas', 'Julien Loreau', 'Franck Brazier', 'Denis Chatelain', 'Christophe Attencourt', 'Martine Leconte', 'Gilles Boschetti', 'Bernard Flourié', 'Eddy Cotte', 'Anne-Laure Charlois', 'Peggy Falgon', 'Helena Hadjisavvas', 'Driffa Moussata', 'Marion Chauvenet', 'Sarah Boyer', 'Xavier Hebuterne', 'Nadia Arab', 'Raja Barhoumi', 'Paul Hofmann', 'Sylvain Le Corff', 'Anna Bonnet', 'Laura Beyer-Berjot', 'Harry Sokol']","[798682, 928425, 763185, 774088, 770596, 1151816, 761210, 762385, 761123, 748817, 1225458, 1151134, 1149906, 1149845, 1111135, 886942, 762251, 604, 801170]","['seksik-philippe', 'julien-kirchgesner', 'sylvainlecorff', 'harry-sokol']",Impact of the Ileal microbiota on surgical site infections in Crohn’s disease: a nationwide prospective cohort,hal-03638385,2022,10.1093/ecco-jcc/jjac026,"['Gut microbiota', 'Crohn’s disease', 'Prediction']","['<b>Background and Aims</b> Surgery is performed in 50–70% of Crohn’s disease [CD] patients, and its main risk is surgical site infection [SSI]. The microbiota has been extensively assessed in CD but not as a potential risk factor for septic morbidity. The objective of this study was to assess the impact of the gut microbiota on SSI in CD. </br></br> <b>Methods</b> We used the multicentric REMIND prospective cohort to identify all patients who experienced SSI after ileocolonic resection for CD, defined as any postoperative local septic complication within 90 days after surgery: wound abscess, intra-abdominal collection, anastomotic leakage or enterocutaneous fistula. The mucosa-associated microbiota of the ileal resection specimen was analysed by 16S gene sequencing in 149 patients. The variable selection and prediction were performed with random forests [R package VSURF] on clinical and microbiotal data. The criterion of performance that we considered was the area under the Receiver Operating Characteristic [ROC] curve [AUC]. </br></br> <b>Results</b> SSI occurred in 24 patients [16.1%], including 15 patients [10.1%] with major morbidity. There were no significant differences between patients with or without SSI regarding alpha and beta diversity. The top selected variables for the prediction of SSI were all microbiota-related. The maximum AUC [0.796] was obtained with a model including 14 genera, but an AUC of 0.78 had already been obtained with a model including only six genera [Hungatella, Epulopiscium, Fusobacterium, Ruminococcaceae_ucg_009, Actinomyces and Ralstonia].</br></br> <b>Conclusion</b> The gut microbiota has the potential to predict SSI after ileocolonic resection for CD. It might play a role in this frequent postoperative complication.']",https://u-picardie.hal.science/hal-03638385,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.chi', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg']"
['Tabea Rebafka'],[1181377],,Model-based clustering of multiple networks with a hierarchical algorithm,hal-03837505,2024,10.1007/s11222-023-10329-w,"['Graph clustering', 'Multiple networks', 'Stochastic block model', 'Agglomerative algorithm', 'Graphon distance', 'Integrated classification likelihood', 'Network comparison', 'Node matching', 'Clustering hierarchy']","['The paper tackles the problem of clustering multiple networks, directed or not, that do not share the same set of vertices, into groups of networks with similar topology. A statistical model-based approach based on a finite mixture of stochastic block models is proposed. A clustering is obtained by maximizing the integrated classification likelihood criterion. This is done by a hierarchical agglomerative algorithm, that starts from singleton clusters and successively merges clusters of networks. As such, a sequence of nested clusterings is computed that can be represented by a dendrogram providing valuable insights on the collection of networks. Using a Bayesian framework, model selection is performed in an automated way since the algorithm stops when the best number of clusters is attained. The algorithm is computationally efficient, when carefully implemented. The aggregation of clusters requires a means to overcome the label-switching problem of the stochastic block model and to match the block labels of the networks. To address this problem, a new tool is proposed based on a comparison of the graphons of the associated stochastic block models. The clustering approach is assessed on synthetic data. An application to a set of ecological networks illustrates the interpretability of the obtained results.']",https://hal.science/hal-03837505v3,"['0.math', '1.math.math-st']"
"['Tabea Rebafka', 'Stéphan Clémençon', 'Max Feinberg']",[174491],['stephan-clemencon'],Bootstrap-based tolerance intervals for application to method validation,hal-02107157,2007,10.1016/j.chemolab.2007.06.001,"['Method validation', 'One-way random effects model tolerance interval', 'Bootstrap', 'Accuracy profile']","['Recently a new validation procedure was developed using a graphical statistical tool - the so-called accuracy profile - that makes interpretation of results easy and straightforward. Accuracy profiles are estimated by tolerance intervals. Most existing methods for constructing tolerance limits are confined to the restrictive case of normally distributed data. The present study is focused on a nonparametric approach based on bootstrap - in order to get out of this constraint. The Mathematical section recalls some definitions and presents the derivation of the new nonparametric bootstrap approach for setting two-sided mean coverage and guaranteed coverage tolerance limits for a balanced one-way random effects model. The section concludes with a simulation study assessing the performance of the bootstrap methods in comparison to classical methods. Finally, the applicability of the proposed intervals is demonstrated by application to the problem of quantitative analytical method validation based on the accuracy profile. This approach is illustrated by an example consisting in the HPLC determination of the vitamers of vitamin 133 (nicotinamide and nicotinic acid) in milk. The efficiency of the new tolerance intervals is demonstrated as well as the applicability of accuracy profiles in the delicate situation where a correction factor must be applied because there is not a full recovery of the analyte. The comparison of the various tolerance intervals also gives some indication on their interpretation. (c) 2007 Published by Elsevier B.V.']",https://telecom-paris.hal.science/hal-02107157,"['0.math', '0.stat', '1.stat.ml', '0.math', '1.math.math-st', '0.math', '1.math.math-pr']"
"['Fabienne Comte', 'Tabea Rebafka']",[2130],['fabienne-comte'],Nonparametric weighted estimators for biased data,hal-01101970,2016,10.1016/j.jspi.2016.01.008,['Adaptive density estimation Biased data Bandwidth selection Fluorescence lifetimes'],"['Several adaptive methods to estimate a density from biased data are pre-sented. Risk bounds for the estimators are provided and an empirical study is performed to compare various kernel and projection estimators associated with different adaptation methods, namely Lepski-type bandwidth selection in pointwise and global settings and model selection for projection estimators. A real data example taken from fluorescence lifetime measurements is also studied.']",https://hal.science/hal-01101970,"['0.math', '1.math.math-st']"
"['Luc Darmé', 'Céline Degrande', 'Claude Duhr', 'Benjamin Fuks', 'Mark Goodsell', 'Gudrun Heinrich', 'Valentin Hirschi', 'Stefan Höche', 'Marius Höfer', 'Joshua Isaacson', 'Olivier Mattelaer', 'Thorsten Ohl', 'Davide Pagani', 'Jürgen Reuter', 'Peter Richardson', 'Steffen Schumann', 'Hua-Sheng Shao', 'Frank Siegert', 'Marco Zaro']",[739195],['mdgoodsell'],UFO 2.0 -- The Universal Feynman Output format,hal-04092803,2023,10.1140/epjc/s10052-023-11780-9,"['Correction', 'Quantum', 'Feynman', 'Philosophy', 'Programming', 'Modular', 'Higher-order', 'Renormalization group', 'Form factor', 'Propagator']","['We present an update of the Universal FeynRules Output model format, commonly known as the UFO format, that is used by several automated matrix-element generators and high-energy physics software. We detail different features that have been proposed as extensions of the initial format during the last ten years, and collect them in the current second version of the model format that we coin the Universal Feynman Output format. Following the initial philosophy of the UFO, they consist of flexible and modular additions to address particle decays, custom propagators, form factors, the renormalisation group running of parameters and masses, and higher-order quantum corrections.']",https://hal.science/hal-04092803,"['0.phys', '1.phys.hphe', '0.phys', '1.phys.hexp']"
"['Daniel Abercrombie', 'Nural Akchurin', 'Ece Akilli', 'Juan Alcaraz Maestre', 'Brandon Allen', 'Barbara Alvarez Gonzalez', 'Jeremy Andrea', 'Alexandre Arbey', 'Georges Azuelos', 'Patrizia Azzi', 'Mihailo Backovic', 'Yang Bai', 'Swagato Banerjee', 'James Beacham', 'Alexander Belyaev', 'Antonio Boveia', 'Amelia Jean Brennan', 'Oliver Buchmueller', 'Matthew R. Buckley', 'Giorgio Busoni', 'Michael Buttignol', 'Giacomo Cacciapaglia', 'Regina Caputo', 'Linda Carpenter', 'Nuno Filipe Castro', 'Guillelmo Gomez Ceballos', 'Yangyang Cheng', 'John Paul Chou', 'Arely Cortes Gonzalez', 'Chris Cowden', ""Francesco d'Eramo"", 'Annapaola de Cosa', 'Michele de Gruttola', 'Albert de Roeck', 'Andrea de Simone', 'Aldo Deandrea', 'Zeynep Demiragli', 'Anthony Difranzo', 'Caterina Doglioni', 'Tristan Du Pree', 'Robin Erbacher', 'Johannes Erdmann', 'Cora Fischer', 'Henning Flaecher', 'Patrick J. Fox', 'Benjamin Fuks', 'Marie-Helene Genest', 'Bhawna Gomber', 'Andreas Goudelis', 'Johanna Gramling', 'John Gunion', 'Kristian Hahn', 'Ulrich Haisch', 'Roni Harnik', 'Philip C. Harris', 'Kerstin Hoepfner', 'Siew Yan Hoh', 'Dylan George Hsu', 'Shih-Chieh Hsu', 'Yutaro Iiyama', 'Valerio Ippolito', 'Thomas Jacques', 'Xiangyang Ju', 'Felix Kahlhoefer', 'Alexis Kalogeropoulos', 'Laser Seymour Kaplan', 'Lashkar Kashif', 'Valentin V. Khoze', 'Raman Khurana', 'Khristian Kotov', 'Dmytro Kovalskyi', 'Suchita Kulkarni', 'Shuichi Kunori', 'Viktor Kutzner', 'Hyun Min Lee', 'Sung-Won Lee', 'Seng Pei Liew', 'Tongyan Lin', 'Steven Lowette', 'Romain Madar', 'Sarah Malik', 'Fabio Maltoni', 'Mario Martinez Perez', 'Olivier Mattelaer', 'Kentarou Mawatari', 'Christopher Mccabe', 'Theo Megy', 'Enrico Morgante', 'Stephen Mrenna', 'Chang-Seong Moon', 'Siddharth M. Narayanan', 'Andy Nelson', 'Sergio F. Novaes', 'Klaas Ole Padeken', 'Priscilla Pani', 'Michele Papucci', 'Manfred Paulini', 'Christoph Paus', 'Jacopo Pazzini', 'Bjorn Penning', 'Michael E. Peskin', 'Deborah Pinna', 'Massimiliano Procura', 'Shamona F. Qazi', 'Davide Racco', 'Emanuele Re', 'Antonio Riotto', 'Thomas G. Rizzo', 'Rainer Roehrig', 'David Salek', 'Arturo Sanchez Pineda', 'Subir Sarkar', 'Alexander Schmidt', 'Steven Randolph Schramm', 'William Shepherd', 'Gurpreet Singh', 'Livia Soffi', 'Norraphat Srimanobhas', 'Kevin Sung', 'Tim M.P. Tait', 'Timothee Theveneaux-Pelzer', 'Marc Thomas', 'Mia Tosi', 'Daniele Trocino', 'Sonaina Undleeb', 'Alessandro Vichi', 'Fuquan Wang', 'Lian-Tao Wang', 'Ren-Jie Wang', 'Nikola Whallon', 'Steven Worm', 'Mengqing Wu', 'Sau Lan Wu', 'Hongtao Yang', 'Yong Yang', 'Shin-Shan Yu', 'Bryan Zaldivar', 'Marco Zanetti', 'Zhiqing Zhang', 'Alberto Zucchetta']","[769677, 735684, 741594, 757061]","['marie-helene-genest', 'emanuele-re']",Dark Matter benchmark models for early LHC Run-2 Searches: Report of the ATLAS/CMS Dark Matter Forum,hal-02351330,2020,10.1016/j.dark.2019.100371,"['Dark Matter', 'Simplified models', 'EFT', 'LHC', 'P p scattering', 'P p colliding beams', 'Dark matter search for', 'Dark matter production', 'Dark matter interaction', 'Dark matter coupling', 'Dark matter mass', 'Direct detection', 'WIMP', 'Mediation', 'CERN LHC Coll', 'Benchmark', 'ATLAS', 'CMS', 'Effective field theory', 'Interpretation of experiments']","['This document is the final report of the ATLAS-CMS Dark Matter Forum, a forum organized by the ATLAS and CMS collaborations with the participation of experts on theories of Dark Matter, to select a minimal basis set of dark matter simplified models that should support the design of the early LHC Run-2 searches. A prioritized, compact set of benchmark models is proposed, accompanied by studies of the parameter space of these models and a repository of generator implementations. This report also addresses how to apply the Effective Field Theory formalism for collider searches and present the results of such interpretations.']",https://hal.science/hal-02351330,"['0.phys', '1.phys.hexp', '0.phys', '1.phys.hphe']"
"['Juliette Alimena', 'James Beacham', 'Martino Borsato', 'Yangyang Cheng', 'Xabier Cid Vidal', 'Giovanna Cottin', 'Albert de Roeck', 'Nishita Desai', 'David Curtin', 'Jared A. Evans', 'Simon Knapen', 'Sabine Kraml', 'Andre Lessa', 'Zhen Liu', 'Sascha Mehlhase', 'Michael J. Ramsey-Musolf', 'Heather Russell', 'Jessie Shelton', 'Brian Shuve', 'Monica Verducci', 'Jose Zurita', 'Todd Adams', 'Michael Adersberger', 'Cristiano Alpigiani', 'Artur Apresyan', 'Robert John Bainbridge', 'Varvara Batozskaya', 'Hugues Beauchesne', 'Lisa Benato', 'S. Berlendis', 'Eshwen Bhal', 'Freya Blekman', 'Christina Borovilou', 'Jamie Boyd', 'Benjamin P. Brau', 'Lene Bryngemark', 'Oliver Buchmueller', 'Malte Buschmann', 'William Buttinger', 'Mario Campanelli', 'Cari Cesarotti', 'Chunhui Chen', 'Hsin-Chia Cheng', 'Sanha Cheong', 'Matthew Citron', 'Andrea Coccaro', 'V. Coco', 'Eric Conte', 'Félix Cormier', 'Louie D. Corpe', 'Nathaniel Craig', 'Yanou Cui', ""Elena Dall'Occo"", 'C. Dallapiccola', 'M.R. Darwish', 'Alessandro Davoli', 'Annapaola de Cosa', 'Andrea de Simone', 'Luigi Delle Rose', 'Frank F. Deppisch', 'Biplab Dey', 'Miriam D. Diamond', 'Keith R. Dienes', 'Sven Dildick', 'Babette Döbrich', 'Marco Drewes', 'Melanie Eich', 'M. Elsawy', 'Alberto Escalante del Valle', 'Gabriel Facini', 'Marco Farina', 'Jonathan L. Feng', 'Oliver Fischer', 'H.U. Flaecher', 'Patrick Foldenauer', 'Marat Freytsis', 'Benjamin Fuks', 'Iftah Galon', 'Yuri Gershtein', 'Stefano Giagu', 'Andrea Giammanco', 'Vladimir V. Gligorov', 'Tobias Golling', 'Sergio Grancagnolo', 'Giuliano Gustavino', 'Andrew Haas', 'Kristian Hahn', 'Jan Hajer', 'Ahmed Hammad', 'Lukas Heinrich', 'Jan Heisig', 'J.C. Helo', 'Gavin Hesketh', 'Christopher S. Hill', 'Martin Hirsch', 'M. Hohlmann', 'W. Hulsbergen', 'John Huth', 'Philip Ilten', 'Thomas Jacques', 'Bodhitha Jayatilaka', 'Geng-Yuan Jeng', 'K.A. Johns', 'Toshiaki Kaji', 'Gregor Kasieczka', 'Yevgeny Kats', 'Malgorzata Kazana', 'Henning Keller', 'Maxim Yu. Khlopov', 'Felix Kling', 'Ted R. Kolberg', 'Igor Kostiuk', 'Emma Sian Kuwertz', 'Audrey Kvam', 'Greg Landsberg', 'Gaia Lanfranchi', 'Iñaki Lara', 'Alexander Ledovskoy', 'Dylan Linthorne', 'Jia Liu', 'Iacopo Longarini', 'Steven Lowette', 'Henry Lubatti', 'Margaret Lutz', 'Jingyu Luo', 'Judita Mamužić', 'Matthieu Marinangeli', 'Alberto Mariotti', 'Daniel Marlow', 'Matthew Mccullough', 'Kevin Mcdermott', 'P. Mermod', 'David Milstead', 'Vasiliki A. Mitsou', 'Javier Montejo Berlingen', 'Filip Moortgat', 'Alessandro Morandini', 'Alice Polyxeni Morris', 'David Michael Morse', 'Stephen Mrenna', 'Benjamin Nachman', 'Miha Nemevšek', 'Fabrizio Nesti', 'Christian Ohm', 'Silvia Pascoli', 'Kevin Pedro', 'Cristián Peña', 'Karla Josefina Pena Rodriguez', 'Jónatan Piedra', 'James L. Pinfold', 'Antonio Policicchio', 'Goran Popara', 'Jessica Prisciandaro', 'Mason Proffitt', 'Giorgia Rauco', 'Federico Redi', 'Matthew Reece', 'Allison Reinsvold Hall', 'H. Rejeb Sfar', 'Sophie Renner', 'Amber Roepe', 'Manfredi Ronzani', 'Ennio Salvioni', 'Arka Santra', 'Ryu Sawada', 'Jakub Scholtz', 'Philip Schuster', 'Pedro Schwaller', 'Cristiano Sebastiani', 'Sezen Sekmen', 'Michele Selvaggi', 'Weinan Si', 'Livia Soffi', 'Daniel Stolarski', 'David Stuart', 'John Stupak', 'Kevin Sung', 'Wendy Taylor', 'Sebastian Templ', 'Brooks Thomas', 'Emma Torró-Pastor', 'Daniele Trocino', 'Sebastian Trojanowski', 'Marco Trovato', 'Yuhsin Tsai', 'C.G. Tully', 'Tamás Álmos Vámi', 'Juan Carlos Vasquez', 'Carlos Vázquez Sierra', 'K. Vellidis', 'Basile Vermassen', 'Martina Vit', 'Devin G.E. Walker', 'Xiao-Ping Wang', 'Gordon Watts', 'Si Xie', 'Melissa Yexley', 'Charles Young', 'Jiang-Hao Yu', 'Piotr Zalewski', 'Yongchao Zhang']","[755000, 1345679, 760208]","['eric-conte', 'louie-corpe']",Searching for long-lived particles beyond the Standard Model at the Large Hadron Collider,hal-02080682,2020,10.1088/1361-6471/ab4574,"['Review', 'P p colliding beams', 'Particle long-lived', 'New physics search for', 'Decay vertex', 'Detector proposed', 'Detector upgrade', 'Vertex primary', 'Scale electroweak interaction', 'P p scattering', 'CERN LHC Coll', 'Signature', 'Tracks', 'Background', 'CERN Lab', 'MATHUSLA', 'Lifetime', 'Showers', 'LHC-B', 'ATLAS', 'CMS', 'Numerical calculations', 'Experimental results', 'Bibliography']","['Particles beyond the Standard Model (SM) can generically have lifetimes that are long compared to SM particles at the weak scale. When produced at experiments such as the Large Hadron Collider (LHC) at CERN, these long-lived particles (LLPs) can decay far from the interaction vertex of the primary proton–proton collision. Such LLP signatures are distinct from those of promptly decaying particles that are targeted by the majority of searches for new physics at the LHC, often requiring customized techniques to identify, for example, significantly displaced decay vertices, tracks with atypical properties, and short track segments. Given their non-standard nature, a comprehensive overview of LLP signatures at the LHC is beneficial to ensure that possible avenues of the discovery of new physics are not overlooked. Here we report on the joint work of a community of theorists and experimentalists with the ATLAS, CMS, and LHCb experiments—as well as those working on dedicated experiments such as MoEDAL, milliQan, MATHUSLA, CODEX-b, and FASER—to survey the current state of LLP searches at the LHC, and to chart a path for the development of LLP searches into the future, both in the upcoming Run 3 and at the high-luminosity LHC. The work is organized around the current and future potential capabilities of LHC experiments to generally discover new LLPs, and takes a signature-based approach to surveying classes of models that give rise to LLPs rather than emphasizing any particular theory motivation. We develop a set of simplified models; assess the coverage of current searches; document known, often unexpected backgrounds; explore the capabilities of proposed detector upgrades; provide recommendations for the presentation of search results; and look towards the newest frontiers, namely high-multiplicity ‘dark showers’, highlighting opportunities for expanding the LHC reach for these signals.']",https://hal.science/hal-02080682,"['0.phys', '1.phys.hexp', '0.phys', '1.phys.hphe']"
"['Diyar Agin', 'Benjamin Fuks', 'Mark D Goodsell', 'Taylor Murphy']",,,Monojets reveal overlapping excesses for light compressed higgsinos,hal-04356123,2024,10.1016/j.physletb.2024.138597,"['Jet single production', 'LSP mass', 'GeV', 'Splitting', 'Sparticle', 'Experimental results', 'Minimal supersymmetric standard model', 'Gap', 'Lepton', 'O10', 'Mass difference', 'ATLAS', 'CMS']","['The ATLAS and CMS collaborations have recently presented results of searches for compressed electroweakinos in final states including soft leptons. These searches are sensitive to mass splittings ranging from quite small values of about 5 GeV to O(10) GeV, which are endemic to scenarios with wino-like and higgsino-like lightest supersymmetric particles (LSPs). While all experimental results exhibit apparently compatible mild excesses, these soft-lepton analyses, taken together with disappearing-track searches targeting much smaller splittings, notably leave unconstrained a sizeable region of parameter space with modest splittings of 1-5 GeV. We point out that this gap can be closed, for scenarios with a higgsino-like LSP, by existing monojet searches. On the other hand, we find at the same time that these monojet searches show excesses in precisely the region favoured by the soft-lepton analyses. We provide an up-to-date map of these results and show, among others, a best-fit point with a global excess greater than $2\\sigma$ that is consistent with a higgsino-like LSP mass around 133 GeV. We finally comment on how such a point can be realised in the MSSM.']",https://hal.science/hal-04356123,"['0.phys', '1.phys.hphe']"
"['Jack Y. Araz', 'Benjamin Fuks', 'Georgios Polykratis']",,,Simplified fast detector simulation in MADANALYSIS 5,hal-02894429,2021,10.1140/epjc/s10052-021-09052-5,"['CERN LHC Coll', 'Numerical calculations', 'Monte Carlo', 'Programming', 'Supersymmetry', 'New physics']","['We introduce a new simplified fast detector simulator in the MadAnalysis\xa05 platform. The Python-like interpreter of the programme has been augmented by new commands allowing for a detector parametrisation through smearing and efficiency functions. On run time, an associated C++ code is automatically generated and executed to produce reconstructed-level events. In addition, we have extended the MadAnalysis\xa05 recasting infrastructure to support our detector emulator, and we provide predefined LHC detector configurations. We have compared predictions obtained with our approach to those resulting from the usage of the Delphes\xa03 software, both for Standard Model processes and a few new physics signals. Results generally agree to a level of about 10% or better, the largest differences in the predictions stemming from the different strategies that are followed to model specific detector effects. Equipped with these new functionalities, MadAnalysis\xa05 now offers a new user-friendly way to include detector effects when analysing collider events, the simulation of the detector and the analysis being both handled either through a set of intuitive Python commands or directly within the C++ core of the platform.']",https://hal.science/hal-02894429,"['0.phys', '1.phys.hphe', '0.phys', '1.phys.hexp']"
"['Benjamin Fuks', 'Yiming Liu', 'Cen Zhang', 'Shuang-Yong Zhou']",,,Positivity in electron-positron scattering: testing the axiomatic quantum field theory principles and probing the existence of UV states,hal-02946163,2021,10.1088/1674-1137/abcd8c,"['New physics', 'Field theory', 'S-matrix', 'Standard model', 'Effective field theory', 'Operator dimension 8', 'Electron positron elastic scattering', 'Electron positron -- electron positron']","['We consider the positivity bounds on dimension-8 four-electron operators and study two related phenomenological aspects at future lepton colliders. First, if positivity is violated, probing such violations will revolutionize our understanding of the fundamental pillars of quantum field theory and the S-matrix theory. We observe that positivity violation at scales of 1-10 TeV can potentially be probed at future lepton colliders even if one assumes that dimension-6 operators are also present. Second, the positive nature of the dimension-8 parameter space often allows us to either directly infer the existence of UV-scale particles together with their quantum numbers or exclude them up to certain scales in a model-independent way. In particular, dimension-8 positivity plays an important role in the test of the Standard Model. If no deviations from the Standard Model are observed, it allows for simultaneous exclusion limits on all kinds of potential UV-complete models. Unlike the dimension-6 case, these limits apply regardless of the UV model setup and cannot be removed by possible cancellations among various UV contributions. This thus consists of a novel and universal test to confirm the Standard Model. We demonstrate with realistic examples how all the previously mentioned possibilities, including the test of positivity violation, can be achieved. Hence, we provide an important motivation for studying dimension-8 operators more comprehensively.']",https://hal.science/hal-02946163,"['0.phys', '1.phys.hphe', '0.phys', '1.phys.hexp', '0.phys', '1.phys.hthe']"
"['Vincent Rocher', 'Anniet M. Laverman', 'Johnny Gasperi', 'Sam Azimi', 'Sabrina Guérin', 'Stéphane Mottelet', 'Thierry Villières', 'André Pauss']","[1083429, 745571, 1838, 845508, 172512]","['anniet-laverman', 'johnny-gasperi', 'andre-pauss']",Nitrite accumulation during denitrification depends on the carbon quality and quantity in wastewater treatment with biofilters.,hal-01128723,2015,10.1007/s11356-015-4196-1,"['Wastewater treatment', 'Nitrite', 'Biofilters', 'Denitrification']","['This study aims to understand the mechanisms of nitrite appearance during wastewater denitrification by biofilters, focusing on the role of the carbon source. Experiments were carried out at lab-scale (batch tests) and full-scale plant (Parisian plant, capacities of 240,000 m3 day−1). Results showed that the nature of the carbon source affects nitrite accumulation rates. This accumulation is low, 0.05 to 0.10 g N-NO2 − per g N-NO3 − eliminated, for alcohols such as methanol, ethanol, or glycerol. The utilization of glycerol leads to fungal development causing clogging of the biofilters. This fungal growth and consequent clogging exclude this carbon source, with little nitrite accumulation, as carbon source for denitrification. Whatever the carbon source, the C/N ratio in the biofilter plays a major role in the appearance of residual nitrite; an optimal C/N ratio from 3.0 to 3.2 allows a complete denitrification without any nitrite accumulation.']",https://enpc.hal.science/hal-01128723,['0.sde']
"['Xiaojun Liu', 'Arnaud Coutu', 'Stéphane Mottelet', 'André Pauss', 'Thierry Ribeiro']","[737220, 1281224, 172512, 746772]","['xiaojunliu92', 'arnaud-dujany-coutu', 'andre-pauss', 'thierry-ribeiro']","Overview of Numerical Simulation of Solid-State Anaerobic Digestion Considering Hydrodynamic Behaviors, Phenomena of Transfer, Biochemical Kinetics and Statistical Approaches",hal-03952114,2023,10.3390/en16031108,"['Modeling', 'CFD', 'Diffusion', 'Degradation kinetics', 'Empirical models', 'Machine learning', 'Biogas modeling CFD diffusion degradation kinetics empirical models machine learning', 'Biogas']","['Anaerobic digestion (AD) is a promising way to produce renewable energy. The solid-state anaerobic digestion (SSAD) with a dry matter content more than 15% in the reactors is seeing its increasing potential in biogas plant deployment. The relevant processes involve multiple of evolving chemical and physical phenomena that are not crucial to conventional liquid-state anaerobic digestion processes (LSAD). A good simulation of SSAD is of great importance to better control and operate the reactors. The modeling of SSAD reactors could be realized either by theoretical or statistical approaches. Both have been studied to a certain extent but are still not sound. This paper introduces the existing mathematical tools for SSAD simulation using theoretical, empirical and advanced statistical approaches and gives a critical review on each type of model. The issues of parameter identifiability, preference of modeling approaches, multiscale simulations, sensibility analysis, particularity of SSAD operations and global lack of knowledge in SSAD media evolution were discussed. The authors call for a stronger collaboration of multidisciplinary research in order to further developing the numeric simulation tools for SSAD.']",https://hal.science/hal-03952114,"['0.spi', '1.spi.gproc']"
"['Cédric Join', 'Jean Bernier', 'Stéphane Mottelet', 'Michel Fliess', 'Sabrina Rechdaoui-Guérin', 'Sam Azimi', 'Vincent Rocher']","[835507, 740117, 942293, 845508, 1083429]",['stephane-mottelet'],A simple and efficient feedback control strategy for wastewater denitrification,hal-01488199,2017,10.1016/j.ifacol.2017.08.1167,"['Wastewater - treatment - treatment biological', 'Algebraic estimation techniques', 'Knowledge-based control', 'Artificial intelligence', 'Intelligent P controllers', 'Model-free control', 'Robustness performance', 'Feedback control design', 'Denitrification', 'Biofiltration']","['Due to severe mathematical modeling and calibration difficulties open-loop feedforward control is mainly employed today for wastewater denitrification, which is a key ecological issue. In order to improve the resulting poor performances a new model-free control setting and its corresponding ""intelligent"" controller are introduced. The pitfall of regulating two output variables via a single input variable is overcome by introducing also an open-loop knowledge-based control deduced from the plant behavior. Several convincing computer simulations are presented and discussed.']",https://polytechnique.hal.science/hal-01488199v2,"['0.sde', '1.sde.ie', '0.sdv', '1.sdv.ee', '0.info', '1.info.info-au', '0.info', '1.info.info-sy', '0.info', '1.info.info-ai', '0.spi', '1.spi.auto', '0.spi', '1.spi.gproc', '0.math', '1.math.math-oc']"
"['Sophie Samain', 'Mikel Leturia', 'Stéphane Mottelet', 'Mohammed Benali', 'Khashayar Saleh']","[176704, 740117, 176698, 971155]","['mikel-leturia', 'stephane-mottelet', 'mohammed-benali']",Characterization of caking for crystalline materials: Comparison and statistical analysis of three mechanical tests,hal-02017563,2019,10.1016/j.ces.2018.11.048,"['Caking', 'Sucrose', 'Shear test', 'Uniaxial compression', 'Diametrical compression', 'Kernel regression']","['Undesired agglomeration of powders, known as caking, results in the loss of product quality and is unacceptable in many powder industries. Information on how ambient conditions influence the cake strength is essential to prevent caking. Although there are a lot of existing methods to form caked samples and even more to characterize them, there is still no consensus regarding these methods. Repeatability is rarely evaluated and the comparative studies remain infrequent. As a deliquescent powder, sucrose is characterized by a threshold Relative Humidity (RH), called Deliquescence Relative Humidity (DRH), above which it turns into an aqueous solution. Partially deliquesced crystals are linked by liquid bridges of aqueous solution. When the RH is decreased below the DRH, these liquid bridges recrystallize into solid bridges to form a hard cake. In this study, an accelerated caking device was developed to obtain homogeneous caked samples of sucrose under controlled conditions. Three mechanical tests were compared on the basis of their sensitivity and repeatability: the uniaxial compression test, the diametrical compression test (tensile test) and the shear test. The varying parameter was the amount of water uptaken before drying, and the data were fitted by cross-validated local linear nonparametric regression. The best mechanical test was found to be the shear test, giving a sharp failure of the cake along a predetermined failure surface and a linear relationship between the cake strength and the amount of water uptaken.']",https://hal.sorbonne-universite.fr/hal-02017563,"['0.spi', '1.spi.meca', '2.spi.meca.mema']"
"['Vincent Rocher', 'Cédric Join', 'Stéphane Mottelet', 'Jean Bernier', 'Sabrina Rechdaoui-Guérin', 'Sam Azimi', 'Paul Lessard', 'André Pauss', 'Michel Fliess']","[845509, 835507, 740117, 845508, 172512]","['stephane-mottelet', 'andre-pauss']","La production de nitrites lors de la dénitrification des eaux usées par biofiltration - Stratégie de contrôle et de réduction des concentrations résiduelles, Nitrite production during wastewater denitrification by biofiltration - a control strategy towards the decrease of residual concentrations",hal-01640983,2018,10.7202/1047053ar,"['Nitrites', 'Plant operation', 'Wastewater', 'Biofiltration', 'Denitrification', 'Wastewater treatment plant']","[""Le développement des unités de post-dénitrification dans les stations d'épuration de l'agglomération parisienne a fait ré-émerger la problématique du nitrite dans les eaux de Seine en aval de Paris. Le contrôle de l'apparition des nitrites au cours de l'étape de post-dénitrification est donc devenu un enjeu technique majeur. Des études visant à mieux appréhender les mécanismes d'apparition du nitrite lors de la dénitrification des eaux usées et à étudier des évolutions techniques (métrologie et boucles de contrôle-commande des procédés) à mettre en oeuvre sur les usines pour contrôler et limiter sa production ont été engagées dans le cadre du programme MOCOPEE (www.mocopee.com). De précédents travaux ont montré que les modes usuels d'injection du méthanol ne permettent pas de s'assurer de la stabilité du rapport C/N dans le réacteur biologique et conduisent à une production erratique et incontrôlée de nitrites. La possibilité d'ajouter une « commande sans modèle » à la commande classique a donc été testée à l'aide du modèle mathématique SimBio, modèle permettant de simuler le fonctionnement des unités de biofiltration. La commande sans modèle placée « en fin de traitement » et basée sur la concentration en nitrites mesurée en sortie de procédé, se greffe à la méthode de contrôle classique en y apportant des corrections seulement au besoin. Les résultats des simulations montrent qu'une régulation des injections de méthanol basée sur la « commande sans modèle » permet de stabiliser et maitriser le nitrite dans le rejet, sans induire d'augmentation des 1 quantités de méthanol injectées."", 'The recent popularity of post-denitrification processes in the greater Paris area wastewater treatmentplants has caused a resurgence of the presence of nitrite in the Seine River. Controlling the productionof nitrite during the post-denitrification process has thus become a major technical issue. Researchstudies have been led in the MOCOPEE program (www.mocopee.com) to better understand theunderlying mechanisms behind the production of nitrite during wastewater denitrification and todevelop technical tools (measurement and control solutions) to assist on-site reductions of nitriteproduction. Prior studies have shown that typical methanol dosage strategies produce a varyingcarbon-to-nitrogen ratio in the reactor, which in turn leads to unstable nitrite concentrations in theeffluent. The possibility of adding a model-free control to the actual classical dosage strategy has thusbeen tested on the SimBio model, which simulates the behavior of wastewater biofilters. Thecorresponding “intelligent” feedback loop, which is using effluent nitrite concentrations, compensatesthe classical strategy only when needed. Simulation results show a clear improvement in averagenitrite concentration level and level stability in the effluent, without a notable overcost in methanol.']",https://polytechnique.hal.science/hal-01640983v2,"['0.sde', '1.sde.ie', '0.sdv', '1.sdv.ee', '0.info', '1.info.info-au', '0.info', '1.info.info-sy', '0.info', '1.info.info-ai', '0.spi', '1.spi.auto', '0.math', '1.math.math-oc']"
"['Dan Istrate', 'Tien Tuan Dao', 'H. Tannous', 'Philippe Pouletaut', 'D. Gamet', 'Marie-Christine Ho Ba Tho']","[170653, 176936, 170844, 786319]","['dan-istrate', 'tien-tuan-dao', 'philippe-pouletaut', 'marie-christine-ho-ba-tho']",Interactive and Connected Rehabilitation Systems for E-Health,hal-03553720,2016,10.1016/j.irbm.2016.02.003,"['Functional rehabilitation', 'Bio-feedback signals', 'System of systems', 'Multi-sensor fusion', 'Serious game', 'Musculoskeletal system', 'Real-time monitoring', 'Rehabilitation at home']","['Functional rehabilitation aims at recovering the locomotion dysfunction of the human body by the physical therapy. The objective of this paper was to develop interactive and connected rehabilitation systems as a system of systems for monitoring the bio-feedbacks of the human musculoskeletal system during the rehabilitation exercises. Video-based non-contact system as Kinect sensor was used to get kinematics data of the human body. Generic and subject-specific avatar representations were integrated. Rehabilitation exercises will be designed as serious games to motivate the end users. Our first prototype was focused on the rehabilitation exercises of the lower limb. Software development and experimental aspects of our proposed solution were presented and discussed. Our system would be of great interest in the supervision of physical therapy exercises in clinical as well as in non-clinical environments (e.g. rehabilitation at home). As perspectives, multi-sensor fusion between Kinect sensor and other kinematics-based sensors like Shimmer ones will be investigated to get an accurate 3D joint motion. Electromyography (EMG) signals will be also used to monitor the muscle functions. Moreover, specific device will also be developed to facilitate the sensors set up and motion monitoring.']",https://hal.science/hal-03553720,"['0.spi', '1.spi.signal']"
"['Mohamad Idriss', 'Halim Tannous', 'Dan Istrate', 'Anaïck Perrochon', 'Jean-Yves Salle', 'Marie-Christine Ho Ba Tho', 'Tien-Tuan Dao']","[1013151, 170653, 965839, 847442, 786319, 176936]","['dan-istrate', 'sc-aperroch', 'marie-christine-ho-ba-tho', 'tien-tuan-dao']",Rehabilitation-Oriented Serious Game Development and Evaluation Guidelines for Musculoskeletal Disorders,hal-01887225,2017,10.2196/games.7284,"['Musculoskeletal diseases', 'Virtual rehabilitation', 'User computer interface', 'Rehabilitation exercise', 'Rehabilitation']","['The progress in information and communication technology (ICT) led to the development of a new rehabilitation technique called ""serious game for functional rehabilitation."" Previous works have shown that serious games can be used for general health and specific disease management. However, there is still lack of consensus on development and evaluation guidelines. It is important to note that the game performance depends on the designed scenario.']",https://unilim.hal.science/hal-01887225,"['0.sdv', '1.sdv.mhep']"
"['Ahmed Barhoum', 'Hubert Rahier', 'Ragab Esmail Abou-Zaied', 'Mohamed Rehan', 'Thierry Dufour', 'Gavin Hill', 'Alain Dufresne']","[8227, 755965]",['thierry-dufour'],Effect of Cationic and Anionic Surfactants on the Application of Calcium Carbonate Nanoparticles in Paper Coating,hal-01303184,2014,10.1021/am405278j,"['Paper air permeability', 'Cationic surfactant', 'Paper coating', 'Hydrophobic', 'Paper surface smoothness', 'Nano calcium carbonate', 'Anionic surfactant']","['Modification of calcium carbonate particles with surfactant significantly improves the properties of the calcium carbonate coating on paper. In this study, unmodified and CTAB (hexadecyltetramethylammonium bromide)-and oleate-modified calcium carbonate nanoparticles were prepared using the wet carbonation technique for paper coating. CTAB (cationic surfactant) and sodium oleate (anionic surfactant) were used to modify the size, morphology, and surface properties of the precipitated nanoparticles. The obtained particles were characterized using X-ray diffraction (XRD), Fourier transform infrared (FT-IR) spectroscopy, zeta potential measurements, thermal gravimetric analysis (TGA), and transmission electron microscopy (TEM). Coating colors were formulated from the prepared unmodified and modified calcium carbonates and examined by creating a thin coating layer on reference paper. The effect of calcium carbonate particle size and surface modification on paper properties, such as coating thickness, coating weight, surface roughness, air permeability, brightness, whiteness, opacity, and hydrophobicity, were investigated and compared with commercial ground (GCC) calcium carbonate-coated papers. The results show that the obtained calcium carbonate nanoparticles are in the calcite phase. The morphology of the prepared calcium carbonate nanoparticles is rhombohedral, and the average particle diameter is less than 100 nm. Compared to commercial GCC, the use of unmodified and CTAB-and oleate-modified calcium carbonate nanoparticles in paper coating improves the properties of paper. The highest measured paper properties were observed for paper coated with oleate-modifed nanoparticles, where an increase in smoothness (decrease in paper roughness) (+23%), brightness (+1.3%), whiteness (+2.8%), and opacity (+2.3%) and a decrease in air permeability (−26%) was obtained with 25% less coat weight. The water contact angle at a drop age time of 10 min was about 112° for the paper coated with oleate-modified nanoparticles and 42° for paper coated with CTAB-modified nanoparticles compared to 104° for GCC-coated paper.']",https://hal.sorbonne-universite.fr/hal-01303184v2,"['0.chim', '1.chim.mate', '0.spi', '1.spi.plasma']"
['Thierry Dufour'],[8227],['thierry-dufour'],From Basics to Frontiers: A Comprehensive Review of Plasma-Modified and Plasma-Synthesized Polymer Films,hal-04259323,2023,10.3390/polym15173607,"['Plasma polymer devices', 'Plasma polymerization', 'Polymer film growth', 'Adhesion', 'Wettability', 'Crosslinking', 'Surface crystallinity', 'PECVD', 'Biopolymers']","['This comprehensive review begins by tracing the historical development and progress of cold plasma technology as an innovative approach to polymer engineering. The study emphasizes the versatility of cold plasma derived from a variety of sources including low-pressure glow discharges (e.g., radiofrequency capacitively coupled plasmas) and atmospheric pressure plasmas (e.g., dielectric barrier devices, piezoelectric plasmas). It critically examines key operational parameters such as reduced electric field, pressure, discharge type, gas type and flow rate, substrate temperature, gap, and how these variables affect the properties of the synthesized or modified polymers. This review also discusses the application of cold plasma in polymer surface modification, underscoring how changes in surface properties (e.g., wettability, adhesion, biocompatibility) can be achieved by controlling various surface processes (etching, roughening, crosslinking, functionalization, crystallinity). A detailed examination of Plasma-Enhanced Chemical Vapor Deposition (PECVD) reveals its efficacy in producing thin polymeric films from an array of precursors. Yasuda’s models, Rapid Step-Growth Polymerization (RSGP) and Competitive Ablation Polymerization (CAP), are explained as fundamental mechanisms underpinning plasma-assisted deposition and polymerization processes. Then, the wide array of applications of cold plasma technology is explored, from the biomedical field, where it is used in creating smart drug delivery systems and biodegradable polymer implants, to its role in enhancing the performance of membrane-based filtration systems crucial for water purification, gas separation, and energy production. It investigates the potential for improving the properties of bioplastics and the exciting prospects for developing self-healing materials using this technology.']",https://hal.science/hal-04259323,"['0.chim', '1.chim.poly', '0.phys', '1.phys.phys', '2.phys.phys.phys-plasm-ph']"
"['Javier Vaquero', 'Florian Judée', 'Marie Vallette', 'Henri Decauchy', 'Ander Arbelaiz', 'Lynda Aoudjehane', 'Olivier Scatton', 'Ester Gonzalez-Sanchez', 'Fatiha Merabtene', 'Jeremy Augustin', 'Chantal Housset', 'Thierry Dufour', 'Laura Fouassier']","[1109265, 1064301, 968737, 987518, 901285, 8227, 968390]","['chantalhousset', 'thierry-dufour', 'laura-fouassier']",Cold-Atmospheric Plasma Induces Tumor Cell Death in Preclinical In Vivo and In Vitro Models of Human Cholangiocarcinoma,hal-02746823,2020,10.3390/cancers12051280,"['Cholangiocarcinoma', 'Cold plasma', 'Innovative therapy', 'Tumor cells', 'Macrophages', 'Plasma selectivity', 'Plasma jet']","['Through the last decade, cold atmospheric plasma (CAP) has emerged as an innovative therapeutic option for cancer treatment. Recently, we have set up a potentially safe atmospheric pressure plasma jet device that displays antitumoral properties in a preclinical model of cholangiocarcinoma (CCA), a rare and very aggressive cancer emerging from the biliary tree with few efficient treatments. In the present study, we aimed at deciphering the molecular mechanisms underlying the antitumor effects of CAP towards CCA both in an in vivo and in vitro context. In vivo, using subcutaneous xenografts into immunocompromised mice, CAP treatment of CCA induced DNA lesions and tumor cell apoptosis, as evaluated by 8-oxoguanine and cleaved caspase-3 immunohistochemistry, respectively. Analysis of the tumor microenvironment showed changes in markers related to macrophage polarization. In vitro, incubation of CCA cells with CAP-treated culture media (i.e. plasma-activated media, PAM) led to a dose response decrease in cell survival. At molecular level, CAP treatment induced double-strand DNA breaks, followed by an increased phosphorylation and activation of the cell cycle master regulators CHK1 and p53, leading to cell cycle arrest and cell death by apoptosis. In conclusion, CAP is a novel therapeutic option to consider for CCA in the future.']",https://hal.science/hal-02746823,"['0.sdv', '1.sdv.can', '0.sdv', '1.sdv.ib', '0.spi', '1.spi.plasma']"
"['Jonas August', 'Thierry Dufour', 'Christophe Bailly']","[1299566, 8227, 1144928]","['thierry-dufour', 'baillyc']",Release of Arabidopsis seed dormancy by cold atmospheric plasma relies on cytoplasmic glass transition,hal-04259321,2023,10.1088/1361-6463/ace36e,"['Plasma agriculture', 'Seeds biology', 'Dormancy release', 'Differential scanning calorimetry', 'Arabidopsis thaliana']","['When mature Arabidopsis thaliana seeds are dormant, their germination is prevented in apparently favorable conditions. This primary dormancy can be released during seed dry storage through a process called after-ripening whose duration can last several months. To reduce this delay, cold atmospheric plasmas (CAPs) can be used as sources of reactive oxygen species (ROS) capable of inducing heterogeneous chemical reactions. While CAP are known to stimulate the germination of various seed species, the relationship between CAP treatments and the amorphous solid state of dry seeds remains unexplored. Here, we demonstrate that seed dormancy can be alleviated using a cold plasma of ambient air and that this alleviation can be amplified for seeds with high water-content (typically 30% DW ) or seeds heated at 60 °C during plasma treatment. Differential scanning micro-calorimetry shows that these characteristics control the glassy/rubbery state of the seed cytoplasm. This technique indicates also that a glass transition to the rubbery state strengthens the CAP effects to alleviate seed dormancy. We propose that lower cytoplasmic viscosity can promote the oxidative signaling induced by CAP which, in turn, improves the germination process.']",https://hal.science/hal-04259321,"['0.sdv', '1.sdv.bv', '2.sdv.bv.bot', '0.sdv', '1.sdv.sa', '2.sdv.sa.sta', '0.spi', '1.spi.plasma']"
"['Sami Abou Rich', 'Thierry Dufour', 'P Leroy', 'Laurent Nittler', 'Jean Jacques Pireaux', 'F Reniers']",[8227],['thierry-dufour'],"Low-density polyethylene films treated by an atmospheric Ar–O2 post-discharge: functionalization, etching, degradation and partial recovery of the native wettability state",hal-01303180,2014,10.1088/0022-3727/47/6/065203,"['Low molecular weight oxidized material', 'LDPE', 'Plasma post-discharge treatment', 'Etching rate', 'Ageing']","[""To optimize the adhesion of layers presenting strong barrier properties on low-density polyethylene (LDPE) surfaces, we investigated the influence of argon and argon-oxygen atmospheric pressure post-discharges. This study was performed using x-ray photoelectron spectroscopy, atomic force microscopy, optical emission spectroscopy (OES) and dynamic water contact angle (WCA) measurements. After the plasma treatment, a slight increase in the roughness was emphasized, more particularly for the samples treated in a post-discharge supplied in oxygen. Measurements of the surface roughness and of the oxygen surface concentration suggested the competition of two processes playing a role on the surface hydrophilicity and occurring during the post-discharge treatment: the etching and the activation of the surface. The etching rate was estimated to about 2.7 nm.s-1 and 5.8 nm.s-1 for Ar and Ar-O2 post-discharges, respectively. The mechanisms underlying this etching were investigated through experiments, in which we discuss the influence of the O2 flow rate and the distance (gap) separating the plasma torch from the LDPE surface located downstream. O atoms and NO molecules (emitting in the UV range) detected by OES seem to be good candidates to explain the etching process. An ageing study is also presented to evidence the stability of the treated surfaces over 60 days. After 60 days of storage, we showed that whatever the O2 flow rate, the treated films registered a loss of their hydrophilic state since their WCA increased towards a common threshold of 80°. This 'hydrophobic recovery' effect was mostly attributed to the reorientation of induced polar chemical groups into the bulk of the material. Indeed, the relative concentrations of the carbonyl and carboxyl groups at the surface decreased with the storage time and seemed to reach a plateau after 30 days.""]",https://hal.sorbonne-universite.fr/hal-01303180,"['0.chim', '0.chim', '1.chim.poly', '0.phys', '1.phys.phys', '2.phys.phys.phys-plasm-ph', '0.spi', '1.spi.plasma']"
"['David Mercier', 'Benjamin Quost', 'Thierry Denœux']","[745859, 10055, 2983]","['davidmercierhal', 'quostben', 'tdenoeux']",Refined modeling of sensor reliability in the belief function framework using contextual discounting,hal-00445473,2008,10.1016/j.inffus.2006.08.001,"['Evidence theory', 'Dempster–Shafer theory', 'Belief functions', 'Transferable belief model', 'Uncertainty', 'Information fusion']","['In belief functions theory, the discounting operation allows to combine information provided by a source in the form of a belief function with meta-knowledge regarding the reliability of that source, resulting in a “weakened”, less informative belief function. In this article, an extension of the discounting operation is proposed, allowing to use more detailed information regarding the reliability of the source in different contexts, i.e., conditionally on different hypotheses regarding the variable on interest. This results in a contextual discounting operation parameterized with a discount rate vector. Some properties of this contextual discounting operation are studied, and its relationship with classical discounting is explained. A method for learning the discount rates is also presented.']",https://hal.science/hal-00445473,"['0.info', '1.info.info-ai']"
"['Benjamin Quost', 'Marie-Hélène Masson', 'Thierry Denoeux']","[10055, 3668, 2983]","['quostben', 'marie-helene-masson', 'tdenoeux']",Classifier fusion in the Dempster-Shafer framework using optimized t-norm based combination rules,hal-00651369,2011,10.1016/j.ijar.2010.11.008,"['Cautious rule', 'Pattern Recognition', 'Machine-Learning', 'Classifier Ensemble', 'Dempster-Shafer theory', 'Belief Functions', 'Cautious rule']","[""When combining classifiers in the Dempster-Shafer framework, Dempster's rule is generally used. However, this rule assumes the classifiers to be independent. This paper investigates the use of other operators for combining non independent classifiers, including the cautious rule and, more generally, t-norm based rules with behavior ranging between Dempster's rule and the cautious rule. Two strategies are investigated for learning an optimal combination scheme, based on a parameterized family of t- norms. The first one learns a single rule by minimizing an error criterion. The second strategy is a two-step procedure, in which groups of classifiers with similar outputs are first identified using a clustering algorithm. Then, within- and between-cluster rules are determined by minimizing an error criterion. Experiments with various synthetic and real data sets demonstrate the effectiveness of both the single rule and two-step strategies. Overall, optimizing a single t-norm based rule yields better results than using a fixed rule, including Dempster's rule, and the two-step strategy brings further improvements.""]",https://hal.science/hal-00651369,"['0.info', '1.info.info-cv']"
"['Violaine Antoine', 'Benjamin Quost', 'Marie-Hélène Masson', 'Thierry Denoeux']","[170782, 10055, 3668, 2983]","['violaine-antoine', 'quostben', 'marie-helene-masson', 'tdenoeux']",CECM: Constrained Evidential C-Means algorithm,hal-00554310,2012,10.1016/j.csda.2010.09.021,"['Clustering', 'Semi-supervised learning', 'Pairwise constraints', 'Adaptive metric', 'Active learning', 'Belief functions', 'Dempster–Shafer theory', 'Evidence theory']","['In clustering applications, prior knowledge about cluster membership is sometimes available. To integrate such auxiliary information, constraint-based (or semi-supervised) methods have been proposed in the hard or fuzzy clustering frameworks. This approach is extended to evidential clustering, in which the membership of objects to clusters is described by belief functions. A variant of the Evidential C-means (ECM) algorithm taking into account pairwise constraints is proposed. These constraints are translated into the belief function framework and integrated in the cost function. Experiments with synthetic and real data sets demonstrate the interest of the method. In particular, an application to medical image segmentation is presented.']",https://hal.science/hal-00554310,"['0.info', '1.info.info-ai']"
"['Haifei Zhang', 'Benjamin Quost', 'Marie-Hélène Masson']","[1200661, 10055, 3668]","['quostben', 'marie-helene-masson']",Cautious weighted random forests,hal-03895122,2023,10.1016/j.eswa.2022.118883,"['Cautious classification', 'Imprecise classification', 'Imprecise Dirichlet Model', 'Belief functions']","['Random forest is an efficient and accurate classification model, which makes decisions by aggregating a set of trees, either by voting or by averaging class posterior probability estimates. However, tree outputs may be unreliable in presence of scarce data. The imprecise Dirichlet model (IDM) provides workaround, by replacing point probability estimates with interval-valued ones. This paper investigates a new tree aggregation method based on the theory of belief functions to combine such probability intervals, resulting in a cautious random forest classifier. In particular, we propose a strategy for computing tree weights based on the minimization of a convex cost function, which takes both determinacy and accuracy into account and makes it possible to adjust the level of cautiousness of the model. The proposed model is evaluated on 25 UCI datasets and is demonstrated to be more adaptive to the noise in training data and to achieve a better compromise between informativeness and cautiousness.']",https://hal.science/hal-03895122,"['0.info', '1.info.info-ai']"
"['Dingfu Zhou', 'Vincent Frémont', 'Benjamin Quost', 'Yuchao Dai', 'Hongdong Li']","[957678, 6530, 10055]","['vincent-fremont', 'quostben']",Moving object detection and segmentation in urban environments from a moving platform,hal-01609038,2017,10.1016/j.imavis.2017.07.006,"['Moving Object Detection', 'Motion', 'Ego-Motion Uncertainty']","['This paper proposes an effective approach to detect and segment moving objects from two time-consecutive stereo frames, which leverages the uncertainties in camera motion estimation and in disparity computation. First, the relative camera motion and its uncertainty are computed by tracking and matching sparse features in four images. Then, the motion likelihood at each pixel is estimated by taking into account the ego-motion uncertainty and disparity in computation procedure. Finally, the motion likelihood, color and depth cues are combined in the graph-cut framework for moving object segmentation. The efficiency of the proposed method is evaluated on the KITTI benchmarking datasets, and our experiments show that the proposed approach is robust against both global (camera motion) and local (optical flow) noise. Moreover, the approach is dense as it applies to all pixels in an image, and even partially occluded moving objects can be detected successfully. Without dedicated tracking strategy, our approach achieves high recall and comparable precision on the KITTI benchmarking sequences.']",https://hal.science/hal-01609038,"['0.info', '1.info.info-cv', '0.info', '1.info.info-rb']"
"['Benjamin Quost', 'Thierry Denœux', 'Marie-Hélène Masson']","[10055, 2983, 3668]","['quostben', 'tdenoeux', 'marie-helene-masson']",Pairwise classifier combination using belief functions,hal-00445480,2007,10.1016/j.patrec.2006.11.002,"['Polychotomous classification', 'Dempster–Shafer theory', 'Evidence theory', 'Classification', 'Classifier fusion']","['In the so-called pairwise approach to polychotomous classification, a multiclass problem is solved by combining classifiers trained to discriminate between each pair of classes. In this paper, this approach is revisited in the framework of the Dempster–Shafer theory of belief functions, a non-probabilistic framework for quantifying and manipulating partial knowledge. It is proposed to interpret the output of each pairwise classifiers by a conditional belief function. The problem of classifier combination then amounts to computing the non-conditional belief function which is the most consistent, according to some criterion, with the conditional belief functions provided by the classifiers. Experiments with various datasets demonstrate the good performances of this method as compared to previous approaches to the same problem.']",https://hal.science/hal-00445480,"['0.info', '1.info.info-ai']"
"['Benjamin Quost', 'Thierry Denoeux', 'Shoumei Li']","[10055, 2983]","['quostben', 'tdenoeux']",Parametric classification with soft labels using the Evidential EM algorithm,hal-01525605,2017,10.1007/s11634-017-0301-2,"['Partially supervised learning', 'Belief functions', 'Dempster–Shafer theory', 'Machine learning', 'Uncertain data', 'Discriminant analysis', 'Logistic regression']","['Partially supervised learning extends both supervised and unsu-pervised learning, by considering situations in which only partial information about the response variable is available. In this paper, we consider partially supervised classification and we assume the learning instances to be labeled by Dempster-Shafer mass functions, called soft labels. Linear discriminant analysis and logistic regression are considered as special cases of generative and discriminative parametric models. We show that the evidential EM algorithm can be particularized to fit the parameters in each of these models. We describe experimental results with simulated data sets as well as with two real applications: K-complex detection in sleep EEGs signals and facial expression recognition. These results confirm the interest of using soft labels for classification as compared to potentially erroneous crisp labels, when the true class membership is partially unknown or ill-defined.']",https://hal.science/hal-01525605v2,"['0.info', '1.info.info-ai', '0.stat', '1.stat.ml', '0.info', '1.info.info-lg']"
"['Xun Wang', 'Benjamin Quost', 'Jean-Daniel Chazot', 'Jérôme Antoni']","[10055, 171166, 172043]","['quostben', 'jean-daniel-chazot', 'jerome-antoni']",Estimation of multiple sound sources with data and model uncertainties using the EM and evidential EM algorithms,hal-01248727,2016,10.1016/j.ymssp.2015.06.011,"['Statistical inference from imprecise data', 'Evidential EM algorithm', 'Sound source localization', 'Belief functions']","['This paper considers the problem of identifying multiple sound sources from acoustical measurements obtained by an array of microphones. The problem is solved via maximum likelihood. In particular, an expectation-maximization (EM) approach is used to estimate the sound source locations and strengths, the pressure measured by a microphone being interpreted as a mixture of latent signals emitted by the sources. This work also considers two kinds of uncertainties pervading the sound propagation and measurement process: uncertain microphone locations and uncertain wavenumber. These uncertainties are transposed to the data in the belief functions framework. Then, the source locations and strengths can be estimated using a variant of the EM algorithm, known as the Evidential EM (E2M) algorithm. Eventually, both simulation and real experiments are shown to illustrate the advantage of using the EM in the case without uncertainty and the E2M in the case of uncertain measurement.']",https://hal.science/hal-01248727,"['0.stat', '0.info', '1.info.info-lg', '0.phys', '1.phys.meca', '2.phys.meca.acou']"
"['Violaine Antoine', 'Benjamin Quost', 'Marie-Hélène Masson', 'Thierry Denoeux']","[170782, 10055, 3668, 2983]","['violaine-antoine', 'quostben', 'marie-helene-masson', 'tdenoeux']",CEVCLUS: evidential clustering with instance-level constraints for relational data,hal-00923311,2014,10.1007/s00500-013-1146-z,"['Belief functions', 'Evidence theory', 'Dempster–Shafer theory', 'Relational data', 'Pairwise constraints', 'Constrained clustering']","['Recent advances in clustering consider incorporating background knowledge in the partitioning algorithm, using, e.g., pairwise constraints between objects. As a matter of fact, prior information, when available, often makes it possible to better retrieve meaningful clusters in data. Here, this approach is investigated in the framework of belief functions, which allows us to handle the imprecision and the uncertainty of the clustering process. In this context, the EVCLUS algorithm was proposed for partitioning objects described by a dissimilarity matrix. It is extended here so as to take pairwise constraints into account, by adding a term to its objective function. This term corresponds to a penalty term that expresses pairwise constraints in the belief function framework. Various synthetic and real datasets are considered to demonstrate the interest of the proposed method, called CEVCLUS, and two applications are presented. The performances of CEVCLUS are also compared to those of other constrained clustering algorithms.']",https://hal.science/hal-00923311,"['0.info', '1.info.info-ai']"
"['Loïc Adam', 'Arthur van Camp', 'Sébastien Destercke', 'Benjamin Quost']","[748900, 1077616, 5026, 10055]","['loic-adam', 'seb-destercke', 'quostben']",Inferring from an Imprecise Plackett–Luce model: application to label ranking,hal-04473580,2024,10.1016/j.fss.2024.108908,"['Preference learning', 'Cautious inference', 'Poor data', 'Imprecise Probability']","['The Plackett–Luce model is a popular parametric probabilistic model to define distributions between rankings of objects, modelling for instance observed preferences of users or ranked performances of algorithms. Since such observations may be scarce (users may provide partial preferences, or not all algorithms are run for a given experiment), it may be useful to consider the case where the parameters of the Plackett–Luce model are imprecisely known. In this paper, we first introduce the imprecise Plackett–Luce model, induced by a set of parameters (for instance, parameters with a high relative likelihood). Given a set of possible parameters for the model, we then provide an efficient algorithm to make cautious inferences, returning sets of possible optimal rankings (for instance in the form of partial orders). We illustrate the use of our imprecise model on label ranking, a specific kind of supervised learning.']",https://hal.science/hal-04473580,"['0.info', '1.info.info-ai', '0.info', '1.info.info-lg', '0.math', '1.math.math-st']"
"['Sébastien Destercke', 'Benjamin Quost']","[5026, 10055]","['seb-destercke', 'quostben']",Combining binary classifiers with imprecise probabilities,hal-00655600,2011,10.1007/978-3-642-24918-1_24,"['Classification', 'Combinaison', 'Binaire', 'Probabilités imprécises']","['This paper proposes a simple framework to combine binary classifiers whose outputs are imprecise probabilities (or are transformed into some imprecise probabilities, e.g., by using confidence intervals). This combination comes down to solve linear programs describing constraints over events (here, subsets of classes). The number of constraints grows linearly with the number of classifiers, making the proposed framework tractable even for problems involving a relatively large number of classes.']",https://hal.science/hal-00655600,"['0.info', '1.info.info-lg', '0.info', '1.info.info-ai', '0.stat', '1.stat.ot']"
"['Elise Lucotte', 'Romain Laurent', 'Evelyne Heyer', 'Laure Ségurel', 'Bruno Toupance']","[777838, 184090, 177102, 174909, 174919]","['romain-laurent', 'evelyne-heyer', 'segurel', 'bruno-toupance']",Detection of Allelic Frequency Differences between the Sexes in Humans: A Signature of Sexually Antagonistic Selection,hal-02122292,2016,10.1093/gbe/evw090,"['Sexual dimorphism', 'Intralocus sexual conflict', 'Sexually antagonistic selection', 'Genome scan', 'X chromosome']","[""Sexually antagonistic (SA) selection, a form of selection that can occur when both sexes have different fitness optima for a trait, is a major force shaping the evolution of organisms. A seminal model developed by Rice (Rice WR. 1984. Sex chromosomes and the evolution of sexual dimorphism. Evolution 38:735-742.) predicts that the X chromosome should be a hotspot for the accumulation of loci under SA selection as compared with the autosomes. Here, we propose a methodological framework designed to detect a specific signature of SA selection on viability, differences in allelic frequencies between the sexes. Applying this method on genome-wide single nucleotide polymorphism (SNP) data in human populations where no sex-specific population stratification could be detected, we show that there are overall significantly more SNPs exhibiting differences in allelic frequencies between the sexes on the X chromosome as compared with autosomes, supporting the predictions of Rice's model. This pattern is consistent across populations and is robust to correction for potential biases such as differences in linkage disequilibrium, sample size, and genotyping errors between chromosomes. Although SA selection is not the only factor resulting in allelic frequency differences between the sexes, we further show that at least part of the identified X-linked loci is caused by such a sex-specific processes.""]",https://hal.science/hal-02122292,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo', '0.sdv', '1.sdv.gen', '2.sdv.gen.gh']"
"['Franz Manni', 'Bruno Toupance', 'Audrey Sabbagh', 'Evelyne Heyer']","[744281, 174919, 177102]","['franz-manni', 'bruno-toupance', 'evelyne-heyer']","New method for surname studies of ancient patrilineal population structures, and possible application to improvement of Y-chromosome sampling.",hal-00263458,2005,10.1002/ajpa.10429,"['Génétique des populations', 'Migrations', 'Démographie']","['Several studies showed that surnames are good markers to infer patrilineal genetic structures of populations, both on regional and microregional scales. As a case study, the spatial patterns of the 9,929 most common surnames of the Netherlands were analyzed by a clustering method called self-organizing maps (SOMs). The resulting clusters grouped surnames with a similar geographic distribution and origin. The analysis was shown to be in agreement with already known features of Dutch surnames, such as 1) the geographic distribution of some well-known locative suffixes, 2) historical census data, 3) the distribution of foreign surnames, and 4) polyphyletic surnames. Thus, these results validate the SOM clustering of surnames, and allow for the generalization of the technique. This method can be applied as a new strategy for a better Y-chromosome sampling design in retrospective population genetics studies, since the idenfication of surnames with a defined geographic origin enables the selection of the living descendants of those families settled, centuries ago, in a given area. In other words, it becomes possible to virtually sample the population as it was when surnames started to be in use. We show that, in a given location, the descendants of those individuals who inhabited the area at the time of origin of surnames can be as low as approximately 20%. This finding suggests 1) the major role played by recent migrations that are likely to have distorted or even defaced ancient genetic patterns, and 2) that standard-designed samplings can hardly portray a reliable picture of the ancient Y-chromosome variability of European populations.']",https://hal.science/hal-00263458,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo']"
"['Vania Yotova', 'Damian Labuda', 'Ewa Zietkiewicz', 'Dominik Gehl', 'Alan Lovell', 'Jean-François Lefebvre', 'Stéphane Bourgeois', 'Emilie Lemieux-Blanchard', 'Marcin Labuda', 'Hélène Vézina', 'Louis Houde', 'Marc Tremblay', 'Bruno Toupance', 'Evelyne Heyer', 'Thomas J. Hudson', 'Claude Laberge']","[174919, 177102]","['bruno-toupance', 'evelyne-heyer']",Anatomy of a founder effect: myotonic dystrophy in Northeastern Quebec.,hal-00216119,2005,10.1007/s00439-005-1298-8,"['Dystrophie', 'Québec']","['Founder effects are largely responsible for changes in frequency profiles of genetic variants in local populations or isolates. They are often recognized by elevated incidence of certain hereditary disorders as observed in regions of Charlevoix and Saguenay-Lac-Saint-Jean (SLSJ) in Northeastern Quebec. Dominantly transmitted myotonic dystrophy (DM1) is highly prevalent in SLSJ where its carrier rate reaches 1/550, compared with 1/5,000 to 1/50,000 elsewhere. To shed light on the origin of DM1 in this region, we have screened 50 nuclear DM1 families from SLSJ and studied the genetic variation in a 2.05 Mb (2.9 cM) segment spanning the site of the expansion mutation. The markers analyzed included 22 biallelic SNPs and two microsatellites. Among 50 independent DM1 chromosomes, we distinguished ten DM1-associated haplotypes and grouped them into three haplotype families, A, B and C, based on the relevant extent of allele sharing between them. To test whether the data were consistent with a single entry of the mutation into SLSJ, we evaluated the age of the founder effect from the proportion of recombinant haplotypes. Taking the prevalent haplotype A1_21 (58%) as ancestral to all the disease-associated haplotypes in this study, the estimated age of the founder effect was 19 generations, long predating the colonization of Nouvelle-France. In contrast, considering A1_21 as ancestral to the haplotype family A only, yielded the estimated founder age of nine generations, consistent with the settlement of Charlevoix at the turn of 17th century and subsequent colonization of SLSJ. We conclude that it was the carrier of haplotype A (present day carrier rate of 1/730) that was a ""driver"" of the founder effect, while minor haplotypes B and C, with corresponding carrier rates of 1/3,000 and 1/10,000, respectively, contribute DM1 to the incidence level known in other populations. Other studies confirm that this might be a general scenario in which a major ""driver"" mutation/haplotype issued from a founder effect is found accompanied by distinct minor mutations/haplotypes occurring at background population frequencies.']",https://hal.science/hal-00216119,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo']"
"['Laure Ségurel', 'Frédéric Austerlitz', 'Bruno Toupance', 'Mathieu M. Gautier', 'Joanna L Kelley', 'Patrick Pasquet', 'Christine Lonjou', 'Myriam Georges', 'Sarah Voisin', 'Corinne Cruaud', 'Arnaud Couloux', 'Tatyana Hegay', 'Almaz Aldashev', 'Renaud Vitalis', 'Evelyne Heyer']","[174909, 175202, 174919, 735868, 845017, 966706, 768749, 908635, 1399808, 920797, 737526, 177102]","['segurel', 'frederic-austerlitz', 'bruno-toupance', 'mathieu-gautier-1976', 'renaud-vitalis', 'evelyne-heyer']",Positive selection of protective variants for type 2 diabetes from the Neolithic onward: a case study in Central Asia,hal-02120826,2013,10.1038/ejhg.2012.295,"['Type 2 diabetes', 'Thrifty genotype', 'Central Asia', 'Genetic adaptation', 'Human evolution']","[""The high prevalence of type 2 diabetes and its uneven distribution among human populations is both a major public health concern and a puzzle in evolutionary biology. Why is this deleterious disease so common, while the associated genetic variants should be removed by natural selection? The 'thrifty genotype' hypothesis proposed that the causal genetic variants were advantageous and selected for during the majority of human evolution. It remains, however, unclear whether genetic data support this scenario. In this study, we characterized patterns of selection at 10 variants associated with type 2 diabetes, contrasting one herder and one farmer population from Central Asia. We aimed at identifying which alleles (risk or protective) are under selection, dating the timing of selective events, and investigating the effect of lifestyle on selective patterns. We did not find any evidence of selection on risk variants, as predicted by the thrifty genotype hypothesis. Instead, we identified clear signatures of selection on protective variants, in both populations, dating from the beginning of the Neolithic, which suggests that this major transition was accompanied by a selective advantage for non-thrifty variants. Combining our results with worldwide data further suggests that East Asia was particularly prone to such recent selection of protective haplotypes. As much effort has been devoted so far to searching for thrifty variants, we argue that more attention should be paid to the evolution of non-thrifty variants.""]",https://hal.science/hal-02120826,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo', '0.sdv', '1.sdv.bid', '2.sdv.bid.evo']"
"['Evelyne Heyer', 'Jean-Tristan Brandenburg', 'Michela Leonardi', 'Bruno Toupance', 'Patricia Balaresque', 'Tanya Hegay', 'Almaz Aldashev', 'Frédéric Austerlitz']","[177102, 1402287, 174919, 180778, 920798, 920797, 175202]","['evelyne-heyer', 'bruno-toupance', 'patricia-balaresque', 'frederic-austerlitz']","Patrilineal populations show more male transmission of reproductive success than cognatic populations in Central Asia, which reduces their genetic diversity",hal-02122584,2015,10.1002/ajpa.22739,"['Cultural transmission of reproductive success', 'Gene culture evolution', 'Patrilineality', 'Human evolution', 'Central asia']","['Objective: The extent to which social organization of human societies impacts the patterns of genetic diversity remains an open question. Here, we investigate the transmission of reproductive success in patrilineal and cognatic populations from Central Asia using a coalescent approach. Methods: We performed a study on the mitochondrial DNA (mtDNA) and Y chromosome polymorphism of patrilineal and cognatic populations from Central Asia. We reconstructed the gene genealogies in each population for both kind of markers and inferred the imbalance level of these genealogies, a parameter directly related to the level of transmission of reproductive success. Results: This imbalance level appeared much stronger for the Y chromosome in patrilineal populations than in cognatic populations, while no difference was found for mtDNA. Furthermore, we showed that this imbalance level correlates negatively with Y-chromosomal, mtDNA, and autosomal genetic diversity. Conclusions: This shows that patrilineality might be one of the factors explaining the male transmission of reproductive success, which, in turn, lead to a reduction of genetic diversity. Thus, notwithstanding the fact that our population genetic approach clearly shows that there is a strong male-biased transmission of reproductive success in patrilineal societies, it also highlights the fact that a social process such as cultural transmission of reproductive success could play an important role in shaping human genetic diversity, although we cannot formally exclude that this transmission has also a genetic component.']",https://hal.science/hal-02122584,"['0.sdv', '1.sdv.gen']"
"['Goki Ly', 'Bérénice Alard', 'Romain Laurent', 'Sophie Lafosse', 'Bruno Toupance', 'Chou Monidarin', 'Gérard Diffloth', 'Frédéric Bourdier', 'Olivier Evrard', 'Samuel Pavard', 'Raphaëlle Chaix']","[1398625, 1375293, 184090, 181910, 174919, 1233026, 745854, 741826]","['romain-laurent', 'lafosse', 'bruno-toupance', 'olivier-evrard', 'samuel-pavard', 'raphaelle-chaix']",Residence rule flexibility and descent groups dynamics shape uniparental genetic diversities in South East Asia,hal-02122543,2018,10.1002/ajpa.23374,"['Matrilineal puzzle', 'Inbreeding', 'Behaviour Keywords residence rule', 'Subject Areas genetics', 'Patrilocal', 'Matrilocal', 'Human genetics']","[""One contribution of 17 to a theme issue 'The evolution of female-biased kinship in humans and other mammals'. In matrilineal populations, the descent group affiliation is transmitted by women whereas the socio-political power frequently remains in the hands of men. This situation, named the 'matrilineal puzzle', is expected to promote local endogamy as a coping mechanism allowing men to maintain their decision-making power over their natal descent group. In this paper, we revisit this 'matrilineal puzzle' from a population genetics' point of view. Indeed, such tendency for local endogamy in matrilineal populations is expected to increase their genetic inbreeding and generate isolation-by-distance patterns between villages. To test this hypothesis, we collected ethno-demographic data for 3261 couples and high-density genetic data for 675 individuals from 11 Southeast Asian populations with a wide range of social organizations: matrilineal and matrilocal populations (M), patrilineal and patrilocal populations (P) or cognatic populations with predominant matrilocal residence (C). We observed that M and C populations have higher levels of village endogamy than P populations, and that such higher village endogamy leads to higher genetic inbreeding. M populations also exhibit isolation-by-distance patterns between villages. We interpret such genetic patterns as the signature of the 'matrilineal puzzle'. Notably, our results suggest that any form of matrilocal marriage (whatever the descent rule is) increases village endogamy. These findings suggest that male dominance, when combined with matrilocality, constrains inter-village migrations, and constitutes an underexplored cultural process shaping genetic patterns in human populations. This article is part of the theme issue 'The evolution of female-biased kinship in humans and other mammals'.""]",https://hal.science/hal-02122543,"['0.sdv', '0.sdv', '1.sdv.gen']"
"['Jérémy Guez', 'Guillaume Achaz', 'François Bienvenu', 'Jean Cury', 'Bruno Toupance', 'Évelyne Heyer', 'Flora Jay', 'Frédéric Austerlitz']","[1399823, 1073344, 1045765, 174919, 177102, 16890, 175202]","['jean-cury', 'bruno-toupance', 'evelyne-heyer', 'flora-jay', 'frederic-austerlitz']","Cultural transmission of reproductive success impacts genomic diversity, coalescent tree topologies and demographic inferences",hal-03875721,2023,10.1093/genetics/iyad007,"['Population genetics', 'Cultural process', 'Demographic inference', 'Genetic diversity', 'Coalescent tree shape', 'Imbalanced topology']","['Cultural Transmission of Reproductive Success (CTRS) has been observed in many human populations as well as other animals. It consists in a positive correlation of non-genetic origin between the progeny size of parents and children. This correlation can result from various factors, such as the social influence of parents on their children, the increase of children’s survival through allocare from uncle and aunts, or the transmission of resources. Here, we study the evolution of genomic diversity through time under CTRS. We show that CTRS has a double impact on population genetics: (1) effective population size decreases when CTRS starts, mimicking a population contraction, and increases back to its original value when CTRS stops; (2) coalescent trees topologies are distorted under CTRS, with higher imbalance and higher number of polytomies. Under long-lasting CTRS, effective population size stabilises but the distortion of tree topology remains, which yields U-shaped Site Frequency Spectra (SFS) under constant population size. We show that this CTRS’ impact yields a bias in SFS-based demographic inference. Considering that CTRS was detected in numerous human and animal populations worldwide, one should be cautious that inferring population past histories from genomic data can be biased by this cultural process.']",https://hal.science/hal-03875721,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo', '0.info', '1.info.info-bi', '0.sdv', '1.sdv.bid', '2.sdv.bid.evo']"
"['Romain Laurent', 'Laure Gineau', 'José Utge', 'Sophie Lafosse', 'Chan Leakhena Phoeung', 'Tatyana Hegay', 'Robert Olaso', 'Anne Boland', 'Jean-François Deleuze', 'Bruno Toupance', 'Evelyne Heyer', 'Anne-Louise Leutenegger', 'Raphaëlle Chaix']","[184090, 1388617, 181910, 1399808, 774936, 757786, 174919, 177102, 175762, 741826]","['romain-laurent', 'lafosse', 'bruno-toupance', 'evelyne-heyer', 'anne-louise-leutenegger', 'raphaelle-chaix']",Measuring the Efficiency of Purging by non-random Mating in Human Populations,hal-04632944,2024,10.1093/molbev/msae094,"['Purifying selection', 'Kinship', 'Mate choice', 'Inbreeding', 'Genomics', 'Deleterious variants', 'Mutational load']","['Human populations harbor a high concentration of deleterious genetic variants. Here, we tested the hypothesis that non-random mating practices affect the distribution of these variants, through exposure in the homozygous state, leading to their purging from the population gene pool. To do so, we produced whole-genome sequencing data for two pairs of Asian populations exhibiting different alliance rules and rates of inbreeding, but with similar effective population sizes. The results show that populations with higher rates of inbred matings do not purge deleterious variants more efficiently. Purging therefore has a low efficiency in human populations, and different mating practices lead to a similar mutational load.']",https://hal.science/hal-04632944,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gh', '0.sdv', '1.sdv.gen', '2.sdv.gen.gpo', '0.shs', '1.shs.anthro-bio']"
"['Mouna Benchekroun', 'Pedro Elkind Velmovitsky', 'Dan Istrate', 'Vincent Zalc', 'Plinio Pelegrini Morita', 'Dominique Lenne']","[752964, 1355766, 170653, 751467, 1355767, 171513]","['mouna-benchekroun', 'dan-istrate', 'vincent-zalc', 'dlenne']",Cross Dataset Analysis for Generalizability of HRV-Based Stress Detection Models,hal-04472605,2023,10.3390/s23041807,"['Stress monitoring', 'E-health', 'IoT', 'Stress bio-markers', 'Generalizability']","['Stress is an increasingly prevalent mental health condition across the world. In Europe, for example, stress is considered one of the most common health problems, and over USD 300 billion are spent on stress treatments annually. Therefore, monitoring, identification and prevention of stress are of the utmost importance. While most stress monitoring is carried out through self-reporting, there are now several studies on stress detection from physiological signals using Artificial Intelligence algorithms. However, the generalizability of these models is only rarely discussed. The main goal of this work is to provide a monitoring proof-of-concept tool exploring the generalization capabilities of Heart Rate Variability-based machine learning models. To this end, two Machine Learning models are used, Logistic Regression and Random Forest to analyze and classify stress in two datasets differing in terms of protocol, stressors and recording devices. First, the models are evaluated using leave-one-subject-out cross-validation with train and test samples from the same dataset. Next, a cross-dataset validation of the models is performed, that is, leave-one-subject-out models trained on a Multi-modal Dataset for Real-time, Continuous Stress Detection from Physiological Signals dataset and validated using the University of Waterloo stress dataset. While both logistic regression and random forest models achieve good classification results in the independent dataset analysis, the random forest model demonstrates better generalization capabilities with a stable F1 score of 61%. This indicates that the random forest can be used to generalize HRV-based stress detection models, which can lead to better analyses in the mental health and medical research field through training and integrating different models.']",https://hal.science/hal-04472605,['0.spi']
"['Idir Benouaret', 'Dominique Lenne']","[1113557, 171513]",['dlenne'],A Package Recommendation Framework for Trip Planning Activities,hal-01404716,2016,10.1145/2959100.2959183,"['Top-k', 'Diversity', 'Trip planning', 'Recommender system', 'Package']","['Classical recommender systems provide users with ranked lists of recommendations, where each one consists of a single item. However, these ranked lists are not suitable for applications such as trip planning, which deal with heterogeneous items. In this paper, we focus on the problem of recommending a set of packages to the user, where each package is constituted with a set of different Points of Interest that may constitute a tour. Given a collection of POIs, our goal is to recommend the most interesting packages for the user, where each package satisfies the budget constraints. We formally define the problem and we present a novel composite recommendation system, inspired from composite retrieval. Experimental evaluation of our proposed system, using a real-world dataset demonstrates its quality and its ability to improve both diversity and relevance of recommendations.']",https://inria.hal.science/hal-01404716,"['0.info', '1.info.info-ir', '0.info', '1.info.info-ai', '0.info', '1.info.info-lg']"
"['Mouna Benchekroun', 'Baptiste Chevallier', 'Vincent Zalc', 'Dan Istrate', 'Dominique Lenne', 'Nicolas Vera']","[752964, 170653, 171513, 1355771]","['mouna-benchekroun', 'dan-istrate', 'dlenne']",The Impact of Missing Data on Heart Rate Variability Features: A Comparative Study of Interpolation Methods for Ambulatory Health Monitoring,hal-04472617,2023,10.1016/j.irbm.2023.100776,"['Stress', 'HRV', 'Signal processing']","[""h i g h l i g h t s g r a p h i c a l a b s t r a c t • Real time HRV analysis of R-R time series with missing data. • Higher impact of interpolation on frequency domain features • Better RMSSD estimation without interpolation beyond 50% missing data. • Combination of different interpolation methods according to both missing values' percentage and targeted HRV features.""]",https://hal.science/hal-04472617,['0.spi']
"['Idir Benouaret', 'Dominique Lenne']","[1113557, 171513]",['dlenne'],Combining Semantic and Collaborative Recommendations to Generate Personalized Museum Tours,hal-01319257,2015,10.1007/978-3-319-23201-0_48,"['Semantic web', 'Recommender systems', 'Context', 'Cultural heritage']","['Our work takes place in the field of support systems to museum visits and access to cultural heritage. Visitors of museums are often overwhelmed by the information available in the space they are exploring. Therefore, finding relevant artworks to see in a limited amount of time is a difficult task. Our goal is to design a recommender system for mobile devices that adapts to the users preferences and is sensitive to their contexts (location, time, expertise...). This system aims to improve the visitors’ experience and help them build their tours on-site according to their preferences and constraints. In this paper we describe our recommendation framework, which consists in a hybrid recommendation system. It combines a semantic approach for the representation of museum knowledge using ontologies and thesauruses with a semantically-enhanced collaborative filtering method. A contextual post-filtering enables the generation of a highly personalized tour based on the physical environment, the location of the visitors and the time they want to spend in the museum. This work is applied to the Compiègne Imperial Palace museum in Picardy.']",https://hal.science/hal-01319257,"['0.info', '1.info.info-ir', '0.info', '1.info.info-ai', '0.info', '1.info.info-lg']"
"['Amjad Abou Assali', 'Dominique Lenne', 'Bruno Debray']","[859731, 171513]",['dlenne'],Case retrieval in ontology-based CBR systems,ineris-00973352,2009,10.1007/978-3-642-04617-9_71,"['CAPTEURS', 'ONTOLOGIE', 'RAISONNEMENT A PARTIR DE CAS --- CASE-BASED REASONING', 'ONTOLOGY', 'HETEROGENEOUS CASE BASE', 'SIMILARITY MEASURES', 'SIMILARITY REGIONS']","[""This paper presents our knowledge-intensive Case-Based Reasoning platform for diagnosis, COBRA. It integrates domain knowledge along with cases in an ontological structure. COBRA allows users to describe cases using any concept or instance of a domain ontology, which leads to a heterogeneous case base. Cases heterogeneity complicates their retrieval since correspondences must be identified between query and case attributes. We present in this paper our system architecture and the case retrieval phase. Then, we introduce the notions of similarity regions and attributes' roles used to overcome cases heterogeneity problems.""]",https://ineris.hal.science/ineris-00973352,['0.spi']
"['Pierre Darlu', 'Gerrit Bloothooft', 'Alessio Boattini', 'Leendert Brouwer', 'Matthijs Brouwer', 'Guy Brunet', 'Pascal Chareille', 'James Cheshire', 'Richard Coates', 'Kathrin Dräger', 'Bertrand Desjardins', 'Patrick Hanks', 'Paul Longley', 'Kees Mandemakers', 'Pablo Mateos', 'Davide Pettener', 'Antonella Useli', 'Franz Manni']","[1103099, 2037, 744281]","['pascal-chareille', 'franz-manni']",The Family Name as Socio-Cultural Feature and Genetic Metaphor: From Concepts to Methods,hal-03183406,2012,10.3378/027.084.0205,"['Surnames', 'Population genetics', 'Database', 'Migration', 'Spacetime evolution', 'Y chromosome', 'Geographical patterns', 'Historical demography']","['A recent workshop entitled ‘‘The Family Name as Socio-CulturalFeature and Genetic Metaphor: From Concepts to Methods” was held inParis in December 2010, sponsored by the French National Centre forScientific Research (CNRS) and by the journal Human Biology. Thisworkshop was intended to foster a debate on questions related to the familynames and to compare different multidisciplinary approaches involvinggeneticists, historians, geographers, sociologists and social anthropologists.This collective paper presents a collection of selected communications.']",https://hal.science/hal-03183406,"['0.shs', '0.sdv', '1.sdv.gen', '2.sdv.gen.gpo']"
"['Alessio Boattini', 'Antonella Lisa', 'Ornella Fiorani', 'Gianna Zei', 'Davide Pettener', 'Franz Manni']",[744281],['franz-manni'],"General Method to Unravel Ancient Population Structures through Surnames, Final Validation on Italian Data",hal-02973093,2012,10.3378/027.084.0302,"['SURNAMES', 'FAMILY NAMES', 'Y-CHROMOSOME', 'ITALY', 'MIGRATIONS', 'POPULATION GENETICS', 'DEMOGRAPHY']","['We analyze the geographic location of 77,451 different Italian surnames (17,579,891 individuals) obtained from the lists of telephone subscribers of the year 1993. By using a specific neural network analysis (Self-Organizing Maps, SOMs), we automatically identify the geographic origin of 49,117 different surnames. To validate the methodology, we compare the results to a study, previously conducted, on the same database, with accurate supervised methods. By comparing the results, we find an overlap of 97%, meaning that the SOMs methodology is highly reliable and well traces back the geographic origin of surnames at the time of their introduction (Late Middle Ages/Renaissance in Italy). SOMs results enables one to distinguish monophyletic surnames from polyphyletic ones, that is surnames having had a single geographic and historic origin from those that started to be in use, with an identical spelling, in different locations (respectively, 76.06% and 21.05% of the total). As we are interested in geographic origins, polyphyletic surnames are excluded from further analyses. By comparing the present location of each monophyletic surname to its inferred geographic origin in late Middle Ages/Renaissance, we measure the extent of the migrations having occurred in Italy since that time. We find that the percentage of individuals presently living in the very area where their surname started to be in use centuries ago is extremely variable (ranging from 22.77% to 77.86% according to the province), thus meaning that self-assessed regional identities seldom correspond to the “autochthony” they imply. For example the upper part of the Thyrennian coast (Northern Latium, Tuscany) has a strong identity but few “autochthonous” inhabitants (∼28%) having been a passageway from the North to the South of Italy.']",https://hal.science/hal-02973093,"['0.shs', '1.shs.anthro-bio', '0.shs', '1.shs.demo', '0.sdv', '1.sdv.gen', '2.sdv.gen.gpo']"
"['Italo Barrai', 'Alvaro Rodriguez-Larralde', 'Franz Manni', 'Chiara Scapoli']",[744281],['franz-manni'],Isonymy and Isolation by Distance in the Netherlands,hal-03183347,2002,10.1353/hub.2002.0016,"['Isonymy', 'Inbreeding', 'Geographic structure', ""Lasker's distance""]","[""The isonymy structure of the Netherlands was studied using the surname distribution of 2.4 million private telephone users selected from a 1996 commercial CD-ROM containing the names of 6.3 million users in the country. The users were distributed in 226 towns selected on a geographic basis to form an approximately regular grid throughout the Netherlands. Names of telephone users in each town were downloaded from the CD-ROM, with private users being selected for inclusion in the analysis. The shortest linear distance between several nearest neighboring towns was less than 2 km (e.g., Kampen and Ijsselmuiden, Krommen and Zaandijk, Hendrikdo and Papendrecht) and the longest distance was 326 km (Delfzijl and Oostburg ZL). The number of different surnames revealed by the analysis was 126,485. Lasker's distance, the negative value of the logarithm of isonymy between localities, was found to be significantly correlated with linear geographic distance, with r = 0.47 +/- 0.006. A dendrogram built using the matrix of isonymy distances, using the nearest neighbor-joining method, separates the Dutch towns into several clusters, most of them correlated with traditional Dutch regions. Comparisons with the results of previous analyses of the structure of other European countries are given. From the present analysis, isolation by distance emerges clearly, and it is relevant, although much weaker than in Switzerland, Austria, Italy, and Germany. The random component of inbreeding estimated from isonymy indicates a considerable degree of homogeneity in the Netherlands.""]",https://hal.science/hal-03183347,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo', '0.shs']"
"['Lama Tarsissi', 'Laurent Vuillon']","[22086, 841767]",['lama-tarsissi'],Second order balance property on Christoffel words,hal-02433984,2020,10.1007/978-3-030-43120-4_23,"['Balance property', 'Second order balance property', 'Christoffel words', 'SternBrocot tree', 'Continued fractions']","['In this paper we study the balance matrix that gives the order of balance of any binary word. In addition, we define for Christoffel words a new matrix called second order balance matrix. This matrix gives more information on the balance property of a word that codes the number of occurrences of the letter 1 in successive blocks of the same length for the studied Christoffel word. By taking the maximum of the Second order balance matrix we define the second order of balance and we are able to order the Christoffel words according to these values. Our construction uses extensively the continued fraction associated with the slope of each Christoffel word, and we prove a recursive formula based on fine properties of the Stern-Brocot tree to construct second order matrices. Finally, we show that an infinite path on the Stern-Brocot tree, which minimizes the second order of balance is given by a path associated with the Fibonacci word.']",https://hal.science/hal-02433984v2,"['0.math', '1.math.math-ds', '0.info', '1.info.info-dm']"
"['Michela Ascolese', 'Andrea Frosini', 'William Lawrence Kocay', 'Lama Tarsissi']",[22086],['lama-tarsissi'],Properties of Unique Degree Sequences of 3-Uniform Hypergraphs,hal-03232982,2021,10.1007/978-3-030-76657-3_22,"['Hypergraph', 'Graphic sequence', 'Uniqueness problem', 'Analysis of algorithms']","['In 2018 Deza et al. proved the NP-completeness of deciding wether there exists a 3-uniform hypergraph compatible with a given degree sequence. A well known result of Erdös and Gallai (1960) shows that the same problem related to graphs can be solved in polynomial time. So, it becomes relevant to detect classes of uniform hypergraphs that are reconstructible in polynomial time. In particular, our study concerns 3-uniform hypergraphs that are defined in the NP-completeness proof of Deza et al. Those hypergraphs are constructed starting from a non-increasing sequence s of integers and have very interesting properties. In particular, they are unique, i.e., there do not exist two non isomorphic 3-uniform hypergraphs having the same degree sequence ds. This property makes us conjecture that the reconstruction of these hypergraphs from their degree sequences can be done in polynomial time. So, we first generalize the computation of the ds degree sequences by Deza et al., and we show their uniqueness. We proceed by defining the equivalence classes of the integer sequences determining the same ds and we define a (minimal) representative. Then, we find the asymptotic growth rate of the maximal element of the representatives in terms of the length of the sequence, with the aim of generating and then reconstructing them. Finally, we show an example of a unique 3-uniform hypergraph similar to those defined by Deza et al. that does not admit a generating integer sequence s. The existence of this hypergraph makes us conjecture an extended generating algorithm for the sequences of Deza et al. to include a much wider class of unique 3-uniform hypergraphs. Further studies could also include strategies for the identification and reconstruction of those new sequences and hypergraphs.']",https://hal.science/hal-03232982,"['0.info', '1.info.info-dm']"
['Marie-Hélène Abel'],[8329],['marie-helene-abel'],Knowledge map-based web platform to facilitate organizational learning return of experiences,hal-01128677,2015,10.1016/j.chb.2014.10.012,"['Organizational learning', 'Knowledge sharing', 'Web platform']","['In this paper, we discuss the role played by a knowledge map in the designing of a web platform for facilitating organizational learning. Globalization, accelerated innovation and ICT (information and communication technology) have changed our economic environment. They have transformed the way we learn and work. In such a context, the knowledge capital of companies is increasingly crucial. Companies realized the importance of using information technology tools to promote organizational learning. With MEMORAe project, our goal is to model and design an original knowledge map-based web platform as support for organizational learning. After presenting the knowledge map-based web platform designed, we discuss results of its usage in academic contexts.']",https://hal.science/hal-01128677,"['0.info', '1.info.eiah', '0.info', '1.info.info-ai', '0.info', '1.info.info-wb']"
"['Qiang Li', 'Marie-Hélène Abel', 'Jean-Paul Barthès']","[770653, 8329, 6556]","['marie-helene-abel', 'jean-paul-barthes']",Modeling and exploiting collaborative traces in web-based collaborative working environment,hal-00942222,2014,10.1016/j.chb.2013.04.028,"['Collaborative working environment', 'Trace-based system', 'Collaborative trace', 'Collaborative engineering', 'Experience Management']","['In a Web-based Collaborative Working Environment (CWE), traces are always produced by past activities or interactions. Although every trace derives from the stored information, the modeled trace not only represents knowledge but also experience from the interactive actions among the actors or between an actor and the system. Normally, with the increasing complexity of group structure and frequent collaboration needs, the existing interactions become more difficult to grasp and analyze. This article focuses on defining, modeling and exploiting the various traces in the context of CWE, in particular Collaborative Traces (CTs) left in the shared/collaborative workspace. A model of collaborative trace that can efficiently enrich group experience and facilitate group collaboration is proposed and explained in details. Furthermore, we introduce and define a type of complex filter as a possible approach to exploit the traces. Four basic scenarios of collaborative trace exploitation are presented to describe its effects and advantages in CWE. A general model and framework of CT-based SWOT Analysis is discussed with examples. For practical applications, the validation of our model is examined in the context of the collaborative platform E-MEMORAe2.0. In addition, a remark concerning recommendations based on collaborative traces is given in the conclusion.']",https://hal.science/hal-00942222,"['0.info', '1.info.info-ai']"
"['Etienne Deparis', 'Marie-Hélène Abel', 'Lortal Gaelle', 'Juliette Mattioli']","[1333598, 8329, 14487, 737491]","['etienne-deparis', 'marie-helene-abel', 'gaelle-lortal', 'juliette-mattioli']",Information Management from Social and Documentary Sources in Organizations,hal-01137349,2014,10.1016/j.chb.2013.10.033,"['Ontology', 'Web 20', 'Knowledge ecosystem', 'Social networks']","['The wide adoption of social and connected tools in organizations leads them to think again about their behavior regarding how they manage their resources. They now consider the resources users can produce on various social media and how correctly index them in the organization knowledge base. We present in this paper the model of a digital ecosystem, which permits the indexing of either documentary resources or those produced on a social platform with the help of an ontology.']",https://hal.science/hal-01137349,"['0.info', '0.shs', '1.shs.gestion', '0.info', '1.info.info-ai', '0.info', '1.info.info-wb']"
"['Ngoc Luyen Le', 'Marie-Hélène Abel', 'Philippe Gouspillou']","[174232, 8329]","['luyen-le-ngoc', 'marie-helene-abel']",Improving Semantic Similarity Measure Within a Recommender System Based-on RDF Graphs,hal-04161309,2023,10.1007/978-3-031-33258-6_42,"['Semantic Similarity Ontology Recommender System', 'Semantic Similarity', 'Ontology', 'Recommender System']","[""In today's era of information explosion, more users are becoming more reliant upon recommender systems to have better advice, suggestions, or inspire them. The measure of the semantic relatedness or likeness between terms, words, or text data plays an important role in different applications dealing with textual data, as in a recommender system. Over the past few years, many ontologies have been developed and used as a form of structured representation of knowledge bases for information systems. The measure of semantic similarity from ontology has developed by several methods. In this paper, we propose and carry on an approach for the improvement of semantic similarity calculations within a recommender system based-on RDF graphs.""]",https://hal.science/hal-04161309,"['0.info', '1.info.info-ir']"
"['Ala Atrash', 'Marie-Hélène Abel', 'Claude Moulin']","[952294, 8329, 8386]","['marie-helene-abel', 'claude-moulin']",Notes and annotations as information resources in a social networking platform,hal-01121206,2015,10.1016/j.chb.2014.12.005,"['Semantic modeling', 'Web platform', 'Knowledge management', 'Note and annotation taking']","['Taking notes and annotations contributes in the learning process. Many platforms are developed as Computer Supported Collaborative Learning (CSCL) thanks to advancements in new technologies. A common limitation of these platforms is the restricted ability to share/retrieve notes and annotations (Su, Yang, Hwang, & Zhang, 2010a). This is because the annotations in these platforms are disconnected from the information system and they are only accessible in the annotation system. As a result, the annotations could not be indexed as any other information resources (e.g., a document). This means that the annotations are not accessible/visible like other resources. In this paper, we present an original semantic model in which notes and annotations are modeled as information resources. The semantic model is used within the MEMORAe web platform. Then we detail an experiment of collaborative learning made within a university course using the MEMORAe web platform. The feedback of this experiment shows us that students are satisfied with the use of the MEMORAe web platform for helping them to index and retrieve notes and annotations as any information resources.']",https://hal.science/hal-01121206,"['0.info', '1.info.info-ai', '0.info', '1.info.eiah', '0.info', '1.info.info-wb']"
"['Ngoc Luyen Le', 'Marie-Hélène Abel', 'Philippe Gouspillou']",[174232],['luyen-le-ngoc'],Designing a User Contextual Profile Ontology: A Focus on the Vehicle Sales Domain,hal-04645398,2024,10.1007/978-3-031-51664-1_14,"['Ontology', 'User Modeling', 'Knowledge base', 'Contextual Profile']","['In the digital age, it is crucial to understand and tailor experiences for users interacting with systems and applications. This requires the creation of user contextual profiles that combine user profiles with contextual information. However, there is a lack of research on the integration of contextual information with different user profiles. This study aims to address this gap by designing a user contextual profile ontology that considers both user profiles and contextual information on each profile. Specifically, we present a design and development of the user contextual profile ontology with a focus on the vehicle sales domain. Our designed ontology serves as a structural foundation for standardizing the representation of user profiles and contextual information, enhancing the system’s ability to capture user preferences and contextual information of the user accurately. Moreover, we illustrate a case study using the User Contextual Profile Ontology in generating personalized recommendations for vehicle sales domain.']",https://inria.hal.science/hal-04645398,"['0.info', '1.info.info-ir']"
"['Xuan-Truong Vu', 'Marie-Hélène Abel', 'Pierre Morizet-Mahoudeaux']","[949454, 8329, 861410]",['marie-helene-abel'],A user-centered and group-based approach for social data filtering and sharing,hal-01101056,2015,10.1016/j.chb.2014.11.079,"['Collaboration', 'Social networking sites', 'Social Data Aggregation', 'Content management', 'Information filtering', 'Information sharing']","['Social networking sites (SNSs) like Facebook, Google+, Twitter, LinkedIn have become a very important part of our daily life. People are connected to multiple SNSs for networking, communicating, collaborating, sharing and seeking for information. Although, the diversity of current SNSs increases and enriches our online experience, they cause some problems. One of the major issues is that users are often overwhelmed by the huge number of social data. It is even worse as these social data are scattered across disconnected SNSs. To address such problems, we propose a user-centered and group-based approach for social data filtering and sharing. First, it allows users to aggregate their social data from different SNSs and to extract relevant contents. Users explicitly define their interests via specific queries, using information filtering techniques, the system will retrieve new corresponding contents. Second, it is expected to extend its first user-centered purpose by allowing group-based information sharing and management. Users can share some part of their own social data with and collectively define the information organization within their respective groups. To describe further and illustrate our proposed approach, a system architecture and a prototype are also presented in this paper. A primary test was carried out and showed encouraging results confirming the added values of our approach.']",https://hal.science/hal-01101056,"['0.info', '0.info', '1.info.info-iu', '0.info', '1.info.info-cy', '0.info', '1.info.info-wb']"
"['Maged Jabbour', 'Philippe Bonnifait', 'Véronique Cherfaoui']","[7088, 182349]","['philippe-bonnifait', 'veronique-cherfaoui']",Map-Matching Integrity using Multi-Sensor Fusion and Multi- Hypothesis Road Tracking,hal-00401783,2008,10.1080/15472450802448179,"['Multi-Hypothesis Tracking', 'Integrity', 'GNSS-based Localization', 'Map-Matching']","['Efficient and reliable map matching algorithms are essential for Advanced Driver Assistance Systems. While most of the existing solutions fail to provide trustworthy outputs when the situation is ambiguous (road intersections, roundabouts, parallel roads ...), we present in this paper a new map-matching method based on a multi-hypothesis road tracking that takes advantage of the geographical database road connectedness to provide a reliable road-matching solution with a confidence indicator that can be used for integrity monitoring purposes']",https://hal.science/hal-00401783,"['0.spi', '1.spi.auto']"
"['Sergio Alberto Rodriguez Florez', 'Vincent Fremont', 'Philippe Bonnifait', 'Véronique Cherfaoui']","[113, 6530, 7088, 182349]","['sergio-rodriguez', 'vincent-fremont', 'philippe-bonnifait', 'veronique-cherfaoui']",Multi-modal object detection and localization for high integrity driving assistance,hal-00777387,2014,10.1007/s00138-011-0386-0,"['Multi-modal perception', 'Visual odometry', 'Object tracking', 'Dynamic map', 'Intelligent vehicles']","['Much work is currently devoted to increasing the reliability, completeness and precision of the data used by driving assistance systems, particularly in urban environments. Urban environments represent a particular challenge for the task of perception, since they are complex, dynamic and completely variable. This article examines a multi-modal perception approach for enhancing vehicle localization and the tracking of dynamic objects in a world-centric map. 3D ego-localization is achieved by merging stereo vision perception data and proprioceptive information from vehicle sensors. Mobile objects are detected using a multi-layer lidar that is simultaneously used to identify a zone of interest to reduce the complexity of the perception process. Object localization and tracking is then performed in a fixed frame which simplifies analysis and understanding of the scene. Finally, tracked objects are confirmed by vision using 3D dense reconstruction in focused regions of interest. Only confirmed objects can generate an alarm or an action on the vehicle. This is crucial to reduce false alarms that affect the trust that the driver places in the driving assistance system. Synchronization issues between the sensing modalities are solved using predictive filtering. Real experimental results are reported so that the performance of the multi-modal system may be evaluated.']",https://hal.science/hal-00777387,"['0.info', '1.info.info-rb', '0.info', '1.info.info-ti']"
"['Zaid Abdi Alkareem Alyasseri', 'Mohammed Azmi Al-Betar', 'Iyad Abu Doush', 'Mohammed Awadallah', 'Ammar Kamal Abasi', 'Sharif Naser Makhadmeh', 'Osama Ahmad Alomari', 'Karrar Hameed Abdulkareem', 'Afzan Adam', 'Robertas Damasevicius', 'Mazin Abed Mohammed', 'Raed Abu Zitar']","[1219332, 1219308, 1219333, 1219307, 1219334, 1219335, 1219336, 1219337, 1219338, 1219339, 1181086]",,Review on COVID ‐19 diagnosis models based on machine learning and deep learning approaches,hal-03955389,2022,10.1111/exsy.12759,"['2019-nCoV', 'Deep learning', 'COVID-19 dataset', 'Machine learning', 'COVID-19']","['COVID-19 is the disease evoked by a new breed of coronavirus called the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Recently, COVID-19 has become a pandemic by infecting more than 152 million people in over 216 countries and territories. The exponential increase in the number of infections has rendered traditional diagnosis techniques inefficient. Therefore, many researchers have developed several intelligent techniques, such as deep learning (DL) and machine learning (ML), which can assist the healthcare sector in providing quick and precise COVID-19 diagnosis. Therefore, this paper provides a comprehensive review of the most recent DL and ML techniques for COVID-19 diagnosis. The studies are published from December 2019 until April 2021. In general, this paper includes more than 200 studies that have been carefully selected from several publishers, such as IEEE, Springer and Elsevier. We classify the research tracks into two categories: DL and ML and present COVID-19 public datasets established and extracted from different countries. The measures used to evaluate diagnosis methods are comparatively analysed and proper discussion is provided. In conclusion, for COVID-19 diagnosing and outbreak prediction, SVM is the most widely used machine learning mechanism, and CNN is the most widely used deep learning mechanism. Accuracy, sensitivity, and specificity are the most widely used measurements in previous studies. Finally, this review paper will guide the research community on the upcoming development of machine learning for COVID-19 and inspire their works for future development. This review paper will guide the research community on the upcoming development of ML and DL for COVID-19 and inspire their works for future development.']",https://hal.science/hal-03955389,"['0.info', '1.info.info-ai']"
"['Raed Abu Zitar', 'Mohammed Azmi Al-Betar', 'Mohammed Awadallah', 'Iyad Abu Doush', 'Khaled Assaleh']",[1219308],,"An Intensive and Comprehensive Overview of JAYA Algorithm, its Versions and Applications",hal-03955349,2022,10.1007/s11831-021-09585-8,"['JAYA Algorithm', 'Metaheuristics', 'Optimization', 'Exploration', 'Exploitation']","['In this review paper, JAYA algorithm, which is a recent population-based algorithm is intensively overviewed. The JAYA algorithm combines the survival of the fittest principle from evolutionary algorithms as well as the global optimal solution attractions of Swarm Intelligence methods. Initially, the optimization model and convergence characteristics of JAYA algorithm are carefully analyzed. Thereafter, the proposed versions of JAYA algorithm have been surveyed such as modified, binary, hybridized, parallel, chaotic, multi-objective and others. The various applications tackled using relevant versions of JAYA algorithm are also discussed and summarized based on several problem domains. Furthermore, the open sources code of JAYA algorithm are identified to provide enrich resources for JAYA research communities. The critical analysis of JAYA algorithm reveals its advantages and limitations in dealing with optimization problems. Finally, the paper ends up with conclusion and possible future enhancements suggested to improve the performance of JAYA algorithm. The reader of this overview will determine the best domains and applications used by JAYA algorithm and can justify their JAYA-related contributions.']",https://hal.science/hal-03955349,"['0.info', '1.info.info-ai']"
"['Laith Abualigah', 'Raed Abu Zitar', 'Khaled Almotairi', 'Ahmad Mohdaziz Hussein', 'Mohamed Abd Elaziz', 'Mohammad Reza Nikoo', 'Amir Gandomi']","[1219306, 1219340, 1219341, 1219312]",,"Wind, Solar, and Photovoltaic Renewable Energy Systems with and without Energy Storage Optimization: A Survey of Advanced Machine Learning and Deep Learning Techniques",hal-03955395,2022,10.3390/en15020578,"['Wind energy', 'Solar energy', 'Photovoltaic PV', 'Renewable energy systems', 'Storage systems', 'Power generation', 'Machine learning', 'Deep learning', 'Optimization', 'Algorithm', 'Artificial Intelligence AI', 'Survey']","['Nowadays, learning-based modeling methods are utilized to build a precise forecast model for renewable power sources. Computational Intelligence (CI) techniques have been recognized as effective methods in generating and optimizing renewable tools. The complexity of this variety of energy depends on its coverage of large sizes of data and parameters, which have to be investigated thoroughly. This paper covered the most resent and important researchers in the domain of renewable problems using the learning-based methods. Various types of Deep Learning (DL) and Machine Learning (ML) algorithms employed in Solar and Wind energy supplies are given. The performance of the given methods in the literature is assessed by a new taxonomy. This paper focus on conducting comprehensive state-of-the-art methods heading to performance evaluation of the given techniques and discusses vital difficulties and possibilities for extensive research. Based on the results, variations in efficiency, robustness, accuracy values, and generalization capability are the most obvious difficulties for using the learning techniques. In the case of the big dataset, the effectiveness of the learning techniques is significantly better than the other computational methods. However, applying and producing hybrid learning techniques with other optimization methods to develop and optimize the construction of the techniques is optionally indicated. In all cases, hybrid learning methods have better achievement than a single method due to the fact that hybrid methods gain the benefit of two or more techniques for providing an accurate forecast. Therefore, it is suggested to utilize hybrid learning techniques in the future to deal with energy generation problems.']",https://hal.science/hal-03955395,"['0.info', '1.info.info-ai']"
"['Serdar Ekinci', 'Davut Izci', 'Laith Abualigah', 'Raed Abu Zitar']","[1219317, 1219318, 1219306]",,A Modified Oppositional Chaotic Local Search Strategy Based Aquila Optimizer to Design an Effective Controller for Vehicle Cruise Control System,hal-03984636,2023,10.1007/s42235-023-00336-y,"['Aquila optimizer', 'Chaotic local search', 'Modified opposition-based learning', 'Real PIDD2 controller', 'Vehicle cruise control system', 'Bionic engineering']","[""In this work, we propose a real proportional-integral-derivative plus second-order derivative (PIDD2) controller as an efficient controller for vehicle cruise control systems to address the challenging issues related to efficient operation. In this regard, this paper is the first report in the literature demonstrating the implementation of a real PIDD2 controller for controlling the respective system. We construct a novel and efficient metaheuristic algorithm by improving the performance of the Aquila Optimizer via chaotic local search and modified opposition-based learning strategies and use it as an excellently performing tuning mechanism. We also propose a simple yet effective objective function to increase the performance of the proposed algorithm (CmOBL-AO) to adjust the real PIDD2 controller's parameters effectively. We show the CmOBL-AO algorithm to perform better than the differential evolution algorithm, gravitational search algorithm, African vultures optimization, and the Aquila Optimizer using well-known unimodal, multimodal benchmark functions. CEC2019 test suite is also used to perform ablation experiments to reveal the separate contributions of chaotic local search and modified opposition-based learning strategies to the CmOBL-AO algorithm. For the vehicle cruise control system, we confirm the more excellent performance of the proposed method against particle swarm, gray wolf, salp swarm, and original Aquila optimizers using statistical, Wilcoxon signed-rank, time response, robustness, and disturbance rejection analyses. We also use fourteen reported methods in the literature for the vehicle cruise control system to further verify the more promising performance of the CmOBL-AO-based real PIDD2 controller from a wider perspective. The excellent performance of the proposed method is also illustrated through different quality indicators and different operating speeds. Lastly, we also demonstrate the good performing capability of the CmOBL-AO algorithm for real traffic cases. We show the CmOBL-AO-based real PIDD2 controller as the most efficient method to control a vehicle cruise control system.""]",https://hal.sorbonne-universite.fr/hal-03984636,['0.info']
"['Laith Abualigah', 'Mahmoud Habash', 'Essam Said Hanandeh', 'Ahmad Mohdaziz Hussein', 'Mohammad Al Shinwan', 'Raed Abu Zitar', 'Heming Jia']",[1219306],,Improved Reptile Search Algorithm by Salp Swarm Algorithm for Medical Image Segmentation,hal-03978077,2023,10.1007/s42235-023-00332-2,"['Bioinspired', 'Reptile Search Algorithm', 'Salp Swarm Algorithm', 'Multi-level thresholding', 'Image segmentation', 'Meta-heuristic algorithm']","['This study proposes a novel nature-inspired meta-heuristic optimizer based on the Reptile Search Algorithm combed with Salp Swarm Algorithm for image segmentation using gray-scale multi-level thresholding, called RSA-SSA. The proposed method introduces a better search space to find the optimal solution at each iteration. However, we proposed RSA-SSA to avoid the searching problem in the same area and determine the optimal multi-level thresholds. The obtained solutions by the proposed method are represented using the image histogram. The proposed RSA-SSA employed Otsu’s variance class function to get the best threshold values at each level. The performance measure for the proposed method is valid by detecting fitness function, structural similarity index, peak signal-to-noise ratio, and Friedman ranking test. Several benchmark images of COVID-19 validate the performance of the proposed RSA-SSA. The results showed that the proposed RSA-SSA outperformed other metaheuristics optimization algorithms published in the literature.']",https://hal.sorbonne-universite.fr/hal-03978077,['0.info']
"['Osama Ahmad Alomari', 'Sharif Naser Makhadmeh', 'Mohammed Azmi Al-Betar', 'Zaid Abdi Alkareem Alyasseri', 'Iyad Abu Doush', 'Ammar Kamal Abasi', 'Mohammed Awadallah', 'Raed Abu Zitar']","[1219336, 1219333, 1219320]",,Gene selection for microarray data classification based on Gray Wolf Optimizer enhanced with TRIZ-inspired operators,hal-04017212,2021,10.1016/j.knosys.2021.107034,"['Gray Wolf Optimizer', 'Gene selection', 'Optimization', 'TRIZ', 'RMRMR', 'SVM', 'Classification']","['DNA microarray technology is the fabrication of a single chip to contain a thousand genetic codes. Each microarray experiment can analyze many thousands of genes in parallel. The outcomes of the DNA microarray is a table/matrix, called gene expression data. Pattern recognition algorithms are widely applied to gene expression data to differentiate between health and cancerous patient samples. However, gene expression data is characterized as a high dimensional data that typically encompassed of redundant, noisy, and irrelevant genes. Datasets with such characteristics pose a challenge to machine learning algorithms. This is because they impede the training and testing process and entail high resource computations that deteriorate the classification performance. In order to avoid these pitfalls, gene selection is needed. This paper proposes a new hybrid filter-wrapper approach using robust Minimum Redundancy Maximum Relevancy (rMRMR) as a filter approach to choose the topranked genes. Modified Gray Wolf Optimizer (MGWO) is used as a wrapper approach to seek further small sets of genes. In MGWO, new optimization operators inspired by the TRIZ-inventive solution are coupled with the original GWO to increase the diversity of the population. To evaluate the performance of the proposed method, nine well-known microarray datasets are tested. The support vector machine (SVM) is employed for the classification task to estimate the goodness of the selected subset of genes. The effectiveness of TRIZ optimization operators in MGWO is evaluated by investigating the convergence behavior of GWO with and without TRIZ optimization operators. Moreover, the results of MGWO are compared with seven state-of-art gene selection methods using the same datasets based on classification accuracy and the number of selected genes. The results show that the proposed method achieves the best results in four out of nine datasets and it obtains remarkable results on the remaining datasets. The experimental results demonstrated the effectiveness of the proposed method in searching the gene search space and it was able to find the best gene combinations.']",https://hal.sorbonne-universite.fr/hal-04017212,['0.info']
"['Mohammed Awadallah', 'Mohammed Azmi Al-Betar', 'Malik Shehadeh Braik', 'Abdelaziz Hammouri', 'Iyad Abu Doush', 'Raed Abu Zitar']",[1219307],,An enhanced binary Rat Swarm Optimizer based on local-best concepts of PSO and collaborative crossover operators for feature selection,hal-03955346,2022,10.1016/j.compbiomed.2022.105675,"['S-shape transfer function', 'Optimization', 'Feature selection', 'Rat swarm optimizer', 'Particle swarm optimization']","['In this paper, an enhanced binary version of the Rat Swarm Optimizer (RSO) is proposed to deal with Feature Selection (FS) problems. FS is an important data reduction step in data mining which finds the most representative features from the entire data. Many FS-based swarm intelligence algorithms have been used to tackle FS. However, the door is still open for further investigations since no FS method gives cutting-edge results for all cases. In this paper, a recent swarm intelligence metaheuristic method called RSO which is inspired by the social and hunting behavior of a group of rats is enhanced and explored for FS problems. The binary enhanced RSO is built based on three successive modifications: i) an S-shape transfer function is used to develop binary RSO algorithms; ii) the local search paradigm of particle swarm optimization is used with the iterative loop of RSO to boost its local exploitation; iii) three crossover mechanisms are used and controlled by a switch probability to improve the diversity. Based on these enhancements, three versions of RSO are produced, referred to as Binary RSO (BRSO), Binary Enhanced RSO (BERSO), and Binary Enhanced RSO with Crossover operators (BERSOC). To assess the performance of these versions, a benchmark of 24 datasets from various domains is used. The proposed methods are assessed concerning the fitness value, number of selected features, classification accuracy, specificity, sensitivity, and computational time. The best performance is achieved by BERSOC followed by BERSO and then BRSO. These proposed versions are comparatively assessed against 25 well-regarded metaheuristic methods and five filter-based approaches. The obtained results underline their superiority by producing new best results for some datasets.']",https://hal.science/hal-03955346,"['0.info', '1.info.info-ai']"
"['Abdelazim Hussien', 'Laith Abualigah', 'Raed Abu Zitar', 'Fatma Hashim', 'Mohamed Amin', 'Abeer Saber', 'Khaled Almotairi', 'Amir Gandomi']","[1219330, 1219306, 1219320, 1219331, 1219305, 1219312]",,Recent Advances in Harris Hawks Optimization: A Comparative Study and Applications,hal-03955385,2022,10.3390/electronics11121919,"['Harris hawks optimization', 'Metaheuristics', 'Optimization problems', 'Variants', 'Applications']","['The Harris hawk optimizer is a recent population-based metaheuristics algorithm that simulates the hunting behavior of hawks. This swarm-based optimizer performs the optimization procedure using a novel way of exploration and exploitation and the multiphases of search. In this review research, we focused on the applications and developments of the recent well-established robust optimizer Harris hawk optimizer (HHO) as one of the most popular swarm-based techniques of 2020. Moreover, several experiments were carried out to prove the powerfulness and effectivness of HHO compared with nine other state-of-art algorithms using Congress on Evolutionary Computation (CEC2005) and CEC2017. The literature review paper includes deep insight about possible future directions and possible ideas worth investigations regarding the new variants of the HHO algorithm and its widespread applications.']",https://hal.science/hal-03955385,"['0.info', '1.info.info-ai']"
"['Serdar Ekinci', 'Davut Izci', 'Raed Abu Zitar', 'Anas Ratib Alsoud', 'Laith Abualigah']","[1219317, 1219318, 1219306]",,Development of Lévy flight-based reptile search algorithm with local search ability for power systems engineering design problems,hal-03955357,2022,10.1007/s00521-022-07575-w,"['Reptile search algorithm', 'Lévy flight', 'Nelder–Mead method', 'Electric power systems']","['The need for better-performing algorithms to solve real-world power systems engineering problems has always been a challenging topic. Due to their stochastic nature, metaheuristic algorithms can provide better results. Thus, they have a rising trend in terms of investigation. This paper is a further attempt to offer a better optimizing structure, therefore, aims to provide a better-performing algorithm both for designing an appropriate proportional–integral–derivative (PID) controller to effectively operate an automatic voltage regulator (AVR) system and extracting the optimum parameters of a power system stabilizer (PSS) employed in a single-machine infinite-bus (SMIB) power system. Therefore, the paper discusses the development of the Lévy flight-based reptile search algorithm with local search capability and evaluates its potential against challenging power systems engineering optimization problems. The Lévy flight concept is used for better exploration capability in the proposed algorithm, whereas the Nelder–Mead simplex search algorithm is integrated for further exploitation. The latter case is confirmed through 23 benchmark functions with different features using statistical and nonparametric tests. The superiority of the proposed Lévy flight-based reptile search and Nelder–Mead (L-RSANM) algorithm-based PID controller for the AVR system is demonstrated comparatively using convergence, statistical and nonparametric tests along with transient and frequency responses. Besides, it is also assessed against previously reported and different methods, showing further superiority for AVR system control. Furthermore, the extraordinary ability of the L-RSANM algorithm to design an efficient PSS employed in the SMIB power system is demonstrated, as well. In conclusion, the proposed L-RSANM algorithm is shown to be more capable to solve the challenging power systems engineering design problems.']",https://hal.science/hal-03955357,"['0.info', '1.info.info-ai']"
"['Jeffrey Agushaka', 'Absalom Ezugwu', 'Oyelade Olaide', 'Olatunji Akinola', 'Raed Abu Zitar', 'Laith Abualigah']",[1219306],,Improved Dwarf Mongoose Optimization for Constrained Engineering Design Problems,hal-03955365,2023,10.1007/s42235-022-00316-8,"['Improved dwarf mongoose', 'Nature-inspired algorithms', 'Constrained optimization', 'Unconstrained optimization', 'Engineering design problems']","[""This paper proposes a modified version of the Dwarf Mongoose Optimization Algorithm (IDMO) for constrained engineering design problems. This optimization technique modifies the base algorithm (DMO) in three simple but effective ways. First, the alpha selection in IDMO differs from the DMO, where evaluating the probability value of each fitness is just a computational overhead and contributes nothing to the quality of the alpha or other group members. The fittest dwarf mongoose is selected as the alpha, and a new operator ω is introduced, which controls the alpha movement, thereby enhancing the exploration ability and exploitability of the IDMO. Second, the scout group movements are modified by randomization to introduce diversity in the search process and explore unvisited areas. Finally, the babysitter's exchange criterium is modified such that once the criterium is met, the babysitters that are exchanged interact with the dwarf mongoose exchanging them to gain information about food sources and sleeping mounds, which could result in better-fitted mongooses instead of initializing them afresh as done in DMO, then the counter is reset to zero. The proposed IDMO was used to solve the classical and CEC 2020 benchmark functions and 12 continuous/discrete engineering optimization problems. The performance of the IDMO, using different performance metrics and statistical analysis, is compared with the DMO and eight other existing algorithms. In most cases, the results show that solutions achieved by the IDMO are better than those obtained by the existing algorithms.""]",https://hal.science/hal-03955365,"['0.info', '1.info.info-ai']"
"['Malik Sh. Braik', 'Mohammed Awadallah', 'Mohammed Azmi Al-Betar', 'Abdelaziz Hammouri', 'Raed Abu Zitar']",[1219307],,A non-convex economic load dispatch problem using chameleon swarm algorithm with roulette wheel and Levy flight methods,hal-03957090,2023,10.1007/s10489-022-04363-w,"['Economic load dispatch', 'Chameleon swarm algorithm', 'Optimization', 'Lévy flight', 'Roulette wheel selection']","['An Enhanced Chameleon Swarm Algorithm (ECSA) by integrating roulette wheel selection and Lé vy flight methods is presented to solve non-convex Economic Load Dispatch (ELD) problems. CSA has diverse strategies to move towards the optimal solution. Even so, this algorithm’s performance faces some hurdles, such as early convergence and slumping into local optimum. In this paper, several enhancements were made to this algorithm. First, it’s position updating process was slightly tweaked and took advantage of the chameleons’ randomization as well as adopting several time-varying functions. Second, the Lévy flight operator is integrated with roulette wheel selection method and both are combined with ECSA to augment the exploration behavior and lessen its bias towards exploitation. Finally, an add-on position updating strategy is proposed to develop a further balance between exploration and exploitation conducts. The optimization performance of ECSA is shown by testing it on five various real ELD cases with a generator having 3, 13, 40, 80 and 140 units, each with different constraints. The results of the ELD systems’ analysis depict that ECSA is better than the parent CSA and other state-of-the art methods. Further, the efficacy of ECSA was experimented on several benchmark test functions, and its performance was compared to other well-known optimization methods. Experimental results show that ECSA surpasses other methods on complex benchmark functions with modest computational burdens. The superiority and practicality of ECSA is demonstrated by getting new best solutions for large-scale ELD cases such as 40-unit and 140-unit test systems.']",https://hal.sorbonne-universite.fr/hal-03957090,"['0.info', '0.info', '1.info.info-ai']"
"['Mahmud Salem Alkoffash', 'Mohammed Awadallah', 'Mohammed Alweshah', 'Raed Abu Zitar', 'Khaled Assaleh', 'Mohammed Azmi Al-Betar']",[1219307],,A Non-convex Economic Load Dispatch Using Hybrid Salp Swarm Algorithm,hal-04017174,2021,10.1007/s13369-021-05646-z,"['Power systems', 'Economic load dispatch', 'Salp swarm algorithm', 'Optimization', 'Β -Hill climbing optimizer', 'Hybrid metaheuristic']","['In this paper, the economic load dispatch (ELD) problem with valve point effect is tackled using a hybridization between salp swarm algorithm (SSA) as a population-based algorithm and β-hill climbing optimizer as a single point-based algorithm. The proposed hybrid SSA is abbreviated as HSSA. This is to achieve the right balance between the intensification and diversification of the ELD search space. ELD is an important problem in the power systems which is concerned with scheduling the generation units in active generators in optimal way to minimize the fuel cost in accordance with equality and inequality constraints. The proposed HSSA is evaluated using six real-world ELD systems: 3-unit generator, two cases of 13-unit generator, 40-unit generator, 80-unit generator, and 140-unit generator system. These ELD systems are well circulated in the previous literature. The comparative results against 66 well-regarded algorithms are conducted. The results show that the proposed HSSA is able to produce viable and competitive solutions for ELD problems.']",https://hal.sorbonne-universite.fr/hal-04017174,['0.info']
"['Serdar Ekinci', 'Davut Izci', 'Mohammad Rustom Al Nasar', 'Raed Abu Zitar', 'Laith Abualigah']","[1219317, 1219318, 1219306]",,Logarithmic spiral search based arithmetic optimization algorithm with selective mechanism and its application to functional electrical stimulation system control,hal-03955368,2022,10.1007/s00500-022-07068-x,"['Functional electrical stimulation', 'PID controller', 'Logarithmic spiral search mechanism', 'Greedy selection scheme', 'Arithmetic optimization algorithm']","['A biomedical application of a novel metaheuristic optimizer is proposed in this paper by constructing an enhanced arithmetic optimization algorithm (AOA). The latter algorithm was constructed using the logarithmic spiral (Ls) search mechanism from the whale optimization algorithm and the greedy selection scheme from the differential evolution algorithm. The proposed algorithm (Ls-AOA) was tested against unimodal and multimodal benchmark functions and demonstrated better capability comparatively using other efficient metaheuristic algorithms reported in the literature. The constructed Ls-AOA algorithm was then proposed to design a proportional-integral-derivative (PID) controller employed in a functional electrical stimulation (FES) system for the first time. The initial statistical and convergence profile assessment showed better performance of the proposed algorithm. The comparative analyses for transient and frequency responses were performed for the PID-controlled FES system using the original AOA, sine–cosine and particle swarm optimization algorithms and the traditional Ziegler-Nichols tuning scheme. Similarly, the FES system tuned with the latter methods was also assessed for disturbance rejection and noise elimination. All the comparative analyses demonstrated that the proposed Ls-AOA has the greater capability for the challenging biomedical FES system.']",https://hal.science/hal-03955368,"['0.info', '1.info.info-ai']"
"['Ala Mughaid', 'Shadi Al-Zu’bi', 'Ahmed Al Arjan', 'Rula Al-Amrat', 'Rathaa Alajmi', 'Raed Abu Zitar', 'Laith Abualigah']",,,An intelligent cybersecurity system for detecting fake news in social media websites,hal-03955347,2022,10.1007/s00500-022-07080-1,"['Artificial intelligence', 'Cybersecurity', 'Fake news', 'Text processing', 'Cyber privacy', 'Social media accuracy']","['People worldwide suffer from fake news in many life aspects, healthcare, transportation, education, economics, and many others. Therefore, many researchers have considered seeking techniques for automatically detecting fake news in the last decade. The most popular news agencies use e-publishing on their websites; even websites can publish any news they want. However, thus before quotation any news from a website, there should be a close look at news resource ranking by using a trusted websites classifier, such as the website world rank, which reflects the repute of these websites. This paper uses the world rank of news websites as the main factor of news accuracy by using two widespread and trusted websites ranking. Moreover, a secondary factor is proposed to compute the news accuracy similarity by comparing the current news with fakes news and getting the possible news accuracy. Experiments results are conducted on several benchmark datasets. The results showed that the proposed method got promising results compared to other comparative methods in defining the news accuracy.']",https://hal.science/hal-03955347,"['0.info', '1.info.info-ai']"
"['Mohammad Sh. Daoud', 'Mohammad Shehab', 'Hani Al-Mimi', 'Laith Abualigah', 'Raed Abu Zitar', 'Mohd Khaled Yousef Shambour']",[1219306],,"Gradient-Based Optimizer (GBO): A Review, Theory, Variants, and Applications",hal-03955363,2023,10.1007/s11831-022-09872-y,"['Gradient-Based Optimizer', 'Optimization algorithms', 'Engineering problems', 'GBO’s variants', 'GBO’s applications']","['This paper introduces a comprehensive survey of a new population-based algorithm so-called gradient-based optimizer (GBO) and analyzes its major features. GBO considers as one of the most effective optimization algorithm where it was utilized in different problems and domains, successfully. This review introduces set of related works of GBO where distributed into; GBO variants, GBO applications, and evaluate the efficiency of GBO compared with other metaheuristic algorithms. Finally, the conclusions concentrate on the existing work on GBO, showing its disadvantages, and propose future works. The review paper will be helpful for the researchers and practitioners of GBO belonging to a wide range of audiences from the domains of optimization, engineering, medical, data mining and clustering. As well, it is wealthy in research on health, environment and public safety. Also, it will aid those who are interested by providing them with potential future research.']",https://hal.science/hal-03955363,"['0.info', '1.info.info-ai']"
"['Shadi Alzu’bi', 'Raed Abu Zitar', 'Bilal Hawashin', 'Samia Abu Shanab', 'Amjed Zraiqat', 'Ala Mughaid', 'Khaled Almotairi', 'Laith Abualigah']","[1219303, 1219304, 1219305, 1219306]",,A Novel Deep Learning Technique for Detecting Emotional Impact in Online Education,hal-03955343,2022,10.3390/electronics11182964,"['Emotional intelligence', 'Online education', 'Deep learning', 'Intelligent education', 'Transfer learning', 'Computer vision']","['Emotional intelligence is the automatic detection of human emotions using various intelligent methods. Several studies have been conducted on emotional intelligence, and only a few have been adopted in education. Detecting student emotions can significantly increase productivity and improve the education process. This paper proposes a new deep learning method to detect student emotions. The main aim of this paper is to map the relationship between teaching practices and student learning based on emotional impact. Facial recognition algorithms extract helpful information from online platforms as image classification techniques are applied to detect the emotions of student and/or teacher faces. As part of this work, two deep learning models are compared according to their performance. Promising results are achieved using both techniques, as presented in the Experimental Results Section. For validation of the proposed system, an online course with students is used; the findings suggest that this technique operates well. Based on emotional analysis, several deep learning techniques are applied to train and test the emotion classification process. Transfer learning for a pre-trained deep neural network is used as well to increase the accuracy of the emotion classification stage. The obtained results show that the performance of the proposed method is promising using both techniques, as presented in the Experimental Results Section.']",https://hal.science/hal-03955343,"['0.info', '1.info.info-ai']"
"['Liyao Ma', 'Sébastien Destercke', 'Yong Wang']","[5026, 764960]",['seb-destercke'],Online active learning of decision trees with evidential data,hal-01254290,2016,10.1016/j.patcog.2015.10.014,"['Decision tree', 'Active learning', 'Uncertain data', 'Evidential likelihood', 'Belief functions']","['Learning from uncertain data has been drawing increasing attention in recent years. In this paper, we propose a tree induction approach which can not only handle uncertain data, but also furthermore reduce epistemic uncertainty by querying the most valuable uncertain instances within the learning procedure. We extend classical decision trees to the framework of belief functions to deal with a variety of uncertainties in the data. In particular, we use entropy intervals extracted from the evidential likelihood to query selected uncertain querying training instances when needed, in order to improve the selection of the splitting attribute. Our experiments show the good performances of proposed active belief decision trees under different conditions.']",https://hal.science/hal-01254290,"['0.info', '1.info.info-oh']"
"['Sébastien Destercke', 'Didier Dubois', 'Eric Chojnacki']","[5026, 743301, 845305]","['seb-destercke', 'didier-dubois']",UNIFYING PRACTICAL UNCERTAINTY REPRESENTATIONS: I. GENERALIZED P-BOXES,irsn-00311696,2008,10.1016/j.ijar.2008.07.003,"['Imprecise probability', 'Random sets', 'Belief functions', 'Possibility', 'Clouds', 'P-boxes', 'Probability intervals']","[""There exist several simple representations of uncertainty that are easier to handle than more general ones. Among them are random sets, possibility distributions, probability intervals, and more recently Ferson's p-boxes and Neumaier's clouds. Both for theoretical and practical considerations, it is very useful to know whether one representation is equivalent to or can be approximated by other ones. In this paper, we define a generalized form of usual p-boxes. These generalized p-boxes have interesting connections with other previously known representations. In particular, we show that they are equivalent to pairs of possibility distributions, and that they are special kinds of random sets. They are also the missing link between p-boxes and clouds, which are the topic of the second part of this study.""]",https://irsn.hal.science/irsn-00311696,"['0.info', '1.info.info-ai', '0.info', '1.info.info-oh', '0.math', '1.math.math-pr']"
"['Sébastien Destercke', 'Didier Dubois']","[5026, 743301]","['seb-destercke', 'didier-dubois']",Idempotent conjunctive combination of belief functions: Extending the minimum rule of possibility theory.,hal-00651875,2011,10.1016/j.ins.2011.05.007,"['Belief functions', 'Least commitment', 'Idempotence', 'Ill-known dependencies', 'Contour function', 'Redondance', 'Variable unique', 'Fusion des fonctions de croyance', 'Fonction de contour']","['When conjunctively merging two belief functions concerning a single variable but coming from different sources, Dempster rule of combination is justified only when information sources can be considered as independent. When dependencies between sources are ill-known, it is usual to require the property of idempotence for the merging of belief functions, as this property captures the possible redundancy of dependent sources. To study idempotent merging, different strategies can be followed. One strategy is to rely on idempotent rules used in either more general or more specific frameworks and to study, respectively, their particularisation or extension to belief functions. In this paper, we study the feasibility of extending the idempotent fusion rule of possibility theory (the minimum) to belief functions. We first investigate how comparisons of information content, in the form of inclusion and least-commitment, can be exploited to relate idempotent merging in possibility theory to evidence theory. We reach the conclusion that unless we accept the idea that the result of the fusion process can be a family of belief functions, such an extension is not always possible. As handling such families seems impractical, we then turn our attention to a more quantitative criterion and consider those combinations that maximise the expected cardinality of the joint belief functions, among the least committed ones, taking advantage of the fact that the expected cardinality of a belief function only depends on its contour function.']",https://hal.science/hal-00651875,"['0.info', '1.info.info-ai']"
"['Matthias M.C.M Troffaes', 'Sébastien Destercke']","[916063, 5026]",['seb-destercke'],Probability boxes on totally preordered spaces for multivariate modelling,hal-00651868,2011,10.1016/j.ijar.2011.02.001,"['Lower prevision', 'P-Box', 'Multivariate', 'Choquet integral', 'Fréchet bounds', 'Full components']","[""A pair of lower and upper cumulative distribution functions, also called probability box or p-box, is among the most popular models used in imprecise probability theory. They arise naturally in expert elicitation, for instance in cases where bounds are specified on the quantiles of a random variable, or when quantiles are specified only at a finite number of points. Many practical and formal results concerning p-boxes already exist in the literature. In this paper, we provide new efficient tools to construct multivariate p-boxes and develop algorithms to draw inferences from them. For this purpose, we formalise and extend the theory of p-boxes using Walley's behavioural theory of imprecise probabilities, and heavily rely on its notion of natural extension and existing results about independence modeling. In particular, we allow p-boxes to be defined on arbitrary totally preordered spaces, hence thereby also admitting multivariate p-boxes via probability bounds over any collection of nested sets. We focus on the cases of independence (using the factorization property), and of unknown dependence (using the Frechet bounds), and we show that our approach extends the probabilistic arithmetic of Williamson and Downs. Two design problems--a damped oscillator, and a river dike--demonstrate the practical feasibility of our results.""]",https://hal.science/hal-00651868,"['0.info', '1.info.info-ai', '0.math', '1.math.math-pr']"
"['Sébastien Destercke', 'Patrice Buche', 'Brigitte Charnomordic']","[5026, 9239]","['seb-destercke', 'patrice-buche']",Evaluating data reliability : an evidential answer with application to a web-enabled data warehouse,hal-01267940,2013,10.1109/tkde.2011.179,"['Belief functions', 'Evidence', 'Information fusion', 'Confidence', 'Maximal', 'Coherent subsets', 'Trust', 'Data quality', 'Relevance']","[""There are many available methods to integrate information source reliability in an uncertainty representation, but there are only a few works focusing on the problem of evaluating this reliability. However, data reliability and confidence are essential components of a data warehousing system, as they influence subsequent retrieval and analysis. In this paper, we propose a generic method to assess data reliability from a set of criteria using the theory of belief functions. Customizable criteria and insightful decisions are provided. The chosen illustrative example comes from real-world data issued from the Sym'Previus predictive microbiology oriented data warehouse.""]",https://hal.science/hal-01267940,"['0.scco', '1.scco.comp']"
"['Valérie Guillard', 'Patrice Buche', 'Sébastien Destercke', 'Nouredine Tamani', 'Madalina Croitoru', 'Luc Menut', 'Carole Guillaume', 'Nathalie Gontard']","[179870, 9239, 5026, 1184380, 742676, 976052, 737154]","['valerie-guillard', 'patrice-buche', 'seb-destercke', 'madalina-croitoru', 'luc-menut', 'nathalie-gontard']",A Decision Support System to design modified atmosphere packaging for fresh produce based on a bipolar flexible querying approach,hal-01104835,2015,10.1016/j.compag.2014.12.010,"['MAP modeling', 'Multi-criteria querying', 'Decision Support System', 'Knowledge engineering', 'Respiring product']","['To design new packaging for fresh food, stakeholders of the food chain express their needs and requirements, according to some goals and objectives. These requirements can be gathered into two groups: (i) fresh food related characteristics and (ii) packaging intrinsic characteristics. Modified Atmosphere Packaging (MAP) is an efficient way to delay senescence and spoilage and thus to extend the very short shelf life of respiring products such as fresh fruits and vegetables. Consequently, packaging O2/CO2 permeabilities must fit the requirements of fresh fruits and vegetable as predicted by virtual MAP simulating tools. Beyond gas permeabilities, the choice of a packaging material for fresh produce includes numerous other factors such as the cost, availability, potential contaminants of raw materials, process ability, waste management constraints, etc. For instance, the user may have the following multi-criteria query for his/her product asking for a packaging with optimal gas permeabilities that guarantee product quality and optionally a transparent packaging material made from renewable resources with a cost for raw material less than 3 e/ kg. To help stakeholders taking a rational decision based on the expressed needs, a new multi-criteria Decision Support System (DSS) for designing biodegradable packaging for fresh produce has been built. In this paper we present the functional specification, the software architecture and the implementation of the developed tool. This tool includes (i) a MAP simulation module combining mass transfer models and respiration of the food, (ii) a multi-criteria flexible querying module which handles imprecise, uncertain and missing data stored in the database. We detail its operational functioning through a real life case study to determine the most satisfactory materials for apricots packaging.']",https://hal.science/hal-01104835,"['0.info', '1.info.info-ai']"
"['Ana Palacios', 'Luciano Sánchez', 'Ines Couso', 'Sébastien Destercke']","[170788, 974635, 5026]","['ana-palacios', 'seb-destercke']",An extension of the FURIA classification algorithm to low quality data through fuzzy rankings and its application to the early diagnosis of dyslexia,hal-01254306,2016,10.1016/j.neucom.2014.11.088,"['FURIA', 'Dyslexia', 'Low Quality Data', 'Fuzzy Rule Based Classifiers']","[""An early detection and reeducation of dyslexic children is critical for their integration in the classroom. Parents and instructors can help the psychologist to detect potential cases of dyslexia before the children's writing age. Artificial intelligence tools can also assist in this task. Dyslexia symptoms are detected with tests whose results may be vague or ambiguous, thus machine learning techniques for low quality data are advised. In particular, in this paper it is suggested that a new extension to vague datasets of the classification algorithm FURIA (Fuzzy Unordered Rule Induction Algorithm) has advantages over other approaches in both the computational effort during the learning stage and the linguistic quality of the induced classification rules. The new approach is benchmarked with different test problems and compared to other artificial intelligence tools for dyslexia diagnosis in the literature.""]",https://hal.science/hal-01254306,"['0.info', '1.info.info-oh']"
"['Ignacio Montes', 'Enrique Miranda', 'Sébastien Destercke']","[974631, 5026]",['seb-destercke'],Unifying neighbourhood and distortion models: part II - new models and synthesis,hal-02944685,2020,10.1080/03081079.2020.1778683,"['Neighbourhood models', 'Distorted probabilities', 'Total variation distance', 'Kolmogorov distance', 'L 1 distance']","['Neighbourhoods of precise probabilities are instrumental to perform robustness analysis, as they rely on very few parameters. In the rst part of this study, we introduced a general, unied view encompassing such neighbourhoods, and revisited some well-known models (pari mutuel, linear vacuous, constant odds-ratio). In this second part, we study models that have received little to no attention, but are induced by classical distances between probabilities, such as the total variation, the Kolmogorov and the L 1 distances. We nish by comparing those models in terms of a number of properties: precision , number of extreme points, n-monotonicity,. .. thus providing possible guidelines to select a neighbourhood rather than another.']",https://hal.science/hal-02944685,"['0.info', '1.info.info-ai', '0.math', '1.math.math-pr']"
"['Mélanie Münch', 'Valérie Guillard', 'Sébastien Gaucel', 'Sébastien Destercke', 'Jonathan Thévenot', 'Patrice Buche']","[177073, 179870, 736995, 5026, 1166678, 9239]","['melanie-munch', 'valerie-guillard', 'sebastien-gaucel', 'seb-destercke', 'patrice-buche']",Composition-based statistical model for predicting CO2 solubility in modified atmosphere packaging application,hal-03783883,2023,10.1016/j.jfoodeng.2022.111283,"['CO2 solubility', 'Machine learning models', 'Food composition', 'Modified Atmosphere Packaging', 'CO2 headspace dynamic']","[""Carbon dioxide (CO2) is an important gas used in modified atmosphere packaging of nonrespiring foods where it solubilizes into the aqueous and lipid phases of food and exerts an antimicrobial effect. Prediction of CO2 solubility within food is thus of paramount importance to anticipate its benefit on food preservation. In the present study, machine learning algorithms were applied on a set of 362 values of CO2 solubilities collected from the scientific literature to tentatively predict the solubility as a function of food composition (water, protein, fat and salt content) and temperature. The best option kept was a random forest algorithm that was used to predict CO2 solubility in four food case studies (ham, salmon, cheese and pâté) that were further 1 Corresponding author 2 used as input parameters in the MAP' OPT tool, predicting the evolution of headspace gas composition. Predicted CO2 solubilities used as input parameters succeeded in representing the CO2 headspace dynamic as a function of time in the four case studies.""]",https://hal.science/hal-03783883,"['0.info', '1.info.info-ai']"
"['Sébastien Destercke', 'Didier Dubois', 'E. Chojnacki']","[5026, 743301]","['seb-destercke', 'didier-dubois']",Unifying practical uncertainty representations. II: Clouds,hal-03005045,2008,10.1016/j.ijar.2008.07.004,"['Clouds', 'Image segmentation', 'Probability', 'Random processes', 'Set theory', 'Imprecise probability representations', 'Incomplete informations', 'P-Boxes', 'Possibility distributions', 'Possibility theory', 'Random sets', 'Uncertainty representations', 'Probability distributions']","[""There exist many simple tools for jointly capturing variability and incomplete information by means of uncertainty representations. Among them are random sets, possibility distributions, probability intervals, and the more recent Ferson's p-boxes and Neumaier's clouds, both defined by pairs of possibility distributions. In the companion paper, we have extensively studied a generalized form of p-box and situated it with respect to other models. This paper focuses on the links between clouds and other representations. Generalized p-boxes are shown to be clouds with comonotonic distributions. In general, clouds cannot always be represented by random sets, in fact not even by two-monotone (convex) capacities.""]",https://hal.science/hal-03005045,"['0.info', '0.info', '1.info.info-ai']"
"['Sébastien Destercke', 'Serge Guillaume', 'Brigitte Charnomordic']","[5026, 837856, 1202749]",['seb-destercke'],Building an interpretable fuzzy rule base from data using Orthogonal Least Squares Application to a depollution problem,irsn-00311750,2007,10.1016/j.fss.2007.04.026,"['Fault detection', 'Learning', 'Rule induction', 'Fuzzy logic', 'Interpretability', 'OLS', 'Orthogonal transformations', 'Depollution']","['In many fields where human understanding plays a crucial role, such as bioprocesses, the capacity of extracting knowledge from data is of critical importance. Within this framework, fuzzy learning methods, if properly used, can greatly help human experts. Amongst these methods, the aim of orthogonal transformations, which have been proven to be mathematically robust, is to build rules from a set of training data and to select the most important ones by linear regression or rank revealing techniques. The OLS algorithm is a good representative of those methods. However, it was originally designed so that it only cared about numerical performance. Thus, we propose some modifications of the original method to take interpretability into account. After recalling the original algorithm, this paper presents the changes made to the original method, then discusses some results obtained from benchmark problems. Finally, the algorithm is applied to a real-world fault detection depollution problem.', ""Dans de nombreux domaines où l'humain intervient de manière décisive, comme les bio-procédés, l'extraction de connaissances à partir des données est susceptible d'apports importants. Les méthodes d'apprentissage floues peuvent être particulièrement utiles dans ce cadre. Parmi celles-ci, l'objectif des méthodes qui réalisent une orthogonalisation est de construire des règles à partir d'un ensemble d'exemples et de sélectionner les plus importantes par régression linéaire. L'algorithme OLS est un bon représentant de ces méthodes. Nous proposons de le modifier pour qu'il prenne en compte l'interprétabilité des règles, en plus des critères de performance numérique. Après avoir rappelé l'algorithme original, l'article présente les modifications proposées et discute les résultats de la comparaison à l'aide de jeux de données bien connus. Enfin, le nouvel algorithme est appliqué à un problème de diagnostic dans un procédé de dépollution des eaux.""]",https://irsn.hal.science/irsn-00311750,"['0.info', '1.info.info-lg', '0.info', '1.info.info-ai', '0.info', '1.info.info-oh', '0.sde']"
"['Ignacio Montes', 'Enrique Miranda', 'Sébastien Destercke']","[974631, 5026]",['seb-destercke'],Unifying neighbourhood and distortion models: part I - new results on old models,hal-02944680,2020,10.1080/03081079.2020.1778682,"['Neighbourhood models', 'Distorted probabilities', 'Pari mutuel model', 'Linear vacuous mixtures', 'Constant odds ratio']","['Neighbourhoods of precise probabilities are instrumental to perform robustness analysis, as they rely on very few parameters. Many such models, sometimes referred to as distortion models, have been proposed in the literature, such as the pari mutuel model, the linear vacuous mixtures or the constant odds ratio model. This paper is the rst part of a two paper series where we study the sets of probabilities induced by such models, regarding them as neighbourhoods dened over specic metrics or premetrics. We also compare them in terms of a number of properties: precision, number of extreme points, n-monotonicity, behaviour under conditioning, etc. This rst part tackles this study on some of the most popular distortion models in the literature, while the second part studies less known neighbourhood models and summarises our findings.']",https://hal.science/hal-02944680,"['0.info', '1.info.info-ai', '0.math', '1.math.math-pr']"
"['Charlotte Lousteau-Cazalet', 'Abdellatif Barakat', 'Jean-Pierre Belaud', 'Patrice Buche', 'Guillaume Busset', 'Brigitte Charnomordic', 'Stéphane Dervaux', 'Sébastien Destercke', 'Juliette Dibie-Barthelemy', 'Caroline Sablayrolles', 'Claire Vialle']","[737725, 930054, 9239, 1202749, 2267, 5026, 7514, 1244361, 1204571]","['abdellatif-barakat', 'jean-pierre-belaud', 'patrice-buche', 'stephane-dervaux', 'seb-destercke', 'juliette-dibie']",A decision support system for eco-efficient biorefinery process comparison using a semantic approach,lirmm-01346685,2016,10.1016/j.compag.2016.06.020,"['Decision support system', 'Biorefinery', 'Uncertainty management', 'Knowledge engineering', 'Ontology', 'Bioprocess eco-design']","['Enzymatic hydrolysis of the main components of lignocellulosic biomass is one of the promising methods to further upgrading it into biofuels. Biomass pre-treatment is an essential step in order to reduce cellulose crystallinity, increase surface and porosity and separate the major constituents of biomass. Scientific literature in this domain is increasing fast and could be a valuable source of data. As these abundant scientific data are mostly in textual format and heterogeneously structured, using them to compute biomass pre-treatment efficiency is not straightforward. This paper presents the implementation of a Decision Support System (DSS) based on an original pipeline coupling knowledge engineering (KE) based on semantic web technologies, soft computing techniques and environmental factor computation. The DSS allows using data found in the literature to assess environmental sustainability of biorefinery systems. The pipeline permits to: (1) structure and integrate relevant experimental data, (2) assess data source reliability, (3) compute and visualize green indicators taking into account data imprecision and source reliability. This pipeline has been made possible thanks to innovative researches in the coupling of ontologies, uncertainty management and propagation. In this first version, data acquisition is done by experts and facilitated by a termino-ontological resource. Data source reliability assessment is based on domain knowledge and done by experts. The operational prototype has been used by field experts on a realistic use case (rice straw). The obtained results have validated the usefulness of the system. Further work will address the question of a higher automation level for data acquisition and data source reliability assessment.']",https://hal-lirmm.ccsd.cnrs.fr/lirmm-01346685,"['0.chim', '1.chim.geni', '0.sdv', '1.sdv.sa', '0.spi', '1.spi.gproc']"
"['Lev Utkin', 'Sébastien Destercke']",[5026],['seb-destercke'],Computing expectations with continuous p-boxes: univariate case,hal-02665084,2009,10.1016/j.ijar.2009.02.004,"['P-boxes', 'Linear programming', 'Random sets', 'Expectations', 'Série aléatoire', 'Attentes', 'Ensembles aléatoires']","['Given an imprecise probabilistic model over a continuous space, computing lower/upper expectations is often computationally hard to achieve, even in simple cases. Because expectations are essential in decision making and risk analysis, tractable methods to compute them are crucial in many applications involving imprecise probabilistic models. We concentrate on p-boxes (a simple and popular model), and on the computation of lower expectations of non-monotone functions. This paper is devoted to the univariate case, that is where only one variable has uncertainty. We propose and compare two approaches: the first using general linear programming, and the second using the fact that p-boxes are special cases of random sets. We underline the complementarity of both approaches, as well as the differences.']",https://hal.inrae.fr/hal-02665084,"['0.sdv', '1.sdv.ida', '0.spi', '1.spi.gproc']"
['Sébastien Destercke'],[5026],['seb-destercke'],A K-nearest neighbours method based on imprecise probabilities,hal-00692149,2012,10.1007/s00500-011-0773-5,"['Classification', 'Uncertain data', 'Lower prevision', 'Nearest neighbours']","['K-nearest neighbours algorithms are among the most popular existing classification methods, due to their simplicity and their good performances. Over the years, several extensions of the initial method have been proposed. In this paper, we propose a K-nearest neighbours approach that uses the theory of imprecise probabilities, and more specifically lower previsions. We show that the proposed approach has several assets: it can handle uncertain data in a very generic way, and decision rules developed within this theory allow us to deal with conflicting information between neighbours or with the absence of close neighbour to the instance to classify. We show that results of the basic k-NN and weighted k-NN methods can be retrieved by the proposed approach. We end with some experiments on classical data sets.']",https://hal.science/hal-00692149,"['0.info', '1.info.info-lg', '0.info', '1.info.info-ai']"
"['Sébastien Destercke', 'Patrice Buche', 'Valérie Guillard']","[5026, 9239, 179870]","['seb-destercke', 'patrice-buche', 'valerie-guillard']",A Flexible Bipolar Querying Approach with Imprecise Data and Guaranteed Results,lirmm-00611940,2011,10.1016/j.fss.2010.12.014,"['Fuzzy databases', 'Food engineering', 'Bipolarity', 'Possibility theory', 'Applications', 'Bipolarité', 'Préférences bipolaires', 'Bases de données floues']","[""In this paper, we propose an approach to query a database when the user preferences are bipolar (i.e., express both constraints and wishes about the desired result) and the data stored in the database are imprecise. Results are then completely ordered with respect to these bipolar preferences, giving priority to constraints over wishes. Additionally, we propose a treatment that allows us to guarantee that any query will return a result, even if no element satisfies all constraints specified by the user. Such a treatment may be useful when user's constraints are unrealistic (i.e., cannot be all satisfied simultaneously) and when the user desires a guaranteed result. The approach is illustrated on a real-world problem concerning the selection of optimal packaging for fresh fruits and vegetables.""]",https://hal-lirmm.ccsd.cnrs.fr/lirmm-00611940,"['0.info', '1.info.info-wb']"
"['Sébastien Destercke', 'Ines Couso']","[5026, 974635]",['seb-destercke'],Ranking of fuzzy intervals seen through the imprecise probabilistic lens,hal-01184644,2015,10.1016/j.fss.2014.12.009,"['Ranking', 'Preferences', 'Partial orders', 'Fuzzy numbers', 'Possibility', 'Deci-sion making']","['Within the fuzzy literature, the issue of ranking fuzzy intervals has been addressed by many authors, who proposed various solutions to the problem. Most of these solutions intend to find a total order on a given collection of fuzzy intervals. However, if one sees fuzzy intervals as descriptions of uncertain quantities, an alternative to rank them is to use ranking rules issued from the imprecise probabilistic literature. In this paper , we investigate ranking rules based on different statistical features (mean, median) and orderings, and relate the obtained (partial) orders to some classical proposals. In particular, we propose a generic expression of stochastic orderings, and then use it to systematically investigate extensions of the most usual stochastic orderings to fuzzy intervals. We also show some relations between those extensions, and explore their relation with existing fuzzy ranking proposals.']",https://hal.science/hal-01184644,"['0.info', '1.info.info-ai']"
"['Madhurima Panja', 'Tanujit Chakraborty', 'Sk Shahid Nadim', 'Indrajit Ghosh', 'Uttam Kumar', 'Nan Liu']",,,An ensemble neural network approach to forecast Dengue outbreak based on climatic condition,hal-03959102,2023,10.1016/j.chaos.2023.113124,"['DengueWavelet transform', 'Forecasting', 'MODWT', 'Neural networks', 'Ensemble']","['Dengue fever is a virulent disease spreading over 100 tropical and subtropical countries in Africa, the Americas, and Asia. This arboviral disease affects around 400 million people globally, severely distressing the healthcare systems. The unavailability of a specific drug and ready-to-use vaccine makes the situation worse. Hence, policymakers must rely on early warning systems to control intervention-related decisions. Forecasts routinely provide critical information for dangerous epidemic events. However, the available forecasting models (e.g., weather-driven mechanistic, statistical time series, and machine learning models) lack a clear understanding of different components to improve prediction accuracy and often provide unstable and unreliable forecasts. This study proposes an ensemble wavelet neural network with exogenous factor(s) (XEWNet) model that can produce reliable estimates for dengue outbreak prediction for three geographical regions, namely San Juan, Iquitos, and Ahmedabad. The proposed XEWNet model is flexible and can easily incorporate exogenous climate variable(s) confirmed by statistical causality tests in its scalable framework. The proposed model is an integrated approach that uses wavelet transformation into an ensemble neural network framework that helps in generating more reliable long-term forecasts. The proposed XEWNet allows complex non-linear relationships between the dengue incidence cases and rainfall; however, mathematically interpretable, fast in execution, and easily comprehensible. The proposal’s competitiveness is measured using computational experiments based on various statistical metrics and several statistical comparison tests. In comparison with statistical, machine learning, and deep learning methods, our proposed XEWNet performs better in 75% of the cases for short-term and long-term forecasting of dengue incidence.']",https://hal.sorbonne-universite.fr/hal-03959102,['0.math']
"['Arinjita Bhattacharyya', 'Tanujit Chakraborty', 'Shesh Rai']",[1219299],,Stochastic forecasting of COVID-19 daily new cases across countries with a novel hybrid time series model,hal-03955345,2022,10.1007/s11071-021-07099-3,"['COVID-19 Forecasting', 'Theta model', 'Autoregressive Neural Networks', 'Hybrid model', 'Asymptotic stationarity']","['An unprecedented outbreak of the novel coronavirus (COVID-19) in the form of peculiar pneumonia has spread globally since its first case in Wuhan province, China, in December 2019. Soon after, the infected cases and mortality increased rapidly. The future of the pandemic’s progress was uncertain, and thus, predicting it became crucial for public health researchers. These predictions help the effective allocation of health-care resources, stockpiling, and help in strategic planning for clinicians, government authorities, and public health policymakers after understanding the extent of the effect. The main objective of this paper is to develop a hybrid forecasting model that can generate real-time out-of-sample forecasts of COVID-19 outbreaks for five profoundly affected countries, namely the USA, Brazil, India, the UK, and Canada. A novel hybrid approach based on the Theta method and autoregressive neural network (ARNN) model, named Theta-ARNN (TARNN) model, is developed. Daily new cases of COVID-19 are nonlinear, non-stationary, and volatile; thus, a single specific model cannot be ideal for future prediction of the pandemic. However, the newly introduced hybrid forecasting model with an acceptable prediction error rate can help healthcare and government for effective planning and resource allocation. The proposed method outperforms traditional univariate and hybrid forecasting models for the test datasets on an average.']",https://hal.sorbonne-universite.fr/hal-03955345,['0.math']
"['Madhurima Panja', 'Tanujit Chakraborty', 'Uttam Kumar', 'Nan Liu']",,,Epicasting: An Ensemble Wavelet Neural Network for forecasting epidemics,hal-04116668,2023,10.1016/j.neunet.2023.05.049,"['Wavelet methods', 'MODWT', 'Epidemiology', 'Neural networks', 'Time series forecasting']","['Infectious diseases remain among the top contributors to human illness and death worldwide, among which many diseases produce epidemic waves of infection. The lack of specific drugs and ready-to-use vaccines to prevent most of these epidemics worsens the situation. These force public health officials and policymakers to rely on early warning systems generated by accurate and reliable epidemic forecasters. Accurate forecasts of epidemics can assist stakeholders in tailoring countermeasures, such as vaccination campaigns, staff scheduling, and resource allocation, to the situation at hand, which could translate to reductions in the impact of a disease. Unfortunately, most of these past epidemics exhibit nonlinear and non-stationary characteristics due to their spreading fluctuations based on seasonal-dependent variability and the nature of these epidemics. We analyze various epidemic time series datasets using a maximal overlap discrete wavelet transform (MODWT) based autoregressive neural network and call it Ensemble Wavelet Neural Network (EWNet) model. MODWT techniques effectively characterize non-stationary behavior and seasonal dependencies in the epidemic time series and improve the nonlinear forecasting scheme of the autoregressive neural network in the proposed ensemble wavelet network framework. From a nonlinear time series viewpoint, we explore the asymptotic stationarity of the proposed EWNet model to show the asymptotic behavior of the associated Markov Chain. We also theoretically investigate the effect of learning stability and the choice of hidden neurons in the proposal. From a practical perspective, we compare our proposed EWNet framework with twenty-two statistical, machine learning, and deep learning models for fifteen real-world epidemic datasets with three test horizons using four key performance indicators. Experimental results show that the proposed EWNet is highly competitive compared to the state-of-the-art epidemic forecasting methods.']",https://hal.sorbonne-universite.fr/hal-04116668,['0.info']
"['Xuhong Li', 'Yves Grandvalet', 'Franck Davoine', 'Jingchun Cheng', 'Yin Cui', 'Hang Zhang', 'Serge Belongie', 'Yi-Hsuan Tsai', 'Ming-Hsuan Yang']","[1041323, 5024, 3173]","['yves-grandvalet', 'franck-davoine']",Transfer Learning in Computer Vision Tasks: Remember Where You Come From,hal-02988362,2020,10.1016/j.imavis.2019.103853,"['Transfer learning', 'Parameter regularization', 'Computer vision']","['Fine-tuning pre-trained deep networks is a practical way of benefiting from the representation learned on a large database while having relatively few examples to train a model. This adjustment is nowadays routinely performed so as to benefit of the latest improvements of convolutional neural networks trained on large databases. Fine-tuning requires some form of reg-ularization, which is typically implemented by weight decay that drives the network parameters towards zero. This choice conflicts with the motivation for fine-tuning, as starting from a pre-trained solution aims at taking advantage of the previously acquired knowledge. Hence, regularizers promoting an explicit inductive bias towards the pre-trained model have been recently proposed. This paper demonstrates the versatility of this type of regular-izer across transfer learning scenarios. We replicated experiments on three state-of-the-art approaches in image classification, image segmentation, and video analysis to compare the relative merits of regularizers. These tests show systematic improvements compared to weight decay. Our experimental protocol put forward the versatility of a regularizer that is easy to implement and to operate that we eventually recommend as the new baseline for future approaches to transfer learning relying on fine-tuning.']",https://hal.science/hal-02988362,"['0.info', '1.info.info-cv']"
"['Xuhong Li', 'Yves Grandvalet', 'Franck Davoine']","[1041323, 5024, 3173]","['yves-grandvalet', 'franck-davoine']",A baseline regularization scheme for transfer learning with convolutional neural networks,hal-02315752,2020,10.1016/j.patcog.2019.107049,"['Transfer Learning', 'Convolutional neural networks', 'Parameter regularization', 'Regularization']","['In inductive transfer learning, fine-tuning pre-trained convolutional networks substantially outperforms training from scratch. When using fine-tuning, the underlying assumption is that the pre-trained model extracts generic features, which are at least partially relevant for solving the target task, but would be difficult to extract from the limited amount of data available on the target task. However, besides the initialization with the pre-trained model and the early stopping, there is no mechanism in fine-tuning for retaining the features learned on the source task. In this paper, we investigate several regularization schemes that explicitly promote the similarity of the final solution with the initial model. We show the benefit of having an explicit inductive bias towards the initial model. We eventually recommend that the baseline protocol for transfer learning should rely on a simple $L^2$ penalty using the pre-trained model as a reference.']",https://hal.science/hal-02315752,"['0.info', '1.info.info-lg', '0.info', '1.info.info-cv', '0.info', '1.info.info-ai']"
"['Julien Chiquet', 'Yves Grandvalet', 'Christophe Ambroise']","[15350, 5024, 1342328]","['julien-chiquet', 'yves-grandvalet', 'christopheambroise']",Inferring Multiple Graphical Structures,hal-00660169,2011,10.1007/s11222-010-9191-2,"['Probabilistic models', 'Network inference', 'Gaussian graphical model', 'Multiple sample setup', 'Cooperative-Lasso', 'Intertwined-Lasso']","['Gaussian Graphical Models provide a convenient framework for representing dependencies between variables. Recently, this tool has received a high interest for the discovery of biological networks. The literature focuses on the case where a single network is inferred from a set of measurements, but, as wetlab data is typically scarce, several assays, where the experimental conditions affect interactions, are usually merged to infer a single network. In this paper, we propose two approaches for estimating multiple related graphs, by rendering the closeness assumption into an empirical prior or group penalties. We provide quantitative results demonstrating the benefits of the proposed approaches. The methods presented in this paper are embeded in the R package simone from version 1.0-0 and later.']",https://hal.science/hal-00660169,"['0.info', '1.info.info-lg', '0.math', '1.math.math-st', '0.stat', '1.stat.th']"
"['Marta Avalos', 'Yves Grandvalet', 'Christophe Ambroise']","[742122, 5024, 1342328]","['mavalosf', 'yves-grandvalet', 'christopheambroise']",Parsimonious Additive Models,inserm-00149798,2007,10.1016/j.csda.2006.10.007,"['Model selection', 'Supervised learning', 'Nonparametric regression', 'Function estimation', 'Splines', 'Smoothing', 'Variable selection', 'Lasso', 'Penalization', 'Interpretable models']","['A new method for function estimation and variable selection, specifically designed for additive models fitted by cubic splines is proposed. This new method involves regularizing additive models using the l""1-norm, which generalizes the lasso to the nonparametric setting. As in the linear case, it shrinks coefficients and produces some coefficients that are exactly zero. It gives parsimonious models, selects significant variables, and reveals nonlinearities in the effects of predictors. Two strategies for finding a parsimonious additive model solution are proposed. Both algorithms are based on a fixed point algorithm, combined with a singular value decomposition that considerably reduces computation. The empirical behavior of parsimonious additive models is compared to the adaptive backfitting BRUTO algorithm. The results allow to characterize the domains in which our approach is effective: it performs significantly better than BRUTO when model estimation is challenging. An implementation of this method is illustrated using real data from the Cophar 1 ANRS 102 trial. Parsimonious additive models are applied to predict the indinavir plasma concentration in HIV patients. Results suggest that this new method is a promising technique for the research and application areas.']",https://inserm.hal.science/inserm-00149798,"['0.sdv', '1.sdv.bibs', '0.info', '1.info.info-lg', '0.math', '1.math.math-st']"
"['Régis Baudoin', 'Jean-Matthieu Prot', 'Grégory Nicolas', 'Jessy Brocheton', 'Céline Brochot', 'Cécile Legallais', 'Henri Benech', 'Eric Leclerc']","[753153, 170850, 945746]","['celine-brochot', 'cecile-legallais', 'cnrslec']",Evaluation of seven drug metabolisms and clearances by cryopreserved human primary hepatocytes cultivated in microfluidic biochips,ineris-00963431,2013,10.3109/00498254.2012.706725,"['HUMAN CRYOPRESERVED HEPATOCYTES', 'IDCCM', 'MICROFLUIDIC BIOCHIPS', 'DRUG METABOLISM', 'CLEARANCES']","[""We present characterization of the metabolic performance of human cryopreserved hepatocytes cultivated in a platform of parallelized microfluidic biochips. The RTqPCR analysis revealed that the mRNA levels of the cytochromes P450 (CYP 1A2, 2B6, 2C8, 2C9, 2C19, 2D6, 2E1, 3A4) were reduced after the adhesion period (when compared to the post-thawing step). The microfluidic perfusion played a part in stabilizing and partially recovering the levels of the HNF4a, PXR, OAPT2, CYP 1A2, 2B6, 2C19 and 3A4 mRNA on contrary to non-perfused cultures. Fluorescein diacetate staining and P-gp mRNA level illustrated the hepatocytes' polarity in the biochips. Drug metabolism was assessed using midazolam, tolbutamide, caffeine, omeprazole, dextromethorphan, acetaminophen and repaglinide as probes. Metabolite detection and quantification revealed that CYP1A2 (via the detection of paraxanthine), CYP3A4 (via 1-OH-midazolam, and omeprazole sulfone detection), CYP2C8 (via hydroxyl-repaglinide detection), CYP2C19 (via hydroxy-omeprazole detection) and CYP2D6 (via dextrorphan detection) were functional in our microfluidic configurations. Furthermore, the RTqPCR analysis showed that the drugs acted as inductors leading to overexpression of mRNA levels when compared to post-thawing values (such as for HNF4a, PXR and CYP3A4 by dextromethorpahn and omeprazole). Finally, intrinsic in vitro biochip clearances were extracted using a PBPK model for predictions. The biochip predictions were compared to literature in vitro data and in vivo situations.""]",https://ineris.hal.science/ineris-00963431,"['0.sdv', '1.sdv.tox', '0.sde']"
"['Chenming Yao', 'Sofiane Boudaoud', 'F Odille', 'O. Fokapu']","[1343264, 1234429, 746717, 751491]","['freddy-odille', 'odette-fokapu']",A preliminary study on the extraction of MRI Gradient-Induced potential from noisy ECG and its application to build a simple mathematical model,hal-04466519,2024,10.1016/j.bspc.2023.105634,['Broadband Electrocardiogram Magnetic Resonance Imaging Gradient-induced potential modelling Wavelets function choice Broyden-Fletcher-Goldfard-Shano algorithm estimation'],"['Background: Magnetic resonance imaging (MRI) is the medical imaging technique that benefits most from recent technological innovations, particularly the constant proposal of new MRI sequences that refine clinical information from the obtained images. However, this generates new gradient-induced potential (GIP) morphologies. These induced potentials (IPs) pollute the electrophysiological signals possibly recorded simultaneously. Several algorithms developed to eliminate this noise rely on modelling the shape of the IP. As each new sequence has a different shape of IP, it might be interesting to find a mathematical approach to building sequence-specific models. In this article, we present a preliminary study that includes wavelet decomposition of contaminated electrocardiographic (ECG) to extract IP morphologies and whose time-frequency characterization allows the elaboration of a harmonic model, using sinusoidal decomposition. Method: The in vitro IPs are used to select analyzing wavelets. A broadband sensor (3.5Khz), placed inside a 3 T MRI scanner, is used to collect 3-lead ECGs while activating three sequences that generate very high noise levels. The in vivo IPs extracted from the polluted ECGs are characterized to verify their quasi-periodicity. Parameters of the sinusoidal model (amplitude, frequency, phase) are estimated using the Broyden-Fletcher-Goldfard-Shano optimization algorithm. Result: Four wavelets (sym7, coif3, bior2.2, bior3.3) showed efficient in vivo IP extraction results. Three evaluation criteria for the modelling algorithm, allowing the calculated models to be compared with the shapes of the extracted IPs, showed promising results. For example, for the chosen efficiency criterion Nash-Sutcliffe efficiency , the values obtained for the three leads are between 0.99980 and 1. Conclusion: Promising preliminary results have been obtained for the extraction on modelling of different IPs from noisy ECG signals. Continuing this preliminary study on more MRI sequences and subjects could help build a database of IP models to initiate deep learning filtering. Since these models are sequence-specific and integrate the distribution of induced voltages on the body surface, we hope to find a generic relationship that enables the prediction of IPs by new sequences and anticipate the development of purification algorithms in a near future.']",https://hal.utc.fr/hal-04466519,['0.spi']
"['Henri Duboc', 'Sylvie Rajca', 'Dominique Rainteau', 'David Benarous', 'Marie-Anne Maubert', 'Elodie Quervain', 'Ginette Thomas', 'Véronique Barbu', 'Lydie Humbert', 'Guillaume Despras', 'Chantal Bridonneau', 'Fabien Dumetz', 'Jean-Pierre Grill', 'Joëlle Masliah', 'Laurent Beaugerie', 'Jacques Cosnes', 'Olivier Chazouillères', 'Raoul Poupon', 'Claude Wolf', 'Jean-Maurice Mallet', 'Philippe Langella', 'Germain Trugnan', 'Harry Sokol', 'Philippe Seksik']","[1223457, 1202992, 765965, 740429, 801170, 761210]","['jean-maurice-mallet', 'harry-sokol', 'seksik-philippe']","Connecting dysbiosis, bile-acid dysmetabolism and gut inflammation in inflammatory bowel diseases.",hal-00734237,2012,10.1136/gutjnl-2012-302578,"['HUMAN INTESTINAL BACTERIA', 'PRIMARY SCLEROSING CHOLANGITIS', 'NF-KAPPA-B', 'LITHOCHOLIC ACID', 'CROHNS-DISEASE', 'IN-VITRO', 'MICE', 'TUMOR-NECROSIS-FACTOR', 'ULCERATIVE-COLITIS', 'FECAL MICROBIOTA']","['OBJECTIVE: Gut microbiota metabolises bile acids (BA). As dysbiosis has been reported in inflammatory bowel diseases (IBD), we aim to investigate the impact of IBD-associated dysbiosis on BA metabolism and its influence on the epithelial cell inflammation response. DESIGN: Faecal and serum BA rates, expressed as a proportion of total BA, were assessed by high-performance liquid chromatography tandem mass spectrometry in colonic IBD patients (42) and healthy subjects (29). The faecal microbiota composition was assessed by quantitative real-time PCR. Using BA profiles and microbiota composition, cluster formation between groups was generated by ranking models. The faecal BA profiles in germ-free and conventional mice were compared. Direct enzymatic activities of BA biotransformation were measured in faeces. The impact of BA on the inflammatory response was investigated in vitro using Caco-2 cells stimulated by IL-1β. RESULTS: IBD-associated dysbiosis was characterised by a decrease in the ratio between Faecalibacterium prausntizii and Escherichia coli. Faecal-conjugated BA rates were significantly higher in active IBD, whereas, secondary BA rates were significantly lower. Interestingly, active IBD patients exhibited higher levels of faecal 3-OH-sulphated BA. The deconjugation, transformation and desulphation activities of the microbiota were impaired in IBD patients. In vitro, secondary BA exerted anti-inflammatory effects, but sulphation of secondary BAs abolished their anti-inflammatory properties. CONCLUSIONS: Impaired microbiota enzymatic activity observed in IBD-associated dysbiosis leads to modifications in the luminal BA pool composition. Altered BA transformation in the gut lumen can erase the anti-inflammatory effects of some BA species on gut epithelial cells and could participate in the chronic inflammation loop of IBD.']",https://hal.science/hal-00734237,"['0.chim', '1.chim.orga']"
"['Romain Daillère', 'Marie Vétizou', 'Nadine Waldschmitt', 'Takahiro Yamazaki', 'Christophe Isnard', 'Vichnou Poirier-Colame', 'Connie\xa0p.M. Duong', 'Caroline Flament', 'Patricia Lepage', 'Maria\xa0paula Roberti', 'Bertrand Routy', 'Nicolas Jacquelot', 'Lionel Apetoh', 'Sonia Becharef', 'Sylvie Rusakiewicz', 'Philip Langella', 'Harry Sokol', 'Guido Kroemer', 'David Enot', 'Antoine Roux', 'Alexander Eggermont', 'Eric Tartour', 'Ludger Johannes', 'Paul-Louis Woerther', 'Elisabeth Chachaty', 'Jean-Charles Soria', 'Encouse Golden', 'Silvia Formenti', 'Magdalena Plebanski', 'Mutsa Madondo', 'Philip Rosenstiel', 'Didier Raoult', 'Vincent Cattoir', 'Ivo\xa0gomperts Boneca', 'Mathias Chamaillard', 'Laurence Zitvogel']","[748833, 780259, 777539, 801170, 758378, 762312, 756960, 8465, 756204]","['patricia-lepage', 'harry-sokol', 'didier-raoult', 'laurence-zitvogel']",Enterococcus hirae and Barnesiella intestinihominis Facilitate Cyclophosphamide-Induced Therapeutic Immunomodulatory Effects,hal-01429856,2016,10.1016/j.immuni.2016.09.009,"['Intestinal Microbiota', 'Dendritic Cells', 'Inflammation', 'Infection', 'Richness', 'Antitumor Immunity', 'Gut Microbiota', 'Cancer', 'Bacteria', 'Translocation']","[""The efficacy of the anti-cancer immunomodulatory agent cyclophosphamide (CTX) relies on intestinal bacteria. How and which relevant bacterial species are involved in tumor immunosurveillance, and their mechanism of action are unclear. Here, we identified two bacterial species, Enterococcus hirae and Barnesiella intestinihominis that are involved during CTX therapy. Whereas E. hirae translocated from the small intestine to secondary lymphoid organs and increased the intratumoral CD8/ Treg ratio, B. intestinihominis accumulated in the colon and promoted the infiltration of IFN-gamma-producing gamma delta Tau cells in cancer lesions. The immune sensor, NOD2, limited CTX-induced cancer immunosurveillance and the bioactivity of these microbes. Finally, E. hirae and B. intestinihominis specific-memory Th1 cell immune responses selectively predicted longer progression-free survival in advanced lung and ovarian cancer patients treated with chemo-immunotherapy. Altogether, E. hirae and B. intestinihominis represent valuable ''oncomicrobiotics'' ameliorating the efficacy of the most common alkylating immunomodulatory compound.""]",https://hal.science/hal-01429856,"['0.sdv', '1.sdv.imm']"
"['Allison Agus', 'Karine Clément', 'Harry Sokol']","[756892, 801170]",['harry-sokol'],Gut microbiota-derived metabolites as central regulators in metabolic disorders,hal-03251679,2021,10.1136/gutjnl-2020-323071,"['Bile acid metabolism', 'Intestinal microbiology', 'Obesity']","['Metabolic disorders represent a growing worldwide health challenge due to their dramatically increasing prevalence. The gut microbiota is a crucial actor that can interact with the host by the production of a diverse reservoir of metabolites, from exogenous dietary substrates or endogenous host compounds. Metabolic disorders are associated with alterations in the composition and function of the gut microbiota. Specific classes of microbiota-derived metabolites, notably bile acids, short-chain fatty acids, branched-chain amino acids, trimethylamine N-oxide, tryptophan and indole derivatives, have been implicated in the pathogenesis of metabolic disorders. This review aims to define the key classes of microbiota-derived metabolites that are altered in metabolic diseases and their role in pathogenesis. They represent potential biomarkers for early diagnosis and prognosis as well as promising targets for the development of novel therapeutic tools for metabolic disorders.']",https://hal.sorbonne-universite.fr/hal-03251679,"['0.sdv', '1.sdv.mhep']"
"['Mathias Lavie-Richard', 'Harry Sokol']","[1205057, 801170]",['harry-sokol'],"The gut mycobiota: insights into analysis, environmental interactions and role in gastrointestinal diseases",hal-02627718,2019,10.1038/s41575-019-0121-2,"['Inhibits hyphal morphogenesis', 'Mucosa-associated microbiota', 'Internal transcribed spacer', 'Regulatory t-cells']","['The gut microbiota is a dense and diverse ecosystem that is involved in many physiological functions as well as in disease pathogenesis. It is dominated by bacteria, which have been extensively studied in the past 15 years; however, other microorganisms, such as fungi, phages, archaea and protists, are also present in the gut microbiota. Exploration of the fungal component, namely, the mycobiota, is at an early stage, and several specific technical challenges are associated with mycobiota analysis. The number of fungi in the lower gastrointestinal tract is far lower than that of bacteria, but fungal cells are much larger and much more complex than bacterial cells. In addition, a role of the mycobiota in disease, notably in IBD, is indicated by both descriptive data in humans and mechanistic data in mice. Interactions between bacteria and fungi within the gut, their functional roles and their interplay with the host and its immune system are fascinating areas that researchers are just beginning to investigate. In this Review, we discuss the newest data on the gut mycobiota and explore both the technical aspects of its study and its role in health and gastrointestinal diseases.']",https://hal.inrae.fr/hal-02627718,['0.sdv']
"['Doogesh Kodi Ramanah', 'Guilhem Lavaux', 'Jens Jasche', 'Benjamin D. Wandelt']",[738873],['g-lavaux'],Cosmological inference from Bayesian forward modelling of deep galaxy redshift surveys,hal-01867538,2019,10.1051/0004-6361/201834117,"['Methods data analysis', 'Methods statistical', 'Cosmology observations', 'Large-scale structure of Universe', 'Galaxies statistics']","['We present a large-scale Bayesian inference framework to constrain cosmological parameters using galaxy redshift surveys, via an application of the Alcock-Paczyński (AP) test. Our physical model of the non-linearly evolved density field, as probed by galaxy surveys, employs Lagrangian perturbation theory (LPT) to connect Gaussian initial conditions to the final density field, followed by a coordinate transformation to obtain the redshift space representation for comparison with data. We have implemented a Hamiltonian Monte Carlo sampler to generate realisations of three-dimensional (3D) primordial and present-day matter fluctuations from a non-Gaussian LPT-Poissonian density posterior given a set of observations. This hierarchical approach encodes a novel AP test, extracting several orders of magnitude more information from the cosmic expansion compared to classical approaches, to infer cosmological parameters and jointly reconstruct the underlying 3D dark matter density field. The novelty of this AP test lies in constraining the comoving-redshift transformation to infer the appropriate cosmology which yields isotropic correlations of the galaxy density field, with the underlying assumption relying purely on the geometrical symmetries of the cosmological principle. Such an AP test does not rely explicitly on modelling the full statistics of the field. We verified in depth via simulations that this renders our test robust to model misspecification. This leads to another crucial advantage, namely that the cosmological parameters exhibit extremely weak dependence on the currently unresolved phenomenon of galaxy bias, thereby circumventing a potentially key limitation. This is consequently among the first methods to extract a large fraction of information from statistics other than that of direct density contrast correlations, without being sensitive to the amplitude of density fluctuations. We perform several statistical efficiency and consistency tests on a mock galaxy catalogue, using the SDSS-III survey as template, taking into account the survey geometry and selection effects, to validate the Bayesian inference machinery implemented.Key words: methods: data analysis / methods: statistical / cosmology: observations / large-scale structure of Universe / galaxies: statistics']",https://hal.science/hal-01867538,"['0.phys', '1.phys.astr', '0.phys', '1.phys.phys', '2.phys.phys.phys-ins-det']"
"['Olivier Martineau-Huynh', 'Kumiko Kotera', 'Mauricio Bustamante', 'Didier Charrier', 'Sijbrand de Jong', 'Krijn D. de Vries', 'Ke Fang', 'Zhaoyang Feng', 'Chad Finley', 'Quanbu Gou', 'Junhua Gu', 'Jordan C. Hanson', 'Hongbo Hu', 'Kohta Murase', 'Valentin Niess', 'Foteini Oikonomou', 'Nicolas Renault-Tinacci', 'Julia Schmid', 'Charles Timmermans', 'Zhen Wang', 'Xiangping Wu', 'Jianli Zhang', 'Yi Zhang']",,,The Giant Radio Array for Neutrino Detection,hal-04012295,2015,10.1051/epjconf/201611603005,"['Showers atmosphere', 'Cosmic radiation UHE', 'Sensitivity', 'Neutrino detector']","['High-energy neutrino astronomy will probe the working of the most violent phenomena in the Universe. The Giant Radio Array for Neutrino Detection (GRAND) project consists of an array of ~ 10^5 radio antennas deployed over ~200000km^2 in a mountainous site. It aims at detecting high-energy neutrinos via the measurement of air showers induced by the decay in the atmosphere of tau leptons produced by the interaction of cosmic neutrinos under the Earth surface. Our objective with GRAND is to reach a neutrino sensitivity of 5 x 10^-11E^-2GeV^-1cm^-2s^-1sr^-1 above 3 x 10^16eV. This sensitivity ensures the detection of cosmogenic neutrinos in the most pessimistic source models, and up to 100 events per year are expected for the standard models. GRAND would also probe the neutrino signals produced at the potential sources of UHECRs.']",https://hal.science/hal-04012295,"['0.phys', '1.phys.astr', '0.phys', '1.phys.phys', '2.phys.phys.phys-ins-det']"
"['Romain Teyssier', 'Andrew Pontzen', 'Yohan Dubois', 'Justin I. Read']","[755250, 738810]",['yohan-dubois'],Cusp-core transformations in dwarf galaxies: observational predictions,hal-03645591,2013,10.1093/mnras/sts563,"['Galaxies dwarf', 'ISM structure', 'Methods numerical', 'Dark matter', 'Astrophysics - Cosmology and Nongalactic Astrophysics']","['The presence of a dark matter core in the central kiloparsec of many dwarf galaxies has been a long-standing problem in galaxy formation theories based on the standard cold dark matter paradigm. Recent simulations, based on smooth particle hydrodynamics and rather strong feedback recipes, have shown that it was indeed possible to form extended dark matter cores using baryonic processes related to a more realistic treatment of the interstellar medium. Using adaptive mesh refinement, together with a new, stronger supernova feedback scheme that we have recently implemented in the RAMSES code, we show that it is also possible to form a prominent dark matter core within the well-controlled framework of an isolated, initially cuspy, 10<SUP>10</SUP> M<SUB>⊙</SUB> dark matter halo. Although our numerical experiment is idealized, it allows a clean and unambiguous identification of the dark matter core formation process. Our dark matter inner profile is well fitted by a pseudo-isothermal profile with a core radius of 800 pc. The core formation mechanism is consistent with the one proposed by Pontzen & Governato. We highlight two key observational predictions of all simulations that find cusp-core transformations: (i) a bursty star formation history with a peak-to-trough ratio of 5 to 10 and a duty cycle comparable to the local dynamical time and (ii) a stellar distribution that is hot with v/σ ∼ 1. We compare the observational properties of our model galaxy with recent measurements of the isolated dwarf Wolf-Lundmark-Mellote (WLM). We show that the spatial and kinematical distribution of stars and H I gas are in striking agreement with observations, supporting the fundamental role played by stellar feedback in shaping both the stellar and dark matter distribution.']",https://hal.science/hal-03645591,['0.sdu']
"['Mélanie Habouzit', 'Marta Volonteri', 'Yohan Dubois']",[766152],,Blossoms from black hole seeds: properties and early growth regulated by supernova feedback,insu-03747457,2017,10.1093/mnras/stx666,"['Black hole physics', 'Methods numerical', 'Galaxies evolution', 'Galaxies formation', 'Galaxies high redshift', 'Astrophysics - Astrophysics of Galaxies']","[""Massive black holes (BHs) inhabit local galaxies, including the Milky Way and some dwarf galaxies. BH formation, occurring at early cosmic times, must account for the properties of BHs in today's galaxies, notably why some galaxies host a BH, and others do not. We investigate the formation, distribution and growth of BH 'seeds' by using the adaptive mesh refinement code ramses. We develop an implementation of BH formation in dense, low-metallicity environments, as advocated by models invoking the collapse of the first generation of stars, or of dense nuclear star clusters. The seed masses are computed one-by-one on-the-fly, based on the star formation rate and the stellar initial mass function. This self-consistent method to seed BHs allows us to study the distribution of BHs in a cosmological context and their evolution over cosmic time. We find that all high-mass galaxies tend to host a BH, whereas low-mass counterparts have a lower probability of hosting a BH. After the end of the epoch of BH formation, this probability is modulated by the growth of the galaxy. The simulated BHs connect to low-redshift observational samples, and span a similar range in accretion properties as Lyman-break analogs. The growth of BHs in low-mass galaxies is stunted by strong supernova (SN) feedback. The properties of BHs in dwarf galaxies thus remain a testbed for BH formation. Simulations with strong SN feedback, which is able to quench BH accretion in shallow potential wells, produce galaxies and BHs in better agreement with observational constraints.""]",https://insu.hal.science/insu-03747457,"['0.sdu', '0.sdu', '1.sdu.astr']"
"['Julien Kirchgesner', 'Magali Lemaitre', 'Fabrice Carrat', 'Mahmoud Zureik', 'Franck Carbonnel', 'Rosemary Dray-Spira']","[748817, 181388, 757933, 1351397, 756222]","['julien-kirchgesner', 'fabrice-carrat']",Risk of Serious and Opportunistic Infections Associated With Treatment of Inflammatory Bowel Diseases.,hal-02878410,2018,10.1053/j.gastro.2018.04.012,"['Anti-TNFs', 'Combination Therapy', 'Infection', 'Inflammatory Bowel Disease', 'Thiopurines']","['Background & aims: The risk of infection associated with tumor necrosis factor antagonists (anti-TNF) and thiopurines (combination therapy) is uncertain. We assessed the risk of serious and opportunistic infections in patients with inflammatory bowel disease (IBD) treated with thiopurine monotherapy, anti-TNF monotherapy, or combination therapy in a large cohort of patients in France. Methods: We performed a nationwide population-based study of patients (18 years or older) with a diagnosis of IBD in the French national health insurance database; we collected data from January 1, 2009 until December 31, 2014. The risks of serious and opportunistic infections associated with exposure to combination therapy, anti-TNF, and thiopurine monotherapies were compared using marginal structural Cox proportional hazard models adjusted for baseline and time-varying sociodemographic characteristics, medications, and comorbidities. Results: Among the 190,694 patients with IBD included in our analysis, 8561 serious infections and 674 opportunistic infections occurred. Compared with anti-TNF monotherapy, combination therapy was associated with increased risks of serious infection (hazard ratio [HR], 1.23; 95% confidence interval [CI], 1.05-1.45) and opportunistic infection (HR, 1.96; 95% CI, 1.32-2.91). Compared with thiopurine monotherapy, anti-TNF monotherapy was associated with increased risks of serious infection (HR, 1.71; 95% CI, 1.56-1.88), mycobacterial infection (HR, 1.98; 95% CI, 1.15-3.40), and bacterial infection (HR, 2.38; 95% CI, 1.23-4.58, respectively). Conversely, anti-TNF monotherapy was associated with decreased risk of opportunistic viral infection compared with thiopurine monotherapy (HR, 0.57; 95% CI, 0.38-0.87). Conclusions: In a nationwide cohort study of patients with IBD in France, we found heterogeneity in risks of serious and opportunistic infections in patients treated with immune-suppressive regimens. These should be carefully considered and weighed against potential benefits for IBD treatment in patient management.']",https://hal.sorbonne-universite.fr/hal-02878410,"['0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.mi', '0.sdv', '1.sdv.spee', '0.sdv', '1.sdv.imm', '2.sdv.imm.imm']"
"['Christophe Hézode', 'Hélène Fontaine', 'Céline Dorival', 'Fabien Zoulim', 'Dominique Larrey', 'Valérie Canva', 'Victor de Ledinghen', 'Thierry Poynard', 'Didier Samuel', 'Marc Bourlière', 'Laurent Alric', 'Jean-Jacques Raabe', 'Jean-Pierre Zarski', 'Patrick Marcellin', 'Ghassan Riachi', 'Pierre-Henri Bernard', 'Véronique Loustaud-Ratti', 'Olivier Chazouillères', 'Armand Abergel', 'Dominique Guyader', 'Sophie Métivier', 'Albert Tran', 'Vincent Di Martino', 'Xavier Causse', 'Thong Dao', 'Damien Lucidarme', 'Isabelle Portal', 'Patrice Cacoub', 'Jérôme Gournay', 'Véronique Grando-Lemaire', 'Patrick Hillon', 'Pierre Attali', 'Thierry Fontanges', 'Isabelle Rosa', 'Ventzislava Petrov-Sanchez', 'Yoann Barthe', 'Jean-Michel Pawlotsky', 'Stanislas Pol', 'Fabrice Carrat', 'Jean-Pierre Bronowicki']","[755798, 890662, 759679, 756883, 881462, 763073, 757059, 759698, 757187, 755799, 181388, 900180]","['fabien-zoulim', 'fabrice-carrat']",Effectiveness of telaprevir or boceprevir in treatment-experienced patients with HCV genotype 1 infection and cirrhosis.,inserm-01057763,2014,10.1053/j.gastro.2014.03.051,"['Chronic hepatitis C', 'Cirrhosis', 'Boceprevir', 'Telaprevir']","['BACKGROUND & AIMS: We investigated the effectiveness of the protease inhibitors peginterferon and ribavirin in treatment-experienced patients with hepatitis C virus (HCV) genotype 1 infection and cirrhosis. METHODS: In the Compassionate Use of Protease Inhibitors in Viral C Cirrhosis study, 511 patients with HCV genotype 1 infection and compensated cirrhosis who did not respond to a prior course of peginterferon and ribavirin (44.3% relapsers or patients with viral breakthrough, 44.8% partial responders, and 8.0% null responders) were given either telaprevir (n\xa0= 299) or boceprevir (n\xa0= 212) for 48 weeks. We assessed percentages of patients with sustained viral responses 12 weeks after therapy and safety. This observational study did not allow for direct comparison of the 2 regimens. RESULTS: Among patients given telaprevir, 74.2% of relapsers, 40.0% of partial responders, and 19.4% of null responders achieved SVR12. Among those given boceprevir, 53.9% of relapsers, 38.3% of partial responders, and none of the null responders achieved SVR12. In multivariate analysis, factors associated with SVR12 included prior response to treatment response, no lead-in phase, HCV subtype 1b (vs 1a), and baseline platelet count greater than 100,000/mm(3). Severe adverse events occurred in 49.9% of cases, including liver decompensation, severe infections in 10.4%, and death in 2.2%. In multivariate analysis, baseline serum albumin level less than 35 g/L and baseline platelet counts of 100,000/mm(3) or less predicted severe side effects or death. CONCLUSIONS: Relatively high percentages of real-life, treatment-experienced patients with HCV genotype 1 infection and cirrhosis respond to the combination of peginterferon and ribavirin with telaprevir or boceprevir. However, side effects are frequent and often severe. Baseline levels of albumin and platelet counts can be used to guide treatment decisions. ClinicalTrials.gov number: NCT01514890.']",https://inserm.hal.science/inserm-01057763,"['0.sdv', '1.sdv.bbm', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.heg']"
"['Giuseppe Paolo', 'Alexandre Coninx', 'Stéphane Doncieux', 'Alban Laflaquière']","[735825, 184690, 3909, 1096132]","['gpaolo', 'alex-coninx', 'stephane-doncieux']",Sparse Reward Exploration via Novelty Search and Emitters,hal-03200022,2021,10.1145/3449639.3459314,"['Novelty search', 'Sparse rewards', 'Emitters', 'Evolutionary algorithm', 'Quality diversity']","['Reward-based optimization algorithms require both exploration, to find rewards, and exploitation, to maximize performance. The need for efficient exploration is even more significant in sparse reward settings, in which performance feedback is given sparingly, thus rendering it unsuitable for guiding the search process. In this work, we introduce the SparsE Reward Exploration via Novelty and Emitters (SERENE) algorithm, capable of efficiently exploring a search space, as well as optimizing rewards found in potentially disparate areas. Contrary to existing emitters-based approaches, SERENE separates the search space exploration and reward exploitation into two alternating processes. The first process performs exploration through Novelty Search, a divergent search algorithm. The second one exploits discovered reward areas through emitters, i.e. local instances of population-based optimization algorithms. A meta-scheduler allocates a global computational budget by alternating between the two processes, ensuring the discovery and efficient exploitation of disjoint reward areas. SERENE returns both a collection of diverse solutions covering the search space and a collection of high-performing solutions for each distinct reward area. We evaluate SERENE on various sparse reward environments and show it compares favorably to existing baselines.']",https://hal.science/hal-03200022,"['0.info', '0.info', '1.info.info-ai', '0.info', '1.info.info-rb']"
"['Baptiste Caramiaux', 'Nicola Montecchio', 'Atau Tanaka', 'Frédéric Bevilacqua']","[179793, 739851, 14805]","['baptiste-caramiaux', 'atau-tanaka', 'frederic-bevilacqua']",Adaptive Gesture Recognition with Variation Estimation for Interactive Systems,hal-01266046,2014,10.1145/2643204,"['Interaction', 'Gesture Recognition', 'Particle Filtering', 'Machine Learning', 'Adaptive Decoding', 'Gesture Analysis']","['This paper presents a gesture recognition/adaptation system for Human Computer Interaction applications that goes beyond activity classification and that, complementary to gesture labeling, characterizes the movement execution. We describe a template-based recognition method that simultaneously aligns the input gesture to the templates using a Sequential Montecarlo inference technique. Contrary to standard template-based methods based on dynamic programming, such as Dynamic Time Warping, the algorithm has an adaptation process that tracks gesture variation in real-time. The method continuously updates, during execution of the gesture, the estimated parameters and recognition results which offers key advantages for continuous human-machine interaction. The technique is evaluated in several different ways: recognition and early recognition are evaluated on a 2D onscreen pen gestures; adaptation is assessed on synthetic data; and both early recognition and adaptation is evaluation in a user study involving 3D free space gestures. The method is not only robust to noise and successfully adapts to parameter variation but also performs recognition as well or better than non-adapting offline template-based methods.']",https://hal.science/hal-01266046,"['0.info', '0.info', '1.info.info-hc']"
"['Baptiste Caramiaux', 'Sarah Fdili Alaoui']","[179793, 1112026]",['baptiste-caramiaux'],"Explorers of Unknown Planets"": Practices and Politics of Artificial Intelligence in Visual Arts",hal-03762351,2022,10.1145/3555578,"['AI-Art', 'Creative AI', 'Art & Technology', 'Cultural Studies']","['Alongside recent advances in artificial intelligence (AI), a new art practice has emerged in recent years that borrows and transforms these advances in the production of artworks. The actors of this emergent practice are coming from contemporary art, media and digital arts. These artists have developed an original practice of AI within their creative field. In this article, we propose a qualitative study to explore the nature of this practice. We interviewed five internationally renowned artists about how AI is integrated into their work. Through a thematic analysis of the interviews, we first find that their practice relies on crafting algorithms and data as materials. We uncover how they explicitly use this material unpredictability rather than avoid it. Secondly, we highlight the politics of their practice that consist of resisting the culture of AI research, as well as its inherent power dynamics. We also highlight how their relationship with the technology is imbued with ethics and how they rethink their role with respect to the technology. In this paper, we aim to provide the CSCW community with a way to expand the framework in which AI can be understood not only as a tool but also as cultural and political design material.']",https://inria.hal.science/hal-03762351,"['0.info', '1.info.info-hc', '0.shs', '1.shs.info']"
"['Chloë Leclère', 'Sylvie Viaux', 'Marie Avril', 'Catherine Achard', 'Mohamed Chetouani', 'Sylvain Missonnier', 'David Cohen']","[182097, 179528, 179406, 746498]","['catherine-achard', 'mohamed-chetouani', 'sylvain-missonnier', 'david-cohen']",Why Synchrony Matters during Mother-Child Interactions: A Systematic Review,hal-01366294,2014,10.1371/journal.pone.0113571,"['Synchrony', 'Mother-child interaction']","['Background: Assessment of mother-child interactions is a core issue of early child development and psychopathology. This paper focuses on the concept of “synchrony” and examines (1) how synchrony in mother-child interaction is defined and operationalized; (2) the contribution that the concept of synchrony has brought to understanding the nature of mother-child interactions. Method: Between 1977 and 2013, we searched several databases using the following key-words: « synchrony » « interaction » and « mother-child ». We focused on studies examining parent-child interactions among children aged 2 months to 5 years. From the 63 relevant studies, we extracted study description variables (authors, year, design, number of subjects, age); assessment conditions and modalities; and main findings. Results: The most common terms referring to synchrony were mutuality, reciprocity, rhythmicity, harmonious interaction, turn-taking and shared affect; all terms were used to characterize the mother-child dyad. As a consequence, we propose defining synchrony as a dynamic and reciprocal adaptation of the temporal structure of behaviors and shared affect between interactive partners. Three main types of assessment methods for studying synchrony emerged: (1) global interaction scales with dyadic items; (2) specific synchrony scales; and (3) micro-coded time-series analyses. It appears that synchrony should be regarded as a social signal per se as it has been shown to be valid in both normal and pathological populations. Better mother-child synchrony is associated with familiarity (vs. unknown partner), a healthy mother (vs. pathological mother), typical development (vs. psychopathological development), and a more positive child outcomes. Discussion: Synchrony is a key feature of mother-infant interactions. Adopting an objective approach in studying synchrony is not a simple task given available assessment tools and due to its temporality and multimodal expression. We propose an integrative approach combining clinical observation and engineering techniques to improve the quality of synchrony analysis.']",https://hal.sorbonne-universite.fr/hal-01366294,"['0.shs', '1.shs.psy', '0.sdv', '1.sdv.mhep', '2.sdv.mhep.ped']"
"['Karim Slimani', 'Catherine Achard', 'Brahim Tamadazte']","[1317292, 182097, 178670]","['catherine-achard', 'brahim-tamadazte']",RoCNet++: Triangle-based descriptor for accurate and robust point cloud registration,hal-04311359,2024,10.1016/j.patcog.2023.110108,['Deep learning registration matching'],"['This paper introduces RoCNet++, a point cloud registration method with two main contributions, one concerning the design of a robust descriptor and another concerning the estimation of the rigid transformation. First, to robustly capture the local geometric properties of the surface, i.e., each point is characterized by all the triangles formed by itself and its nearest neighbours in the 3D point cloud. The idea is to assist the learning of the descriptor by introducing a priori information about interesting geometric properties such as the invariance of triangle angles under rigid transformations. This local triangle-based descriptor is integrated into the recently developed RoCNet architecture for estimating the correspondences between source and target point clouds. We then introduce the Farthest Sampling-guided Registration (FSR), which relies on successive farthest point samplings to estimate the global rigid transformation between 3D point clouds. The new proposed architecture RoCNet++ has been evaluated in different configurations: clean, noisy and partial data on both synthetic and real databases such as ModelNet40, KITTI, and 3DMatch. RoCNet++ shows improved performances on these benchmark datasets in favourable and unfavourable conditions. Furthermore, both the local triangle-based descriptor and the Farthest Sampling-guided Registration (FSR) can be used in other registration algorithms.']",https://hal.science/hal-04311359,"['0.info', '1.info.info-ai']"
"['Abdallah Benzine', 'Bertrand Luvison', 'Quoc-Cuong Pham', 'Catherine Achard']","[855568, 182097]","['quoc-cuong-pham', 'catherine-achard']",Single-shot 3D multi-person pose estimation in complex images,hal-02926239,2021,10.1016/j.patcog.2020.107534,"['Multi-person', '3D', 'Human pose', 'Deep learning']","['In this paper, we propose a new single shot method for multi-person 3D human pose estimation in complex images. The model jointly learns to locate the human joints in the image, to estimate their 3D coordinates and to group these predictions into full human skeletons. The proposed method deals with a variable number of people and does not need bounding boxes to estimate the 3D poses. It leverages and extends the Stacked Hourglass Network and its multi-scale feature learning to manage multi-person situations. Thus, we exploit a robust 3D human pose formulation to fully describe several 3D human poses even in case of strong occlusions or crops. Then, joint grouping and human pose estimation for an arbitrary number of people are performed using the asso-ciative embedding method. Our approach significantly outperforms the state of the art on the challenging CMU Panoptic. Furthermore, it leads to good results on the complex and synthetic images from the newly proposed JTA Dataset.']",https://hal.sorbonne-universite.fr/hal-02926239,"['0.info', '1.info.info-cv', '0.info', '1.info.info-ai']"
"['Adrien Chan-Hon-Tong', 'Catherine Achard', 'Laurent Lucat']","[967233, 182097]",['catherine-achard'],Simultaneous segmentation and classification of human actions in video streams using deeply optimized Hough transform,cea-01818435,2014,10.1016/j.patcog.2014.05.010,"['Temporal localization', 'Image recognition', 'Temporal domain', 'Hough', 'Video streaming', 'Image segmentation', 'Hough transforms', 'Classification of information', 'Human actions', 'State-of-the-art performance', 'Human activity recognition']","['Most researches on human activity recognition do not take into account the temporal localization of actions. In this paper, a new method is designed to model both actions and their temporal domains. This method is based on a new Hough method which outperforms previous published ones on honeybee dataset thanks to a deeper optimization of the Hough variables. Experiments are performed to select skeleton features adapted to this method and relevant to capture human actions. With these features, our pipeline improves state-of-the-art performances on TUM dataset and outperforms baselines on several public datasets.']",https://cea.hal.science/cea-01818435,['0.spi']
"['Micael Carvalho', 'Rémi Cadène', 'David Picard', 'Laure Soulier', 'Nicolas Thome', 'Matthieu Cord']","[173554, 8070, 181803, 13617]","['rcadene', 'soulierl', 'nicolas-thome', 'matthieucord']",Cross-Modal Retrieval in the Cooking Context,hal-01839068,2018,10.1145/3209978.3210036,"['Cross-modal Retrieval', 'Semantic Embeddings', 'Neural networks Computer science', 'Deep Learning', 'Multimedia and multimodal retrieval']","['Designing powerful tools that support cooking activities has rapidly gained popularity due to the massive amounts of available data, as well as recent advances in machine learning that are capable of analyzing them. In this paper, we propose a cross-modal retrieval model aligning visual and textual data (like pictures of dishes and their recipes) in a shared representation space. We describe an effective learning scheme, capable of tackling large-scale problems, and validate it on the Recipe1M dataset containing nearly 1 million picture-recipe pairs. We show the effectiveness of our approach regarding previous state-of-the-art models and present qualitative results over computational cooking use cases.', '.']",https://hal.science/hal-01839068,"['0.info', '1.info.info-cv']"
"['Laure Soulier', 'Chirag Shah', 'Lynda Tamine']","[8070, 963520, 744669]","['soulierl', 'lynda-tamine-lechani']",User-Driven System-Mediated Collaborative Information Retrieval,hal-01132594,2014,10.1145/2600428.2609598,"['Collaborative information retrieval', 'User study', 'Role mining']","[""Most of the previous approaches surrounding collaborative information retrieval (CIR) provide either a user-based me-diation, in which the system only supports users' collab-orative activities, or a system-based mediation, in which the system plays an active part in balancing user roles, re-ranking results, and distributing them to optimize overall retrieval performance. In this paper, we propose to com-bine both of these approaches by a role mining methodology that learns from users' actions about the retrieval strategy they adapt. This hybrid method aims at showing how users are different and how to use these differences for suggesting roles. The core of the method is expressed as an algorithm that (1) monitors users' actions in a CIR setting; (2) discov-ers differences among the collaborators along certain dimen-sions; and (3) suggests appropriate roles to make the most out of individual skills and optimize IR performance. Our approach is empirically evaluated and relies on two different laboratory studies involving 70 pairs of users. Our experi-ments show promising results that highlight how role min-ing could optimize the collaboration within a search session. The contributions of this work include a new algorithm for mining user roles in collaborative IR, an evaluation method-ology, and a new approach to improve IR performance with the operationalization of user-driven system-mediated col-laboration.""]",https://hal.science/hal-01132594v2,"['0.info', '1.info.info-ir']"
"['Jesus Lovon', 'Laure Soulier', 'Karen Pinel-Sauvagnat', 'Lynda Tamine']","[744259, 8070, 21007, 744669]","['jesus-lovon-melgarejo', 'soulierl', 'karen-pinel-sauvagnat', 'lynda-tamine-lechani']","Studying Catastrophic Forgetting in Neural Ranking Models, Oubli catastrophique et approches neuronales pour la Recherche d’Information",hal-03156630,2021,10.1007/978-3-030-72113-8_25,"['Neural ranking', 'Catastrophic forgetting', 'Lifelong learning']","['Several deep neural ranking models have been proposed in the recent IR literature. While their transferability to one target domain held by a dataset has been widely addressed using traditional domain adaptation strategies, the question of their cross-domain transferability is still under-studied. We study here in what extent neural ranking models catastrophically forget old knowledge acquired from previously observed domains after acquiring new knowledge, leading to performance decrease on those domains. Our experiments show that the effectiveness of neural IR ranking models is achieved at the cost of catastrophic forgetting and that a lifelong learning strategy using a cross-domain regularizer successfully mitigates the problem. Using an explanatory approach built on a regression model, we also show the effect of domain characteristics on the rise of catastrophic forgetting. We believe that the obtained results can be useful for both theoretical and practical future work in neural IR.']",https://hal.science/hal-03156630,"['0.info', '1.info.info-ir', '0.info', '1.info.info-ai']"
"['Jean-Baptiste Mouret', 'Stéphane Doncieux']","[1495, 3909]","['jb-mouret', 'stephane-doncieux']",Using Behavioral Exploration Objectives to Solve Deceptive Problems in Neuro-evolution,hal-00473132,2009,10.1145/1569901.1569988,"['Neural networks', 'Multiobjective evolutionary algorithm', 'Diversity', 'Deceptive problems']","['Encouraging exploration, typically by preserving the diversity within the population, is one of the most common method to improve the behavior of evolutionary algorithms with deceptive fitness functions. Most of the published approaches to stimulate exploration rely on a distance between genotypes or phenotypes; however, such distances are difficult to compute when evolving neural networks due to (1) the algorithmic complexity of graph similarity measures, (2) the competing conventions problem and (3) the complexity of most neural-network encodings. In this paper, we introduce and compare two conceptually simple, yet efficient methods to improve exploration and avoid premature convergence when evolving both the topology and the parameters of neural networks. The two proposed methods, respectively called behavioral novelty and behavioral diversity are built on multiobjective evolutionary algorithms and on a user-defined distance between behaviors. They can be employed with any genotype. We benchmarked them on the evolution of a neural network to compute a Boolean function with a deceptive fitness. The results obtained with the two proposed methods are statistically similar to those of NEAT and substantially better than those of the control experiment and of a phenotype-based diversity mechanism.']",https://hal.science/hal-00473132,"['0.info', '1.info.info-ai']"
"['Marc Lensink', 'Guillaume Brysbaert', 'Nurul Nadzirin', 'Sameer Velankar', 'Raphaël A.G. Chaleil', 'Tereza Gerguri', 'Paul Bates', 'Elodie Laine', 'Alessandra Carbone', 'Sergei Grudinin', 'Ren Kong', 'Ran‐ran Liu', 'Xi‐ming Xu', 'Hang Shi', 'Shan Chang', 'Miriam Eisenstein', 'Agnieszka Karczynska', 'Cezary Czaplewski', 'Emilia Lubecka', 'Agnieszka Lipska', 'Paweł Krupa', 'Magdalena Mozolewska', 'Łukasz Golon', 'Sergey Samsonov', 'Adam Liwo', 'Silvia Crivelli', 'Guillaume Pagès', 'Mikhail Karasikov', 'Maria Kadukova', 'Yumeng Yan', 'Sheng‐you Huang', 'Mireia Rosell', 'Luis Angel Rodríguez‐lumbreras', 'Miguel Romero‐durana', 'Lucía Díaz‐bueno', 'Juan Fernandez‐recio', 'Charles Christoffer', 'Genki Terashi', 'Woong‐hee Shin', 'Tunde Aderinwale', 'Sai Raghavendra Maddhuri Venkata Subram', 'Daisuke Kihara', 'Dima Kozakov', 'Sandor Vajda', 'Kathyn Porter', 'Dzmitry Padhorny', 'Israel Desta', 'Dmitri Beglov', 'Mikhail Ignatov', 'Sergey Kotelnikov', 'Iain Moal', 'David Ritchie', 'Isaure Chauvot de Beauchêne', 'Bernard Maigret', 'Marie-Dominique Devignes', 'Maria Elisa Ruiz Echartea', 'Didier Barradas‐bautista', 'Zhen Cao', 'Luigi Cavallo', 'Romina Oliva', 'Yue Cao', 'Yang Shen', 'Minkyung Baek', 'Taeyong Park', 'Hyeonuk Woo', 'Chaok Seok', 'Merav Braitbard', 'Lirane Bitton', 'Dina Scheidman‐duhovny', 'Justas Dapkūnas', 'Kliment Olechnovič', 'Česlovas Venclovas', 'Petras J. Kundrotas', 'Saveliy Belkin', 'Devlina Chakravarty', 'Varsha Badal', 'Ilya A. Vakser', 'Thom Vreven', 'Sweta Vangaveti', 'Tyler M. Borrman', 'Zhiping Weng', 'Johnathan D Guest', 'Ragul Gowthaman', 'Brian G Pierce', 'Xianjin Xu', 'Rui Duan', 'Liming Qiu', 'Jie Hou', 'Benjamin Ryan Merideth', 'Zhiwei Ma', 'Jianlin Cheng', 'Xiaoqin Zou', 'Panos Koukos', 'Jorge Roel‐touris', 'Francesco Ambrosetti', 'Cunliang Geng', 'Jörg Schaarschmidt', 'Mikael Trellet', 'Adrien S.J. Melquiond', 'Li Xue', 'Brian Jiménez‐garcía', 'Charlotte Noort', 'Rodrigo Honorato', 'Alexandre M.J.J. Bonvin', 'Shoshana J. Wodak']","[180132, 184734, 760664, 871038, 926099, 175316, 797462, 767440, 996541, 797463, 797464, 797465, 765070, 761929, 761930, 779076, 1609, 14814, 742369, 1244103, 768356, 765067, 797466, 766140, 765071]","['marc-lensink', 'guillaume-brysbaert', 'alessandra-carbone', 'sergei-grudinin', 'david-ritchie', 'isaure-chauvot-de-beauchene', 'mddevignes']",Blind prediction of homo‐ and hetero‐ protein complexes: The CASP13‐CAPRI experiment,hal-02320974,2019,10.1002/prot.25838,"['CAPRI', 'CASP', 'Oligomeric state', 'Blind prediction', 'Protein-protein interaction', 'Protein complexes', 'Protein assemblies', 'Template-based modeling', 'Docking']","['We present the results for CAPRI Round 46, the third joint CASP‐CAPRI protein assembly prediction challenge. The Round comprised a total of 20 targets including 14 homo‐oligomers and 6 heterocomplexes. Eight of the homo‐oligomer targets and one heterodimer comprised proteins that could be readily modeled using templates from the Protein Data Bank, often available for the full assembly. The remaining 11 targets comprised 5 homodimers, 3 heterodimers, and two higher‐order assemblies. These were more difficult to model, as their prediction mainly involved “ab‐initio” docking of subunit models derived from distantly related templates. A total of ~30 CAPRI groups, including 9 automatic servers, submitted on average ~2000 models per target. About 17 groups participated in the CAPRI scoring rounds, offered for most targets, submitting ~170 models per target. The prediction performance, measured by the fraction of models of acceptable quality or higher submitted across all predictors groups, was very good to excellent for the nine easy targets. Poorer performance was achieved by predictors for the 11 difficult targets, with medium and high quality models submitted for only 3 of these targets. A similar performance “gap” was displayed by scorer groups, highlighting yet again the unmet challenge of modeling the conformational changes of the protein components that occur upon binding or that must be accounted for in template‐based modeling. Our analysis also indicates that residues in binding interfaces were less well predicted in this set of targets than in previous Rounds, providing useful insights for directions of future improvements.']",https://inria.hal.science/hal-02320974,"['0.info', '1.info.info-bi']"
"['Yasaman Karami', 'Elodie Laine', 'Alessandra Carbone']","[776565, 1102065, 926099]","['yasaman-karami', 'elodie-laine', 'alessandra-carbone']",Dissecting protein architecture with communication blocks and communicating segment pairs,hal-01260475,2016,10.1186/s12859-015-0855-y,"['Protein structure', 'Protein dynamics', 'Allostery', 'Molecular dynamics', 'Residue network']","['Background: Proteins adapt to environmental conditions by changing their shape and motions. Characterising protein conformational dynamics is increasingly recognised as necessary to understand how proteins function. Given a conformational ensemble, computational tools are needed to extract in a systematic way pertinent and comprehensive biological information. Results: Here, we present a method, Communication Mapping (COMMA), to decipher the dynamical architecture of a protein. The method first extracts residue-based dynamic properties from all-atom molecular dynamics simulations. Then, it integrates them in a graph theoretic framework, where it identifies groups of residues or protein regions that mediate short-and long-range communication. COMMA introduces original concepts to contrast the different roles played by these regions, namely communication blocks and communicating segment pairs, and evaluates the connections and communication strengths between them. We show the utility and capabilities of COMMA by applying it to three archetypal proteins, namely protein A, the tyrosine kinase KIT and the tumour suppressor p53. Conclusion: Our method permits to compare in a direct way the dynamical behaviour either of proteins with different characteristics or of the same protein in different conditions. It is useful to identify residues playing a key role in protein allosteric regulation and to explain the effects of deleterious mutations in a mechanistic way. COMMA is a fully automated tool with broad applicability. It is freely available to the community at www.lcqb.upmc.fr/COMMA.']",https://hal.sorbonne-universite.fr/hal-01260475,"['0.info', '1.info.info-bi']"
"['Joanna I. Sulkowska', 'Faruck Morcos', 'Martin Weigt', 'Terence Hwa', 'Jose N. Onuchic']",[976468],['martin-weigt'],Genomics-aided structure prediction,hal-01528443,2012,10.1073/pnas.1207864109,"['Protein folding', 'Residue contact prediction', 'Contact map estimation', 'Residue-residue coevolution', 'Statistical potentials']","['We introduce a theoretical framework that exploits the ever-increasing genomic sequence information for protein structure prediction. Structure-based models are modified to incorporate constraints by a large number of non-local contacts estimated from direct coupling analysis (DCA) of co-evolving genomic sequences. A simple hybrid method, called DCA-fold, integrating DCA contacts with an accurate knowledge of local information (e. g., the local secondary structure) is sufficient to fold proteins in the range of 1-3 angstrom resolution.']",https://hal.science/hal-01528443,['0.sdv']
"['Angel E. Dago', 'Alexander Schug', 'Andrea Procaccini', 'James A. Hoch', 'Martin Weigt', 'Hendrik Szurmant']",[976468],['martin-weigt'],"Structural basis of histidine kinase autophosphorylation deduced by integrating genomics, molecular dynamics, and mutagenesis",hal-01528442,2012,10.1073/pnas.1201301109,"['Protein structure prediction', 'Biological physics', 'Coevolution', 'Signal transduction', 'Two component system']","['Signal transduction proteins such as bacterial sensor histidine kinases, designed to transition between multiple conformations, are often ruled by unstable transient interactions making structural characterization of all functional states difficult. This study explored the inactive and signal-activated conformational states of the two catalytic domains of sensor histidine kinases, HisKA and HATPase. Direct coupling analyses, a global statistical inference approach, was applied to > 13,000 such domains from protein databases to identify residue contacts between the two domains. These contacts guided structural assembly of the domains using MAGMA, an advanced molecular dynamics docking method. The active conformation structure generated by MAGMA simultaneously accommodated the sequence derived residue contacts and the ATP-catalytic histidine contact. The validity of this structure was confirmed biologically by mutation of contact positions in the Bacillus subtilis sensor histidine kinase KinA and by restoration of activity in an inactive KinA(HisKA): KinD(HATPase) hybrid protein. These data indicate that signals binding to sensor domains activate sensor histidine kinases by causing localized strain and unwinding at the end of the C-terminal helix of the HisKA domain. This destabilizes the contact positions of the inactive conformation of the two domains, identified by previous crystal structure analyses and by the sequence analysis described here, inducing the formation of the active conformation. This study reveals that structures of unstable transient complexes of interacting proteins and of protein domains are accessible by applying this combination of cross-validating technologies.']",https://hal.science/hal-01528442,['0.sdv']
"['Wenlu Yang', 'Maria Rifqi', 'Christophe Marsala', 'Andrea Pinna']","[1031724, 754, 8248, 955698]","['maria-rifqi', 'christophe-marsala']",Towards Better Understanding of Player's Game Experience,hal-01784787,2018,10.1145/3206025.3206072,"['CCS CONCEPTS • General and reference → Empirical studies', 'Experimenta- tion', '• Applied computing → Computer games', '• Human- centered computing → User models', 'KEYWORDS User experience research', 'Game experience', 'Affective gaming', 'Phys- iological signal', 'Game events', 'Machine learning', 'Interpretability', 'CCS CONCEPTS • General and reference → Empirical studies']","[""Improving player's game experience has always been the common goal of video game practitioner. In order to get a better understanding of player's perception of game experience, we carry out experimental study for data collection and present game experience prediction model based on machine learning method. The model is trained on the proposed multi-modal database which contains: physiological modality, behavioral modality and meta-information to predict the player game experience in terms of difficulty, immersion and amusement. By investigating the model trained on separate and fusion feature sets, we show that physiological modality is effective. Moreover, better understanding is achieved with further analysis on the most relevant features in the behavioral and meta-information features set. We argue that combining the physiological modalities with behavioral and meta information can provide a better performance on the game experience prediction.""]",https://hal.sorbonne-universite.fr/hal-01784787,"['0.info', '0.info', '1.info.info-ai']"
"['Chen Chen', 'Xue Liu', 'Adrien Ugon', 'Xun Zhang', 'Amara Amara', 'Patrick Garda', 'Jean-Gabriel Ganascia', 'Carole Philippe', 'Andrea Pinna']","[10474, 184904, 955698]","['chen-chen', 'xun-zhang']",Symbolic Fusion: A Novel Decision Support Algorithm for Sleep Staging Application,hal-01315584,2015,10.4108/eai.14-10-2015.2261933,"['Symbolic Fusion', 'Decision support', 'Sleep staging', 'Polysomnography PSG']","['With the rapid extension of clinical data and knowledge, decision making becomes a complex task for manual sleep staging. In this process, there is a need for integrating and analyzing information from heterogeneous data sources with high accuracy. This paper proposes a novel decision support algorithm—Symbolic Fusion for sleep staging application. The proposed algorithm provides high accuracy by combining data from heterogeneous sources, like EEG, EOG and EMG. This algorithm is developed for implementation in portable embedded systems for automatic sleep staging at low complexity and cost. The proposed algorithm proved to be an efficient design support method and achieved up to 76% overall agreement rate on our database of 12 patients.']",https://hal.sorbonne-universite.fr/hal-01315584,"['0.info', '1.info.info-ai', '0.info', '1.info.info-bi']"
"['Juan S. Silva', 'Aymeric Histace', 'Olivier Romain', 'Xavier Dray', 'Bertrand Granado']","[1028, 4376, 934208, 9619]","['aymeric-histace', 'romain-etis', 'bertrand-granado']",Towards embedded detection of polyps in WCE images for early diagnosis of colorectal cancer,hal-00843459,2014,10.1007/s11548-013-0926-3,"['Boosting', 'Co-occurence matrix Hardware implementation', 'Videoendoscopy', 'WCE', 'Polyp', 'Colorectal cancer']","[""Purpose: Wireless capsule endoscopy (WCE) is commonly used for noninvasive gas- trointestinal tract evaluation, including the detection of mucosal polyps. A new embed- dable method for polyp detection in wireless capsule endoscopic images was developed and tested. Methods: First, possible polyps within the image were extracted using geometric shape features. Next, the candidate regions of interest were evaluated with a boosting-based method using textural features. Each step was carefully chosen to accommodate hard- ware implementation constraints. The method's performance was evaluated on WCE datasets including 300 images with polyps and 1200 images without polyps. Hardware implementation of the proposed approach was evaluated to quantitatively demonstrate the feasibility of such integration into the WCE itself. Results: The boosting-based polyp classi cation demonstrated a sensitivity of 91.0%, a speci city of 95.2% and a false detection rate of 4.8%. This performance is close to that reported recently in systems developed for an on-line analysis of video colonoscopy images. Conclusion: A new method for polyp detection in videoendoscopic WCE examinations was developed using boosting-based approach. This method achieved good classi ca- tion performance and can be implemented in situ with embedded hardware.""]",https://hal.science/hal-00843459,"['0.spi', '1.spi.tron', '0.spi', '1.spi.signal', '0.info', '1.info.info-ts', '0.sdv', '1.sdv.ib', '0.info', '1.info.info-ti']"
"['Laurent Rodriguez', 'Benoit Miramond', 'Bertrand Granado']","[5099, 1514, 9619]","['laurent-rodriguez', 'benoitmiramond', 'bertrand-granado']",Toward a sparse self-organizing map for neuromorphic architectures,hal-01103430,2015,10.1145/2638559,"['Hardware architectures', 'Cortical plasticity', 'Neuromorphic architectures', 'Self-organizing maps']","['Neuro-biological systems have often been a source of inspiration for computational science and engineering, but in the past their impact has also been limited by the understanding of biological models. Today, new technologies lead to an equilibrium situation where powerful and complex computers bring new biological knowledge of the brain behavior. At this point, we possess sufﬁcient understanding to both imagine new brain-inspired computing paradigms and to sustain a classical paradigm which reaches its end program- ming and intellectual limitations. In this context we propose to reconsider the computation problem ﬁrst in the speciﬁc domain of mobile robotics. Our main proposal consists in considering computation as part of a global adaptive system, com- posed of sensors, actuators, a source of energy and a controlling unit. During the adaptation process, the proposed brain-inspired computing structure does not only execute the tasks of the application but also re- acts to the external stimulation and acts on the emergent behavior of the system. This approach is inspired by cortical plasticity in mammalian brains and suggests developing the computation architecture along the system’s experience. This paper proposes modeling this plasticity as a problem of estimating a probability density function. This function would correspond to the nature and the richness of the environment perceived through multiple modalities. We deﬁne and develop a novel neural model solving the problem in a distributed and sparse manner. And we integrate this neural map into a bio-inspired hardware substrate that brings the plasticity property into parallel many-core architectures. The approach is then called Hardware Plasticity. The results show that the self-organization properties of our model solve the problem of multimodal sensory data clusterization. The properties of the proposed model allow envisaging the deployment of this adaptation layer into hardware architectures embedded into the robot’s body in order to build intelligent controllers.']",https://hal.science/hal-01103430,"['0.info', '1.info.info-ne', '0.info', '1.info.info-ar', '0.spi', '1.spi.nano']"
"['Eric Angel', 'Evripidis Bampis', 'Vincent Chau']","[855946, 855947, 931462]",,Low complexity scheduling algorithms minimizing the energy for tasks with agreeable deadlines,hal-01006549,2014,10.1016/j.dam.2014.05.023,"['Identical processors', 'Power management', 'Scheduling', 'Unit tasks']","['Power management aims in reducing the energy consumed by computer systems while maintaining a good level of performance. One of the mechanisms used to save energy is the shut-down mechanism which puts the system into a sleep state when it is idle. No energy is consumed in this state, but a fixed amount of energy is required for a transition from the sleep state to the active state which is equal to L times the energy required for the execution of a unit-time task. In this paper, we focus on the off-line version of this problem where a set of unit-time tasks with release dates and deadlines have to be scheduled in order to minimize the overall consumed energy during the idle periods of the schedule. Here we focus on the case where the tasks have agreeable deadlines. For the single processor case, an O (n3) algorithm has been proposed in Gururaj et al. (2010) for unit-time tasks and arbitrary L. We improve this result by introducing a new O (n2) polynomial-time algorithm for tasks with arbitrary processing times and arbitrary L. For the multiprocessor case we also improve the complexity from O (n3 m2) Gururaj et al. (2010) to O (n2 m) in the case of unit-time tasks and unit L.']",https://hal.science/hal-01006549,"['0.info', '1.info.info-ro']"
"['Francois Bonnet', 'Xavier Défago', 'Thanh Dang Nguyen', 'Maria Potop-Butucaru']",[833381],,Tight bound on mobile Byzantine Agreement,hal-01340236,2016,10.1016/j.tcs.2015.10.019,"['Distributed agreement', 'Mobile byzantine faults']","[""This paper investigates the problem of Byzantine Agreement in a synchronous system where malicious agents can move from process to process, corrupting their host. Earlier works on the problem are based on biased models which, as we argue in the paper, give an unfair advantage either to the correct processes or to the adversary controlling the malicious agents. Indeed, earlier studies of the problem assume that, after a malicious agent has left a process, that process, said to be cured, is able to instantly and accurately detect the fact that it was corrupted in earlier rounds, and thus can take local actions to recover a valid state (Garay's model). We found no justification for that assumption which clearly favors correct processes. Under that model, an algorithm is known for n>4t, where n is the number of processes and t the maximum number of malicious agents. The tightness of the bound is however unknown. In contrast, more recent works on the problem remove the assumption on detection and assume instead that a malicious agent may have left corrupted messages in the send queue of a cured process in addition to a corrupted state. As a result, the adversary controlling the malicious agents can corrupt the messages sent by cured processes, in addition to those sent by the newly corrupted ones, thus doubling the number of effective faults. Under that model, which favors the malicious agents, the problem can be solved if and only if n>6t. In this paper, we refine the latter model to avoid the above biases. While a cured process may send messages (based on a state corrupted by the malicious agent), it will behave correctly in the way it sends those messages: i.e., send messages according to the algorithm. Surprisingly, in this model we could derive a new non-trivial tight bound for Byzantine Agreement. We prove that at least 5t+1 processors are needed in order to tolerate t mobile Byzantine agents and provide a time optimal algorithm that matches this lower bound, altogether with a formal specification of the problem.""]",https://hal.science/hal-01340236,"['0.info', '0.info', '1.info.info-dc']"
"['Tiphaine Viard', 'Matthieu Latapy', 'Clémence Magnien']","[4259, 749042, 9355]","['tiphaine-viard', 'matthieu-latapy', 'clemence-magnien']","Computing maximal cliques in link streams, Calcul de cliques maximales dans les flots de liens",hal-01112627,2016,10.1016/j.tcs.2015.09.030,"['Temporal networks', 'Link streams', 'Time-varying graphs', 'Graphs', 'Algorithms', 'Cliques']","['A link stream is a sequence of triplets $(t,u,v)$ indicating that an interaction occurred between $u$ and $v$ at time $t$. We generalize the classical notion of cliques in graphs to such link streams: for a given $\\Delta$, a $\\Delta$-clique is a set of nodes and a time interval such that all pairs of nodes in this set interact at least every $\\Delta$ during this time interval. We propose an algorithm to enumerate all maximal cliques of a link stream, and illustrate its practical relevance on a real-world contact trace.']",https://hal.science/hal-01112627v5,"['0.info', '1.info.info-ds', '0.info', '1.info.info-oh']"
"['Tiphaine Viard', 'Clémence Magnien', 'Matthieu Latapy']","[4259, 9355, 749042]","['tiphaine-viard', 'clemence-magnien', 'matthieu-latapy']",Enumerating maximal cliques in link streams with durations,hal-02085259,2018,10.1016/j.ipl.2018.01.006,"['Time-varying graphs', 'Temporal networks', 'Link streams', 'Cliques', 'Graphs', 'Algorithms']","['Link streams model interactions over time, and a clique in a link stream is defined as a set of nodes and a time interval such that all pairs of nodes in this set interact permanently during this time interval. This notion was introduced recently in the case where interactions are instantaneous. We generalize it to the case of interactions with durations and show that the instantaneous case actually is a particular case of the case with durations. We propose an algorithm to detect maximal cliques that improves our previous one for instantaneous link streams, and performs better than the state of the art algorithms in several cases of interest.']",https://hal.science/hal-02085259,"['0.info', '0.info', '1.info.info-si', '0.info', '1.info.info-ni']"
"['Bruno Escoffier', 'Olivier Spanjaard', 'Magdaléna Tydrichová']","[5124, 14601, 1356552]","['brunoescoffier', 'olivier-spanjaard']",Recognizing single-peaked preferences on an arbitrary graph: Complexity and algorithms,hal-04475674,2024,10.1016/j.dam.2024.02.009,"['Structured preferences', 'Single-peaked preferences']","['We study in this paper single-peakedness on arbitrary graphs. Given a collection of preferences (rankings of alternatives), we aim to determine a connected graph on which the preferences are single-peaked, in the sense that all the preferences are traversals of $G$. Note that a collection of preferences is always single-peaked on the complete graph. We propose an Integer Linear Programming formulation (ILP) of the problem of minimizing the number of edges in $G$ or the maximum degree of a vertex in $G$. We prove that both problems are NP-hard in the general case. However, we show that if the optimal number of edges is $m-1$ (where $m$ is the number of candidates) then any optimal extreme point solution of the continuous relaxation of the ILP is integer and thus the integrality constraints can be relaxed. This provides an alternative proof of the polynomial time complexity of recognizing single-peaked preferences on a tree. We prove the same result for the case of a path (an axis), providing here also an alternative proof of polynomiality of the recognition problem. Furthermore, we provide a polynomial time procedure to recognize single-peaked preferences on a pseudotree (a connected graph that contains at most one cycle). We also give some experimental results, both on real and synthetic datasets.']",https://hal.science/hal-04475674,"['0.info', '1.info.info-ai', '0.info', '1.info.info-cc', '0.info', '1.info.info-ds']"
"['Hugo Gilbert', 'Olivier Spanjaard']","[971449, 14601]",['olivier-spanjaard'],A double oracle approach to minmax regret optimization problems with interval data,hal-01525976,2017,10.1016/j.ejor.2017.04.058,"['Combinatorial optimization', 'Branch and bound', 'Minmax regret', 'Robust optimization', 'Robust shortest paths']","['In this paper, we provide a generic anytime lower bounding procedure for minmax regret optimization problems. We show that the lower bound obtained is always at least as accurate as the lower bound recently proposed by Chassein and Goerigk [3]. This lower bound can be viewed as the optimal value of a linear programming relaxation of a mixed integer programming formulation of minmax regret optimization, but the contribution of the paper is to compute this lower bound via a double oracle algorithm [10] that we specify. The double oracle algorithm is designed by relying on a game theoretic view of robust optimization, similar to the one developed by Mastin et al. [9], and it can be efficiently implemented for any minmax regret optimization problem whose standard version is "" easy "". We describe how to efficiently embed this lower bound in a branch and bound procedure. Finally we apply our approach to the robust shortest path problem. Our numerical results show a significant gain in the computation times compared to previous approaches in the literature.']",https://hal.sorbonne-universite.fr/hal-01525976,"['0.info', '1.info.info-ro']"
"['Spyros Angelopoulos', 'Diogo Arsénio', 'Christoph Dürr']","[738275, 1000124, 5030]","['spyros-angelopoulos', 'christoph-durr']",Infinite linear programming and online searching with turn cost,hal-01452876,2017,10.1016/j.tcs.2017.01.013,"['Search and exploration problems', 'Infinite linear programming', 'Competitive analysis of online algorithms']","['We consider the problem of searching for a hidden target in an environment that consists of a set of concurrent rays. Every time the searcher turns direction , it incurs a fixed cost. The objective is to derive a search strategy for locating the target as efficiently as possible, and the performance of the strategy is evaluated by means of the well-established competitive ratio. In this paper we revisit an approach due to Demaine et al. [TCS 2006] based on infinite linear-programming formulations of this problem. We first demonstrate that their definition of duality in infinite LPs can lead to erroneous results. We then provide a non-trivial correction which establishes the optimality of a certain round-robin search strategy.']",https://hal.sorbonne-universite.fr/hal-01452876,['0.info']
"['Andrés Sanoja', 'Stéphane Gançarski']","[934855, 13308]",['stephane-gancarski'],Web page segmentation evaluation,hal-01500681,2015,10.1145/2695664.2695786,"['Web page segmentation', ""Evaluation métrique d'évaluation""]","['In this paper, we present a framework for evaluating segmentation algorithms for Web pages. Web page segmentation consists in dividing a Web page into coherent fragments, called blocks. Each block represents one distinct information element in the page. We define an evaluation model that includes different metrics to evaluate the quality of a segmentation obtained with a given algorithm. Those metrics compute the distance between the obtained segmentation and a manually built segmentation that serves as a ground truth. We apply our framework to four state-of-the-art segmentation algorithms (BOM, Block Fusion, VIPS and JVIPS) on several categories (types) of Web pages. Results show that the tested algorithms usually perform rather well for text extraction, but may have serious problems for the extraction of geometry. They also show that the relative quality of a segmentation algorithm depends on the category of the segmented page.']",https://hal.science/hal-01500681,"['0.info', '1.info.info-wb', '0.info', '1.info.info-db']"
"['Fatima Harrak', 'François Bouchet', 'Vanda Luengo']","[1008587, 9857, 13359]","['fbouchet', 'vanda-luengo']",From Student Questions to Student Profiles in a Blended Learning Environment,hal-02100131,2019,10.18608/jla.2019.61.4,"['Question coding scheme', 'Clustering', 'Student behaviour', 'Blended learning']","[""The analysis of student questions can be used to improve the learning experience for both students and teachers. We investigated questions (N = 6457) asked before the class by first-year medicine/pharmacy students on an online platform, used by professors to prepare for Q&A sessions. Our long-term objectives are to help professors in categorizing those questions, and to provide students with feedback on the quality of their questions. To do so, we developed a coding scheme and then used it for automatic annotation of the whole corpus. We identified student characteristics from the typology of questions they asked using the k-means algorithm over four courses. Students were clustered based on question dimensions only. Then, we characterized the clusters by attributes not used for clustering, such as student grade, attendance, and number and popularity of questions asked. Two similar clusters always appeared (lower than average students with popular questions, and higher than average students with unpopular questions). We replicated these analyses on the same courses across different years to show the possibility of predicting student profiles online. This work shows the usefulness and validity of our coding scheme and the relevance of this approach to identify different student profiles. Notes for Practice • Questions provide important insights into students' level of knowledge, but coding schemes are lacking to study this phenomenon. • After providing a bottom-up coding scheme of student questions in a blended environment, we analyzed the relationship between the questions asked and the student profiles. • Profiling students based on their questions over a year allows us to predict the profiles of future students to help the teacher understand who asks what. • These results provide both a coding scheme that can be reused in various contexts involving questions, and a methodology that can be replicated in any context where students ask many questions, in particular to help the teacher in prioritizing them according to their own criteria. • Teachers need to focus on the nature of questions asked by their students, because they can reveal information about their profile (attendance, activity, etc.).""]",https://hal.science/hal-02100131,"['0.info', '1.info.eiah']"
"['Mélina Verger', 'Chunyang Fan', 'Sébastien Lallé', 'François Bouchet', 'Vanda Luengo']",,,A Comprehensive Study on Evaluating and Mitigating Algorithmic Unfairness with the MADD Metric,hal-04633868,2024,10.5281/zenodo.12180668,"['Fairness metric', 'Unfairness mitigation', 'Classification', 'Student modeling', 'Models’ behaviors', 'Sensitive features']","['Predictive student models are increasingly used in learning environments due to their ability to enhance educational outcomes and support stakeholders in making informed decisions. However, predictive models can be biased and produce unfair outcomes, leading to potential discrimination against certain individuals and harmful long-term implications. This has prompted research on fairness metrics meant to capture and quantify such biases. Nonetheless, current metrics primarily focus on predictive performance comparisons between groups, without considering the behavior of the models or the severity of the biases in the outcomes. To address this gap, we proposed a novel metric in a previous work (Verger et al., 2023) named Model Absolute Density Distance (MADD), measuring algorithmic unfairness as the difference of the probability distributions of the model’s outcomes. In this paper, we extended our previous work with two major additions. Firstly, we provided theoretical and practical considerations on a hyperparameter of MADD, named bandwidth, useful for optimal measurement of fairness with this metric. Secondly, we demonstrated how MADD can be used not only to measure unfairness but also to mitigate it through postprocessing of the model’s outcomes while preserving its accuracy. We experimented with our approach on the same task of predicting student success in online courses as our previous work, and obtained successful results. To facilitate replication and future usages of MADD in different contexts, we developed an open-source Python package called maddlib (https://pypi.org/project/maddlib/). Altogether, our work contributes to advancing the research on fair student models in education.']",https://hal.science/hal-04633868,"['0.info', '1.info.eiah', '0.info', '1.info.info-ai', '0.info', '1.info.info-cy']"
"['Francis Jambon', 'Vanda Luengo']","[172997, 13359]","['francis-jambon', 'vanda-luengo']","Analyse oculométrique ""on-line "" avec zones d'intérêt dynamiques : application aux environnements d'apprentissage sur simulateur",hal-00873898,2012,10.1145/2652574.2653401,"['Analyse on-line', 'Oculométrie']","[""L'analyse oculométrique permet l'indentification des informations prises en compte visuellement par un utilisateur. C'est une approche aujourd'hui connue et éprouvée. Or, pour certains domaines d'application, notamment celui des environnements d'apprentissage sur simulateur, cette analyse doit avoir lieu en cours d'activité, et en s'appuyant sur des zones d'intérêt qui évoluent de manière opportuniste au cours du temps. Ces aspects ne sont pas pris en compte par les approches actuelles. C'est pourquoi nous proposons une nouvelle approche, de nouveaux algorithmes d'analyse et une chaîne d'acquisition permettant de répondre de manière générique à cette limitation. Nous avons mis en øeuvre cette approche sur deux exemples issus du domaine de l'apprentissage sur simulateur.""]",https://hal.science/hal-00873898,"['0.info', '1.info.eiah', '0.shs', '1.shs.edu']"
"['Vanda Luengo', 'Lucile Vadcard', 'Jêrome Tonetti', 'Michel Dubois']","[13359, 1164486]",['vanda-luengo'],Diagnostic des connaissances et rétroaction épistémique adaptative en chirurgie,hal-00911388,2011,10.3166/ria.25.499-524,"['Diagnosis', 'Feedback', 'Bayesian network', 'Decisional systems', 'Orthopaedic surgery', 'Diagnostic', 'Rétroaction adaptative', 'Réseaux bayésiens', 'Système de décision', 'Apprentissage', 'Chirurgie orthopédique']","[""La recherche présentée porte sur la conception et l'évaluation des systèmes de diagnostic et de rétroaction adaptatifs et épistémiques. Le système a été développé dans le cadre du projet TELEOS (Technology Enhanced Learning in Orthopaedic Surgery), qui est un environnement d'apprentissage pour la chirurgie orthopédique. Dans cet article nous exposons le contexte général et les cadres théoriques, la méthode employée pour analyser l'expertise chirurgicale ainsi que les modèles et outils informatiques qui constituent l'environnement d'apprentissage. Nous présentons en particulier les méthodes et techniques d'intelligence artificielle utilisées dans le projet afin de calculer le diagnostic des connaissances et produire une rétroaction épistémique et adaptative."", 'The research question presented in this paper is about the design and evaluation of the diagnosis and feedback systems, which would be adapted and epistemic. The system was developed in TELEOS project framework, which is a Technological Enhanced Learning (TEL) environment for orthopaedic surgery. In this paper we present the general context and theoretical frameworks, the method used to analyze the surgical expertise as well as models and tools that constitute the learning environment. We present in particular the artificial intelligence methods and techniques used in the project to calculate the diagnosis and produce a feedback, which is epistemic and adaptive.']",https://hal.science/hal-00911388,"['0.info', '1.info.eiah', '0.shs', '1.shs.edu']"
"['Farouk Lemmouchi', 'Juan Cuesta', 'Mathieu Lachatre', 'Julien Brajard', 'Adriana Coman', 'Matthias Beekmann', 'Claude Derognat']","[1136147, 760138, 13461, 740641, 1304603]","['juan-cuesta', 'julien-brajard', 'matthias-beekmann']",Machine Learning-Based Improvement of Aerosol Optical Depth from CHIMERE Simulations Using MODIS Satellite Observations,hal-04274400,2023,10.3390/rs15061510,"['Saharan dust', 'Bodélé Depression', 'Bias correction', 'Machine learning', 'Aerosol optical depth', 'Chemistry transport model', 'Aerosols', 'Particulate matter', 'Mineral dust North African dust Saharan dust Bodélé Depression bias correction machine learning aerosol optical depth chemistry transport model aerosols particulate matter', 'Mineral dust', 'North African dust']","['We present a supervised machine learning (ML) approach to improve the accuracy of the regional horizontal distribution of the aerosol optical depth (AOD) simulated by the CHIMERE chemistry transport model over North Africa and the Arabian Peninsula using Moderate Resolution Imaging Spectroradiometer (MODIS) AOD satellite observations. Our method produces daily AOD maps with enhanced precision and full spatial domain coverage, which is particularly relevant for regions with a high aerosol abundance, such as the Sahara Desert, where there is a dramatic lack of ground-based measurements for validating chemistry transport simulations. We use satellite observations and some geophysical variables to train four popular regression models, namely multiple linear regression (MLR), random forests (RF), gradient boosting (XGB), and artificial neural networks (NN). We evaluate their performances against satellite and independent ground-based AOD observations. The results indicate that all models perform similarly, with RF exhibiting fewer spatial artifacts. While the regression slightly overcorrects extreme AODs, it remarkably reduces biases and absolute errors and significantly improves linear correlations with respect to the independent observations. We analyze a case study to illustrate the importance of the geophysical input variables and demonstrate the regional significance of some of them.']",https://cnrs.hal.science/hal-04274400,['0.sde']
"['Elizabeth Allman', 'Catherine Matias', 'John Rhodes']","[900618, 6516, 900619]",['catherinematias'],Parameter identifiability in a class of random graph mixture models,hal-00591197,2011,10.1016/j.jspi.2010.11.022,"['Identifiability', 'Mixture model', 'Random graph', 'Stochastic blockmodel']","['We prove identifiability of parameters for a broad class of random graph mixture models. These models are characterized by a partition of the set of graph nodes into latent (unobservable) groups. The connectivities between nodes are independent random variables when conditioned on the groups of the nodes being connected. In the binary random graph case, in which edges are either present or absent, these models are known as stochastic blockmodels and have been widely used in the social sciences and, more recently, in biology. Their generalizations to weighted random graphs, either in parametric or non-parametric form, are also of interest. Despite these many applications, the parameter identifiability issue for such models has only been touched upon in the literature. We give here a thorough investigation of this problem. Our work also has consequences for parameter estimation. In particular, the estimation procedure proposed by Frank and Harary for binary affiliation models is revisited in this article.']",https://hal.science/hal-00591197,"['0.math', '1.math.math-st', '0.stat', '1.stat.th']"
"['Francis Comets', 'Mikael Falconnet', 'Oleg Loukianov', 'Dasha Loukianova', 'Catherine Matias']","[955037, 856516, 858715, 858714, 6516]","['dasha-loukianova', 'catherinematias']",Maximum likelihood estimator consistency for a ballistic random walk in a parametric random environment,hal-02633373,2014,10.1016/j.spa.2013.08.002,"['Ballistic regime', 'Branching process in random environment', 'Maximum likelihood estimation', 'Random walk in random environment', 'Multitype branching-processe', 'Immigration']","['We consider a one dimensional ballistic random walk evolving in an i.i.d. parametric random environment. We provide a maximum likelihood estimation procedure of the parameters based on a single observation of the path till the time it reaches a distant site, and prove that the estimator is consistent as the distant site tends to infinity. Our main tool consists in using the link between random walks and branching processes in random environments and explicitly characterising the limiting distribution of the process that arises. We also explore the numerical performance of our estimation procedure.']",https://hal.inrae.fr/hal-02633373,"['0.math', '1.math.math-st']"
"['Marc Ohlmann', 'Catherine Matias', 'Giovanni Poggiato', 'Stéphane Dray', 'Wilfried Thuiller', 'Vincent Miele']","[6516, 1091595, 21636, 184825, 178373]","['catherinematias', 'stephane-dray', 'wilfried-thuiller', 'vincent-miele']",Quantifying the overall effect of biotic interactions on species distributions along environmental gradients,hal-03172480,2023,10.1016/j.ecolmodel.2023.110424,"['Biodiversity patterns', 'C-score', 'Species co-occurrence', 'Metanetwork', 'Markov random fields', 'Environmental niche']","['Separating environmental effects from those of interspecific interactions on species distributions has always been a central objective of community ecology. Despite years of effort in analysing patterns of species co-occurrences and the developments of sophisticated tools, we are still unable to address this major objective. A key reason is that the wealth of ecological knowledge is not sufficiently harnessed in current statistical models, notably the knowledge on interspecific interactions. Here, we develop ELGRIN, a statistical model that simultaneously combines knowledge on interspecific interactions (i.e., the metanetwork), environmental data and species occurrences to tease apart their relative effects on species distributions. Instead of focusing on single effects of pairwise species interactions, which have little sense in complex communities, ELGRIN contrasts the overall effect of species interactions to that of the environment. Using various simulated and empirical data, we demonstrate the suitability of ELGRIN to address the objectives for various types of interspecific interactions like mutualism, competition and trophic interactions. We then apply the model on vertebrate trophic networks in the European Alps to map the effect of biotic interactions on species distributions. Data on ecological networks are everyday increasing and we believe the time is ripe to mobilize these data to better understand biodiversity patterns. ELGRIN provides this opportunity to unravel how interspecific interactions actually influence species distributions.']",https://hal.science/hal-03172480v4,"['0.sde', '1.sde.be', '0.sde', '1.sde.mcg', '0.sdv', '1.sdv.bid', '0.stat', '1.stat.me']"
"['Anna Bonnet', 'Miguel Martinez Herrera', 'Maxime Sangnier']","[1133289, 1133290, 1133291]",,Inference of multivariate exponential Hawkes processes with inhibition and application to neuronal activity,hal-03652497,2023,10.1007/s11222-023-10264-w,"['Non-linear Hawkes process', 'Point process', 'Maximum likelihood estimation', 'Goodness-of-fit', 'Identifiability', 'Support recovery']","['The multivariate Hawkes process is a past-dependent point process used to model the relationship of event occurrences between different phenomena. Although the Hawkes process was originally introduced to describe excitation effects, which means that one event increases the chances of another occurring, there has been a growing interest in modelling the opposite effect, known as inhibition. In this paper, we focus on how to infer the parameters of a multidimensional exponential Hawkes process with both excitation and inhibition effects. Our first result is to prove the identifiability of this model under a few sufficient assumptions. Then we propose a maximum likelihood approach to estimate the interaction functions, which is, to the best of our knowledge, the first exact inference procedure in the frequentist framework. Our method includes a variable selection step in order to recover the support of interactions and therefore to infer the connectivity graph. A benefit of our method is to provide an explicit computation of the log-likelihood, which enables in addition to perform a goodness-of-fit test for assessing the quality of estimations. We compare our method to standard approaches, which were developed in the linear framework and are not specifically designed for handling inhibiting effects. We show that the proposed estimator performs better on synthetic data than alternative approaches. We also illustrate the application of our procedure to a neuronal activity dataset, which highlights the presence of both exciting and inhibiting effects between neurons.']",https://hal.science/hal-03652497v5,"['0.stat', '1.stat.me']"
"['Jean-David Fermanian', 'Olivier Lopez']",[21529],['olopezclermont'],Single-index copulas,hal-01700864,2018,10.1016/j.jmva.2017.11.004,"['Conditional copulas', ""Conditional Kendall's tau"", 'Kernel smoothing', 'Single-index models']","[""We introduce so-called single-index copulas. They are semi-parametric conditional copulas whose parameter is an unknown link function of a univariate index only. We propose estimates of this link function and of the finite-dimensional unknown parameter. The asymptotic properties of the latter estimates are stated. Thanks to some properties of conditional Kendall's tau, we illustrate our technical conditions with several usual copula families.""]",https://hal.sorbonne-universite.fr/hal-01700864,['0.phys']
"['Thierry Dufour', 'Johan Minnebo', 'Sami Abou Rich', 'E.C. Neyts', 'A Bogaerts', 'F Reniers']",[8227],['thierry-dufour'],"Understanding polyethylene surface functionalization by an atmospheric He/O2 plasma through combined experiments and simulations, Comprendre la fonctionnalisation de la surface du polyéthylène par un plasma atmosphérique He/O2 grâce à des expériences et des simulations combinées",hal-01303181,2014,10.1088/0022-3727/47/22/224007,"['ARXPS', 'Nudged elastic band simulations', 'He/O2 plasma treatment', 'Molecular dynamics simulations', 'Polyethylene surface functionalization']","['High density polyethylene surfaces were exposed to the atmospheric post-discharge of a radiofrequency plasma torch supplied in helium and oxygen. Dynamic water contact angle measurements were performed to evaluate changes in surface hydrophilicity and angle resolved x-ray photoelectron spectroscopy was carried out to identify the functional groups responsible for wettability changes and to study their subsurface depth profiles, up to 9 nm in depth. The reactions leading to the formation of C–O, C=O and O–C=O groups were simulated by molecular dynamics. These simulations demonstrate that impinging oxygen atoms do not react immediately upon impact but rather remain at or close to the surface before eventually reacting. The simulations also explain the release of gaseous species in the ambient environment as well as the ejection of low molecular weight oxidized materials from the surface.', ""Des surfaces de polyéthylène haute densité ont été exposées à la post-décharge atmosphérique d'une torche à plasma radiofréquence alimentée en hélium et en oxygène. Des mesures dynamiques de l'angle de contact avec l'eau ont été effectuées pour évaluer les changements dans l'hydrophilie de la surface et la spectroscopie photoélectronique à rayons X résolue en angle a été réalisée pour identifier les groupes fonctionnels responsables des changements de mouillabilité et pour étudier leurs profils de profondeur sous la surface, jusqu'à 9 nm de profondeur. Les réactions conduisant à la formation des groupes C-O, C=O et O-C=O ont été simulées par dynamique moléculaire. Ces simulations démontrent que les atomes d'oxygène ne réagissent pas immédiatement à l'impact mais restent plutôt à la surface ou à proximité de celle-ci avant de réagir. Les simulations expliquent également la libération d'espèces gazeuses dans l'environnement ambiant ainsi que l'éjection de matériaux oxydés de faible poids moléculaire de la surface.""]",https://hal.sorbonne-universite.fr/hal-01303181v2,"['0.chim', '0.chim', '1.chim.poly', '0.phys', '1.phys.phys', '2.phys.phys.phys-plasm-ph', '0.spi', '1.spi.plasma']"
"['Florian Judée', 'J Vaquero', 'S. Guégan', 'L Fouassier', 'Thierry Dufour']","[1064301, 1109265, 8227]",['thierry-dufour'],Atmospheric pressure plasma jets applied to cancerology: correlating electrical configuration with in vivo toxicity and therapeutic efficiency,hal-02188633,2019,10.1088/1361-6463/ab0fbb,"['Plasmas for in vivo model', 'Solid tumor', 'Plasma gun', 'Plasma Tesla jet', 'Nano pulse discharge', 'Cancer', 'Plasmas for in vivo model']","['Two atmospheric pressure plasma jet (APPJ) devices-a plasma gun and a plasma Tesla jet-are compared in terms of safety and therapeutic efficiency to reduce the tumor volume progression of cholangiocarcinoma, i.e. a rare and very aggressive cancer emerging in biliary tree. For this, a three steps methodology is carried out. First, the two APPJ have been benchmarked in regard to their electrical and physico-chemical properties while interacting with material targets: dielectric plate, liquid sample, metal plate and an equivalent electrical circuit of human body. The propagation properties of the ionization wave interacting with these targets are discussed, in particular the profile of the related pulsed atmospheric plasma streams. In a second step, a dermal toxicity survey is performed so as to define an experimental operating window where plasma parameters can be changed without damaging healthy skin of mice during their exposure to plasma and without inducing any electrical hazards (burnings, ventricular fibrillation). Optimal conditions are identified discarding the conditions where slight alterations may be evidenced by histology (e.g. prenecrotic aspect of keratinocytes, alterations in the collagen structure). Hence, for the two APPJ plasma parameters these conditions are as follow: duty cycle = 14%, repetition frequency = 30 kHz, magnitude = 7 kV, gap = 10 mm and exposure time = 1 min. In a third step, the two plasma jets are utilized on cholangiocarcinoma xenograft tumor model developed in immunodeficient mice. The two devices are safe and a significant therapeutic efficiency is demonstrated with the plasma Tesla. In conclusion, we have developed a safe cold atmospheric plasma device with antitumoral properties in preclinical model of cholangiocarcinoma, opening the path for new anticancer treatment opportunities.']",https://hal.sorbonne-universite.fr/hal-02188633,['0.phys']
"['Anna Palmé', 'Qiao Su', 'Anja Rautenberg', 'Franz Manni', 'Martin Lascoux']","[744281, 776779]",['franz-manni'],"Postglacial recolonization and cpDNA variation of silver birch, Betula pendula",hal-03183398,2003,10.1046/j.1365-294x.2003.01724.x,"['Betula', 'Chloroplast', 'Genetic boundaries', 'Glacial refugia', 'Last glacial maximum', 'Phylogeography']","['Chloroplast PCR‐RFLP markers were used to reconstruct the history of the silver birch, Betula pendula Roth, in Europe since the last glacial maximum (LGM). In birch, fossil pollen maps do not reveal a clear chronological sequence of postglacial spread. If anything, the pollen record suggests that most of Europe was recolonized by birches as early as 10 000 bp, probably from populations that remained close to the ice sheets during the LGM. The geographical distribution of haplotypes supports a scenario of early colonization. Two of the 13 haplotypes that were observed are common, representing 35% and 49% of the total sample, respectively. Although one of the common haplotypes is predominant in the NW and the other in the SE, both are present throughout most of the investigated geographical area. Rare haplotypes are geographically restricted. The distribution of the haplotypes reveals five genetic boundaries between groups of haplotypes and allows us to infer patterns of postglacial recolonization. Europe was re‐occupied by two main waves of recolonization: one eastern and one western, with origins at intermediate latitudes. Populations in the Iberian Peninsula and in Italy did not take part in the postglacial recolonization of Europe.']",https://hal.science/hal-03183398,"['0.sdv', '1.sdv.gen', '2.sdv.gen.gpo']"
"['Andrea Frosini', 'William L Kocay', 'Giulia Palma', 'Lama Tarsissi']","[1085548, 1085549, 1085550, 22086]",['lama-tarsissi'],On Null 3-Hypergraphs,hal-03058519,2021,10.1016/j.dam.2020.10.020,"['3-hypergraph', 'Null labelling', 'Null hypergraph', 'NP-complete', 'Self-complementary']","['Given a 3-uniform hypergraph H consisting of a set V of vertices, and T ⊆ V 3 triples, a null labelling is an assignment of ±1 to the triples such that each vertex is contained in an equal number of triples labelled +1 and −1. Thus, the signed degree of each vertex is zero. A necessary condition for a null labelling is that the degree of every vertex of H is even. The Null Labelling Problem is to determine whether H has a null labelling. It is proved that this problem is NP-complete. Computer enumerations suggest that most hypergraphs which satisfy the necessary condition do have a null labelling. Some constructions are given which produce hypergraphs satisfying the necessary condition, but which do not have a null labelling. A self complementary 3-hypergraph with this property is also constructed.']",https://hal.science/hal-03058519,"['0.info', '0.info', '1.info.info-dm']"
"['Fatiha Tali', 'Lucie Loubère', 'Christiana Charalampopoulou', 'Jean-François Desbiens', 'Marie-Hélène Abel', 'Jean-François Céci']","[12434, 181045, 8329, 16567]","['fatiha-tali', 'lucie-loubere', 'marie-helene-abel', 'jean-francois-ceci']","L’auto-efficacité des enseignantes et enseignants du supérieur à enseigner avec le numérique, de la période Covid à nos jours, Higher education teachers’ self-efficacy in teaching with digital technology, from the Covid period to the present day",hal-04634520,2024,10.4000/11ulw,"['Self-efficacy', 'Remote teaching', 'Digital technology', 'Pandemic', 'Teaching practices', 'Higher education', 'Auto-efficacité', 'Enseignement à distance', 'Usage du numérique', 'Pandémie', 'Pratiques enseignantes', 'Enseignement supérieur']","['Avec la pandémie causée par la Covid-19, l’usage du numérique s’est imposé et traduit par des pratiques très diversifiées dans le contexte de l’enseignement supérieur. Enseigner à distance suppose cependant que les personnes enseignantes (PE) détiennent des compétences techniques pour exploiter au mieux le numérique au service de leurs objectifs pédagogiques. Mobilisant la théorie sociocognitive de Bandura, cette étude utilise une enquête par questionnaire auprès de 290 PE pour valider une échelle d’auto efficacité à l’enseignement en ligne (AE) et examiner ses relations avec les attitudes, les pratiques d’enseignement à l’aide du numérique, ainsi que le sexe des répondants. Après validation de l’échelle unidimensionnelle, les résultats révèlent pour une AE élevée une corrélation positive et significative avec l’éventail d’outils mobilisés et des corrélations négatives (et significatives) avec les émotions et croyances négatives sur le numérique. L’étude identifie également une différence significative entre les sexes, les hommes ayant un niveau d’AE supérieur à celui des femmes, malgré une plus grande participation de ces dernières aux formations numériques. En conclusion, l’AE émerge comme un facteur déterminant pour l’adaptation des PE aux exigences du numérique en enseignement supérieur, soulignant l’importance des initiatives de formation pour renforcer ce dernier.', 'With the pandemic caused by Covid-19, the use of digital technologies has become imperative, resulting in highly diversified practices within the context of higher education. However, teaching remotely requires that instructors possess technical skills to effectively leverage digital tools to achieve their educational objectives. Drawing on Bandura’s social cognitive theory, this study employs a questionnaire survey of 290 instructors to validate a scale of self-efficacy in online teaching (SE) and to examine its relationships with attitudes, digital teaching practices, and the gender of respondents. After validating the unidimensional scale, the results reveal that a high SE is significantly correlated with a broader range of tools utilized and shows significant negative correlations with negative emotions and beliefs about digital technologies. The study also identifies a significant gender difference, with men exhibiting higher SE levels compared to women, despite the latter’s higher participation in digital training. In conclusion, SE emerges as a critical factor for instructors’ adaptation to the demands of digital technologies in higher education, highlighting the importance of training initiatives to enhance this aspect.']",https://hal.science/hal-04634520,"['0.shs', '1.shs.edu', '0.shs', '1.shs.psy']"
"['Ala Atrash', 'Marie-Hélène Abel', 'Claude Moulin', 'Nathalie Darène', 'Frédéric Huet', 'Sabine Bruaux']","[952294, 8329, 8386]","['marie-helene-abel', 'claude-moulin']",Note-taking as a main feature in a social networking platform for small and medium sized enterprises,hal-01121203,2015,10.1016/j.chb.2014.12.010,"['Collaboration organizational learning', 'Enterprise modeling', 'Ontology', 'Semantic modeling', 'Small and medium-sized enterprise']","[""Managing knowledge (especially tacit knowledge) in small and medium sized enterprises has always been a challenge. They have special characteristics that are related to their size, structure and their mem-bers' coordination and collaboration. Theses specifications affect the process of knowledge management in such enterprises. In addition, they suffer from the missing of codified and standardized supports. All these factors illustrate the urgent need to provide them with an appropriate knowledge management solution. In this paper, the special needs for knowledge management in this kind of enterprises is illustrated. The importance of an effective note-taking tool is justified. A semantic model that takes into account these needs is presented. In addition, we explain our choice of MEMORAe web platform as a tool for knowledge organization. We also clarify the functionalities which have been added to MEMORAe platform in order to be dedicated to these enterprises. Finally, the web platform is introduced.""]",https://hal.science/hal-01121203,"['0.info', '1.info.info-ai', '0.info', '1.info.info-wb', '0.shs', '1.shs.gestion']"
"['Hichem Omrani', 'Luminita Ion', 'Philippe Trigano', 'A. Awasthi']","[858688, 829522]",,A hybrid Approach for Evaluating Environmental Impacts for Urban Transportation Mode Sharing,hal-00367862,2009,10.3166/jds.18.185-201,"['AHP', 'Environmental impacts assessment', 'Car-sharing', 'Car-sharing']","['The current paper presents an AHP based approach for evaluating sustainable transport solution measures like car-sharing, park and ride, access control zones etc. In the first stage, we identify the indicators (criteria) for evaluating the transportation solution measure. These indicators (criteria) can be divided into several sub-indicators (sub-criteria). In the second stage, we allot weights to the indicators and sub-indicators using AHP. The values for the sub-indicators are measured using multiple sources and multiplied with their weights in order to compute state change variable values that form part of the city state equation. The respective values of the state change variables in the city state equation are then used to evaluate the efficiency of the transportation solution measure. Finally, we illustrate our approach by giving an example of car-sharing and measuring its impact on city environmental conditions.']",https://hal.science/hal-00367862,"['0.info', '1.info.info-se', '0.info', '1.info.info-ia', '0.info', '1.info.info-mm']"
"['Mohammed Azmi Al-Betar', 'Mohammed Awadallah', 'Raed Abu Zitar', 'Khaled Assaleh']",[1219307],,Economic load dispatch using memetic sine cosine algorithm,hal-03955361,2022,10.1007/s12652-022-03731-1,['Economic load dispatch Hybrid metaheuristics Sine cosine algorithm β -hill climbing optimizer Power systems'],"['In this paper, the economic load dispatch (ELD) problem which is an important problem in electrical engineering is tackled using a hybrid sine cosine algorithm (SCA) in a form of memetic technique. ELD is tackled by assigning a set of generation units with a minimum fuel costs to generate predefined load demand with accordance to a set of equality and inequality constraints. SCA is a recent population based optimizer turned towards the optimal solution using a mathematical-based model based on sine and cosine trigonometric functions. As other optimization methods, SCA has main shortcoming in exploitation process when a non-linear constraints problem like ELD is tackled. Therefore, β -hill climbing optimizer, a recent local search algorithm, is hybridized as a new operator in SCA to empower its exploitation capability to tackle ELD. The proposed hybrid algorithm is abbreviated as SCA-β HC which is evaluated using two sets of real-world generation cases: (i) 3-units, two versions of 13-units, and 40-units, with neglected Ramp Rate Limits and Prohibited Operating Zones constraints. (ii) 6-units and 15-units with Ramp Rate Limits and Prohibited Operating Zones constraints. The sensitivity analysis of the control parameters for SCA-β HC is initially studied. The results show that the performance of the SCA-β HC algorithm is increased by tuning its parameters in proper value. The comparative evaluation against several state-of-the-art methods show that the proposed method is able to produce new best results for some tested cases as well as the second-best for others. In a nutshell, hybridizing β HC optimizer as a new operator for SCA is very powerful algorithm for tackling ELD problems.']",https://hal.science/hal-03955361,"['0.info', '1.info.info-ai']"
